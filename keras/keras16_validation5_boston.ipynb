{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.3\n",
      "2.10.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bitcamp\\anaconda3\\envs\\tf27\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn as sk\n",
    "print(sk.__version__)\n",
    "print(tf.__version__)\n",
    "dataset = load_boston()\n",
    "x = dataset.data\n",
    "y = dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13)\n",
      "(506,)\n"
     ]
    }
   ],
   "source": [
    "# 13개의 칼럼 을 가지고있는 데이터를 조회합니다\n",
    "print(x.shape) #(506,13)\n",
    "# print(x)\n",
    "print(y.shape) #(506,)\n",
    "# print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CRIM' 'ZN' 'INDUS' 'CHAS' 'NOX' 'RM' 'AGE' 'DIS' 'RAD' 'TAX' 'PTRATIO'\n",
      " 'B' 'LSTAT']\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "# 사이킥 런의 칼럼 조회기능\n",
    "print(dataset.feature_names)\n",
    "print(len(dataset.feature_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _boston_dataset:\n",
      "\n",
      "Boston house prices dataset\n",
      "---------------------------\n",
      "\n",
      "**Data Set Characteristics:**  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of black people by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      ".. topic:: References\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 사이킥런의 데이터 요약\n",
    "print(dataset.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354\n",
      "152\n"
     ]
    }
   ],
   "source": [
    "# 3. 모델구성\n",
    "# 실습 train 0.7 이상\n",
    "# 평가지표 R2 : 0.8 이상으로 뽑아내보기 / RMSE 사용\n",
    "\n",
    "x_train, x_test,y_train,y_test = train_test_split(x,y,\n",
    "    train_size=0.7,\n",
    "    shuffle = True,\n",
    "    random_state= 123\n",
    ")\n",
    "\n",
    "print(len(x_train))\n",
    "print(len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randrange\n",
    "number1 = randrange(1,10,1)\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(10,input_dim = 13),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(1)\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from sklearn.metrics import r2_score\n",
    "now = datetime.now()\n",
    "\n",
    "model.compile(loss=\"mae\",optimizer=\"adam\")\n",
    "f = open(\"C:\\study\\keras\\\\boston.txt\",'a')\n",
    "while (True):\n",
    "    model.fit(x_train, y_train, epochs=100, batch_size=32, validation_split=0.25)\n",
    "    loss = model.evaluate(x_test,y_test)\n",
    "    print(\"loss : \",loss)\n",
    "    y_predict =model.predict(x_test)\n",
    "    print(\"=================\")\n",
    "    print(y_test)\n",
    "    print(y_predict)\n",
    "    print(\"=================\")\n",
    "    r2 = r2_score(y_test,y_predict)\n",
    "    print(\"R2 : \",r2)\n",
    "\n",
    "    f.write(str(datetime.now())+str(r2)+\"\\n\") \n",
    "    \n",
    "    if r2 >= 0.8 :\n",
    "        model.save(\"boston.h5\")\n",
    "        f.write(str(datetime.now())+str(r2)+\"\\n\") \n",
    "        f.close()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['model_weights', 'optimizer_weights']\n"
     ]
    }
   ],
   "source": [
    "# 저장된 모델 블러오기\n",
    "import h5py\n",
    "\n",
    "with h5py.File('boston.h5', 'r') as f:\n",
    "    print(list(f.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "load_model = load_model('boston.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 1ms/step - loss: 2.7756\n",
      "loss :  2.775620460510254\n",
      "5/5 [==============================] - 0s 997us/step\n",
      "=================\n",
      "[15.  26.6 45.4 20.8 34.9 21.9 28.7  7.2 20.  32.2 24.1 18.5 13.5 27.\n",
      " 23.1 18.9 24.5 43.1 19.8 13.8 15.6 50.  37.2 46.  50.  21.2 14.9 19.6\n",
      " 19.4 18.6 26.5 32.  10.9 20.  21.4 31.  25.  15.4 13.1 37.6 37.  18.9\n",
      " 27.9 50.  14.4 22.  19.9 21.6 15.6 15.  32.4 29.6 20.4 12.3 19.1 14.9\n",
      " 17.8  8.8 35.4 11.5 19.6 20.6 15.6 19.9 23.3 22.3 24.8 16.1 22.8 30.5\n",
      " 20.4 24.4 16.6 26.2 16.4 20.1 13.9 19.4 22.8 13.8 31.6 10.5 23.8 22.4\n",
      " 19.3 22.2 12.6 19.4 22.2 29.8  9.6 34.9 21.4 25.3 32.9 26.6 14.6 31.5\n",
      " 23.3 33.3 17.5 19.1 48.5 17.1 23.1 28.4 18.9 13.  17.2 24.1 18.5 21.8\n",
      " 13.3 23.  14.1 23.9 24.  17.2 21.5 19.1 20.8 36.  20.1  8.7 13.6 22.\n",
      " 22.2 21.1 13.4 17.4 20.1 10.2 23.1 10.2 13.1 14.3 14.5  7.2 19.6 20.6\n",
      " 22.7 26.4  7.5 20.3 50.   8.5 20.3 16.1 22.  19.6 10.2 23.2]\n",
      "[[13.90755  ]\n",
      " [27.860558 ]\n",
      " [44.572166 ]\n",
      " [21.441126 ]\n",
      " [28.376183 ]\n",
      " [29.093588 ]\n",
      " [29.783838 ]\n",
      " [10.085397 ]\n",
      " [17.839375 ]\n",
      " [26.11634  ]\n",
      " [24.753056 ]\n",
      " [21.255259 ]\n",
      " [13.560304 ]\n",
      " [30.884378 ]\n",
      " [22.043982 ]\n",
      " [20.767742 ]\n",
      " [22.15159  ]\n",
      " [38.03694  ]\n",
      " [20.729324 ]\n",
      " [16.62786  ]\n",
      " [15.062292 ]\n",
      " [24.7343   ]\n",
      " [37.940613 ]\n",
      " [49.975475 ]\n",
      " [48.936737 ]\n",
      " [24.354134 ]\n",
      " [20.76946  ]\n",
      " [22.789013 ]\n",
      " [23.226042 ]\n",
      " [16.1005   ]\n",
      " [23.628754 ]\n",
      " [36.100758 ]\n",
      " [11.701324 ]\n",
      " [21.207277 ]\n",
      " [22.41269  ]\n",
      " [30.632492 ]\n",
      " [25.263474 ]\n",
      " [14.572211 ]\n",
      " [14.705399 ]\n",
      " [46.31725  ]\n",
      " [30.115688 ]\n",
      " [20.129211 ]\n",
      " [20.303741 ]\n",
      " [52.574673 ]\n",
      " [19.001251 ]\n",
      " [24.895948 ]\n",
      " [22.288057 ]\n",
      " [23.407568 ]\n",
      " [17.527733 ]\n",
      " [19.399618 ]\n",
      " [39.19269  ]\n",
      " [21.346495 ]\n",
      " [22.36193  ]\n",
      " [12.376923 ]\n",
      " [19.183144 ]\n",
      " [17.731255 ]\n",
      " [13.890906 ]\n",
      " [ 7.732693 ]\n",
      " [33.797638 ]\n",
      " [13.0597515]\n",
      " [19.560863 ]\n",
      " [21.26727  ]\n",
      " [19.007828 ]\n",
      " [22.816525 ]\n",
      " [22.688766 ]\n",
      " [24.689764 ]\n",
      " [25.31958  ]\n",
      " [14.247009 ]\n",
      " [25.661726 ]\n",
      " [32.56245  ]\n",
      " [19.887253 ]\n",
      " [26.486538 ]\n",
      " [18.023155 ]\n",
      " [25.51799  ]\n",
      " [25.969501 ]\n",
      " [20.689756 ]\n",
      " [14.906992 ]\n",
      " [20.303326 ]\n",
      " [28.39028  ]\n",
      " [ 7.732693 ]\n",
      " [30.178577 ]\n",
      " [11.954364 ]\n",
      " [24.81407  ]\n",
      " [21.42692  ]\n",
      " [17.917868 ]\n",
      " [26.381474 ]\n",
      " [16.879581 ]\n",
      " [22.94835  ]\n",
      " [21.716839 ]\n",
      " [33.57577  ]\n",
      " [13.013654 ]\n",
      " [37.34725  ]\n",
      " [19.260685 ]\n",
      " [26.25     ]\n",
      " [28.398096 ]\n",
      " [30.556332 ]\n",
      " [16.35776  ]\n",
      " [37.506744 ]\n",
      " [24.820967 ]\n",
      " [40.53844  ]\n",
      " [21.731483 ]\n",
      " [16.22821  ]\n",
      " [45.569473 ]\n",
      " [14.859627 ]\n",
      " [20.18028  ]\n",
      " [24.79837  ]\n",
      " [15.727142 ]\n",
      " [15.906518 ]\n",
      " [20.562498 ]\n",
      " [22.976856 ]\n",
      " [21.792728 ]\n",
      " [24.019121 ]\n",
      " [15.882111 ]\n",
      " [19.56142  ]\n",
      " [12.721895 ]\n",
      " [25.1415   ]\n",
      " [31.68607  ]\n",
      " [10.916682 ]\n",
      " [19.75102  ]\n",
      " [20.582033 ]\n",
      " [20.526106 ]\n",
      " [35.909344 ]\n",
      " [19.927387 ]\n",
      " [ 9.548765 ]\n",
      " [15.400225 ]\n",
      " [19.566471 ]\n",
      " [22.114216 ]\n",
      " [23.795164 ]\n",
      " [19.282646 ]\n",
      " [20.217482 ]\n",
      " [21.543524 ]\n",
      " [12.964794 ]\n",
      " [19.29881  ]\n",
      " [ 7.732693 ]\n",
      " [14.339836 ]\n",
      " [13.663994 ]\n",
      " [19.313217 ]\n",
      " [12.974493 ]\n",
      " [19.909145 ]\n",
      " [22.768023 ]\n",
      " [21.12891  ]\n",
      " [20.679937 ]\n",
      " [ 9.6181965]\n",
      " [22.682549 ]\n",
      " [52.146408 ]\n",
      " [13.255099 ]\n",
      " [19.09801  ]\n",
      " [20.664474 ]\n",
      " [24.66682  ]\n",
      " [19.742983 ]\n",
      " [10.452682 ]\n",
      " [21.801842 ]]\n",
      "=================\n",
      "R2 :  0.8123512359763676\n"
     ]
    }
   ],
   "source": [
    "# 모델의 R2 스코어 출력\n",
    "from tensorflow.keras.models import load_model\n",
    "load_model = load_model('boston.h5')\n",
    "\n",
    "loss = load_model.evaluate(x_test,y_test)\n",
    "print(\"loss : \",loss)\n",
    "y_predict =load_model.predict(x_test)\n",
    "print(\"=================\")\n",
    "print(y_test)\n",
    "print(y_predict)\n",
    "print(\"=================\")\n",
    "r2 = r2_score(y_test,y_predict)\n",
    "print(\"R2 : \",r2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf27",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b47fb4e6c68d4941015efb0bbf71549277582fe8531338196fc3c7fa71b6aab8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
