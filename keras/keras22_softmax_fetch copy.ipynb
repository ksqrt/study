{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_covtype\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "# 1. 데이터 \n",
    "datasets = (fetch_covtype())\n",
    "\n",
    "x = pd.DataFrame(datasets[\"data\"])\n",
    "y = pd.DataFrame(datasets[\"target\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(581012, 54) (581012, 1)\n",
      "[1 2 3 4 5 6 7]\n",
      "(array([1, 2, 3, 4, 5, 6, 7]), array([211840, 283301,  35754,   2747,   9493,  17367,  20510],\n",
      "      dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "print(x.shape,y.shape) \n",
    "\n",
    "print(np.unique(y)) # [1 2 3 4 5 6 7]\n",
    "# 불균형확인\n",
    "# 참고로 이 y 값은 0 클래스가 없기 대문에 0 을 지워줘야합니다 ... ㅂㄷㅂㄷ\n",
    "\n",
    "print(np.unique(y,return_counts=True)) # [211840, 283301,  35754,   2747,   9493,  17367,  20510\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1    2    3    4    5    6    7\n",
      "0  0.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
      "1  1.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "2  1.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "3  0.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
      "4  1.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "5  0.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
      "6  0.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
      "7  0.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
      "8  1.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "9  1.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "y_train shape :  (464809, 7)\n",
      "y_test shape :  (116203, 7)\n"
     ]
    }
   ],
   "source": [
    "# print(x.info())\n",
    "# print(x.describe())\n",
    "# 데이터 분리\n",
    "x_train, x_test, y_train,y_test = train_test_split(\n",
    "                                                    x,\n",
    "                                                    y,\n",
    "                                                    train_size=0.8,\n",
    "                                                    \n",
    "                                                    shuffle = True,\n",
    "                                                    #  stratify 는 데이터 불균형을 해결해줌\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=21\n",
    "                                                   )\n",
    "# print(x.columns)\n",
    "# y 를 원 핫 인코딩 변환\n",
    "y_train = tf.one_hot(y_train[0],depth =8)\n",
    "\n",
    "# y 의 0 번 칼럼을 드랍해야함 왜 why ? 원핫 인코딩한뒤 자동으로 0 칼럼이 붇기 때문\n",
    "y_train = pd.DataFrame(y_train).drop(columns=[0])\n",
    "\n",
    "y_test = tf.one_hot(y_test[0],depth= 8)\n",
    "y_test = pd.DataFrame(y_test).drop(columns=[0])\n",
    "\n",
    "\n",
    "print(y_train[:10])\n",
    "print(\"y_train shape : \",y_train.shape)\n",
    "print(\"y_test shape : \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(128,activation=\"relu\",input_shape=(54,)),\n",
    "    Dense(128,activation=\"relu\") ,\n",
    "    Dense(128,activation=\"relu\") ,\n",
    "    Dense(64,activation=\"relu\") ,\n",
    "    Dense(64,activation=\"relu\") ,\n",
    "    Dense(32,activation=\"relu\") ,\n",
    "    Dense(32,activation=\"relu\") ,\n",
    "    # 다중분류모델의 활성화 함수는 softmax 입니다\n",
    "    Dense(7,activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1453/1453 [==============================] - 6s 4ms/step - loss: 0.9948 - accuracy: 0.6193 - val_loss: 0.7507 - val_accuracy: 0.6588\n",
      "Epoch 2/100\n",
      "1453/1453 [==============================] - 5s 4ms/step - loss: 0.6818 - accuracy: 0.7046 - val_loss: 0.6449 - val_accuracy: 0.7194\n",
      "Epoch 3/100\n",
      "1453/1453 [==============================] - 5s 4ms/step - loss: 0.6205 - accuracy: 0.7320 - val_loss: 0.5971 - val_accuracy: 0.7474\n",
      "Epoch 4/100\n",
      "1453/1453 [==============================] - 5s 4ms/step - loss: 0.5871 - accuracy: 0.7464 - val_loss: 0.5874 - val_accuracy: 0.7471\n",
      "Epoch 5/100\n",
      "1453/1453 [==============================] - 5s 4ms/step - loss: 0.5544 - accuracy: 0.7613 - val_loss: 0.5519 - val_accuracy: 0.7571\n",
      "Epoch 6/100\n",
      "1453/1453 [==============================] - 6s 4ms/step - loss: 0.5237 - accuracy: 0.7752 - val_loss: 0.5398 - val_accuracy: 0.7639\n",
      "Epoch 7/100\n",
      "1453/1453 [==============================] - 5s 4ms/step - loss: 0.5020 - accuracy: 0.7845 - val_loss: 0.5010 - val_accuracy: 0.7822\n",
      "Epoch 8/100\n",
      "1453/1453 [==============================] - 5s 4ms/step - loss: 0.4813 - accuracy: 0.7941 - val_loss: 0.4656 - val_accuracy: 0.8019\n",
      "Epoch 9/100\n",
      "1453/1453 [==============================] - 5s 4ms/step - loss: 0.4625 - accuracy: 0.8024 - val_loss: 0.4632 - val_accuracy: 0.8000\n",
      "Epoch 10/100\n",
      "1453/1453 [==============================] - 5s 4ms/step - loss: 0.4434 - accuracy: 0.8111 - val_loss: 0.4583 - val_accuracy: 0.8027\n",
      "Epoch 11/100\n",
      "1453/1453 [==============================] - 5s 4ms/step - loss: 0.4303 - accuracy: 0.8161 - val_loss: 0.4207 - val_accuracy: 0.8218\n",
      "Epoch 12/100\n",
      "1453/1453 [==============================] - 5s 4ms/step - loss: 0.4172 - accuracy: 0.8227 - val_loss: 0.3957 - val_accuracy: 0.8343\n",
      "Epoch 13/100\n",
      "1453/1453 [==============================] - 5s 4ms/step - loss: 0.4033 - accuracy: 0.8286 - val_loss: 0.3941 - val_accuracy: 0.8324\n",
      "Epoch 14/100\n",
      "1453/1453 [==============================] - 5s 4ms/step - loss: 0.3946 - accuracy: 0.8333 - val_loss: 0.3830 - val_accuracy: 0.8373\n",
      "Epoch 15/100\n",
      "1453/1453 [==============================] - 5s 4ms/step - loss: 0.3852 - accuracy: 0.8374 - val_loss: 0.3829 - val_accuracy: 0.8390\n",
      "Epoch 16/100\n",
      "1453/1453 [==============================] - 5s 4ms/step - loss: 0.3764 - accuracy: 0.8413 - val_loss: 0.3782 - val_accuracy: 0.8401\n",
      "Epoch 17/100\n",
      "1453/1453 [==============================] - 6s 4ms/step - loss: 0.3666 - accuracy: 0.8459 - val_loss: 0.4057 - val_accuracy: 0.8297\n",
      "Epoch 18/100\n",
      "1453/1453 [==============================] - 5s 4ms/step - loss: 0.3611 - accuracy: 0.8482 - val_loss: 0.3572 - val_accuracy: 0.8503\n",
      "Epoch 19/100\n",
      "1453/1453 [==============================] - 5s 4ms/step - loss: 0.3536 - accuracy: 0.8522 - val_loss: 0.3615 - val_accuracy: 0.8480\n",
      "Epoch 20/100\n",
      "1453/1453 [==============================] - 5s 4ms/step - loss: 0.3465 - accuracy: 0.8546 - val_loss: 0.3478 - val_accuracy: 0.8553\n",
      "Epoch 21/100\n",
      "1453/1453 [==============================] - 6s 4ms/step - loss: 0.3419 - accuracy: 0.8570 - val_loss: 0.3456 - val_accuracy: 0.8548\n",
      "Epoch 22/100\n",
      "1453/1453 [==============================] - 6s 4ms/step - loss: 0.3373 - accuracy: 0.8588 - val_loss: 0.3321 - val_accuracy: 0.8611\n",
      "Epoch 23/100\n",
      "1453/1453 [==============================] - 6s 4ms/step - loss: 0.3302 - accuracy: 0.8623 - val_loss: 0.3409 - val_accuracy: 0.8580\n",
      "Epoch 24/100\n",
      "1453/1453 [==============================] - 5s 4ms/step - loss: 0.3267 - accuracy: 0.8638 - val_loss: 0.3361 - val_accuracy: 0.8592\n",
      "Epoch 25/100\n",
      "1453/1453 [==============================] - 5s 4ms/step - loss: 0.3246 - accuracy: 0.8648 - val_loss: 0.3392 - val_accuracy: 0.8580\n",
      "Epoch 26/100\n",
      "1453/1453 [==============================] - 5s 4ms/step - loss: 0.3181 - accuracy: 0.8677 - val_loss: 0.3158 - val_accuracy: 0.8699\n",
      "Epoch 27/100\n",
      "1453/1453 [==============================] - 6s 4ms/step - loss: 0.3136 - accuracy: 0.8699 - val_loss: 0.3243 - val_accuracy: 0.8644\n",
      "Epoch 28/100\n",
      "1453/1453 [==============================] - 5s 4ms/step - loss: 0.3095 - accuracy: 0.8716 - val_loss: 0.3578 - val_accuracy: 0.8541\n",
      "Epoch 29/100\n",
      "1453/1453 [==============================] - 5s 4ms/step - loss: 0.3071 - accuracy: 0.8726 - val_loss: 0.3167 - val_accuracy: 0.8712\n",
      "Epoch 30/100\n",
      "1453/1453 [==============================] - 5s 4ms/step - loss: 0.3025 - accuracy: 0.8748 - val_loss: 0.3078 - val_accuracy: 0.8745\n",
      "Epoch 31/100\n",
      "1453/1453 [==============================] - 5s 4ms/step - loss: 0.3021 - accuracy: 0.8751 - val_loss: 0.3106 - val_accuracy: 0.8711\n",
      "Epoch 32/100\n",
      "1453/1453 [==============================] - 5s 4ms/step - loss: 0.2958 - accuracy: 0.8783 - val_loss: 0.2928 - val_accuracy: 0.8792\n",
      "Epoch 33/100\n",
      "1453/1453 [==============================] - 5s 4ms/step - loss: 0.2943 - accuracy: 0.8784 - val_loss: 0.3118 - val_accuracy: 0.8723\n",
      "Epoch 34/100\n",
      "1453/1453 [==============================] - 5s 4ms/step - loss: 0.2932 - accuracy: 0.8792 - val_loss: 0.2985 - val_accuracy: 0.8791\n",
      "Epoch 35/100\n",
      "1453/1453 [==============================] - 5s 4ms/step - loss: 0.2876 - accuracy: 0.8812 - val_loss: 0.3127 - val_accuracy: 0.8713\n",
      "Epoch 36/100\n",
      "1453/1453 [==============================] - 6s 4ms/step - loss: 0.2854 - accuracy: 0.8824 - val_loss: 0.2913 - val_accuracy: 0.8822\n",
      "Epoch 37/100\n",
      "1453/1453 [==============================] - 5s 4ms/step - loss: 0.2838 - accuracy: 0.8828 - val_loss: 0.2882 - val_accuracy: 0.8813\n",
      "Epoch 38/100\n",
      "1453/1453 [==============================] - 5s 4ms/step - loss: 0.2810 - accuracy: 0.8839 - val_loss: 0.3252 - val_accuracy: 0.8654\n",
      "Epoch 39/100\n",
      "1453/1453 [==============================] - 6s 4ms/step - loss: 0.2799 - accuracy: 0.8848 - val_loss: 0.2992 - val_accuracy: 0.8794\n",
      "Epoch 40/100\n",
      "1453/1453 [==============================] - 6s 4ms/step - loss: 0.2760 - accuracy: 0.8862 - val_loss: 0.2793 - val_accuracy: 0.8866\n",
      "Epoch 41/100\n",
      "1453/1453 [==============================] - 5s 4ms/step - loss: 0.2730 - accuracy: 0.8876 - val_loss: 0.2847 - val_accuracy: 0.8824\n",
      "Epoch 42/100\n",
      "1453/1453 [==============================] - 5s 4ms/step - loss: 0.2713 - accuracy: 0.8894 - val_loss: 0.2908 - val_accuracy: 0.8823\n",
      "Epoch 43/100\n",
      "1453/1453 [==============================] - 5s 4ms/step - loss: 0.2706 - accuracy: 0.8890 - val_loss: 0.2947 - val_accuracy: 0.8801\n",
      "Epoch 44/100\n",
      "1453/1453 [==============================] - 5s 4ms/step - loss: 0.2678 - accuracy: 0.8902 - val_loss: 0.2688 - val_accuracy: 0.8916\n",
      "Epoch 45/100\n",
      "1453/1453 [==============================] - 5s 4ms/step - loss: 0.2657 - accuracy: 0.8910 - val_loss: 0.3041 - val_accuracy: 0.8756\n",
      "Epoch 46/100\n",
      "1453/1453 [==============================] - 5s 4ms/step - loss: 0.2643 - accuracy: 0.8915 - val_loss: 0.2627 - val_accuracy: 0.8934\n",
      "Epoch 47/100\n",
      "1453/1453 [==============================] - 5s 4ms/step - loss: 0.2619 - accuracy: 0.8933 - val_loss: 0.2791 - val_accuracy: 0.8866\n",
      "Epoch 48/100\n",
      "1453/1453 [==============================] - 5s 4ms/step - loss: 0.2595 - accuracy: 0.8939 - val_loss: 0.2904 - val_accuracy: 0.8816\n",
      "Epoch 49/100\n",
      "1453/1453 [==============================] - 5s 4ms/step - loss: 0.2569 - accuracy: 0.8949 - val_loss: 0.2774 - val_accuracy: 0.8854\n",
      "Epoch 50/100\n",
      "1453/1453 [==============================] - 5s 4ms/step - loss: 0.2553 - accuracy: 0.8955 - val_loss: 0.2702 - val_accuracy: 0.8898\n",
      "Epoch 51/100\n",
      "1453/1453 [==============================] - 5s 4ms/step - loss: 0.2555 - accuracy: 0.8956 - val_loss: 0.2807 - val_accuracy: 0.8872\n",
      "Epoch 52/100\n",
      "1453/1453 [==============================] - 5s 4ms/step - loss: 0.2563 - accuracy: 0.8960 - val_loss: 0.2840 - val_accuracy: 0.8855\n",
      "Epoch 53/100\n",
      "1453/1453 [==============================] - 5s 4ms/step - loss: 0.2525 - accuracy: 0.8973 - val_loss: 0.2669 - val_accuracy: 0.8908\n",
      "Epoch 54/100\n",
      "1453/1453 [==============================] - 5s 4ms/step - loss: 0.2494 - accuracy: 0.8985 - val_loss: 0.2602 - val_accuracy: 0.8942\n",
      "Epoch 55/100\n",
      "1453/1453 [==============================] - 5s 4ms/step - loss: 0.2497 - accuracy: 0.8977 - val_loss: 0.2477 - val_accuracy: 0.9004\n",
      "Epoch 56/100\n",
      "1453/1453 [==============================] - 5s 4ms/step - loss: 0.2471 - accuracy: 0.8993 - val_loss: 0.2619 - val_accuracy: 0.8944\n",
      "Epoch 57/100\n",
      "1453/1453 [==============================] - 5s 4ms/step - loss: 0.2471 - accuracy: 0.9001 - val_loss: 0.2705 - val_accuracy: 0.8908\n",
      "Epoch 58/100\n",
      "1453/1453 [==============================] - 5s 4ms/step - loss: 0.2466 - accuracy: 0.9003 - val_loss: 0.2526 - val_accuracy: 0.8995\n",
      "Epoch 59/100\n",
      "1453/1453 [==============================] - 5s 4ms/step - loss: 0.2421 - accuracy: 0.9018 - val_loss: 0.2618 - val_accuracy: 0.8947\n",
      "Epoch 60/100\n",
      "1453/1453 [==============================] - 5s 4ms/step - loss: 0.2448 - accuracy: 0.9006 - val_loss: 0.2980 - val_accuracy: 0.8797\n",
      "Epoch 61/100\n",
      "1453/1453 [==============================] - 5s 4ms/step - loss: 0.2401 - accuracy: 0.9031 - val_loss: 0.2873 - val_accuracy: 0.8839\n",
      "Epoch 62/100\n",
      "1453/1453 [==============================] - 6s 4ms/step - loss: 0.2391 - accuracy: 0.9035 - val_loss: 0.2599 - val_accuracy: 0.8966\n",
      "Epoch 63/100\n",
      "1453/1453 [==============================] - 6s 4ms/step - loss: 0.2391 - accuracy: 0.9029 - val_loss: 0.2482 - val_accuracy: 0.9010\n",
      "Epoch 64/100\n",
      "1453/1453 [==============================] - 5s 4ms/step - loss: 0.2368 - accuracy: 0.9043 - val_loss: 0.2436 - val_accuracy: 0.9021\n",
      "Epoch 65/100\n",
      "1453/1453 [==============================] - 5s 4ms/step - loss: 0.2392 - accuracy: 0.9030 - val_loss: 0.2423 - val_accuracy: 0.9029\n",
      "Epoch 66/100\n",
      "1453/1453 [==============================] - 5s 4ms/step - loss: 0.2342 - accuracy: 0.9053 - val_loss: 0.2500 - val_accuracy: 0.9011\n",
      "Epoch 67/100\n",
      "1453/1453 [==============================] - 5s 4ms/step - loss: 0.2364 - accuracy: 0.9046 - val_loss: 0.2551 - val_accuracy: 0.8967\n",
      "Epoch 68/100\n",
      "1453/1453 [==============================] - 5s 4ms/step - loss: 0.2347 - accuracy: 0.9050 - val_loss: 0.2752 - val_accuracy: 0.8888\n",
      "Epoch 69/100\n",
      "1453/1453 [==============================] - 5s 4ms/step - loss: 0.2329 - accuracy: 0.9062 - val_loss: 0.2592 - val_accuracy: 0.8987\n",
      "Epoch 70/100\n",
      "1453/1453 [==============================] - 5s 4ms/step - loss: 0.2295 - accuracy: 0.9075 - val_loss: 0.2489 - val_accuracy: 0.9025\n",
      "Epoch 71/100\n",
      "1453/1453 [==============================] - 6s 4ms/step - loss: 0.2335 - accuracy: 0.9062 - val_loss: 0.2616 - val_accuracy: 0.8970\n",
      "Epoch 72/100\n",
      "1453/1453 [==============================] - 5s 4ms/step - loss: 0.2283 - accuracy: 0.9085 - val_loss: 0.2779 - val_accuracy: 0.8909\n",
      "Epoch 73/100\n",
      "1453/1453 [==============================] - 5s 4ms/step - loss: 0.2285 - accuracy: 0.9077 - val_loss: 0.2546 - val_accuracy: 0.8996\n",
      "Epoch 74/100\n",
      "1453/1453 [==============================] - 5s 4ms/step - loss: 0.2301 - accuracy: 0.9067 - val_loss: 0.2623 - val_accuracy: 0.8968\n",
      "Epoch 75/100\n",
      "1453/1453 [==============================] - 6s 4ms/step - loss: 0.2309 - accuracy: 0.9078 - val_loss: 0.2381 - val_accuracy: 0.9062\n",
      "Epoch 76/100\n",
      "1453/1453 [==============================] - 5s 4ms/step - loss: 0.2269 - accuracy: 0.9083 - val_loss: 0.2475 - val_accuracy: 0.9024\n",
      "Epoch 77/100\n",
      "1453/1453 [==============================] - 5s 4ms/step - loss: 0.2269 - accuracy: 0.9091 - val_loss: 0.2523 - val_accuracy: 0.9004\n",
      "Epoch 78/100\n",
      "1453/1453 [==============================] - 5s 4ms/step - loss: 0.2228 - accuracy: 0.9108 - val_loss: 0.2308 - val_accuracy: 0.9087\n",
      "Epoch 79/100\n",
      "1453/1453 [==============================] - 5s 4ms/step - loss: 0.2230 - accuracy: 0.9110 - val_loss: 0.2633 - val_accuracy: 0.8981\n",
      "Epoch 80/100\n",
      "1453/1453 [==============================] - 5s 4ms/step - loss: 0.2228 - accuracy: 0.9106 - val_loss: 0.2393 - val_accuracy: 0.9051\n",
      "Epoch 81/100\n",
      "1453/1453 [==============================] - 5s 4ms/step - loss: 0.2234 - accuracy: 0.9106 - val_loss: 0.2395 - val_accuracy: 0.9049\n",
      "Epoch 82/100\n",
      "1453/1453 [==============================] - 5s 4ms/step - loss: 0.2222 - accuracy: 0.9106 - val_loss: 0.2545 - val_accuracy: 0.8991\n",
      "Epoch 83/100\n",
      "1453/1453 [==============================] - 5s 4ms/step - loss: 0.2204 - accuracy: 0.9109 - val_loss: 0.2483 - val_accuracy: 0.9033\n",
      "Epoch 84/100\n",
      "1453/1453 [==============================] - 5s 4ms/step - loss: 0.2216 - accuracy: 0.9115 - val_loss: 0.2605 - val_accuracy: 0.8968\n",
      "Epoch 85/100\n",
      "1453/1453 [==============================] - 6s 4ms/step - loss: 0.2185 - accuracy: 0.9128 - val_loss: 0.2400 - val_accuracy: 0.9066\n",
      "Epoch 86/100\n",
      "1453/1453 [==============================] - 6s 4ms/step - loss: 0.2239 - accuracy: 0.9107 - val_loss: 0.2396 - val_accuracy: 0.9057\n",
      "Epoch 87/100\n",
      "1453/1453 [==============================] - 5s 4ms/step - loss: 0.2158 - accuracy: 0.9131 - val_loss: 0.2308 - val_accuracy: 0.9106\n",
      "Epoch 88/100\n",
      "1453/1453 [==============================] - 5s 4ms/step - loss: 0.2176 - accuracy: 0.9123 - val_loss: 0.2532 - val_accuracy: 0.8984\n",
      "Epoch 00088: early stopping\n"
     ]
    }
   ],
   "source": [
    "# 이진분류는 마지막 활성함수는 sigmoid + loss 는 바이너리 크로스 엔트로피 \n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "monitor='val_loss',\n",
    "patience=10, \n",
    "verbose=1, \n",
    "mode='min')\n",
    "\n",
    "# 훈련값이 int 형이기 때문에 sparse 를 사용합니다.\n",
    "model.compile(loss=\"categorical_crossentropy\"\n",
    "              ,optimizer=\"adam\"\n",
    "              ,metrics=[\"accuracy\"]\n",
    "              )\n",
    "\n",
    "hist = model.fit(x_train, y_train, epochs=100, \n",
    "                 validation_split=0.2,batch_size=256,\n",
    "                 callbacks = [early_stopping])\n",
    "\n",
    "# metrics 에 accuracy 사용가능\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3632/3632 [==============================] - 7s 2ms/step - loss: 0.2510 - accuracy: 0.9001\n",
      "loss: 0.25100550055503845 \n",
      "acc : 0.9000627994537354\n"
     ]
    }
   ],
   "source": [
    "loss,accuracy = model.evaluate(x_test,y_test)\n",
    "\n",
    "print(\"loss:\",loss,\"\\nacc :\" ,accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.9999928e-01 4.6706285e-07 0.0000000e+00 ... 5.2797424e-14\n",
      "  0.0000000e+00 2.3549717e-07]\n",
      " [2.3933532e-04 9.9971741e-01 2.2561000e-05 ... 2.0765980e-05\n",
      "  3.5783958e-09 6.0112543e-35]\n",
      " [9.9874628e-01 6.9678295e-04 0.0000000e+00 ... 1.3404945e-10\n",
      "  0.0000000e+00 5.5694004e-04]\n",
      " ...\n",
      " [1.6505672e-02 9.8347962e-01 9.4122252e-06 ... 9.1939233e-07\n",
      "  4.4419007e-06 1.6440261e-09]\n",
      " [3.8507733e-01 3.9241138e-01 4.8341703e-06 ... 2.2248405e-01\n",
      "  2.0870464e-05 1.5434058e-06]\n",
      " [1.3462229e-01 8.6527860e-01 7.6926772e-06 ... 9.0807531e-05\n",
      "  2.3793865e-07 2.9445823e-07]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_predict = model.predict(x_test)\n",
    "print(y_predict)\n",
    "y_predict = np.argmax(y_predict,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_predict)\n",
    "\n",
    "y_predict = tf.one_hot(y_predict,depth =7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측데이터 :  tf.Tensor(\n",
      "[[1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]], shape=(20, 7), dtype=float32)\n",
      "실제데이터 :        1    2    3    4    5    6    7\n",
      "0   1.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "1   0.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
      "2   1.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "3   1.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "4   0.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
      "5   1.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "6   1.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "7   1.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "8   0.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
      "9   1.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "10  0.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
      "11  0.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
      "12  0.0  0.0  1.0  0.0  0.0  0.0  0.0\n",
      "13  0.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
      "14  0.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
      "15  0.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
      "16  0.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
      "17  0.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
      "18  0.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
      "19  1.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "========================================\n",
      "0.900062821097562\n"
     ]
    }
   ],
   "source": [
    "# 데이터 출력\n",
    "\n",
    "print(\"예측데이터 : \",y_predict[:20])\n",
    "print(\"실제데이터 : \",y_test[:20])\n",
    "\n",
    "print\n",
    "print(\"========================================\")\n",
    "acc = accuracy_score(y_test,y_predict)\n",
    "print(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./_data\\\\\"+\"fetch(val_acc=0.89).h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf274gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov 24 2022, 14:39:17) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "10848e9bd3f5e7d93542d388001135334854454e7336dcf54c4ef52885ee0fb0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
