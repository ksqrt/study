{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 불러오기\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 데이터 불러오기\n",
    "# 절대경로\n",
    "path = \"C:\\study\\_bike\\\\\"\n",
    "# 상대경로\n",
    "# path = \".\\_bike\\\\\"\n",
    "\n",
    "# index_col = 0 은 0번째 있는 id 를 index로 구분해줌 \n",
    "train_csv = pd.read_csv(path+ \"train.csv\",index_col=0)\n",
    "test_csv = pd.read_csv(path+\"test.csv\",index_col=0)\n",
    "submission = pd.read_csv(path + \"sampleSubmission.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['season', 'holiday', 'workingday', 'weather', 'temp', 'atemp',\n",
      "       'humidity', 'windspeed', 'casual', 'registered', 'count'],\n",
      "      dtype='object')\n",
      "(10886, 11)\n",
      "Index(['season', 'holiday', 'workingday', 'weather', 'temp', 'atemp',\n",
      "       'humidity', 'windspeed'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# 해야할것 1. train 의 casual, registered 칼럼 삭제\n",
    "#  2. y 칼럼인 count 분리\n",
    "print(train_csv.columns)\n",
    "print(train_csv.shape)\n",
    "print(test_csv.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 10886 entries, 2011-01-01 00:00:00 to 2012-12-19 23:00:00\n",
      "Data columns (total 11 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   season      10886 non-null  int64  \n",
      " 1   holiday     10886 non-null  int64  \n",
      " 2   workingday  10886 non-null  int64  \n",
      " 3   weather     10886 non-null  int64  \n",
      " 4   temp        10886 non-null  float64\n",
      " 5   atemp       10886 non-null  float64\n",
      " 6   humidity    10886 non-null  int64  \n",
      " 7   windspeed   10886 non-null  float64\n",
      " 8   casual      10886 non-null  int64  \n",
      " 9   registered  10886 non-null  int64  \n",
      " 10  count       10886 non-null  int64  \n",
      "dtypes: float64(3), int64(8)\n",
      "memory usage: 1020.6+ KB\n",
      "None\n",
      "(10886, 9)\n",
      "Index(['season', 'holiday', 'workingday', 'weather', 'temp', 'atemp',\n",
      "       'humidity', 'windspeed', 'count'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# 결측치 이상치를 확인해보기위한 카운트 조회\n",
    "print(train_csv.info())\n",
    "\n",
    "# 데이터셋을 결측치가 없는 데이터셋으로 초기화 \n",
    "# 결측치 열 제거 \n",
    "train_csv = train_csv.dropna(axis=0)\n",
    "# \n",
    "train_csv = train_csv.drop([\"casual\"],axis=1)\n",
    "train_csv = train_csv.drop([\"registered\"],axis=1)\n",
    "# 결측치확인\n",
    "train_csv.isnull().any()\n",
    "print(train_csv.shape)\n",
    "print(train_csv.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     season  holiday  workingday  weather  temp   atemp  \\\n",
      "datetime                                                                  \n",
      "2011-01-01 00:00:00       1        0           0        1  9.84  14.395   \n",
      "2011-01-01 01:00:00       1        0           0        1  9.02  13.635   \n",
      "2011-01-01 02:00:00       1        0           0        1  9.02  13.635   \n",
      "2011-01-01 03:00:00       1        0           0        1  9.84  14.395   \n",
      "2011-01-01 04:00:00       1        0           0        1  9.84  14.395   \n",
      "\n",
      "                     humidity  windspeed  \n",
      "datetime                                  \n",
      "2011-01-01 00:00:00        81        0.0  \n",
      "2011-01-01 01:00:00        80        0.0  \n",
      "2011-01-01 02:00:00        80        0.0  \n",
      "2011-01-01 03:00:00        75        0.0  \n",
      "2011-01-01 04:00:00        75        0.0  \n",
      "(10886, 8)\n"
     ]
    }
   ],
   "source": [
    "# 데이터 정리하기 x \n",
    "x = train_csv.drop([\"count\"],axis=1)\n",
    "\n",
    "#  x는 이제 count 칼럼이 사라졌습니다!\n",
    "print(x.head())\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime\n",
      "2011-01-01 00:00:00    16\n",
      "2011-01-01 01:00:00    40\n",
      "2011-01-01 02:00:00    32\n",
      "2011-01-01 03:00:00    13\n",
      "2011-01-01 04:00:00     1\n",
      "Name: count, dtype: int64\n",
      "(10886,)\n"
     ]
    }
   ],
   "source": [
    "# 데이터 정리하기 y\n",
    "# count 칼럼만 가지고옵니다 이떄 train_csv 은 변형하지 않는게 포인트\n",
    "y = train_csv[\"count\"]\n",
    "print(y.head())\n",
    "\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7620\n",
      "3266\n"
     ]
    }
   ],
   "source": [
    "# 데이터를 분할하기\n",
    "\n",
    "x_train, x_test, y_train,y_test = train_test_split(x,y,\n",
    "                                                   train_size=0.7,\n",
    "                                                   shuffle = True,\n",
    "                                                   random_state=21\n",
    "                                                   )\n",
    "\n",
    "print(len(x_train))\n",
    "print(len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 10)                90        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 981\n",
      "Trainable params: 981\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 2. 모델구성\n",
    "\n",
    "model = Sequential([\n",
    "    \n",
    "    Dense(10,input_dim = 8 ,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    # 마지막 레이어는 통상 relu 넣지 않습니다. 히든레이어에 많이쓰임\n",
    "    Dense(1),\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "100/100 [==============================] - 1s 3ms/step - loss: 69865.9219\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 40535.9727\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 31729.0059\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 26810.9258\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 25222.9922\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 25019.5312\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 25567.3027\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 24936.3164\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 25213.0156\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 24884.1641\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 24970.7539\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 25109.8730\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 24619.3477\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 24456.9824\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 24488.6699\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 24948.0312\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 24307.7578\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 24483.9375\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 24565.0723\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 24632.7578\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 24301.1270\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 24046.8457\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 25024.8262\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 23949.3301\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 24077.5820\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 24648.5898\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 23882.8301\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 24149.9238\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 24122.7461\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 24495.8438\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 23913.3438\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 24200.4766\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 23812.0312\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 23909.1133\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 24173.5156\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 24007.2090\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 23711.0547\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 24351.6504\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 23486.8691\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 23877.5215\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 23921.7012\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 24556.2812\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 23320.6445\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 24142.1133\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 23498.4746\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 23779.9688\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 24072.8008\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 24049.2969\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 23381.7344\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 24059.5859\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 24514.6543\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 23090.5508\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 23630.2812\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 24092.6953\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 24056.4570\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 23453.3086\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 23428.0312\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 24148.9902\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 23161.4355\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 24134.0996\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 23667.5430\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 23359.4355\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 24037.3750\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 22880.6367\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 24828.3359\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 23338.5547\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 24449.8789\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 23214.5879\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 23713.8750\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 23846.2734\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 23249.9980\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 24030.3105\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 23688.8652\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 23589.7539\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 23432.5742\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 23921.5840\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 23140.8223\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 24251.1074\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 23606.6582\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 23820.6133\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 23406.7715\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 23527.2285\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 23751.9277\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 23627.2656\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 23734.1230\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 23609.0430\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 23530.7852\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 23817.4766\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 23585.4238\n",
      "Epoch 90/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 23222.2598\n",
      "Epoch 91/100\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 23990.2500\n",
      "Epoch 92/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 23607.1094\n",
      "Epoch 93/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 23828.3926\n",
      "Epoch 94/100\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 23471.4863\n",
      "Epoch 95/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 23803.4082\n",
      "Epoch 96/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 23474.1836\n",
      "Epoch 97/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 23552.1992\n",
      "Epoch 98/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 23706.2676\n",
      "Epoch 99/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 23507.8926\n",
      "Epoch 100/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 23507.8926\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25724b93b80>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.컴파일 + 훈련\n",
    "model.compile(loss=\"mse\",optimizer=\"adam\")\n",
    "model.fit(x_train,y_train,epochs=100,steps_per_epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - 0s 2ms/step - loss: 22978.0723\n",
      "loss :  22978.072265625\n",
      "RMSE :  151.58517827229235\n",
      "R2 :  0.27907757871668604\n"
     ]
    }
   ],
   "source": [
    "# 성능평가\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def RMSE(y_test,y_predict):\n",
    "    return np.sqrt(mean_squared_error(y_test,y_predict))\n",
    "# 평가 손실률 가져오기\n",
    "loss = model.evaluate(x_test,y_test)\n",
    "print(\"loss : \",loss)\n",
    "\n",
    "y_predict =model.predict(x_test)\n",
    "# print(\"=================\")\n",
    "# print(y_test)\n",
    "# print(y_predict)\n",
    "# print(\"=================\")\n",
    "\n",
    "print(\"RMSE : \",RMSE(y_test,y_predict))\n",
    "print(\"R2 : \",r2_score(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15. 저장\n",
    "import pandas as pd\n",
    "# 15-1.제출용를 predcit 로 뽑아냄\n",
    "y_submit = model.predict(test_csv)\n",
    "# 15-2 제출용의 카운트 칼럼에 y_submit 삽입\n",
    "submission[\"count\"] = y_submit\n",
    "# 15-3 경로와 파일명 지정\n",
    "submission.to_csv(path + \"submission_0106.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf274gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov 24 2022, 14:39:17) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "10848e9bd3f5e7d93542d388001135334854454e7336dcf54c4ef52885ee0fb0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
