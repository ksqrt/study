{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 불러오기\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 데이터 불러오기\n",
    "# 절대경로\n",
    "path = \"C:\\study\\_bike\\\\\"\n",
    "# 상대경로\n",
    "# path = \".\\_bike\\\\\"\n",
    "\n",
    "# index_col = 0 은 0번째 있는 id 를 index로 구분해줌 \n",
    "train_csv = pd.read_csv(path+ \"train.csv\",index_col=0)\n",
    "test_csv = pd.read_csv(path+\"test.csv\",index_col=0)\n",
    "submission = pd.read_csv(path + \"sampleSubmission.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['season', 'holiday', 'workingday', 'weather', 'temp', 'atemp',\n",
      "       'humidity', 'windspeed', 'casual', 'registered', 'count'],\n",
      "      dtype='object')\n",
      "(10886, 11)\n",
      "Index(['season', 'holiday', 'workingday', 'weather', 'temp', 'atemp',\n",
      "       'humidity', 'windspeed'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# 해야할것 1. train 의 casual, registered 칼럼 삭제\n",
    "#  2. y 칼럼인 count 분리\n",
    "print(train_csv.columns)\n",
    "print(train_csv.shape)\n",
    "print(test_csv.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 10886 entries, 2011-01-01 00:00:00 to 2012-12-19 23:00:00\n",
      "Data columns (total 11 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   season      10886 non-null  int64  \n",
      " 1   holiday     10886 non-null  int64  \n",
      " 2   workingday  10886 non-null  int64  \n",
      " 3   weather     10886 non-null  int64  \n",
      " 4   temp        10886 non-null  float64\n",
      " 5   atemp       10886 non-null  float64\n",
      " 6   humidity    10886 non-null  int64  \n",
      " 7   windspeed   10886 non-null  float64\n",
      " 8   casual      10886 non-null  int64  \n",
      " 9   registered  10886 non-null  int64  \n",
      " 10  count       10886 non-null  int64  \n",
      "dtypes: float64(3), int64(8)\n",
      "memory usage: 1020.6+ KB\n",
      "None\n",
      "(10886, 9)\n",
      "Index(['season', 'holiday', 'workingday', 'weather', 'temp', 'atemp',\n",
      "       'humidity', 'windspeed', 'count'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# 결측치 이상치를 확인해보기위한 카운트 조회\n",
    "print(train_csv.info())\n",
    "\n",
    "# 데이터셋을 결측치가 없는 데이터셋으로 초기화 \n",
    "# 결측치 열 제거 \n",
    "train_csv = train_csv.dropna(axis=0)\n",
    "# \n",
    "train_csv = train_csv.drop([\"casual\"],axis=1)\n",
    "train_csv = train_csv.drop([\"registered\"],axis=1)\n",
    "# 결측치확인\n",
    "train_csv.isnull().any()\n",
    "print(train_csv.shape)\n",
    "print(train_csv.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     season  holiday  workingday  weather  temp   atemp  \\\n",
      "datetime                                                                  \n",
      "2011-01-01 00:00:00       1        0           0        1  9.84  14.395   \n",
      "2011-01-01 01:00:00       1        0           0        1  9.02  13.635   \n",
      "2011-01-01 02:00:00       1        0           0        1  9.02  13.635   \n",
      "2011-01-01 03:00:00       1        0           0        1  9.84  14.395   \n",
      "2011-01-01 04:00:00       1        0           0        1  9.84  14.395   \n",
      "\n",
      "                     humidity  windspeed  \n",
      "datetime                                  \n",
      "2011-01-01 00:00:00        81        0.0  \n",
      "2011-01-01 01:00:00        80        0.0  \n",
      "2011-01-01 02:00:00        80        0.0  \n",
      "2011-01-01 03:00:00        75        0.0  \n",
      "2011-01-01 04:00:00        75        0.0  \n",
      "(10886, 8)\n"
     ]
    }
   ],
   "source": [
    "# 데이터 정리하기 x \n",
    "x = train_csv.drop([\"count\"],axis=1)\n",
    "\n",
    "#  x는 이제 count 칼럼이 사라졌습니다!\n",
    "print(x.head())\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime\n",
      "2011-01-01 00:00:00    16\n",
      "2011-01-01 01:00:00    40\n",
      "2011-01-01 02:00:00    32\n",
      "2011-01-01 03:00:00    13\n",
      "2011-01-01 04:00:00     1\n",
      "Name: count, dtype: int64\n",
      "(10886,)\n"
     ]
    }
   ],
   "source": [
    "# 데이터 정리하기 y\n",
    "# count 칼럼만 가지고옵니다 이떄 train_csv 은 변형하지 않는게 포인트\n",
    "y = train_csv[\"count\"]\n",
    "print(y.head())\n",
    "\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7620\n",
      "3266\n"
     ]
    }
   ],
   "source": [
    "# 데이터를 분할하기\n",
    "\n",
    "x_train, x_test, y_train,y_test = train_test_split(x,y,\n",
    "                                                   train_size=0.7,\n",
    "                                                   shuffle = True,\n",
    "                                                   random_state=21\n",
    "                                                   )\n",
    "\n",
    "print(len(x_train))\n",
    "print(len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_10 (Dense)            (None, 10)                90        \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 981\n",
      "Trainable params: 981\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 2. 모델구성\n",
    "\n",
    "model = Sequential([\n",
    "    \n",
    "    Dense(10,input_dim = 8 ,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    # 마지막 레이어는 통상 relu 넣지 않습니다. 히든레이어에 많이쓰임\n",
    "    Dense(1),\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "191/191 [==============================] - 3s 12ms/step - loss: 51171.6797 - val_loss: 31782.2363\n",
      "Epoch 2/100\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 30002.1094 - val_loss: 27494.2852\n",
      "Epoch 3/100\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 26008.2188 - val_loss: 25986.2676\n",
      "Epoch 4/100\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 25304.1621 - val_loss: 25864.7188\n",
      "Epoch 5/100\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 25089.4648 - val_loss: 25464.3203\n",
      "Epoch 6/100\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 24907.1055 - val_loss: 25306.4375\n",
      "Epoch 7/100\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 24893.7695 - val_loss: 25169.0742\n",
      "Epoch 8/100\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 24774.4277 - val_loss: 25152.3027\n",
      "Epoch 9/100\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 24695.0547 - val_loss: 25132.3535\n",
      "Epoch 10/100\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 24589.7012 - val_loss: 24943.2148\n",
      "Epoch 11/100\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 24500.0762 - val_loss: 25252.3281\n",
      "Epoch 12/100\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 24516.8691 - val_loss: 24980.0684\n",
      "Epoch 13/100\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 24311.2910 - val_loss: 25021.9180\n",
      "Epoch 14/100\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 24378.0898 - val_loss: 24893.1465\n",
      "Epoch 15/100\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 24282.3418 - val_loss: 24893.5020\n",
      "Epoch 16/100\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 24182.1543 - val_loss: 25778.3047\n",
      "Epoch 17/100\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 24258.8105 - val_loss: 24541.7305\n",
      "Epoch 18/100\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 24158.8926 - val_loss: 24518.9941\n",
      "Epoch 19/100\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 24045.5273 - val_loss: 24560.7422\n",
      "Epoch 20/100\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 24058.2676 - val_loss: 24490.6270\n",
      "Epoch 21/100\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 23986.7734 - val_loss: 24556.8613\n",
      "Epoch 22/100\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 23984.8730 - val_loss: 24408.1504\n",
      "Epoch 23/100\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 23950.2363 - val_loss: 24371.0020\n",
      "Epoch 24/100\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 23881.6113 - val_loss: 24536.5547\n",
      "Epoch 25/100\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 23862.4375 - val_loss: 24457.6387\n",
      "Epoch 26/100\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 23842.0176 - val_loss: 24407.2441\n",
      "Epoch 27/100\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 23794.3867 - val_loss: 24401.6562\n",
      "Epoch 28/100\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 23800.7988 - val_loss: 24430.9492\n",
      "Epoch 29/100\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 23773.9375 - val_loss: 24423.0059\n",
      "Epoch 30/100\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 23751.7148 - val_loss: 24411.6855\n",
      "Epoch 31/100\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 23843.6328 - val_loss: 25159.1895\n",
      "Epoch 32/100\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 23980.7559 - val_loss: 24292.6582\n",
      "Epoch 33/100\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 23694.1270 - val_loss: 24589.3516\n",
      "Epoch 34/100\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 23719.7422 - val_loss: 25152.9023\n",
      "Epoch 35/100\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 23763.0000 - val_loss: 24314.1094\n",
      "Epoch 36/100\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 23713.0020 - val_loss: 24303.0020\n",
      "Epoch 37/100\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 23723.6797 - val_loss: 24314.9941\n",
      "Epoch 38/100\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 23811.0547 - val_loss: 24266.7305\n",
      "Epoch 39/100\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 23605.1660 - val_loss: 24342.6875\n",
      "Epoch 40/100\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 23695.1699 - val_loss: 24413.3281\n",
      "Epoch 41/100\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 23742.3906 - val_loss: 24297.0078\n",
      "Epoch 42/100\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 23602.5977 - val_loss: 24260.6094\n",
      "Epoch 43/100\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 23563.4141 - val_loss: 24245.9922\n",
      "Epoch 44/100\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 23649.9922 - val_loss: 24248.3984\n",
      "Epoch 45/100\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 23575.7031 - val_loss: 24249.1270\n",
      "Epoch 46/100\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 23625.7578 - val_loss: 24159.0020\n",
      "Epoch 47/100\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 23582.5195 - val_loss: 24228.1074\n",
      "Epoch 48/100\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 23534.7656 - val_loss: 24254.0684\n",
      "Epoch 49/100\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 23598.8066 - val_loss: 24193.1777\n",
      "Epoch 50/100\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 23675.3574 - val_loss: 24213.3262\n",
      "Epoch 51/100\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 23526.9707 - val_loss: 24193.9023\n",
      "Epoch 52/100\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 23550.8555 - val_loss: 24255.9746\n",
      "Epoch 53/100\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 23569.1934 - val_loss: 24088.4531\n",
      "Epoch 54/100\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 23667.8164 - val_loss: 24094.4180\n",
      "Epoch 55/100\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 23528.8457 - val_loss: 24499.1289\n",
      "Epoch 56/100\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 23496.3672 - val_loss: 24153.2656\n",
      "Epoch 57/100\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 23595.0859 - val_loss: 24071.9414\n",
      "Epoch 58/100\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 23476.6094 - val_loss: 24235.5977\n",
      "Epoch 59/100\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 23506.2148 - val_loss: 24171.7656\n",
      "Epoch 60/100\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 23446.9473 - val_loss: 24045.4961\n",
      "Epoch 61/100\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 23470.9609 - val_loss: 24179.2500\n",
      "Epoch 62/100\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 23454.9297 - val_loss: 24257.0020\n",
      "Epoch 63/100\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 23580.3418 - val_loss: 24762.3359\n",
      "Epoch 64/100\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 23548.4785 - val_loss: 24113.1289\n",
      "Epoch 65/100\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 23503.5059 - val_loss: 24008.6055\n",
      "Epoch 66/100\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 23404.1523 - val_loss: 24092.1309\n",
      "Epoch 67/100\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 23458.2422 - val_loss: 24159.7227\n",
      "Epoch 68/100\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 23381.2422 - val_loss: 24191.9980\n",
      "Epoch 69/100\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 23570.6816 - val_loss: 24017.9492\n",
      "Epoch 70/100\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 23479.9414 - val_loss: 23993.0938\n",
      "Epoch 71/100\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 23324.5723 - val_loss: 24938.6465\n",
      "Epoch 72/100\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 23452.8477 - val_loss: 23973.0703\n",
      "Epoch 73/100\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 23369.1074 - val_loss: 24049.3379\n",
      "Epoch 74/100\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 23445.2422 - val_loss: 24029.2812\n",
      "Epoch 75/100\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 23281.8496 - val_loss: 24042.0859\n",
      "Epoch 76/100\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 23398.6641 - val_loss: 24006.3359\n",
      "Epoch 77/100\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 23373.9395 - val_loss: 23974.2266\n",
      "Epoch 78/100\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 23332.6172 - val_loss: 23991.6660\n",
      "Epoch 79/100\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 23305.9707 - val_loss: 24082.4746\n",
      "Epoch 80/100\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 23385.4258 - val_loss: 24068.7871\n",
      "Epoch 81/100\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 23346.1602 - val_loss: 24259.6699\n",
      "Epoch 82/100\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 23461.2617 - val_loss: 23969.6055\n",
      "Epoch 83/100\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 23360.8086 - val_loss: 24133.0820\n",
      "Epoch 84/100\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 23238.2383 - val_loss: 24047.7109\n",
      "Epoch 85/100\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 23439.8027 - val_loss: 24040.2422\n",
      "Epoch 86/100\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 23327.5957 - val_loss: 24017.0938\n",
      "Epoch 87/100\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 23357.2969 - val_loss: 23958.3965\n",
      "Epoch 88/100\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 23297.9980 - val_loss: 24118.9258\n",
      "Epoch 89/100\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 23361.7930 - val_loss: 23968.2070\n",
      "Epoch 90/100\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 23373.6562 - val_loss: 24198.5645\n",
      "Epoch 91/100\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 23302.2598 - val_loss: 25177.4180\n",
      "Epoch 92/100\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 23412.4219 - val_loss: 24052.4375\n",
      "Epoch 93/100\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 23253.2812 - val_loss: 23930.7266\n",
      "Epoch 94/100\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 23244.9902 - val_loss: 24259.1289\n",
      "Epoch 95/100\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 23275.3750 - val_loss: 23987.0547\n",
      "Epoch 96/100\n",
      "191/191 [==============================] - 1s 4ms/step - loss: 23334.7695 - val_loss: 24028.3809\n",
      "Epoch 97/100\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 23345.9824 - val_loss: 23944.1172\n",
      "Epoch 98/100\n",
      "191/191 [==============================] - 2s 12ms/step - loss: 23402.0859 - val_loss: 24326.1836\n",
      "Epoch 99/100\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 23321.1934 - val_loss: 23942.0898\n",
      "Epoch 100/100\n",
      "191/191 [==============================] - 2s 11ms/step - loss: 23306.2969 - val_loss: 24200.3223\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x232cabca820>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.컴파일 + 훈련\n",
    "model.compile(loss=\"mse\",optimizer=\"adam\")\n",
    "model.fit(x_train, y_train, epochs=100, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103/103 [==============================] - 0s 2ms/step - loss: 22634.9180\n",
      "loss :  22634.91796875\n",
      "RMSE :  150.44905123629422\n",
      "R2 :  0.2898436713933469\n"
     ]
    }
   ],
   "source": [
    "# 성능평가\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def RMSE(y_test,y_predict):\n",
    "    return np.sqrt(mean_squared_error(y_test,y_predict))\n",
    "# 평가 손실률 가져오기\n",
    "loss = model.evaluate(x_test,y_test)\n",
    "print(\"loss : \",loss)\n",
    "\n",
    "y_predict =model.predict(x_test)\n",
    "# print(\"=================\")\n",
    "# print(y_test)\n",
    "# print(y_predict)\n",
    "# print(\"=================\")\n",
    "\n",
    "print(\"RMSE : \",RMSE(y_test,y_predict))\n",
    "print(\"R2 : \",r2_score(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15. 저장\n",
    "import pandas as pd\n",
    "# 15-1.제출용를 predcit 로 뽑아냄\n",
    "y_submit = model.predict(test_csv)\n",
    "# 15-2 제출용의 카운트 칼럼에 y_submit 삽입\n",
    "submission[\"count\"] = y_submit\n",
    "# 15-3 경로와 파일명 지정\n",
    "submission.to_csv(path + \"submission_0106.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf274gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "10848e9bd3f5e7d93542d388001135334854454e7336dcf54c4ef52885ee0fb0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
