{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "dataset = load_diabetes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(442, 10)\n",
      "(442,)\n"
     ]
    }
   ],
   "source": [
    "x = dataset.data\n",
    "y = dataset.target\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# 사이킥 런의 칼럼 조회기능\n",
    "print(dataset.feature_names)\n",
    "print(len(dataset.feature_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _diabetes_dataset:\n",
      "\n",
      "Diabetes dataset\n",
      "----------------\n",
      "\n",
      "Ten baseline variables, age, sex, body mass index, average blood\n",
      "pressure, and six blood serum measurements were obtained for each of n =\n",
      "442 diabetes patients, as well as the response of interest, a\n",
      "quantitative measure of disease progression one year after baseline.\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "  :Number of Instances: 442\n",
      "\n",
      "  :Number of Attributes: First 10 columns are numeric predictive values\n",
      "\n",
      "  :Target: Column 11 is a quantitative measure of disease progression one year after baseline\n",
      "\n",
      "  :Attribute Information:\n",
      "      - age     age in years\n",
      "      - sex\n",
      "      - bmi     body mass index\n",
      "      - bp      average blood pressure\n",
      "      - s1      tc, total serum cholesterol\n",
      "      - s2      ldl, low-density lipoproteins\n",
      "      - s3      hdl, high-density lipoproteins\n",
      "      - s4      tch, total cholesterol / HDL\n",
      "      - s5      ltg, possibly log of serum triglycerides level\n",
      "      - s6      glu, blood sugar level\n",
      "\n",
      "Note: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times the square root of `n_samples` (i.e. the sum of squares of each column totals 1).\n",
      "\n",
      "Source URL:\n",
      "https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\n",
      "\n",
      "For more information see:\n",
      "Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\n",
      "(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 사이킥런의 데이터 요약\n",
    "print(dataset.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309\n",
      "133\n"
     ]
    }
   ],
   "source": [
    "# 3. 모델구성\n",
    "# 실습 train 0.7 이상\n",
    "# 평가지표 R2 : 0.8 이상으로 뽑아내보기 / RMSE 사용\n",
    "\n",
    "x_train, x_test,y_train,y_test = train_test_split(x,y,\n",
    "    train_size=0.7,\n",
    "    shuffle = True,\n",
    "    random_state= 123\n",
    ")\n",
    "\n",
    "print(len(x_train))\n",
    "print(len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_54 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_56 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_57 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_58 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_59 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_60 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_61 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_62 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_63 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_64 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_65 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_66 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_67 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_68 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_69 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_70 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_71 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,881\n",
      "Trainable params: 1,881\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from random import randrange\n",
    "number1 = randrange(1,10,1)\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(10,input_dim = 10),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(1)\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "100/100 [==============================] - 1s 1ms/step - loss: 131.6397\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 69.6269\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 64.5878\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 60.6215\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 55.2056\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 51.2623\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 49.1408\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 45.6820\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 48.1777\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 45.2876\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 44.4992\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 46.3000\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 44.0915\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 45.1726\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 45.6168\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 44.6218\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 43.0376\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 43.2854\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 43.6395\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 45.1315\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 42.6864\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 43.7421\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 43.5618\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 44.2500\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 42.8524\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 43.7200\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 45.0107\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 43.9753\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 42.3148\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 42.6601\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 44.7511\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 45.3250\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 42.7779\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 43.6020\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 42.7493\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 43.9210\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 42.1603\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 41.9403\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 43.0280\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 44.1818\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 41.9417\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 41.8434\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 45.5354\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 43.0589\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 44.7739\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 43.0010\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 42.6668\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 43.2585\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 44.1710\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 44.0074\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 43.6567\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 43.3312\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 44.0226\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 43.0970\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 41.8269\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 44.7150\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 43.0703\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 42.6579\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 41.7804\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 43.8067\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 43.3627\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 42.7537\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 43.1559\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 42.3170\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 44.1950\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 41.5424\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 43.5366\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 42.7460\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 43.0428\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 41.9245\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 43.0688\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 43.5352\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 42.0859\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 42.9812\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 43.0143\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 43.3596\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 44.3392\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 40.6623\n",
      "Epoch 79/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 140us/step - loss: 40.6623\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 45.9282\n",
      "loss :  45.92816162109375\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "=================\n",
      "[185. 150. 246. 184. 110. 202. 336.  69.  69.  87.  66. 164. 265. 198.\n",
      " 248. 171. 102. 182. 262. 233. 151. 275. 230.  39.  42. 122.  81.  31.\n",
      " 156. 161.  80. 215. 310. 163. 265.  84.  54. 137. 248.  72. 248.  59.\n",
      "  97.  61.  72. 296.  55.  75.  53. 173. 158.  96. 140. 186.  93. 123.\n",
      " 237. 138. 292.  78. 182. 127. 321. 109. 212.  45.  96. 109.  89.  96.\n",
      "  60.  51. 200. 265.  68.  91. 172. 115. 125.  53.  63. 259. 214. 195.\n",
      " 258. 235. 173.  59. 219. 170.  77.  49.  66. 144. 113. 233. 162. 121.\n",
      "  88. 302. 128.  52. 178.  90. 164. 135. 103. 200. 178. 261.  64.  59.\n",
      "  79.  47. 107.  39. 151. 104. 217. 232.  55. 245. 131.  64. 222. 249.\n",
      " 128. 293. 138. 273. 158. 168. 103.]\n",
      "[[145.62285 ]\n",
      " [138.22334 ]\n",
      " [263.9626  ]\n",
      " [171.15027 ]\n",
      " [143.94507 ]\n",
      " [123.7944  ]\n",
      " [296.58163 ]\n",
      " [ 88.18084 ]\n",
      " [ 91.65962 ]\n",
      " [109.06965 ]\n",
      " [109.857506]\n",
      " [183.85051 ]\n",
      " [149.85912 ]\n",
      " [227.99329 ]\n",
      " [247.622   ]\n",
      " [166.90718 ]\n",
      " [ 93.16942 ]\n",
      " [161.24557 ]\n",
      " [185.32701 ]\n",
      " [211.86804 ]\n",
      " [173.41568 ]\n",
      " [261.36835 ]\n",
      " [141.47717 ]\n",
      " [ 71.92418 ]\n",
      " [116.20024 ]\n",
      " [203.48393 ]\n",
      " [101.79058 ]\n",
      " [116.59482 ]\n",
      " [146.54    ]\n",
      " [183.24234 ]\n",
      " [ 78.766335]\n",
      " [283.17548 ]\n",
      " [227.18398 ]\n",
      " [224.75479 ]\n",
      " [212.97739 ]\n",
      " [107.253586]\n",
      " [ 81.0696  ]\n",
      " [107.886246]\n",
      " [244.23096 ]\n",
      " [106.28249 ]\n",
      " [212.85588 ]\n",
      " [ 92.40467 ]\n",
      " [121.11946 ]\n",
      " [137.39317 ]\n",
      " [114.60153 ]\n",
      " [253.67075 ]\n",
      " [ 99.06985 ]\n",
      " [ 88.183495]\n",
      " [ 85.19049 ]\n",
      " [259.5471  ]\n",
      " [ 95.789925]\n",
      " [ 97.78835 ]\n",
      " [195.5736  ]\n",
      " [221.93198 ]\n",
      " [155.3383  ]\n",
      " [212.66003 ]\n",
      " [254.08936 ]\n",
      " [169.87616 ]\n",
      " [202.06541 ]\n",
      " [198.75607 ]\n",
      " [136.53288 ]\n",
      " [129.64378 ]\n",
      " [267.3733  ]\n",
      " [232.94682 ]\n",
      " [195.30492 ]\n",
      " [ 64.13934 ]\n",
      " [ 80.781166]\n",
      " [159.69713 ]\n",
      " [108.402664]\n",
      " [ 95.595566]\n",
      " [116.03392 ]\n",
      " [ 76.57295 ]\n",
      " [152.91287 ]\n",
      " [216.91583 ]\n",
      " [135.6384  ]\n",
      " [167.62889 ]\n",
      " [155.10515 ]\n",
      " [143.28151 ]\n",
      " [114.60309 ]\n",
      " [103.27682 ]\n",
      " [ 83.121994]\n",
      " [152.3563  ]\n",
      " [137.83118 ]\n",
      " [263.5661  ]\n",
      " [357.05475 ]\n",
      " [166.90852 ]\n",
      " [215.1725  ]\n",
      " [ 87.9957  ]\n",
      " [121.20418 ]\n",
      " [117.23716 ]\n",
      " [166.62273 ]\n",
      " [ 76.78202 ]\n",
      " [181.41223 ]\n",
      " [168.17278 ]\n",
      " [106.93869 ]\n",
      " [299.00867 ]\n",
      " [147.61273 ]\n",
      " [239.6843  ]\n",
      " [143.55939 ]\n",
      " [148.92549 ]\n",
      " [ 80.45857 ]\n",
      " [ 76.255844]\n",
      " [123.43174 ]\n",
      " [182.48875 ]\n",
      " [201.54253 ]\n",
      " [ 92.66283 ]\n",
      " [142.08926 ]\n",
      " [164.13618 ]\n",
      " [198.94685 ]\n",
      " [276.96515 ]\n",
      " [ 96.94958 ]\n",
      " [136.85864 ]\n",
      " [123.44284 ]\n",
      " [ 79.36938 ]\n",
      " [ 97.23954 ]\n",
      " [ 90.83278 ]\n",
      " [213.44855 ]\n",
      " [ 79.37608 ]\n",
      " [176.50632 ]\n",
      " [195.6166  ]\n",
      " [159.57828 ]\n",
      " [148.29852 ]\n",
      " [144.63579 ]\n",
      " [114.65758 ]\n",
      " [209.1211  ]\n",
      " [228.46077 ]\n",
      " [266.00305 ]\n",
      " [214.31577 ]\n",
      " [ 75.61774 ]\n",
      " [310.62274 ]\n",
      " [ 97.476715]\n",
      " [136.50923 ]\n",
      " [104.66156 ]]\n",
      "=================\n",
      "R2 :  0.46785425551103066\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 42.0261\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 42.9550\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 43.2974\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 40.0183\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 43.6157\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 42.3094\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 41.5774\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 43.0386\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 40.5097\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 42.7219\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 42.0987\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 43.0774\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 42.7225\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 39.7355\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 42.8613\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 41.7323\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 42.1629\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 41.9041\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 39.2069\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 42.5072\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 40.0700\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 41.3314\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 40.3037\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 41.1581\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 41.3055\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 40.0793\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 42.5645\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 39.0677\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 39.4080\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 40.1711\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 37.7339\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 43.6522\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 40.5059\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 40.1567\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 41.0745\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 39.6640\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 39.6684\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 37.9529\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 40.7984\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 40.6388\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 39.0733\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 40.9171\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 40.4329\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 37.9043\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 41.8340\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 39.0590\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 42.0818\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 38.9261\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 37.5095\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 40.4597\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 38.2034\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 39.9783\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 38.8501\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 38.9488\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 40.2496\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 39.2226\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 41.4196\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 40.8630\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.3828\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 39.7106\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 38.8713\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 38.8633\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 39.5554\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.0251\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 38.8655\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 39.0119\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 37.7993\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 38.1600\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 37.7533\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 38.6195\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 39.2687\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 39.1028\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 37.4050\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 38.1102\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 39.7815\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 38.7746\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 38.2729\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 39.1087\n",
      "Epoch 79/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 110us/step - loss: 39.1087\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 44.7488\n",
      "loss :  44.748783111572266\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "=================\n",
      "[185. 150. 246. 184. 110. 202. 336.  69.  69.  87.  66. 164. 265. 198.\n",
      " 248. 171. 102. 182. 262. 233. 151. 275. 230.  39.  42. 122.  81.  31.\n",
      " 156. 161.  80. 215. 310. 163. 265.  84.  54. 137. 248.  72. 248.  59.\n",
      "  97.  61.  72. 296.  55.  75.  53. 173. 158.  96. 140. 186.  93. 123.\n",
      " 237. 138. 292.  78. 182. 127. 321. 109. 212.  45.  96. 109.  89.  96.\n",
      "  60.  51. 200. 265.  68.  91. 172. 115. 125.  53.  63. 259. 214. 195.\n",
      " 258. 235. 173.  59. 219. 170.  77.  49.  66. 144. 113. 233. 162. 121.\n",
      "  88. 302. 128.  52. 178.  90. 164. 135. 103. 200. 178. 261.  64.  59.\n",
      "  79.  47. 107.  39. 151. 104. 217. 232.  55. 245. 131.  64. 222. 249.\n",
      " 128. 293. 138. 273. 158. 168. 103.]\n",
      "[[126.64497 ]\n",
      " [122.39296 ]\n",
      " [239.11876 ]\n",
      " [174.18452 ]\n",
      " [145.47435 ]\n",
      " [168.76888 ]\n",
      " [293.0391  ]\n",
      " [ 68.68572 ]\n",
      " [ 75.382484]\n",
      " [136.83395 ]\n",
      " [131.14554 ]\n",
      " [168.13121 ]\n",
      " [144.26778 ]\n",
      " [215.03764 ]\n",
      " [259.80188 ]\n",
      " [165.92957 ]\n",
      " [ 55.895737]\n",
      " [160.11734 ]\n",
      " [154.24529 ]\n",
      " [195.62411 ]\n",
      " [183.69542 ]\n",
      " [274.8298  ]\n",
      " [122.396774]\n",
      " [ 44.630577]\n",
      " [ 83.62256 ]\n",
      " [199.51317 ]\n",
      " [ 88.179245]\n",
      " [107.68447 ]\n",
      " [129.14575 ]\n",
      " [156.98709 ]\n",
      " [ 59.004192]\n",
      " [270.07895 ]\n",
      " [221.91864 ]\n",
      " [255.17896 ]\n",
      " [182.70445 ]\n",
      " [ 98.77794 ]\n",
      " [ 62.123783]\n",
      " [112.83629 ]\n",
      " [243.02557 ]\n",
      " [ 98.49939 ]\n",
      " [179.7233  ]\n",
      " [ 90.823074]\n",
      " [132.75671 ]\n",
      " [125.21884 ]\n",
      " [ 96.11947 ]\n",
      " [239.20984 ]\n",
      " [118.29277 ]\n",
      " [110.9749  ]\n",
      " [ 68.329414]\n",
      " [251.32071 ]\n",
      " [120.60003 ]\n",
      " [103.1375  ]\n",
      " [193.09573 ]\n",
      " [193.44302 ]\n",
      " [172.01534 ]\n",
      " [190.56247 ]\n",
      " [252.21407 ]\n",
      " [157.29132 ]\n",
      " [205.34402 ]\n",
      " [189.31331 ]\n",
      " [127.148834]\n",
      " [136.36311 ]\n",
      " [262.43433 ]\n",
      " [232.45041 ]\n",
      " [176.96637 ]\n",
      " [ 42.061985]\n",
      " [ 78.33972 ]\n",
      " [185.08191 ]\n",
      " [104.75549 ]\n",
      " [ 79.995285]\n",
      " [ 97.810074]\n",
      " [ 77.837654]\n",
      " [170.71922 ]\n",
      " [197.72305 ]\n",
      " [142.5372  ]\n",
      " [153.75987 ]\n",
      " [147.90338 ]\n",
      " [119.873856]\n",
      " [119.514786]\n",
      " [104.73797 ]\n",
      " [ 86.69325 ]\n",
      " [140.18529 ]\n",
      " [155.91301 ]\n",
      " [250.6623  ]\n",
      " [334.3286  ]\n",
      " [190.51134 ]\n",
      " [197.62613 ]\n",
      " [ 78.05317 ]\n",
      " [134.17801 ]\n",
      " [159.81097 ]\n",
      " [152.85153 ]\n",
      " [ 50.918262]\n",
      " [175.88821 ]\n",
      " [160.9606  ]\n",
      " [128.08363 ]\n",
      " [296.71542 ]\n",
      " [168.02768 ]\n",
      " [236.88562 ]\n",
      " [125.5373  ]\n",
      " [139.88449 ]\n",
      " [ 62.797157]\n",
      " [ 64.310905]\n",
      " [104.01019 ]\n",
      " [160.2859  ]\n",
      " [183.1063  ]\n",
      " [ 50.741695]\n",
      " [127.03967 ]\n",
      " [171.57591 ]\n",
      " [216.25699 ]\n",
      " [289.80307 ]\n",
      " [ 81.30929 ]\n",
      " [135.43068 ]\n",
      " [128.22552 ]\n",
      " [ 95.37073 ]\n",
      " [ 90.1658  ]\n",
      " [110.9749  ]\n",
      " [215.24808 ]\n",
      " [ 83.24373 ]\n",
      " [203.15811 ]\n",
      " [234.30841 ]\n",
      " [150.00241 ]\n",
      " [127.355286]\n",
      " [161.37878 ]\n",
      " [100.70325 ]\n",
      " [205.02983 ]\n",
      " [213.21921 ]\n",
      " [268.98322 ]\n",
      " [209.34845 ]\n",
      " [ 65.05236 ]\n",
      " [268.9162  ]\n",
      " [ 78.1525  ]\n",
      " [185.29936 ]\n",
      " [119.10834 ]]\n",
      "=================\n",
      "R2 :  0.46012528063836355\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 37.5101\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 38.2372\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 39.0915\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 37.1073\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.6490\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 41.2309\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 37.6725\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 38.3730\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 38.3271\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 37.2604\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 37.2541\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 37.6013\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 37.2599\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 38.4015\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 37.9645\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 38.3897\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 37.4550\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 37.2046\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 37.3054\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 37.6850\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 37.3633\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 38.2783\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 38.9446\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.5572\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 37.1584\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.7210\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 35.2585\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 39.8601\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 37.0882\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 35.8358\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.6609\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 38.0454\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.9845\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 37.0339\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 38.2685\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.3147\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 38.2718\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.4353\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 37.9390\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 35.3877\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 40.2909\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.2078\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 38.3064\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 35.7818\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 39.0826\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 37.9261\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.2727\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 37.8444\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 35.5969\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.9708\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 38.6574\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 35.2750\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 37.1132\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 37.1825\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.9037\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 37.4897\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 35.8403\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.8470\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 38.9926\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 37.1242\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 37.0758\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 35.9578\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.7838\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.1979\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.3334\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.4312\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 37.5908\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.7484\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.8105\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.6385\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 37.8008\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 38.5239\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.0659\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 35.7487\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.3844\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 35.9720\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.5868\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.0534\n",
      "Epoch 79/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 140us/step - loss: 36.0534\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 46.1226\n",
      "loss :  46.1225700378418\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "=================\n",
      "[185. 150. 246. 184. 110. 202. 336.  69.  69.  87.  66. 164. 265. 198.\n",
      " 248. 171. 102. 182. 262. 233. 151. 275. 230.  39.  42. 122.  81.  31.\n",
      " 156. 161.  80. 215. 310. 163. 265.  84.  54. 137. 248.  72. 248.  59.\n",
      "  97.  61.  72. 296.  55.  75.  53. 173. 158.  96. 140. 186.  93. 123.\n",
      " 237. 138. 292.  78. 182. 127. 321. 109. 212.  45.  96. 109.  89.  96.\n",
      "  60.  51. 200. 265.  68.  91. 172. 115. 125.  53.  63. 259. 214. 195.\n",
      " 258. 235. 173.  59. 219. 170.  77.  49.  66. 144. 113. 233. 162. 121.\n",
      "  88. 302. 128.  52. 178.  90. 164. 135. 103. 200. 178. 261.  64.  59.\n",
      "  79.  47. 107.  39. 151. 104. 217. 232.  55. 245. 131.  64. 222. 249.\n",
      " 128. 293. 138. 273. 158. 168. 103.]\n",
      "[[106.44851 ]\n",
      " [125.28498 ]\n",
      " [231.35316 ]\n",
      " [170.0606  ]\n",
      " [113.02219 ]\n",
      " [148.12761 ]\n",
      " [282.1343  ]\n",
      " [ 69.02589 ]\n",
      " [ 83.04526 ]\n",
      " [168.52495 ]\n",
      " [143.19499 ]\n",
      " [171.08516 ]\n",
      " [124.07545 ]\n",
      " [216.44148 ]\n",
      " [255.38365 ]\n",
      " [176.1581  ]\n",
      " [ 50.54174 ]\n",
      " [152.7646  ]\n",
      " [136.61142 ]\n",
      " [201.22859 ]\n",
      " [191.14479 ]\n",
      " [259.51187 ]\n",
      " [133.82596 ]\n",
      " [ 48.28009 ]\n",
      " [ 85.54521 ]\n",
      " [202.80458 ]\n",
      " [ 71.93944 ]\n",
      " [ 99.48957 ]\n",
      " [122.78193 ]\n",
      " [143.29556 ]\n",
      " [ 48.28009 ]\n",
      " [265.0792  ]\n",
      " [213.06912 ]\n",
      " [246.36276 ]\n",
      " [179.61856 ]\n",
      " [105.74906 ]\n",
      " [ 65.79456 ]\n",
      " [ 95.49026 ]\n",
      " [254.75926 ]\n",
      " [ 98.17498 ]\n",
      " [181.5969  ]\n",
      " [ 80.21043 ]\n",
      " [125.68827 ]\n",
      " [124.777   ]\n",
      " [ 90.56398 ]\n",
      " [246.4363  ]\n",
      " [110.52966 ]\n",
      " [ 94.69642 ]\n",
      " [ 70.39619 ]\n",
      " [252.17526 ]\n",
      " [121.820885]\n",
      " [114.70052 ]\n",
      " [201.47818 ]\n",
      " [192.73082 ]\n",
      " [175.95303 ]\n",
      " [177.20193 ]\n",
      " [241.16164 ]\n",
      " [168.71513 ]\n",
      " [212.38919 ]\n",
      " [181.32632 ]\n",
      " [127.880226]\n",
      " [115.063286]\n",
      " [258.1771  ]\n",
      " [244.29106 ]\n",
      " [175.1774  ]\n",
      " [ 48.28009 ]\n",
      " [ 79.45505 ]\n",
      " [206.0544  ]\n",
      " [116.03483 ]\n",
      " [ 77.11452 ]\n",
      " [ 98.51061 ]\n",
      " [ 81.03017 ]\n",
      " [175.59106 ]\n",
      " [196.91452 ]\n",
      " [142.53511 ]\n",
      " [161.49294 ]\n",
      " [141.63843 ]\n",
      " [119.88366 ]\n",
      " [109.720795]\n",
      " [ 99.47945 ]\n",
      " [ 80.07855 ]\n",
      " [141.41704 ]\n",
      " [160.33124 ]\n",
      " [251.98108 ]\n",
      " [320.37576 ]\n",
      " [156.23453 ]\n",
      " [202.31265 ]\n",
      " [ 70.123634]\n",
      " [141.25893 ]\n",
      " [125.59692 ]\n",
      " [164.50298 ]\n",
      " [ 54.8383  ]\n",
      " [183.31377 ]\n",
      " [170.51782 ]\n",
      " [136.03072 ]\n",
      " [288.8934  ]\n",
      " [168.03539 ]\n",
      " [238.81023 ]\n",
      " [120.58922 ]\n",
      " [136.40717 ]\n",
      " [ 64.208855]\n",
      " [ 69.17513 ]\n",
      " [ 92.05629 ]\n",
      " [156.11977 ]\n",
      " [175.91986 ]\n",
      " [ 48.31048 ]\n",
      " [117.63463 ]\n",
      " [175.07285 ]\n",
      " [188.57045 ]\n",
      " [287.31653 ]\n",
      " [ 77.505394]\n",
      " [138.87886 ]\n",
      " [133.40115 ]\n",
      " [ 87.85379 ]\n",
      " [ 96.50344 ]\n",
      " [105.11547 ]\n",
      " [198.36421 ]\n",
      " [ 87.22843 ]\n",
      " [191.33833 ]\n",
      " [236.9821  ]\n",
      " [143.83205 ]\n",
      " [119.60795 ]\n",
      " [140.19672 ]\n",
      " [ 82.530716]\n",
      " [213.94351 ]\n",
      " [215.81813 ]\n",
      " [269.51227 ]\n",
      " [216.06718 ]\n",
      " [ 70.739   ]\n",
      " [260.40698 ]\n",
      " [ 87.00007 ]\n",
      " [186.97649 ]\n",
      " [144.01675 ]]\n",
      "=================\n",
      "R2 :  0.42853827864388017\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 35.8097\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.7354\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 35.9860\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.2971\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 35.8967\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.4538\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 37.4734\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 35.8180\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 37.0091\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 35.9071\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.3853\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.3855\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 35.8815\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.2759\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.3210\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 34.8810\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.2484\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.3785\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 37.6208\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 34.2617\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.4763\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 37.5537\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 34.9621\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 35.8125\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.3365\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.8812\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 34.6693\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 37.4780\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.8279\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 38.4865\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.3018\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.3902\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.3588\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 37.3179\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.1316\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 35.8325\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 35.2693\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 37.8499\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 34.8770\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.8458\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 34.6726\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 34.7598\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 35.7403\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.1184\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.9428\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.0611\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 34.0432\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 37.4690\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.9308\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 35.1212\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 37.4438\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.0855\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 38.1590\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.5401\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 34.9887\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.1930\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.8560\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 35.1907\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 35.0012\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 37.1616\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.6348\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 35.7151\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 35.2807\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 35.3215\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.6530\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 37.7532\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.6549\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 35.7187\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 34.9359\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 35.3079\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 35.7971\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.1111\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.9868\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 35.9718\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.5241\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.4717\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 35.7709\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 35.2167\n",
      "Epoch 79/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 109us/step - loss: 35.2167\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 46.3521\n",
      "loss :  46.352108001708984\n",
      "5/5 [==============================] - 0s 997us/step\n",
      "=================\n",
      "[185. 150. 246. 184. 110. 202. 336.  69.  69.  87.  66. 164. 265. 198.\n",
      " 248. 171. 102. 182. 262. 233. 151. 275. 230.  39.  42. 122.  81.  31.\n",
      " 156. 161.  80. 215. 310. 163. 265.  84.  54. 137. 248.  72. 248.  59.\n",
      "  97.  61.  72. 296.  55.  75.  53. 173. 158.  96. 140. 186.  93. 123.\n",
      " 237. 138. 292.  78. 182. 127. 321. 109. 212.  45.  96. 109.  89.  96.\n",
      "  60.  51. 200. 265.  68.  91. 172. 115. 125.  53.  63. 259. 214. 195.\n",
      " 258. 235. 173.  59. 219. 170.  77.  49.  66. 144. 113. 233. 162. 121.\n",
      "  88. 302. 128.  52. 178.  90. 164. 135. 103. 200. 178. 261.  64.  59.\n",
      "  79.  47. 107.  39. 151. 104. 217. 232.  55. 245. 131.  64. 222. 249.\n",
      " 128. 293. 138. 273. 158. 168. 103.]\n",
      "[[106.24968 ]\n",
      " [108.44358 ]\n",
      " [197.77008 ]\n",
      " [147.61746 ]\n",
      " [104.280815]\n",
      " [129.61057 ]\n",
      " [243.86214 ]\n",
      " [ 62.027054]\n",
      " [ 68.41026 ]\n",
      " [159.60417 ]\n",
      " [133.26247 ]\n",
      " [147.24796 ]\n",
      " [115.68071 ]\n",
      " [183.15164 ]\n",
      " [227.97281 ]\n",
      " [146.16985 ]\n",
      " [ 48.879284]\n",
      " [140.887   ]\n",
      " [131.97725 ]\n",
      " [163.89128 ]\n",
      " [167.85794 ]\n",
      " [217.11206 ]\n",
      " [113.34894 ]\n",
      " [ 45.94006 ]\n",
      " [ 75.0381  ]\n",
      " [169.99979 ]\n",
      " [ 81.832954]\n",
      " [ 87.64094 ]\n",
      " [112.00728 ]\n",
      " [142.6474  ]\n",
      " [ 47.114155]\n",
      " [221.85611 ]\n",
      " [190.39374 ]\n",
      " [210.80263 ]\n",
      " [157.66403 ]\n",
      " [101.336655]\n",
      " [ 58.574192]\n",
      " [101.92664 ]\n",
      " [213.18817 ]\n",
      " [ 87.90786 ]\n",
      " [153.74594 ]\n",
      " [ 75.47696 ]\n",
      " [116.74568 ]\n",
      " [111.53146 ]\n",
      " [ 86.39738 ]\n",
      " [206.73022 ]\n",
      " [110.00358 ]\n",
      " [ 91.85779 ]\n",
      " [ 58.540592]\n",
      " [216.56549 ]\n",
      " [113.23577 ]\n",
      " [ 90.11011 ]\n",
      " [174.72375 ]\n",
      " [161.61255 ]\n",
      " [157.53691 ]\n",
      " [152.56686 ]\n",
      " [201.1974  ]\n",
      " [138.79565 ]\n",
      " [185.66107 ]\n",
      " [161.27646 ]\n",
      " [110.17598 ]\n",
      " [107.60232 ]\n",
      " [222.68121 ]\n",
      " [209.89697 ]\n",
      " [145.69374 ]\n",
      " [ 45.94006 ]\n",
      " [ 68.260735]\n",
      " [182.68134 ]\n",
      " [ 97.10193 ]\n",
      " [ 78.1929  ]\n",
      " [ 90.75809 ]\n",
      " [ 95.62585 ]\n",
      " [154.70898 ]\n",
      " [177.67133 ]\n",
      " [131.94873 ]\n",
      " [136.7723  ]\n",
      " [125.26924 ]\n",
      " [105.21634 ]\n",
      " [100.5293  ]\n",
      " [ 92.47754 ]\n",
      " [ 77.28459 ]\n",
      " [120.73956 ]\n",
      " [144.01216 ]\n",
      " [212.88062 ]\n",
      " [269.2477  ]\n",
      " [147.27394 ]\n",
      " [172.49084 ]\n",
      " [ 63.269226]\n",
      " [127.66544 ]\n",
      " [121.28192 ]\n",
      " [144.76404 ]\n",
      " [ 56.93709 ]\n",
      " [160.68892 ]\n",
      " [146.43625 ]\n",
      " [120.17297 ]\n",
      " [247.19122 ]\n",
      " [154.45595 ]\n",
      " [196.08145 ]\n",
      " [106.79061 ]\n",
      " [120.61847 ]\n",
      " [ 59.61749 ]\n",
      " [ 60.951523]\n",
      " [ 92.035614]\n",
      " [136.34042 ]\n",
      " [148.73055 ]\n",
      " [ 47.6421  ]\n",
      " [101.97046 ]\n",
      " [153.7633  ]\n",
      " [164.03307 ]\n",
      " [240.8268  ]\n",
      " [ 73.9507  ]\n",
      " [122.92758 ]\n",
      " [122.95353 ]\n",
      " [ 93.021286]\n",
      " [ 75.02626 ]\n",
      " [ 95.62585 ]\n",
      " [162.47008 ]\n",
      " [ 77.70213 ]\n",
      " [170.86124 ]\n",
      " [209.40807 ]\n",
      " [126.180504]\n",
      " [101.22021 ]\n",
      " [142.0785  ]\n",
      " [ 83.46622 ]\n",
      " [178.8179  ]\n",
      " [181.31087 ]\n",
      " [233.00671 ]\n",
      " [187.61578 ]\n",
      " [ 64.47289 ]\n",
      " [226.6907  ]\n",
      " [ 72.97923 ]\n",
      " [183.33524 ]\n",
      " [144.99277 ]]\n",
      "=================\n",
      "R2 :  0.4114695572225904\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.4108\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.8887\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.6122\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 35.1240\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.0356\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.5207\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 35.4852\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 37.2788\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.1418\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 35.8437\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 35.2363\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 35.6339\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.9695\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.0831\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.3447\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.8628\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.2564\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 35.5491\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.6755\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.9905\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.2030\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.9874\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 35.3603\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 35.2885\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.2957\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.5485\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.5036\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.9834\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 35.6603\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.2350\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.3549\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.5021\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 35.2579\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.7657\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 35.0761\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.3630\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.9210\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.6970\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.8519\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.8623\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.0655\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 35.6587\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 35.1001\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.1474\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.2813\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 35.3462\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.2297\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.3980\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.4420\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.3947\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.4021\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.6815\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 35.5037\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.7044\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 34.9746\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.2779\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.9086\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.6278\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.3549\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.2769\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 35.8410\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.3813\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.2650\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.5569\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.4072\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.5580\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.1774\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.1225\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.9911\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.7173\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.2145\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.7991\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.9967\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 34.3999\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.7638\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.9544\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 34.7448\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.3262\n",
      "Epoch 79/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 130us/step - loss: 33.3262\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 45.2568\n",
      "loss :  45.256832122802734\n",
      "5/5 [==============================] - 0s 748us/step\n",
      "=================\n",
      "[185. 150. 246. 184. 110. 202. 336.  69.  69.  87.  66. 164. 265. 198.\n",
      " 248. 171. 102. 182. 262. 233. 151. 275. 230.  39.  42. 122.  81.  31.\n",
      " 156. 161.  80. 215. 310. 163. 265.  84.  54. 137. 248.  72. 248.  59.\n",
      "  97.  61.  72. 296.  55.  75.  53. 173. 158.  96. 140. 186.  93. 123.\n",
      " 237. 138. 292.  78. 182. 127. 321. 109. 212.  45.  96. 109.  89.  96.\n",
      "  60.  51. 200. 265.  68.  91. 172. 115. 125.  53.  63. 259. 214. 195.\n",
      " 258. 235. 173.  59. 219. 170.  77.  49.  66. 144. 113. 233. 162. 121.\n",
      "  88. 302. 128.  52. 178.  90. 164. 135. 103. 200. 178. 261.  64.  59.\n",
      "  79.  47. 107.  39. 151. 104. 217. 232.  55. 245. 131.  64. 222. 249.\n",
      " 128. 293. 138. 273. 158. 168. 103.]\n",
      "[[ 97.2331  ]\n",
      " [112.850815]\n",
      " [215.17126 ]\n",
      " [155.96054 ]\n",
      " [119.20479 ]\n",
      " [153.22485 ]\n",
      " [263.83646 ]\n",
      " [ 72.37134 ]\n",
      " [ 73.514915]\n",
      " [152.51668 ]\n",
      " [156.03702 ]\n",
      " [157.47495 ]\n",
      " [111.57952 ]\n",
      " [195.11443 ]\n",
      " [227.86665 ]\n",
      " [171.43562 ]\n",
      " [ 58.948933]\n",
      " [161.04889 ]\n",
      " [122.17992 ]\n",
      " [176.37007 ]\n",
      " [179.9061  ]\n",
      " [236.72682 ]\n",
      " [132.30292 ]\n",
      " [ 47.9219  ]\n",
      " [ 79.357414]\n",
      " [178.00607 ]\n",
      " [ 73.350006]\n",
      " [ 95.529434]\n",
      " [129.9412  ]\n",
      " [144.16562 ]\n",
      " [ 60.843563]\n",
      " [233.77753 ]\n",
      " [207.23329 ]\n",
      " [200.40106 ]\n",
      " [171.76047 ]\n",
      " [ 82.234184]\n",
      " [ 60.18563 ]\n",
      " [133.00003 ]\n",
      " [236.33682 ]\n",
      " [ 95.92014 ]\n",
      " [169.81213 ]\n",
      " [ 79.06603 ]\n",
      " [128.65034 ]\n",
      " [119.30405 ]\n",
      " [ 99.97405 ]\n",
      " [233.63425 ]\n",
      " [122.299515]\n",
      " [ 92.06294 ]\n",
      " [ 61.049686]\n",
      " [235.92921 ]\n",
      " [122.88247 ]\n",
      " [ 90.40081 ]\n",
      " [192.91852 ]\n",
      " [179.64555 ]\n",
      " [170.78975 ]\n",
      " [158.55576 ]\n",
      " [218.37958 ]\n",
      " [164.91727 ]\n",
      " [200.41467 ]\n",
      " [172.15475 ]\n",
      " [118.748505]\n",
      " [118.44825 ]\n",
      " [258.74423 ]\n",
      " [233.84238 ]\n",
      " [150.94751 ]\n",
      " [ 47.9219  ]\n",
      " [ 67.26199 ]\n",
      " [173.90956 ]\n",
      " [ 79.45852 ]\n",
      " [ 98.66156 ]\n",
      " [ 83.79503 ]\n",
      " [ 90.14587 ]\n",
      " [166.65819 ]\n",
      " [197.51541 ]\n",
      " [143.93091 ]\n",
      " [155.74365 ]\n",
      " [133.34506 ]\n",
      " [114.87939 ]\n",
      " [119.38404 ]\n",
      " [105.883736]\n",
      " [ 78.34557 ]\n",
      " [129.75124 ]\n",
      " [156.62708 ]\n",
      " [236.29022 ]\n",
      " [287.59775 ]\n",
      " [142.4282  ]\n",
      " [186.14389 ]\n",
      " [ 66.47836 ]\n",
      " [104.50083 ]\n",
      " [129.69676 ]\n",
      " [167.75813 ]\n",
      " [ 52.2131  ]\n",
      " [173.16391 ]\n",
      " [153.9752  ]\n",
      " [127.382484]\n",
      " [269.8956  ]\n",
      " [167.41232 ]\n",
      " [204.28357 ]\n",
      " [115.6453  ]\n",
      " [128.12843 ]\n",
      " [ 50.51817 ]\n",
      " [ 67.74351 ]\n",
      " [100.339195]\n",
      " [144.30408 ]\n",
      " [146.52582 ]\n",
      " [ 49.818974]\n",
      " [107.78875 ]\n",
      " [164.2446  ]\n",
      " [168.74536 ]\n",
      " [218.26077 ]\n",
      " [ 88.24697 ]\n",
      " [132.70584 ]\n",
      " [135.57872 ]\n",
      " [ 83.09965 ]\n",
      " [ 88.99231 ]\n",
      " [ 93.729454]\n",
      " [178.6976  ]\n",
      " [ 78.67922 ]\n",
      " [175.16159 ]\n",
      " [220.2143  ]\n",
      " [132.26566 ]\n",
      " [106.703476]\n",
      " [143.82938 ]\n",
      " [101.397385]\n",
      " [199.37418 ]\n",
      " [185.67737 ]\n",
      " [248.28    ]\n",
      " [217.52426 ]\n",
      " [ 66.86641 ]\n",
      " [242.21362 ]\n",
      " [ 61.20576 ]\n",
      " [224.96039 ]\n",
      " [102.132515]]\n",
      "=================\n",
      "R2 :  0.429520999683491\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.3306\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.4879\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.9859\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.7765\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.9185\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 34.6966\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.6479\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.9411\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.2399\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.7025\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.7217\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.5763\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.7251\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.3526\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.7237\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.3518\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.7448\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.1030\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 35.0181\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.6672\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.3937\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.9459\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.7809\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.6032\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.7938\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.4809\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.5801\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.0307\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.6275\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 35.5016\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.2935\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.4882\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.4172\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.9292\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.6336\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.1352\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.4284\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.7448\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.4805\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.6126\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.8468\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.9852\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.0717\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.1066\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.5214\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.2985\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.6237\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.3027\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.6740\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.3162\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.5636\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.7092\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.1017\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.1411\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.0657\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.9174\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.2031\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.7743\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.6451\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 34.5805\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.1259\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.7243\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.1643\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.5877\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.9230\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.3905\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.1295\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.5613\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.7895\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.7667\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.2547\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.7469\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.1159\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.3647\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.9641\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 35.1139\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.1543\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.0401\n",
      "Epoch 79/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 120us/step - loss: 31.0401\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 46.1587\n",
      "loss :  46.158748626708984\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "=================\n",
      "[185. 150. 246. 184. 110. 202. 336.  69.  69.  87.  66. 164. 265. 198.\n",
      " 248. 171. 102. 182. 262. 233. 151. 275. 230.  39.  42. 122.  81.  31.\n",
      " 156. 161.  80. 215. 310. 163. 265.  84.  54. 137. 248.  72. 248.  59.\n",
      "  97.  61.  72. 296.  55.  75.  53. 173. 158.  96. 140. 186.  93. 123.\n",
      " 237. 138. 292.  78. 182. 127. 321. 109. 212.  45.  96. 109.  89.  96.\n",
      "  60.  51. 200. 265.  68.  91. 172. 115. 125.  53.  63. 259. 214. 195.\n",
      " 258. 235. 173.  59. 219. 170.  77.  49.  66. 144. 113. 233. 162. 121.\n",
      "  88. 302. 128.  52. 178.  90. 164. 135. 103. 200. 178. 261.  64.  59.\n",
      "  79.  47. 107.  39. 151. 104. 217. 232.  55. 245. 131.  64. 222. 249.\n",
      " 128. 293. 138. 273. 158. 168. 103.]\n",
      "[[120.91799 ]\n",
      " [123.911644]\n",
      " [229.8096  ]\n",
      " [158.36414 ]\n",
      " [139.67395 ]\n",
      " [196.29526 ]\n",
      " [278.1683  ]\n",
      " [ 72.236176]\n",
      " [ 77.87443 ]\n",
      " [197.10458 ]\n",
      " [148.26231 ]\n",
      " [165.57005 ]\n",
      " [140.23102 ]\n",
      " [202.00739 ]\n",
      " [281.82944 ]\n",
      " [191.4891  ]\n",
      " [ 74.99681 ]\n",
      " [173.38513 ]\n",
      " [145.58505 ]\n",
      " [179.83528 ]\n",
      " [195.10881 ]\n",
      " [253.76369 ]\n",
      " [145.37346 ]\n",
      " [ 51.524162]\n",
      " [ 82.90452 ]\n",
      " [191.45918 ]\n",
      " [ 82.89262 ]\n",
      " [ 86.773575]\n",
      " [141.9502  ]\n",
      " [171.98897 ]\n",
      " [ 78.80965 ]\n",
      " [249.79497 ]\n",
      " [223.48416 ]\n",
      " [226.94283 ]\n",
      " [178.85483 ]\n",
      " [106.878944]\n",
      " [ 61.612267]\n",
      " [144.99742 ]\n",
      " [258.10733 ]\n",
      " [103.090675]\n",
      " [189.1104  ]\n",
      " [ 80.23344 ]\n",
      " [130.06876 ]\n",
      " [121.84643 ]\n",
      " [ 95.44576 ]\n",
      " [252.84164 ]\n",
      " [135.56052 ]\n",
      " [102.65177 ]\n",
      " [ 60.471203]\n",
      " [260.86618 ]\n",
      " [131.47995 ]\n",
      " [ 89.28559 ]\n",
      " [206.33838 ]\n",
      " [193.97833 ]\n",
      " [182.97462 ]\n",
      " [164.16307 ]\n",
      " [226.46352 ]\n",
      " [185.12625 ]\n",
      " [208.96591 ]\n",
      " [182.97919 ]\n",
      " [119.66285 ]\n",
      " [138.22375 ]\n",
      " [272.87344 ]\n",
      " [246.75516 ]\n",
      " [157.785   ]\n",
      " [ 51.524162]\n",
      " [ 70.133   ]\n",
      " [242.43153 ]\n",
      " [118.0312  ]\n",
      " [ 94.682045]\n",
      " [100.94953 ]\n",
      " [ 88.40312 ]\n",
      " [187.10088 ]\n",
      " [213.06598 ]\n",
      " [153.68181 ]\n",
      " [167.55261 ]\n",
      " [139.3234  ]\n",
      " [128.76953 ]\n",
      " [123.91915 ]\n",
      " [112.83955 ]\n",
      " [ 76.453964]\n",
      " [139.83719 ]\n",
      " [167.89636 ]\n",
      " [256.39087 ]\n",
      " [310.25345 ]\n",
      " [165.77734 ]\n",
      " [194.02786 ]\n",
      " [ 67.76148 ]\n",
      " [126.195625]\n",
      " [156.47096 ]\n",
      " [179.90031 ]\n",
      " [ 55.308357]\n",
      " [179.16449 ]\n",
      " [161.23682 ]\n",
      " [138.7143  ]\n",
      " [290.86325 ]\n",
      " [188.00876 ]\n",
      " [216.48082 ]\n",
      " [115.89404 ]\n",
      " [129.91042 ]\n",
      " [ 51.524162]\n",
      " [ 66.338394]\n",
      " [146.70087 ]\n",
      " [149.79166 ]\n",
      " [155.20805 ]\n",
      " [ 51.524162]\n",
      " [ 94.88575 ]\n",
      " [166.86449 ]\n",
      " [198.5401  ]\n",
      " [219.44759 ]\n",
      " [ 87.055855]\n",
      " [137.94794 ]\n",
      " [138.89514 ]\n",
      " [ 91.78093 ]\n",
      " [ 94.24923 ]\n",
      " [ 93.31434 ]\n",
      " [189.89038 ]\n",
      " [ 84.15939 ]\n",
      " [194.00638 ]\n",
      " [267.6758  ]\n",
      " [133.63412 ]\n",
      " [110.47462 ]\n",
      " [161.07211 ]\n",
      " [ 92.66079 ]\n",
      " [217.23328 ]\n",
      " [198.35529 ]\n",
      " [264.5015  ]\n",
      " [229.92245 ]\n",
      " [ 71.13572 ]\n",
      " [257.68243 ]\n",
      " [ 65.89257 ]\n",
      " [277.71558 ]\n",
      " [141.63454 ]]\n",
      "=================\n",
      "R2 :  0.41720282861649494\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.5027\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.1421\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.0696\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.8381\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.5242\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.7866\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.1103\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.4965\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.6360\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.1427\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.8043\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.9896\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.5731\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.5155\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.0354\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.8854\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.5345\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.1806\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.5440\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.0022\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.7433\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.3336\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.2971\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.4341\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.6654\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.9545\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.1742\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.2166\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.6109\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.8537\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.9567\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.8578\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.5716\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.2262\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.7704\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.5750\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.9081\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.7380\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.8239\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.0593\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.7512\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.9290\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.8521\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.7092\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.8130\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.3130\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.2808\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.1725\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.4980\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.5112\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.8354\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.5300\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.3305\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.9717\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.9250\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.6755\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.2853\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.0836\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.4182\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.1587\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.3509\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.7217\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.3408\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.8703\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.1128\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.7513\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.5542\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.2341\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.7685\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.1429\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.1319\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.0445\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.8392\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.9300\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.6266\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.3762\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.1224\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.2303\n",
      "Epoch 79/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 120us/step - loss: 30.2303\n",
      "5/5 [==============================] - 0s 997us/step - loss: 45.6161\n",
      "loss :  45.6160888671875\n",
      "5/5 [==============================] - 0s 748us/step\n",
      "=================\n",
      "[185. 150. 246. 184. 110. 202. 336.  69.  69.  87.  66. 164. 265. 198.\n",
      " 248. 171. 102. 182. 262. 233. 151. 275. 230.  39.  42. 122.  81.  31.\n",
      " 156. 161.  80. 215. 310. 163. 265.  84.  54. 137. 248.  72. 248.  59.\n",
      "  97.  61.  72. 296.  55.  75.  53. 173. 158.  96. 140. 186.  93. 123.\n",
      " 237. 138. 292.  78. 182. 127. 321. 109. 212.  45.  96. 109.  89.  96.\n",
      "  60.  51. 200. 265.  68.  91. 172. 115. 125.  53.  63. 259. 214. 195.\n",
      " 258. 235. 173.  59. 219. 170.  77.  49.  66. 144. 113. 233. 162. 121.\n",
      "  88. 302. 128.  52. 178.  90. 164. 135. 103. 200. 178. 261.  64.  59.\n",
      "  79.  47. 107.  39. 151. 104. 217. 232.  55. 245. 131.  64. 222. 249.\n",
      " 128. 293. 138. 273. 158. 168. 103.]\n",
      "[[136.01932 ]\n",
      " [132.6798  ]\n",
      " [219.08104 ]\n",
      " [155.43965 ]\n",
      " [154.34547 ]\n",
      " [215.95659 ]\n",
      " [289.69623 ]\n",
      " [ 75.44508 ]\n",
      " [ 80.34714 ]\n",
      " [163.49141 ]\n",
      " [135.26375 ]\n",
      " [156.89662 ]\n",
      " [137.83391 ]\n",
      " [188.96722 ]\n",
      " [306.9663  ]\n",
      " [193.89505 ]\n",
      " [ 80.234055]\n",
      " [183.1703  ]\n",
      " [138.34933 ]\n",
      " [177.07022 ]\n",
      " [190.45464 ]\n",
      " [251.39981 ]\n",
      " [150.85338 ]\n",
      " [ 52.468002]\n",
      " [ 85.39447 ]\n",
      " [190.20927 ]\n",
      " [ 88.89435 ]\n",
      " [ 82.71299 ]\n",
      " [151.09926 ]\n",
      " [188.54813 ]\n",
      " [ 83.538666]\n",
      " [237.33528 ]\n",
      " [217.1452  ]\n",
      " [225.00716 ]\n",
      " [188.50475 ]\n",
      " [106.64015 ]\n",
      " [ 65.60369 ]\n",
      " [124.21046 ]\n",
      " [263.15186 ]\n",
      " [118.542206]\n",
      " [204.70187 ]\n",
      " [ 77.47331 ]\n",
      " [124.800934]\n",
      " [115.04628 ]\n",
      " [ 91.91661 ]\n",
      " [238.55891 ]\n",
      " [142.41559 ]\n",
      " [104.144135]\n",
      " [ 63.367188]\n",
      " [249.75667 ]\n",
      " [119.92935 ]\n",
      " [ 85.40196 ]\n",
      " [193.34093 ]\n",
      " [215.17302 ]\n",
      " [171.65112 ]\n",
      " [152.03279 ]\n",
      " [219.23833 ]\n",
      " [188.50827 ]\n",
      " [206.35886 ]\n",
      " [185.13991 ]\n",
      " [115.22922 ]\n",
      " [148.8094  ]\n",
      " [288.10944 ]\n",
      " [233.16869 ]\n",
      " [149.69096 ]\n",
      " [ 48.042297]\n",
      " [ 69.47175 ]\n",
      " [259.61185 ]\n",
      " [162.61949 ]\n",
      " [ 97.62448 ]\n",
      " [109.25549 ]\n",
      " [ 81.20406 ]\n",
      " [185.74135 ]\n",
      " [211.04425 ]\n",
      " [146.91017 ]\n",
      " [170.0243  ]\n",
      " [136.36156 ]\n",
      " [138.78969 ]\n",
      " [129.48048 ]\n",
      " [107.87996 ]\n",
      " [ 71.5077  ]\n",
      " [137.53233 ]\n",
      " [157.77083 ]\n",
      " [255.51427 ]\n",
      " [298.90964 ]\n",
      " [151.42137 ]\n",
      " [195.07056 ]\n",
      " [ 66.38087 ]\n",
      " [133.54198 ]\n",
      " [172.48128 ]\n",
      " [177.93277 ]\n",
      " [ 63.29425 ]\n",
      " [174.13707 ]\n",
      " [166.2725  ]\n",
      " [136.04384 ]\n",
      " [277.81873 ]\n",
      " [181.02129 ]\n",
      " [204.8238  ]\n",
      " [118.610886]\n",
      " [123.07361 ]\n",
      " [ 51.909695]\n",
      " [ 65.74703 ]\n",
      " [176.63837 ]\n",
      " [155.99066 ]\n",
      " [156.18489 ]\n",
      " [ 56.079773]\n",
      " [ 92.655174]\n",
      " [158.93419 ]\n",
      " [189.02834 ]\n",
      " [247.68465 ]\n",
      " [ 89.78006 ]\n",
      " [133.66557 ]\n",
      " [135.4338  ]\n",
      " [ 89.482994]\n",
      " [ 89.33165 ]\n",
      " [ 81.717575]\n",
      " [190.16147 ]\n",
      " [ 88.309204]\n",
      " [184.78102 ]\n",
      " [253.79251 ]\n",
      " [134.68123 ]\n",
      " [109.72676 ]\n",
      " [154.20998 ]\n",
      " [ 82.043396]\n",
      " [215.00044 ]\n",
      " [198.95369 ]\n",
      " [244.23409 ]\n",
      " [229.85759 ]\n",
      " [ 66.40683 ]\n",
      " [265.16266 ]\n",
      " [ 67.158585]\n",
      " [281.9615  ]\n",
      " [135.0553  ]]\n",
      "=================\n",
      "R2 :  0.434556041975225\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.8450\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.6414\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.8732\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.9234\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.8568\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.6539\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.1482\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.9916\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.2914\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.1776\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.9160\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.3916\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.5406\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.7772\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.3081\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.7549\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.8309\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.8170\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.3625\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.6786\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.1263\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.4411\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.5842\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.0661\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.0023\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.8176\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.4753\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.7310\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.8229\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.0263\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.3771\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.7452\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.5280\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.3279\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.3558\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.9560\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.1244\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.6805\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.8813\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.6658\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.5194\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.2212\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.4933\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.0435\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.8248\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.1171\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.5574\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.4540\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.1260\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.8079\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.3635\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.9696\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.2433\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.7126\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.4820\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.1497\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.8187\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.6359\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.7805\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.5646\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.4003\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.4868\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.4759\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.0846\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.8806\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.9840\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.5545\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.8474\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.0373\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.7430\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.6273\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.8678\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.8738\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.4427\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.1817\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.3311\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.7574\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.3587\n",
      "Epoch 79/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 119us/step - loss: 29.3587\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 45.4574\n",
      "loss :  45.457435607910156\n",
      "5/5 [==============================] - 0s 748us/step\n",
      "=================\n",
      "[185. 150. 246. 184. 110. 202. 336.  69.  69.  87.  66. 164. 265. 198.\n",
      " 248. 171. 102. 182. 262. 233. 151. 275. 230.  39.  42. 122.  81.  31.\n",
      " 156. 161.  80. 215. 310. 163. 265.  84.  54. 137. 248.  72. 248.  59.\n",
      "  97.  61.  72. 296.  55.  75.  53. 173. 158.  96. 140. 186.  93. 123.\n",
      " 237. 138. 292.  78. 182. 127. 321. 109. 212.  45.  96. 109.  89.  96.\n",
      "  60.  51. 200. 265.  68.  91. 172. 115. 125.  53.  63. 259. 214. 195.\n",
      " 258. 235. 173.  59. 219. 170.  77.  49.  66. 144. 113. 233. 162. 121.\n",
      "  88. 302. 128.  52. 178.  90. 164. 135. 103. 200. 178. 261.  64.  59.\n",
      "  79.  47. 107.  39. 151. 104. 217. 232.  55. 245. 131.  64. 222. 249.\n",
      " 128. 293. 138. 273. 158. 168. 103.]\n",
      "[[131.57347 ]\n",
      " [134.49728 ]\n",
      " [214.92516 ]\n",
      " [166.09709 ]\n",
      " [162.8803  ]\n",
      " [210.59145 ]\n",
      " [270.87848 ]\n",
      " [ 78.71102 ]\n",
      " [ 82.95641 ]\n",
      " [139.48802 ]\n",
      " [121.381485]\n",
      " [155.36632 ]\n",
      " [140.60683 ]\n",
      " [187.91486 ]\n",
      " [295.89645 ]\n",
      " [196.89459 ]\n",
      " [ 80.03119 ]\n",
      " [202.82603 ]\n",
      " [134.93855 ]\n",
      " [181.61421 ]\n",
      " [193.6122  ]\n",
      " [256.28632 ]\n",
      " [150.54968 ]\n",
      " [ 53.12334 ]\n",
      " [ 87.84818 ]\n",
      " [191.08098 ]\n",
      " [ 82.19688 ]\n",
      " [ 94.39523 ]\n",
      " [163.83936 ]\n",
      " [177.1707  ]\n",
      " [ 86.21743 ]\n",
      " [237.37276 ]\n",
      " [221.77791 ]\n",
      " [218.42819 ]\n",
      " [202.43822 ]\n",
      " [103.96171 ]\n",
      " [ 66.860794]\n",
      " [119.03568 ]\n",
      " [250.94809 ]\n",
      " [128.2343  ]\n",
      " [216.88914 ]\n",
      " [ 82.29599 ]\n",
      " [135.16252 ]\n",
      " [124.100174]\n",
      " [ 83.15742 ]\n",
      " [215.82396 ]\n",
      " [145.94281 ]\n",
      " [102.17575 ]\n",
      " [ 64.90843 ]\n",
      " [225.67223 ]\n",
      " [126.25338 ]\n",
      " [ 84.64207 ]\n",
      " [199.15022 ]\n",
      " [204.22554 ]\n",
      " [176.2043  ]\n",
      " [142.96715 ]\n",
      " [220.54904 ]\n",
      " [187.76193 ]\n",
      " [214.37292 ]\n",
      " [194.88911 ]\n",
      " [115.41665 ]\n",
      " [131.49532 ]\n",
      " [285.66962 ]\n",
      " [232.86903 ]\n",
      " [144.03867 ]\n",
      " [ 48.94293 ]\n",
      " [ 72.068115]\n",
      " [225.65413 ]\n",
      " [156.80882 ]\n",
      " [106.56106 ]\n",
      " [101.2144  ]\n",
      " [ 78.26591 ]\n",
      " [199.66823 ]\n",
      " [213.53424 ]\n",
      " [150.59438 ]\n",
      " [168.52655 ]\n",
      " [133.8241  ]\n",
      " [132.48058 ]\n",
      " [143.00826 ]\n",
      " [113.68188 ]\n",
      " [ 74.75506 ]\n",
      " [133.57861 ]\n",
      " [162.44165 ]\n",
      " [266.36023 ]\n",
      " [296.83325 ]\n",
      " [144.98796 ]\n",
      " [200.4187  ]\n",
      " [ 66.78189 ]\n",
      " [110.246284]\n",
      " [162.90475 ]\n",
      " [165.2579  ]\n",
      " [ 64.88875 ]\n",
      " [181.47481 ]\n",
      " [169.20451 ]\n",
      " [154.50597 ]\n",
      " [291.9328  ]\n",
      " [187.85489 ]\n",
      " [199.46478 ]\n",
      " [126.47538 ]\n",
      " [124.20808 ]\n",
      " [ 53.70011 ]\n",
      " [ 66.91514 ]\n",
      " [178.80647 ]\n",
      " [161.14532 ]\n",
      " [153.5904  ]\n",
      " [ 56.499638]\n",
      " [ 97.081406]\n",
      " [166.3394  ]\n",
      " [192.00433 ]\n",
      " [210.76753 ]\n",
      " [ 92.5018  ]\n",
      " [140.56007 ]\n",
      " [140.61513 ]\n",
      " [ 91.38161 ]\n",
      " [ 82.76737 ]\n",
      " [ 80.7998  ]\n",
      " [200.4496  ]\n",
      " [ 94.18541 ]\n",
      " [168.1128  ]\n",
      " [237.83301 ]\n",
      " [139.98477 ]\n",
      " [115.89367 ]\n",
      " [136.84859 ]\n",
      " [ 78.47383 ]\n",
      " [213.87529 ]\n",
      " [195.29918 ]\n",
      " [238.24748 ]\n",
      " [222.14587 ]\n",
      " [ 64.729324]\n",
      " [268.48334 ]\n",
      " [ 66.26397 ]\n",
      " [236.98311 ]\n",
      " [109.83106 ]]\n",
      "=================\n",
      "R2 :  0.4424153325705976\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.0344\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.7972\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.5794\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.5519\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.4649\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 27.0576\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 31.6821\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 30.1196\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.4138\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 30.3228\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.6957\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 27.8109\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.7132\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.6609\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.5561\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.9423\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.4706\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.0978\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.5714\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.4301\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.8619\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.4632\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.2490\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.8498\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.6112\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.7170\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.8703\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.3183\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.7979\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.1359\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.6562\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.4942\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.9801\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.1264\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.2454\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.4579\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.4771\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.7880\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.0033\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.3503\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.1797\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.2981\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.5179\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.8451\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.5138\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.1556\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.1132\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.2052\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.8596\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.8313\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.0725\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.7022\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.9026\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.7656\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.1529\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.3931\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.9290\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.3814\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.2175\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.0609\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.6853\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.3146\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.5163\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.9434\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 27.4387\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.3699\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.3422\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.9565\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.9572\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.4393\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.9427\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.9601\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.5955\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.5680\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.7388\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.6776\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.3865\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.9511\n",
      "Epoch 79/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 110us/step - loss: 27.9511\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 45.0844\n",
      "loss :  45.08443832397461\n",
      "5/5 [==============================] - 0s 731us/step\n",
      "=================\n",
      "[185. 150. 246. 184. 110. 202. 336.  69.  69.  87.  66. 164. 265. 198.\n",
      " 248. 171. 102. 182. 262. 233. 151. 275. 230.  39.  42. 122.  81.  31.\n",
      " 156. 161.  80. 215. 310. 163. 265.  84.  54. 137. 248.  72. 248.  59.\n",
      "  97.  61.  72. 296.  55.  75.  53. 173. 158.  96. 140. 186.  93. 123.\n",
      " 237. 138. 292.  78. 182. 127. 321. 109. 212.  45.  96. 109.  89.  96.\n",
      "  60.  51. 200. 265.  68.  91. 172. 115. 125.  53.  63. 259. 214. 195.\n",
      " 258. 235. 173.  59. 219. 170.  77.  49.  66. 144. 113. 233. 162. 121.\n",
      "  88. 302. 128.  52. 178.  90. 164. 135. 103. 200. 178. 261.  64.  59.\n",
      "  79.  47. 107.  39. 151. 104. 217. 232.  55. 245. 131.  64. 222. 249.\n",
      " 128. 293. 138. 273. 158. 168. 103.]\n",
      "[[117.25179 ]\n",
      " [139.5905  ]\n",
      " [200.92068 ]\n",
      " [149.7016  ]\n",
      " [161.86293 ]\n",
      " [220.34612 ]\n",
      " [259.885   ]\n",
      " [ 78.16436 ]\n",
      " [ 76.88568 ]\n",
      " [129.01192 ]\n",
      " [107.75932 ]\n",
      " [147.5101  ]\n",
      " [137.05835 ]\n",
      " [175.98479 ]\n",
      " [306.16373 ]\n",
      " [192.74228 ]\n",
      " [ 59.369976]\n",
      " [193.25977 ]\n",
      " [120.96937 ]\n",
      " [174.37074 ]\n",
      " [177.59244 ]\n",
      " [245.29765 ]\n",
      " [145.79747 ]\n",
      " [ 46.123642]\n",
      " [ 80.875046]\n",
      " [183.58856 ]\n",
      " [ 69.8733  ]\n",
      " [ 67.112495]\n",
      " [159.30157 ]\n",
      " [175.99802 ]\n",
      " [ 78.43094 ]\n",
      " [224.39455 ]\n",
      " [202.35837 ]\n",
      " [207.76006 ]\n",
      " [196.14825 ]\n",
      " [ 97.64022 ]\n",
      " [ 62.50284 ]\n",
      " [109.20273 ]\n",
      " [246.98538 ]\n",
      " [136.58745 ]\n",
      " [212.35231 ]\n",
      " [ 74.038574]\n",
      " [126.349075]\n",
      " [114.13777 ]\n",
      " [ 72.290146]\n",
      " [203.6045  ]\n",
      " [141.50705 ]\n",
      " [ 87.39813 ]\n",
      " [ 57.383774]\n",
      " [221.36783 ]\n",
      " [115.74072 ]\n",
      " [ 77.43005 ]\n",
      " [195.64462 ]\n",
      " [207.72089 ]\n",
      " [155.7367  ]\n",
      " [133.83101 ]\n",
      " [210.21834 ]\n",
      " [186.28584 ]\n",
      " [196.36493 ]\n",
      " [184.44437 ]\n",
      " [110.114655]\n",
      " [118.83794 ]\n",
      " [277.8279  ]\n",
      " [213.83784 ]\n",
      " [139.07947 ]\n",
      " [ 46.123642]\n",
      " [ 67.4305  ]\n",
      " [219.4345  ]\n",
      " [122.06496 ]\n",
      " [ 85.05705 ]\n",
      " [ 87.237366]\n",
      " [ 72.69939 ]\n",
      " [199.97278 ]\n",
      " [192.90453 ]\n",
      " [139.35437 ]\n",
      " [163.83237 ]\n",
      " [117.54777 ]\n",
      " [121.33368 ]\n",
      " [136.41562 ]\n",
      " [ 98.252396]\n",
      " [ 69.125916]\n",
      " [129.03069 ]\n",
      " [142.39111 ]\n",
      " [256.6074  ]\n",
      " [277.54782 ]\n",
      " [128.2681  ]\n",
      " [186.59628 ]\n",
      " [ 63.976166]\n",
      " [103.43409 ]\n",
      " [144.68015 ]\n",
      " [157.83847 ]\n",
      " [ 52.230686]\n",
      " [165.25665 ]\n",
      " [149.19385 ]\n",
      " [159.94498 ]\n",
      " [290.70285 ]\n",
      " [175.25737 ]\n",
      " [195.55203 ]\n",
      " [116.442154]\n",
      " [119.67311 ]\n",
      " [ 48.71536 ]\n",
      " [ 61.824535]\n",
      " [167.03764 ]\n",
      " [152.71974 ]\n",
      " [143.67809 ]\n",
      " [ 46.123642]\n",
      " [ 73.754906]\n",
      " [147.57498 ]\n",
      " [181.53366 ]\n",
      " [198.26744 ]\n",
      " [ 78.71127 ]\n",
      " [139.10004 ]\n",
      " [128.9461  ]\n",
      " [ 84.61813 ]\n",
      " [ 74.185875]\n",
      " [ 72.12874 ]\n",
      " [193.73657 ]\n",
      " [ 85.31148 ]\n",
      " [163.5804  ]\n",
      " [212.8492  ]\n",
      " [126.035095]\n",
      " [113.1938  ]\n",
      " [120.49327 ]\n",
      " [ 63.273594]\n",
      " [206.66483 ]\n",
      " [187.96567 ]\n",
      " [219.99545 ]\n",
      " [213.90732 ]\n",
      " [ 61.779552]\n",
      " [253.93634 ]\n",
      " [ 50.346043]\n",
      " [229.32672 ]\n",
      " [ 81.80574 ]]\n",
      "=================\n",
      "R2 :  0.43894890253559005\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.3458\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.9975\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.7304\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.7687\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.4998\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.3034\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.4456\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.8078\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 27.2046\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.6558\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.0895\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.6675\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.5216\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.3917\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.8542\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.5138\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.8220\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.3673\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.7894\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.7224\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.4220\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.4319\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.6341\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 27.4955\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.6830\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.8171\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.8680\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.6564\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.6437\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.8942\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.0959\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.5602\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.2682\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 27.3885\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.3662\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.4741\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.3204\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.9332\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.7016\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.2246\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.7128\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.2060\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.1238\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.1742\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 27.6327\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.7505\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.8085\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 27.0637\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.9946\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.9951\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.0744\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.2180\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.4627\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.8974\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.4569\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.4645\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.5894\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.0557\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.1035\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.0822\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.0669\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.1313\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.6201\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.6583\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.6975\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.1636\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.4285\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.1619\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.1901\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.9160\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.0056\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.9424\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.5906\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.7833\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.8030\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.6419\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.6100\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.4709\n",
      "Epoch 79/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 110us/step - loss: 28.4709\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 46.9452\n",
      "loss :  46.945220947265625\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "=================\n",
      "[185. 150. 246. 184. 110. 202. 336.  69.  69.  87.  66. 164. 265. 198.\n",
      " 248. 171. 102. 182. 262. 233. 151. 275. 230.  39.  42. 122.  81.  31.\n",
      " 156. 161.  80. 215. 310. 163. 265.  84.  54. 137. 248.  72. 248.  59.\n",
      "  97.  61.  72. 296.  55.  75.  53. 173. 158.  96. 140. 186.  93. 123.\n",
      " 237. 138. 292.  78. 182. 127. 321. 109. 212.  45.  96. 109.  89.  96.\n",
      "  60.  51. 200. 265.  68.  91. 172. 115. 125.  53.  63. 259. 214. 195.\n",
      " 258. 235. 173.  59. 219. 170.  77.  49.  66. 144. 113. 233. 162. 121.\n",
      "  88. 302. 128.  52. 178.  90. 164. 135. 103. 200. 178. 261.  64.  59.\n",
      "  79.  47. 107.  39. 151. 104. 217. 232.  55. 245. 131.  64. 222. 249.\n",
      " 128. 293. 138. 273. 158. 168. 103.]\n",
      "[[129.86838 ]\n",
      " [164.95049 ]\n",
      " [194.76921 ]\n",
      " [150.03412 ]\n",
      " [167.6829  ]\n",
      " [236.11488 ]\n",
      " [260.9993  ]\n",
      " [ 78.79301 ]\n",
      " [ 76.92229 ]\n",
      " [138.40446 ]\n",
      " [110.0951  ]\n",
      " [142.19301 ]\n",
      " [150.96901 ]\n",
      " [168.12376 ]\n",
      " [332.54272 ]\n",
      " [196.2672  ]\n",
      " [ 73.21408 ]\n",
      " [191.14607 ]\n",
      " [134.42706 ]\n",
      " [177.0125  ]\n",
      " [185.52895 ]\n",
      " [250.71303 ]\n",
      " [150.3763  ]\n",
      " [ 46.29879 ]\n",
      " [ 84.3388  ]\n",
      " [202.22807 ]\n",
      " [ 96.4675  ]\n",
      " [ 65.58593 ]\n",
      " [166.94115 ]\n",
      " [183.65446 ]\n",
      " [ 86.92164 ]\n",
      " [219.88623 ]\n",
      " [198.54443 ]\n",
      " [221.62643 ]\n",
      " [196.38635 ]\n",
      " [112.58777 ]\n",
      " [ 67.61732 ]\n",
      " [115.53334 ]\n",
      " [230.45851 ]\n",
      " [132.84862 ]\n",
      " [207.7959  ]\n",
      " [ 79.45294 ]\n",
      " [130.98335 ]\n",
      " [118.73936 ]\n",
      " [ 81.072624]\n",
      " [205.02354 ]\n",
      " [155.8496  ]\n",
      " [ 95.78686 ]\n",
      " [ 64.04599 ]\n",
      " [222.82666 ]\n",
      " [127.083374]\n",
      " [ 76.4337  ]\n",
      " [195.71745 ]\n",
      " [210.70215 ]\n",
      " [148.48044 ]\n",
      " [130.42818 ]\n",
      " [201.43358 ]\n",
      " [183.27307 ]\n",
      " [191.4078  ]\n",
      " [190.30244 ]\n",
      " [103.39869 ]\n",
      " [165.35956 ]\n",
      " [285.80096 ]\n",
      " [200.21788 ]\n",
      " [132.29692 ]\n",
      " [ 46.29879 ]\n",
      " [ 72.69308 ]\n",
      " [273.31885 ]\n",
      " [107.771034]\n",
      " [ 72.09734 ]\n",
      " [ 80.228905]\n",
      " [ 78.44231 ]\n",
      " [233.00078 ]\n",
      " [183.3903  ]\n",
      " [153.15384 ]\n",
      " [166.7293  ]\n",
      " [130.35965 ]\n",
      " [119.041405]\n",
      " [144.97209 ]\n",
      " [ 80.939316]\n",
      " [ 71.78099 ]\n",
      " [140.71391 ]\n",
      " [140.11528 ]\n",
      " [256.09973 ]\n",
      " [261.9682  ]\n",
      " [146.08604 ]\n",
      " [179.55807 ]\n",
      " [ 85.48926 ]\n",
      " [116.5329  ]\n",
      " [170.14618 ]\n",
      " [164.64851 ]\n",
      " [ 58.10767 ]\n",
      " [158.59767 ]\n",
      " [131.52785 ]\n",
      " [200.76004 ]\n",
      " [288.91766 ]\n",
      " [191.11848 ]\n",
      " [191.52553 ]\n",
      " [124.71505 ]\n",
      " [138.22932 ]\n",
      " [ 65.58593 ]\n",
      " [ 67.386314]\n",
      " [191.73526 ]\n",
      " [147.76921 ]\n",
      " [142.10634 ]\n",
      " [ 46.29879 ]\n",
      " [ 68.63421 ]\n",
      " [143.47093 ]\n",
      " [181.00525 ]\n",
      " [221.51244 ]\n",
      " [ 72.43105 ]\n",
      " [162.69505 ]\n",
      " [132.4226  ]\n",
      " [ 88.84996 ]\n",
      " [ 72.99713 ]\n",
      " [ 77.89218 ]\n",
      " [192.9022  ]\n",
      " [ 89.961876]\n",
      " [165.84789 ]\n",
      " [239.38448 ]\n",
      " [145.01357 ]\n",
      " [132.78468 ]\n",
      " [141.54321 ]\n",
      " [ 65.61111 ]\n",
      " [197.26479 ]\n",
      " [201.63904 ]\n",
      " [210.63954 ]\n",
      " [206.69057 ]\n",
      " [ 65.58593 ]\n",
      " [254.21065 ]\n",
      " [ 63.930588]\n",
      " [268.8886  ]\n",
      " [110.08998 ]]\n",
      "=================\n",
      "R2 :  0.41943362162619513\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.6870\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 27.0182\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.8902\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.1161\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.7211\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.3653\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.5861\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 26.9154\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.2981\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.7008\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.3678\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.5727\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.5987\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.0125\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.8590\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.1814\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.7906\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 27.7299\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.7042\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.4790\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.3222\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.1218\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.1733\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.3107\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.2506\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 26.1826\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.6166\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.7013\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.4304\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.5296\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.9536\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.6820\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.3511\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 25.6303\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.9103\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.5811\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.6646\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.4060\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.5915\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.6534\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.9433\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.5354\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 27.9662\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.4251\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.2067\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.8338\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.7536\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.1347\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.4005\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.0390\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 26.7533\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.2900\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.6577\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.4136\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.7629\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.3274\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.7285\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.9266\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.1413\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.7604\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 25.5608\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.5610\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.3674\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.5750\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.1105\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.3623\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.6219\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.0263\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 23.8891\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.5725\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.4359\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.8628\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.3882\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.9742\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.5316\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.2574\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.3708\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 24.7237\n",
      "Epoch 79/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 100us/step - loss: 24.7237\n",
      "5/5 [==============================] - 0s 889us/step - loss: 46.4528\n",
      "loss :  46.45281219482422\n",
      "5/5 [==============================] - 0s 997us/step\n",
      "=================\n",
      "[185. 150. 246. 184. 110. 202. 336.  69.  69.  87.  66. 164. 265. 198.\n",
      " 248. 171. 102. 182. 262. 233. 151. 275. 230.  39.  42. 122.  81.  31.\n",
      " 156. 161.  80. 215. 310. 163. 265.  84.  54. 137. 248.  72. 248.  59.\n",
      "  97.  61.  72. 296.  55.  75.  53. 173. 158.  96. 140. 186.  93. 123.\n",
      " 237. 138. 292.  78. 182. 127. 321. 109. 212.  45.  96. 109.  89.  96.\n",
      "  60.  51. 200. 265.  68.  91. 172. 115. 125.  53.  63. 259. 214. 195.\n",
      " 258. 235. 173.  59. 219. 170.  77.  49.  66. 144. 113. 233. 162. 121.\n",
      "  88. 302. 128.  52. 178.  90. 164. 135. 103. 200. 178. 261.  64.  59.\n",
      "  79.  47. 107.  39. 151. 104. 217. 232.  55. 245. 131.  64. 222. 249.\n",
      " 128. 293. 138. 273. 158. 168. 103.]\n",
      "[[114.22928 ]\n",
      " [158.0187  ]\n",
      " [183.44597 ]\n",
      " [146.17876 ]\n",
      " [169.81815 ]\n",
      " [227.02466 ]\n",
      " [236.97427 ]\n",
      " [ 79.8379  ]\n",
      " [ 65.85582 ]\n",
      " [106.72824 ]\n",
      " [ 98.990036]\n",
      " [120.38396 ]\n",
      " [177.5104  ]\n",
      " [146.62917 ]\n",
      " [310.7225  ]\n",
      " [190.91023 ]\n",
      " [ 68.25537 ]\n",
      " [195.0206  ]\n",
      " [105.13598 ]\n",
      " [188.57274 ]\n",
      " [151.20856 ]\n",
      " [251.23576 ]\n",
      " [151.60034 ]\n",
      " [ 42.283154]\n",
      " [ 75.0002  ]\n",
      " [182.88022 ]\n",
      " [ 82.96663 ]\n",
      " [ 58.696312]\n",
      " [171.59933 ]\n",
      " [172.8291  ]\n",
      " [ 78.75497 ]\n",
      " [203.01279 ]\n",
      " [191.07706 ]\n",
      " [220.63571 ]\n",
      " [187.6384  ]\n",
      " [ 96.53563 ]\n",
      " [ 58.696312]\n",
      " [120.527534]\n",
      " [229.37482 ]\n",
      " [140.19391 ]\n",
      " [201.42535 ]\n",
      " [ 72.653824]\n",
      " [116.476074]\n",
      " [161.50609 ]\n",
      " [ 64.85639 ]\n",
      " [191.70515 ]\n",
      " [141.32013 ]\n",
      " [ 76.73391 ]\n",
      " [ 42.39261 ]\n",
      " [220.88142 ]\n",
      " [105.7855  ]\n",
      " [ 80.03291 ]\n",
      " [208.44963 ]\n",
      " [213.61292 ]\n",
      " [130.49353 ]\n",
      " [108.93255 ]\n",
      " [192.04053 ]\n",
      " [174.71078 ]\n",
      " [182.10086 ]\n",
      " [198.04977 ]\n",
      " [106.542595]\n",
      " [123.60111 ]\n",
      " [272.8782  ]\n",
      " [187.38118 ]\n",
      " [106.260826]\n",
      " [ 42.352818]\n",
      " [ 66.90583 ]\n",
      " [252.0578  ]\n",
      " [129.09521 ]\n",
      " [ 85.54089 ]\n",
      " [ 67.25957 ]\n",
      " [ 67.30329 ]\n",
      " [238.78326 ]\n",
      " [171.13354 ]\n",
      " [128.27039 ]\n",
      " [164.51852 ]\n",
      " [107.611435]\n",
      " [ 89.88678 ]\n",
      " [136.78296 ]\n",
      " [ 65.995224]\n",
      " [ 62.824444]\n",
      " [129.13696 ]\n",
      " [113.131584]\n",
      " [251.59933 ]\n",
      " [253.77197 ]\n",
      " [141.50685 ]\n",
      " [170.44548 ]\n",
      " [ 62.869205]\n",
      " [125.07015 ]\n",
      " [164.30742 ]\n",
      " [180.91072 ]\n",
      " [ 44.94005 ]\n",
      " [142.80261 ]\n",
      " [115.81215 ]\n",
      " [204.61118 ]\n",
      " [297.34747 ]\n",
      " [155.44257 ]\n",
      " [158.98468 ]\n",
      " [148.89957 ]\n",
      " [141.52376 ]\n",
      " [ 55.011646]\n",
      " [ 62.52148 ]\n",
      " [141.22978 ]\n",
      " [132.17676 ]\n",
      " [136.12566 ]\n",
      " [ 42.357483]\n",
      " [ 82.709724]\n",
      " [135.45605 ]\n",
      " [169.6357  ]\n",
      " [215.64642 ]\n",
      " [ 63.576534]\n",
      " [154.5186  ]\n",
      " [128.6192  ]\n",
      " [ 78.22818 ]\n",
      " [ 68.7482  ]\n",
      " [ 55.209057]\n",
      " [195.13905 ]\n",
      " [ 82.56823 ]\n",
      " [152.74133 ]\n",
      " [217.44917 ]\n",
      " [139.03773 ]\n",
      " [137.95709 ]\n",
      " [137.94464 ]\n",
      " [ 66.76599 ]\n",
      " [186.86803 ]\n",
      " [158.6882  ]\n",
      " [202.8461  ]\n",
      " [207.55074 ]\n",
      " [ 61.109913]\n",
      " [254.81244 ]\n",
      " [ 58.696312]\n",
      " [243.88893 ]\n",
      " [107.60321 ]]\n",
      "=================\n",
      "R2 :  0.3980343980168154\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.0505\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.6928\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.0492\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.7105\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.5091\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.9983\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 24.1080\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.4743\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.3433\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.6097\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.3240\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.5811\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.8733\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 25.4022\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.1088\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.7924\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.9506\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.6313\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.0004\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.3200\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.7140\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 25.1585\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.5862\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.7253\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.0992\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.8256\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.0358\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.6340\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.5202\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 24.2953\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.3998\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.2774\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.2883\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.0724\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.8013\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.6776\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.8645\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.9487\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 26.0359\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.1111\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.9111\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.1785\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.4408\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.4087\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.0857\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.2732\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.1176\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.5780\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 23.4857\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.5072\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.5527\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.6385\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.3685\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.7306\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 22.9577\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.3165\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.1811\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.6310\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.1361\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.5267\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.2345\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.9589\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 23.6959\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.7205\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.3459\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.6312\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.0301\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.4337\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.8616\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.9100\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.0406\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 23.0864\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.0289\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.6134\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.1809\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.1673\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.2526\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.3556\n",
      "Epoch 79/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 110us/step - loss: 23.3556\n",
      "5/5 [==============================] - 0s 998us/step - loss: 49.9794\n",
      "loss :  49.979393005371094\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "=================\n",
      "[185. 150. 246. 184. 110. 202. 336.  69.  69.  87.  66. 164. 265. 198.\n",
      " 248. 171. 102. 182. 262. 233. 151. 275. 230.  39.  42. 122.  81.  31.\n",
      " 156. 161.  80. 215. 310. 163. 265.  84.  54. 137. 248.  72. 248.  59.\n",
      "  97.  61.  72. 296.  55.  75.  53. 173. 158.  96. 140. 186.  93. 123.\n",
      " 237. 138. 292.  78. 182. 127. 321. 109. 212.  45.  96. 109.  89.  96.\n",
      "  60.  51. 200. 265.  68.  91. 172. 115. 125.  53.  63. 259. 214. 195.\n",
      " 258. 235. 173.  59. 219. 170.  77.  49.  66. 144. 113. 233. 162. 121.\n",
      "  88. 302. 128.  52. 178.  90. 164. 135. 103. 200. 178. 261.  64.  59.\n",
      "  79.  47. 107.  39. 151. 104. 217. 232.  55. 245. 131.  64. 222. 249.\n",
      " 128. 293. 138. 273. 158. 168. 103.]\n",
      "[[123.82856 ]\n",
      " [192.01033 ]\n",
      " [192.16286 ]\n",
      " [162.59265 ]\n",
      " [189.66594 ]\n",
      " [216.12033 ]\n",
      " [265.7359  ]\n",
      " [ 87.86185 ]\n",
      " [ 73.53975 ]\n",
      " [133.37097 ]\n",
      " [122.8207  ]\n",
      " [123.84249 ]\n",
      " [180.96553 ]\n",
      " [147.13841 ]\n",
      " [351.17194 ]\n",
      " [225.62302 ]\n",
      " [ 75.302315]\n",
      " [210.2252  ]\n",
      " [114.33813 ]\n",
      " [210.29013 ]\n",
      " [167.8456  ]\n",
      " [266.72275 ]\n",
      " [196.91573 ]\n",
      " [ 46.3148  ]\n",
      " [ 79.5449  ]\n",
      " [244.77141 ]\n",
      " [101.59979 ]\n",
      " [ 62.984776]\n",
      " [194.67667 ]\n",
      " [186.63428 ]\n",
      " [ 90.57354 ]\n",
      " [206.2602  ]\n",
      " [201.32535 ]\n",
      " [248.15024 ]\n",
      " [201.6441  ]\n",
      " [ 90.4945  ]\n",
      " [ 61.26389 ]\n",
      " [135.1547  ]\n",
      " [265.0974  ]\n",
      " [159.37361 ]\n",
      " [227.28302 ]\n",
      " [ 75.447685]\n",
      " [135.29486 ]\n",
      " [167.64082 ]\n",
      " [ 69.20176 ]\n",
      " [197.3948  ]\n",
      " [127.088005]\n",
      " [ 84.77335 ]\n",
      " [ 47.345867]\n",
      " [228.40182 ]\n",
      " [124.379845]\n",
      " [ 92.616356]\n",
      " [214.01685 ]\n",
      " [238.8578  ]\n",
      " [142.14691 ]\n",
      " [ 98.86139 ]\n",
      " [199.91043 ]\n",
      " [202.61092 ]\n",
      " [201.2506  ]\n",
      " [207.45865 ]\n",
      " [ 80.50353 ]\n",
      " [117.904976]\n",
      " [307.71265 ]\n",
      " [197.00507 ]\n",
      " [109.091705]\n",
      " [ 46.874226]\n",
      " [ 71.76641 ]\n",
      " [240.50754 ]\n",
      " [118.23147 ]\n",
      " [ 75.67188 ]\n",
      " [ 76.593056]\n",
      " [ 74.84934 ]\n",
      " [310.59686 ]\n",
      " [178.97298 ]\n",
      " [134.07236 ]\n",
      " [188.50366 ]\n",
      " [128.56964 ]\n",
      " [ 94.581566]\n",
      " [160.04382 ]\n",
      " [ 66.729706]\n",
      " [ 78.43835 ]\n",
      " [147.67888 ]\n",
      " [125.82079 ]\n",
      " [278.08948 ]\n",
      " [279.55386 ]\n",
      " [160.73166 ]\n",
      " [186.5568  ]\n",
      " [ 74.52754 ]\n",
      " [ 78.622856]\n",
      " [162.51015 ]\n",
      " [209.31491 ]\n",
      " [ 63.564716]\n",
      " [155.64484 ]\n",
      " [127.62767 ]\n",
      " [243.13312 ]\n",
      " [304.79117 ]\n",
      " [180.6886  ]\n",
      " [197.22101 ]\n",
      " [146.48328 ]\n",
      " [185.77432 ]\n",
      " [ 61.26389 ]\n",
      " [ 68.91593 ]\n",
      " [151.39886 ]\n",
      " [147.55598 ]\n",
      " [142.95569 ]\n",
      " [ 46.861656]\n",
      " [ 69.57949 ]\n",
      " [152.84581 ]\n",
      " [180.4762  ]\n",
      " [222.8998  ]\n",
      " [ 65.642555]\n",
      " [185.775   ]\n",
      " [125.03039 ]\n",
      " [ 79.172874]\n",
      " [ 73.63159 ]\n",
      " [ 72.78888 ]\n",
      " [209.036   ]\n",
      " [ 93.66087 ]\n",
      " [161.81552 ]\n",
      " [236.97299 ]\n",
      " [160.9004  ]\n",
      " [141.32576 ]\n",
      " [155.80635 ]\n",
      " [ 81.386345]\n",
      " [207.31479 ]\n",
      " [185.27135 ]\n",
      " [218.02446 ]\n",
      " [224.67517 ]\n",
      " [ 76.14788 ]\n",
      " [283.98788 ]\n",
      " [ 66.43964 ]\n",
      " [252.32123 ]\n",
      " [130.07089 ]]\n",
      "=================\n",
      "R2 :  0.3387288663567378\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.5606\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.5442\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.7397\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.7141\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.0104\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.4906\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 23.0474\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 24.1744\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.1650\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.9542\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.8685\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.3319\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.9825\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 22.4095\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.4881\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.0956\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.4391\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.0392\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.6803\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.7652\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.9348\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 22.7777\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.0197\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.8920\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.5529\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.5378\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.7425\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 24.5693\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.0598\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.7089\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.5635\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.7296\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 21.8920\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.2416\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.0418\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.6341\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.9123\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.3664\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.6711\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.6820\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 23.0352\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.1753\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.0161\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.5632\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.1074\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.3400\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.5894\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 21.0233\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.7682\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.8358\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.1988\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.1584\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.5775\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.3291\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.2908\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 22.6907\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.0940\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.2749\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.1836\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.6416\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.8618\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 22.0253\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.9832\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.5857\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.2012\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.1693\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.9461\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.4857\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.2815\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.1479\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 21.9664\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.2028\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.1654\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.5503\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.2536\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.2600\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.5116\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.2025\n",
      "Epoch 79/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 110us/step - loss: 22.2025\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 49.5115\n",
      "loss :  49.511531829833984\n",
      "5/5 [==============================] - 0s 756us/step\n",
      "=================\n",
      "[185. 150. 246. 184. 110. 202. 336.  69.  69.  87.  66. 164. 265. 198.\n",
      " 248. 171. 102. 182. 262. 233. 151. 275. 230.  39.  42. 122.  81.  31.\n",
      " 156. 161.  80. 215. 310. 163. 265.  84.  54. 137. 248.  72. 248.  59.\n",
      "  97.  61.  72. 296.  55.  75.  53. 173. 158.  96. 140. 186.  93. 123.\n",
      " 237. 138. 292.  78. 182. 127. 321. 109. 212.  45.  96. 109.  89.  96.\n",
      "  60.  51. 200. 265.  68.  91. 172. 115. 125.  53.  63. 259. 214. 195.\n",
      " 258. 235. 173.  59. 219. 170.  77.  49.  66. 144. 113. 233. 162. 121.\n",
      "  88. 302. 128.  52. 178.  90. 164. 135. 103. 200. 178. 261.  64.  59.\n",
      "  79.  47. 107.  39. 151. 104. 217. 232.  55. 245. 131.  64. 222. 249.\n",
      " 128. 293. 138. 273. 158. 168. 103.]\n",
      "[[129.43826 ]\n",
      " [175.4277  ]\n",
      " [180.3423  ]\n",
      " [151.62459 ]\n",
      " [180.75195 ]\n",
      " [210.21805 ]\n",
      " [268.37833 ]\n",
      " [ 98.23294 ]\n",
      " [ 78.393585]\n",
      " [138.87051 ]\n",
      " [123.44825 ]\n",
      " [133.13962 ]\n",
      " [202.26842 ]\n",
      " [135.40125 ]\n",
      " [352.80423 ]\n",
      " [226.53314 ]\n",
      " [ 68.31343 ]\n",
      " [193.89415 ]\n",
      " [107.95941 ]\n",
      " [217.95862 ]\n",
      " [164.18622 ]\n",
      " [269.7582  ]\n",
      " [154.53683 ]\n",
      " [ 45.13142 ]\n",
      " [ 74.84976 ]\n",
      " [205.12527 ]\n",
      " [ 93.18212 ]\n",
      " [ 59.728992]\n",
      " [182.35995 ]\n",
      " [192.32213 ]\n",
      " [ 96.582016]\n",
      " [198.26984 ]\n",
      " [176.1256  ]\n",
      " [248.78754 ]\n",
      " [191.02292 ]\n",
      " [ 95.86515 ]\n",
      " [ 58.686558]\n",
      " [108.998184]\n",
      " [256.2844  ]\n",
      " [156.47057 ]\n",
      " [222.96274 ]\n",
      " [ 72.763756]\n",
      " [122.42032 ]\n",
      " [186.0395  ]\n",
      " [ 63.972393]\n",
      " [199.98576 ]\n",
      " [133.26001 ]\n",
      " [ 82.23458 ]\n",
      " [ 44.429195]\n",
      " [215.79456 ]\n",
      " [123.814545]\n",
      " [ 92.61428 ]\n",
      " [223.6079  ]\n",
      " [242.8776  ]\n",
      " [127.76071 ]\n",
      " [ 89.89473 ]\n",
      " [200.0718  ]\n",
      " [207.41933 ]\n",
      " [180.53598 ]\n",
      " [203.59956 ]\n",
      " [ 76.286804]\n",
      " [105.7852  ]\n",
      " [290.12503 ]\n",
      " [189.19037 ]\n",
      " [126.14246 ]\n",
      " [ 47.427387]\n",
      " [ 70.27915 ]\n",
      " [233.22353 ]\n",
      " [120.63931 ]\n",
      " [ 88.1413  ]\n",
      " [ 74.0284  ]\n",
      " [ 72.406235]\n",
      " [287.45416 ]\n",
      " [159.21341 ]\n",
      " [141.41237 ]\n",
      " [184.90053 ]\n",
      " [110.8979  ]\n",
      " [ 85.81992 ]\n",
      " [144.90755 ]\n",
      " [ 66.10434 ]\n",
      " [ 86.20484 ]\n",
      " [152.53084 ]\n",
      " [120.55591 ]\n",
      " [268.2503  ]\n",
      " [257.17886 ]\n",
      " [156.96121 ]\n",
      " [172.18864 ]\n",
      " [ 72.31944 ]\n",
      " [111.18481 ]\n",
      " [162.85944 ]\n",
      " [208.26364 ]\n",
      " [ 74.14715 ]\n",
      " [142.70314 ]\n",
      " [114.64041 ]\n",
      " [235.2009  ]\n",
      " [304.6149  ]\n",
      " [183.95738 ]\n",
      " [167.57301 ]\n",
      " [169.94006 ]\n",
      " [177.9277  ]\n",
      " [ 58.686558]\n",
      " [ 64.05118 ]\n",
      " [153.1983  ]\n",
      " [140.06343 ]\n",
      " [139.03981 ]\n",
      " [ 54.383602]\n",
      " [ 68.83449 ]\n",
      " [143.91385 ]\n",
      " [171.36137 ]\n",
      " [222.6969  ]\n",
      " [ 61.762333]\n",
      " [172.4414  ]\n",
      " [120.36423 ]\n",
      " [ 76.81354 ]\n",
      " [ 70.95212 ]\n",
      " [ 69.42475 ]\n",
      " [210.43613 ]\n",
      " [ 90.938   ]\n",
      " [168.23679 ]\n",
      " [231.97995 ]\n",
      " [144.4478  ]\n",
      " [128.82928 ]\n",
      " [154.0958  ]\n",
      " [ 94.119446]\n",
      " [220.45035 ]\n",
      " [192.5425  ]\n",
      " [214.23969 ]\n",
      " [222.54958 ]\n",
      " [ 79.39319 ]\n",
      " [264.136   ]\n",
      " [ 63.42771 ]\n",
      " [265.78705 ]\n",
      " [109.814964]]\n",
      "=================\n",
      "R2 :  0.3507556176665666\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.6108\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.6615\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.3969\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.3541\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 21.9204\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.2054\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.8779\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.7419\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.9116\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.9951\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 22.4462\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.9557\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.2369\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.6677\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.2765\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.7106\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.1700\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 22.4649\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.8527\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.4118\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 22.5884\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.8203\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.5079\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 21.4983\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 21.2713\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.9556\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.5655\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.4297\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.6542\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 22.1420\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.7349\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.0430\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 22.8215\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.2179\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.6052\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.8498\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.6430\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.6938\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.5786\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 19.6983\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.2694\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.9028\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.7912\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.6940\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.8925\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.3017\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 21.7379\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.3713\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.4215\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.2500\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.2735\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.9804\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.3977\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 22.7415\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.2598\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.8787\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.1698\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.4104\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.1881\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.0437\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 21.5106\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 20.9900\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.1729\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.8620\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.3114\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.4369\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.1537\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.1077\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 20.5566\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.3902\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.2177\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.8809\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.8812\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.0585\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.7687\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 21.9541\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.5982\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.8096\n",
      "Epoch 79/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 100us/step - loss: 21.8096\n",
      "5/5 [==============================] - 0s 999us/step - loss: 50.1843\n",
      "loss :  50.18426513671875\n",
      "5/5 [==============================] - 0s 998us/step\n",
      "=================\n",
      "[185. 150. 246. 184. 110. 202. 336.  69.  69.  87.  66. 164. 265. 198.\n",
      " 248. 171. 102. 182. 262. 233. 151. 275. 230.  39.  42. 122.  81.  31.\n",
      " 156. 161.  80. 215. 310. 163. 265.  84.  54. 137. 248.  72. 248.  59.\n",
      "  97.  61.  72. 296.  55.  75.  53. 173. 158.  96. 140. 186.  93. 123.\n",
      " 237. 138. 292.  78. 182. 127. 321. 109. 212.  45.  96. 109.  89.  96.\n",
      "  60.  51. 200. 265.  68.  91. 172. 115. 125.  53.  63. 259. 214. 195.\n",
      " 258. 235. 173.  59. 219. 170.  77.  49.  66. 144. 113. 233. 162. 121.\n",
      "  88. 302. 128.  52. 178.  90. 164. 135. 103. 200. 178. 261.  64.  59.\n",
      "  79.  47. 107.  39. 151. 104. 217. 232.  55. 245. 131.  64. 222. 249.\n",
      " 128. 293. 138. 273. 158. 168. 103.]\n",
      "[[130.94695 ]\n",
      " [195.81015 ]\n",
      " [183.69138 ]\n",
      " [159.42712 ]\n",
      " [183.1972  ]\n",
      " [239.22412 ]\n",
      " [273.90625 ]\n",
      " [ 78.0071  ]\n",
      " [ 79.26879 ]\n",
      " [135.27475 ]\n",
      " [121.94338 ]\n",
      " [142.36214 ]\n",
      " [188.98167 ]\n",
      " [140.88965 ]\n",
      " [392.08325 ]\n",
      " [244.32593 ]\n",
      " [ 72.13496 ]\n",
      " [197.6184  ]\n",
      " [111.87423 ]\n",
      " [241.96584 ]\n",
      " [174.28271 ]\n",
      " [285.09586 ]\n",
      " [168.39163 ]\n",
      " [ 45.66671 ]\n",
      " [ 77.46029 ]\n",
      " [221.85455 ]\n",
      " [103.462135]\n",
      " [ 59.80121 ]\n",
      " [182.45403 ]\n",
      " [202.95195 ]\n",
      " [102.68659 ]\n",
      " [216.84613 ]\n",
      " [194.71277 ]\n",
      " [262.58713 ]\n",
      " [197.39545 ]\n",
      " [ 96.595894]\n",
      " [ 62.06318 ]\n",
      " [ 99.581184]\n",
      " [256.22876 ]\n",
      " [152.13129 ]\n",
      " [234.67358 ]\n",
      " [ 75.227135]\n",
      " [126.51049 ]\n",
      " [169.30539 ]\n",
      " [ 71.73066 ]\n",
      " [195.28775 ]\n",
      " [131.17288 ]\n",
      " [ 89.9957  ]\n",
      " [ 45.304806]\n",
      " [225.11754 ]\n",
      " [131.11203 ]\n",
      " [ 98.77485 ]\n",
      " [223.22632 ]\n",
      " [241.35498 ]\n",
      " [132.74434 ]\n",
      " [ 94.736855]\n",
      " [200.1083  ]\n",
      " [219.2891  ]\n",
      " [186.06961 ]\n",
      " [212.19247 ]\n",
      " [ 76.29258 ]\n",
      " [103.13894 ]\n",
      " [288.83453 ]\n",
      " [192.66434 ]\n",
      " [120.155426]\n",
      " [ 47.300205]\n",
      " [ 72.19622 ]\n",
      " [231.61194 ]\n",
      " [107.19825 ]\n",
      " [ 71.40722 ]\n",
      " [ 79.369736]\n",
      " [ 75.46745 ]\n",
      " [296.1237  ]\n",
      " [172.04865 ]\n",
      " [142.50397 ]\n",
      " [190.39401 ]\n",
      " [123.310585]\n",
      " [ 91.17972 ]\n",
      " [146.06818 ]\n",
      " [ 67.888245]\n",
      " [ 67.56079 ]\n",
      " [166.58307 ]\n",
      " [141.49976 ]\n",
      " [282.4063  ]\n",
      " [269.9037  ]\n",
      " [156.40622 ]\n",
      " [177.68724 ]\n",
      " [ 92.33485 ]\n",
      " [123.56757 ]\n",
      " [174.55775 ]\n",
      " [212.83636 ]\n",
      " [ 63.86457 ]\n",
      " [147.4699  ]\n",
      " [126.28687 ]\n",
      " [259.23972 ]\n",
      " [305.70734 ]\n",
      " [195.58209 ]\n",
      " [159.75919 ]\n",
      " [106.776436]\n",
      " [204.3677  ]\n",
      " [ 59.90171 ]\n",
      " [ 66.34959 ]\n",
      " [160.29431 ]\n",
      " [143.78113 ]\n",
      " [138.17958 ]\n",
      " [ 47.990444]\n",
      " [ 71.78643 ]\n",
      " [144.26271 ]\n",
      " [179.84795 ]\n",
      " [207.37494 ]\n",
      " [ 65.270874]\n",
      " [197.21759 ]\n",
      " [116.6623  ]\n",
      " [ 81.38521 ]\n",
      " [ 76.14924 ]\n",
      " [ 71.68958 ]\n",
      " [221.5124  ]\n",
      " [ 96.00367 ]\n",
      " [172.2356  ]\n",
      " [254.68288 ]\n",
      " [157.20976 ]\n",
      " [118.16697 ]\n",
      " [144.93027 ]\n",
      " [ 72.60195 ]\n",
      " [226.64554 ]\n",
      " [213.20952 ]\n",
      " [236.33272 ]\n",
      " [219.62003 ]\n",
      " [ 58.88807 ]\n",
      " [280.61932 ]\n",
      " [ 55.373486]\n",
      " [250.34409 ]\n",
      " [131.38055 ]]\n",
      "=================\n",
      "R2 :  0.32605628970603096\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.3583\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.8612\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 21.7704\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.2147\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.5941\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.1341\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.9100\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.5922\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 21.2082\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.2711\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.1798\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.7732\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.1274\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.4373\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.6366\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 22.9960\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.5330\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.1030\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.8611\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.2167\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.7440\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.4000\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.8110\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.8400\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 20.0733\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.7634\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.7485\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.9825\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.2845\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.9707\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 21.2181\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.2034\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.4495\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.5838\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.0349\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.1026\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.4068\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 20.7744\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.4738\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.8348\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.3943\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.0027\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.4460\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.2213\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 23.4767\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.8266\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.2555\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.9797\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.6883\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.4924\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.6711\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.7189\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.2017\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.0779\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.3168\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.0916\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.7395\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 20.7283\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.9805\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.0551\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.2085\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.6047\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.1779\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.5843\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.9507\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 19.6118\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.7427\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.2506\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.6851\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.5904\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.7453\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.0881\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 20.3934\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.3291\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.5867\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.0213\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.3467\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.2851\n",
      "Epoch 79/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 100us/step - loss: 20.2851\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 48.5579\n",
      "loss :  48.557899475097656\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "=================\n",
      "[185. 150. 246. 184. 110. 202. 336.  69.  69.  87.  66. 164. 265. 198.\n",
      " 248. 171. 102. 182. 262. 233. 151. 275. 230.  39.  42. 122.  81.  31.\n",
      " 156. 161.  80. 215. 310. 163. 265.  84.  54. 137. 248.  72. 248.  59.\n",
      "  97.  61.  72. 296.  55.  75.  53. 173. 158.  96. 140. 186.  93. 123.\n",
      " 237. 138. 292.  78. 182. 127. 321. 109. 212.  45.  96. 109.  89.  96.\n",
      "  60.  51. 200. 265.  68.  91. 172. 115. 125.  53.  63. 259. 214. 195.\n",
      " 258. 235. 173.  59. 219. 170.  77.  49.  66. 144. 113. 233. 162. 121.\n",
      "  88. 302. 128.  52. 178.  90. 164. 135. 103. 200. 178. 261.  64.  59.\n",
      "  79.  47. 107.  39. 151. 104. 217. 232.  55. 245. 131.  64. 222. 249.\n",
      " 128. 293. 138. 273. 158. 168. 103.]\n",
      "[[117.05389 ]\n",
      " [193.67146 ]\n",
      " [174.33978 ]\n",
      " [155.9299  ]\n",
      " [173.65428 ]\n",
      " [219.56273 ]\n",
      " [278.00677 ]\n",
      " [ 72.19505 ]\n",
      " [ 73.9015  ]\n",
      " [138.66975 ]\n",
      " [121.29063 ]\n",
      " [182.44112 ]\n",
      " [215.06685 ]\n",
      " [123.15305 ]\n",
      " [332.62408 ]\n",
      " [215.61412 ]\n",
      " [ 65.182014]\n",
      " [180.37627 ]\n",
      " [149.62886 ]\n",
      " [220.57567 ]\n",
      " [154.26595 ]\n",
      " [264.0075  ]\n",
      " [153.5423  ]\n",
      " [ 45.945175]\n",
      " [ 75.859886]\n",
      " [205.91771 ]\n",
      " [ 98.262146]\n",
      " [ 60.81654 ]\n",
      " [176.77087 ]\n",
      " [202.34093 ]\n",
      " [ 89.65521 ]\n",
      " [186.91344 ]\n",
      " [169.62538 ]\n",
      " [248.66656 ]\n",
      " [186.77834 ]\n",
      " [ 92.84648 ]\n",
      " [ 61.58434 ]\n",
      " [ 99.67685 ]\n",
      " [235.98726 ]\n",
      " [153.36034 ]\n",
      " [220.69728 ]\n",
      " [ 71.624405]\n",
      " [122.2161  ]\n",
      " [197.5312  ]\n",
      " [ 63.71741 ]\n",
      " [177.67064 ]\n",
      " [132.59258 ]\n",
      " [ 83.643166]\n",
      " [ 44.51892 ]\n",
      " [204.66151 ]\n",
      " [126.783264]\n",
      " [ 94.57263 ]\n",
      " [203.79253 ]\n",
      " [237.16708 ]\n",
      " [115.05515 ]\n",
      " [ 72.298035]\n",
      " [190.27046 ]\n",
      " [201.37842 ]\n",
      " [169.94556 ]\n",
      " [187.05515 ]\n",
      " [ 72.8957  ]\n",
      " [ 86.55959 ]\n",
      " [277.09393 ]\n",
      " [185.78583 ]\n",
      " [192.49644 ]\n",
      " [ 49.645374]\n",
      " [ 71.58433 ]\n",
      " [227.97853 ]\n",
      " [105.42694 ]\n",
      " [ 96.22541 ]\n",
      " [ 72.71698 ]\n",
      " [ 71.332726]\n",
      " [280.99625 ]\n",
      " [146.11595 ]\n",
      " [118.81136 ]\n",
      " [175.51088 ]\n",
      " [106.90386 ]\n",
      " [ 79.29268 ]\n",
      " [142.01445 ]\n",
      " [ 65.29263 ]\n",
      " [102.469795]\n",
      " [158.45715 ]\n",
      " [128.71269 ]\n",
      " [274.78397 ]\n",
      " [260.53845 ]\n",
      " [174.8323  ]\n",
      " [172.19597 ]\n",
      " [ 84.76829 ]\n",
      " [ 98.81998 ]\n",
      " [149.16412 ]\n",
      " [201.2519  ]\n",
      " [ 77.184204]\n",
      " [140.7452  ]\n",
      " [101.51882 ]\n",
      " [243.18102 ]\n",
      " [255.03288 ]\n",
      " [181.2643  ]\n",
      " [139.94315 ]\n",
      " [143.30905 ]\n",
      " [199.91063 ]\n",
      " [ 64.96237 ]\n",
      " [ 63.340374]\n",
      " [154.75883 ]\n",
      " [133.40996 ]\n",
      " [101.350296]\n",
      " [ 49.255863]\n",
      " [ 68.72079 ]\n",
      " [138.79138 ]\n",
      " [163.37782 ]\n",
      " [191.96362 ]\n",
      " [ 62.344322]\n",
      " [183.13843 ]\n",
      " [111.29799 ]\n",
      " [ 73.82381 ]\n",
      " [ 71.70645 ]\n",
      " [ 68.16084 ]\n",
      " [213.19316 ]\n",
      " [ 91.27284 ]\n",
      " [152.80542 ]\n",
      " [235.92299 ]\n",
      " [133.19945 ]\n",
      " [137.07831 ]\n",
      " [142.60008 ]\n",
      " [ 92.92121 ]\n",
      " [208.26698 ]\n",
      " [168.85529 ]\n",
      " [213.70451 ]\n",
      " [208.04156 ]\n",
      " [ 60.406048]\n",
      " [267.20062 ]\n",
      " [ 49.255863]\n",
      " [220.70932 ]\n",
      " [127.22218 ]]\n",
      "=================\n",
      "R2 :  0.37737347050851466\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.4831\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.8395\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.1789\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.2260\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.6152\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 20.0439\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.8138\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.1206\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.4376\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.2667\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.5259\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.0372\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 19.7401\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.3618\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.1427\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.3271\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.6526\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.7422\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 19.7586\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.4131\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.1861\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.9441\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.4809\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.7368\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 21.2427\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.4313\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.1169\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.2125\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.8448\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.6354\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.2972\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 19.1034\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.1099\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.2252\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.7460\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.3262\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.1735\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 20.1424\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.5200\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.9534\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.5966\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.9726\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.3575\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 22.1120\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.2016\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.2592\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.4274\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.8528\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.7055\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 19.3476\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.9435\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.3472\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.3774\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.7667\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.8827\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.3375\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 20.4593\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.0069\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.0319\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.0945\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.0806\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.2926\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.3305\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.7269\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.9845\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.4193\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.5900\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.3107\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 20.1155\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.0009\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.8173\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.5129\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.6028\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.8646\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 21.5520\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.2092\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.9702\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.9731\n",
      "Epoch 79/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 90us/step - loss: 20.9731\n",
      "5/5 [==============================] - 0s 998us/step - loss: 48.6063\n",
      "loss :  48.60625457763672\n",
      "5/5 [==============================] - 0s 998us/step\n",
      "=================\n",
      "[185. 150. 246. 184. 110. 202. 336.  69.  69.  87.  66. 164. 265. 198.\n",
      " 248. 171. 102. 182. 262. 233. 151. 275. 230.  39.  42. 122.  81.  31.\n",
      " 156. 161.  80. 215. 310. 163. 265.  84.  54. 137. 248.  72. 248.  59.\n",
      "  97.  61.  72. 296.  55.  75.  53. 173. 158.  96. 140. 186.  93. 123.\n",
      " 237. 138. 292.  78. 182. 127. 321. 109. 212.  45.  96. 109.  89.  96.\n",
      "  60.  51. 200. 265.  68.  91. 172. 115. 125.  53.  63. 259. 214. 195.\n",
      " 258. 235. 173.  59. 219. 170.  77.  49.  66. 144. 113. 233. 162. 121.\n",
      "  88. 302. 128.  52. 178.  90. 164. 135. 103. 200. 178. 261.  64.  59.\n",
      "  79.  47. 107.  39. 151. 104. 217. 232.  55. 245. 131.  64. 222. 249.\n",
      " 128. 293. 138. 273. 158. 168. 103.]\n",
      "[[115.580246]\n",
      " [203.8511  ]\n",
      " [180.70335 ]\n",
      " [169.95868 ]\n",
      " [175.61934 ]\n",
      " [206.15096 ]\n",
      " [279.33688 ]\n",
      " [ 72.07438 ]\n",
      " [ 76.356636]\n",
      " [145.43991 ]\n",
      " [130.97835 ]\n",
      " [167.39442 ]\n",
      " [213.95485 ]\n",
      " [132.4822  ]\n",
      " [313.19815 ]\n",
      " [236.38205 ]\n",
      " [ 66.27199 ]\n",
      " [187.08136 ]\n",
      " [150.99847 ]\n",
      " [249.63489 ]\n",
      " [157.11531 ]\n",
      " [270.23364 ]\n",
      " [138.95691 ]\n",
      " [ 45.054688]\n",
      " [ 75.444145]\n",
      " [203.90356 ]\n",
      " [ 95.614784]\n",
      " [ 60.200375]\n",
      " [174.63985 ]\n",
      " [203.7843  ]\n",
      " [ 88.23549 ]\n",
      " [194.56587 ]\n",
      " [191.5429  ]\n",
      " [248.02441 ]\n",
      " [191.07758 ]\n",
      " [ 91.279465]\n",
      " [ 62.158043]\n",
      " [ 99.04304 ]\n",
      " [255.44019 ]\n",
      " [157.25763 ]\n",
      " [224.86372 ]\n",
      " [ 71.778404]\n",
      " [124.86549 ]\n",
      " [187.36012 ]\n",
      " [ 61.622665]\n",
      " [187.83688 ]\n",
      " [143.84131 ]\n",
      " [ 83.18747 ]\n",
      " [ 43.96633 ]\n",
      " [221.92525 ]\n",
      " [127.683174]\n",
      " [ 96.37592 ]\n",
      " [199.42467 ]\n",
      " [246.40231 ]\n",
      " [106.66625 ]\n",
      " [ 69.676956]\n",
      " [200.20305 ]\n",
      " [203.18843 ]\n",
      " [194.16342 ]\n",
      " [205.03885 ]\n",
      " [ 72.000404]\n",
      " [ 68.65587 ]\n",
      " [294.84366 ]\n",
      " [203.55646 ]\n",
      " [152.33638 ]\n",
      " [ 48.789024]\n",
      " [ 70.6503  ]\n",
      " [212.23819 ]\n",
      " [ 99.22895 ]\n",
      " [ 72.327675]\n",
      " [ 79.63056 ]\n",
      " [ 68.69518 ]\n",
      " [278.88846 ]\n",
      " [150.20874 ]\n",
      " [123.37145 ]\n",
      " [181.40068 ]\n",
      " [114.43477 ]\n",
      " [ 81.38944 ]\n",
      " [141.96405 ]\n",
      " [ 64.87837 ]\n",
      " [ 84.56244 ]\n",
      " [160.76367 ]\n",
      " [120.43778 ]\n",
      " [282.37543 ]\n",
      " [268.04883 ]\n",
      " [179.1903  ]\n",
      " [196.33778 ]\n",
      " [ 72.78528 ]\n",
      " [103.325836]\n",
      " [152.44102 ]\n",
      " [201.65201 ]\n",
      " [ 60.02301 ]\n",
      " [163.17796 ]\n",
      " [110.68554 ]\n",
      " [256.3961  ]\n",
      " [274.7865  ]\n",
      " [189.76529 ]\n",
      " [151.40413 ]\n",
      " [124.25402 ]\n",
      " [196.77583 ]\n",
      " [ 61.062134]\n",
      " [ 63.324314]\n",
      " [147.85542 ]\n",
      " [135.28207 ]\n",
      " [112.13881 ]\n",
      " [ 48.789024]\n",
      " [ 68.1204  ]\n",
      " [152.06728 ]\n",
      " [166.14905 ]\n",
      " [196.86664 ]\n",
      " [ 62.46836 ]\n",
      " [188.7541  ]\n",
      " [112.09607 ]\n",
      " [ 68.99976 ]\n",
      " [ 72.10741 ]\n",
      " [ 66.18165 ]\n",
      " [228.44083 ]\n",
      " [ 96.75762 ]\n",
      " [160.04196 ]\n",
      " [230.42787 ]\n",
      " [142.98186 ]\n",
      " [114.13812 ]\n",
      " [123.079605]\n",
      " [ 79.98211 ]\n",
      " [229.66336 ]\n",
      " [201.92877 ]\n",
      " [236.91765 ]\n",
      " [214.0028  ]\n",
      " [ 59.925213]\n",
      " [273.7397  ]\n",
      " [ 48.789024]\n",
      " [219.86314 ]\n",
      " [129.73196 ]]\n",
      "=================\n",
      "R2 :  0.36760104089101264\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.8640\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.4155\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 20.3548\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.4318\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.3819\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.5204\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.9647\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 20.2885\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.4205\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.7339\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.7145\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.3723\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 20.0602\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.3773\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.6756\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.8109\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.6775\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.5302\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 19.7642\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.4077\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.4676\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.5875\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.5553\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.0790\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.5976\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 19.9638\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.4763\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.4545\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.3610\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.9446\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.7205\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.1927\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 19.4426\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.4118\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.8175\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.5034\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.7845\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.2344\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 20.6002\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.8344\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.7943\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.7681\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.3132\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.7353\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.8854\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 21.5981\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.9737\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.9758\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.2375\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.6278\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.5997\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.3211\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 19.4611\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.8679\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.4346\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.5275\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.4082\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.1755\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 18.0490\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.9887\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.4700\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.3585\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.7278\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.5166\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 18.1643\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.0821\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.9946\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.2634\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.3587\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.2929\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.5148\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 18.3222\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.5538\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.9375\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.0852\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.6422\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.9956\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.4979\n",
      "Epoch 79/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 100us/step - loss: 19.4979\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 49.1772\n",
      "loss :  49.177181243896484\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "=================\n",
      "[185. 150. 246. 184. 110. 202. 336.  69.  69.  87.  66. 164. 265. 198.\n",
      " 248. 171. 102. 182. 262. 233. 151. 275. 230.  39.  42. 122.  81.  31.\n",
      " 156. 161.  80. 215. 310. 163. 265.  84.  54. 137. 248.  72. 248.  59.\n",
      "  97.  61.  72. 296.  55.  75.  53. 173. 158.  96. 140. 186.  93. 123.\n",
      " 237. 138. 292.  78. 182. 127. 321. 109. 212.  45.  96. 109.  89.  96.\n",
      "  60.  51. 200. 265.  68.  91. 172. 115. 125.  53.  63. 259. 214. 195.\n",
      " 258. 235. 173.  59. 219. 170.  77.  49.  66. 144. 113. 233. 162. 121.\n",
      "  88. 302. 128.  52. 178.  90. 164. 135. 103. 200. 178. 261.  64.  59.\n",
      "  79.  47. 107.  39. 151. 104. 217. 232.  55. 245. 131.  64. 222. 249.\n",
      " 128. 293. 138. 273. 158. 168. 103.]\n",
      "[[112.3288  ]\n",
      " [214.21332 ]\n",
      " [173.10924 ]\n",
      " [174.36975 ]\n",
      " [168.7961  ]\n",
      " [220.29276 ]\n",
      " [273.3898  ]\n",
      " [ 74.21394 ]\n",
      " [ 70.42068 ]\n",
      " [138.85107 ]\n",
      " [129.00046 ]\n",
      " [164.85933 ]\n",
      " [207.76874 ]\n",
      " [123.50342 ]\n",
      " [324.49786 ]\n",
      " [206.19147 ]\n",
      " [ 77.34535 ]\n",
      " [171.74966 ]\n",
      " [112.328964]\n",
      " [249.74603 ]\n",
      " [158.27167 ]\n",
      " [261.38736 ]\n",
      " [129.78345 ]\n",
      " [ 43.099945]\n",
      " [ 76.19685 ]\n",
      " [213.48376 ]\n",
      " [106.44267 ]\n",
      " [ 60.857212]\n",
      " [168.05696 ]\n",
      " [196.07803 ]\n",
      " [109.060005]\n",
      " [195.21999 ]\n",
      " [191.94104 ]\n",
      " [236.79947 ]\n",
      " [180.38986 ]\n",
      " [106.400696]\n",
      " [ 64.43662 ]\n",
      " [ 88.95604 ]\n",
      " [258.98236 ]\n",
      " [159.13669 ]\n",
      " [225.22585 ]\n",
      " [ 77.20851 ]\n",
      " [115.76893 ]\n",
      " [185.54822 ]\n",
      " [ 66.96145 ]\n",
      " [188.6309  ]\n",
      " [132.99072 ]\n",
      " [ 94.323456]\n",
      " [ 43.099945]\n",
      " [209.38164 ]\n",
      " [128.69548 ]\n",
      " [ 94.95154 ]\n",
      " [199.28726 ]\n",
      " [243.76553 ]\n",
      " [ 97.55259 ]\n",
      " [ 76.59585 ]\n",
      " [185.59207 ]\n",
      " [203.10896 ]\n",
      " [173.66156 ]\n",
      " [202.87349 ]\n",
      " [ 74.61843 ]\n",
      " [ 84.86308 ]\n",
      " [280.5735  ]\n",
      " [195.40689 ]\n",
      " [130.7395  ]\n",
      " [ 50.092236]\n",
      " [ 71.63251 ]\n",
      " [227.18018 ]\n",
      " [101.21722 ]\n",
      " [ 82.310745]\n",
      " [ 82.50609 ]\n",
      " [ 71.28974 ]\n",
      " [294.2402  ]\n",
      " [142.51306 ]\n",
      " [121.153854]\n",
      " [180.5716  ]\n",
      " [114.80527 ]\n",
      " [ 86.131744]\n",
      " [134.6066  ]\n",
      " [ 67.29072 ]\n",
      " [ 65.90061 ]\n",
      " [161.42665 ]\n",
      " [157.53043 ]\n",
      " [282.92886 ]\n",
      " [269.1543  ]\n",
      " [175.29742 ]\n",
      " [193.261   ]\n",
      " [ 88.06303 ]\n",
      " [121.98598 ]\n",
      " [188.2385  ]\n",
      " [197.76154 ]\n",
      " [ 60.857212]\n",
      " [159.35313 ]\n",
      " [129.70139 ]\n",
      " [262.4748  ]\n",
      " [253.78369 ]\n",
      " [204.49307 ]\n",
      " [147.39746 ]\n",
      " [115.7671  ]\n",
      " [204.3947  ]\n",
      " [ 63.30381 ]\n",
      " [ 65.888145]\n",
      " [155.82538 ]\n",
      " [130.35938 ]\n",
      " [ 95.05377 ]\n",
      " [ 50.092236]\n",
      " [ 68.8559  ]\n",
      " [146.54074 ]\n",
      " [163.66052 ]\n",
      " [208.64314 ]\n",
      " [ 65.16583 ]\n",
      " [195.62947 ]\n",
      " [120.53404 ]\n",
      " [ 76.23367 ]\n",
      " [ 74.147964]\n",
      " [ 68.82213 ]\n",
      " [223.48036 ]\n",
      " [107.85097 ]\n",
      " [160.13939 ]\n",
      " [231.92133 ]\n",
      " [137.47394 ]\n",
      " [120.178955]\n",
      " [135.9935  ]\n",
      " [ 83.39303 ]\n",
      " [228.14165 ]\n",
      " [194.69322 ]\n",
      " [238.21684 ]\n",
      " [205.63669 ]\n",
      " [ 60.857216]\n",
      " [269.14957 ]\n",
      " [ 50.092236]\n",
      " [218.35675 ]\n",
      " [150.14294 ]]\n",
      "=================\n",
      "R2 :  0.34808960699242464\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.1208\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.3331\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.2847\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.8783\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 17.8836\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.8441\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.5066\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.9049\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.5755\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.0866\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 18.4911\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.3388\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.0167\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.9639\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.0031\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.7856\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 20.0285\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.0548\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.1579\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.8348\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.0288\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.7976\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 18.8500\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.8326\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.9821\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.7608\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.9312\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 17.6696\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.4795\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.2673\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.9388\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.6474\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.6386\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 18.3946\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.1057\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.4666\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.0815\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.2636\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 17.9575\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.9678\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.3910\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.7637\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.0320\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 19.3480\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.3865\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.0718\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.7681\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.7001\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 19.1654\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.6145\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.0012\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.4389\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.5537\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.0117\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.9935\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 17.9608\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.7673\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.5657\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.2430\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.4081\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 19.2246\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.3331\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.2592\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.2809\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.7899\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.1806\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 19.5141\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.1652\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.7889\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.2041\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.2418\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 17.9600\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.7296\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.8040\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.2418\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.4683\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 17.4980\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.0927\n",
      "Epoch 79/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 100us/step - loss: 19.0927\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 49.4072\n",
      "loss :  49.407196044921875\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "=================\n",
      "[185. 150. 246. 184. 110. 202. 336.  69.  69.  87.  66. 164. 265. 198.\n",
      " 248. 171. 102. 182. 262. 233. 151. 275. 230.  39.  42. 122.  81.  31.\n",
      " 156. 161.  80. 215. 310. 163. 265.  84.  54. 137. 248.  72. 248.  59.\n",
      "  97.  61.  72. 296.  55.  75.  53. 173. 158.  96. 140. 186.  93. 123.\n",
      " 237. 138. 292.  78. 182. 127. 321. 109. 212.  45.  96. 109.  89.  96.\n",
      "  60.  51. 200. 265.  68.  91. 172. 115. 125.  53.  63. 259. 214. 195.\n",
      " 258. 235. 173.  59. 219. 170.  77.  49.  66. 144. 113. 233. 162. 121.\n",
      "  88. 302. 128.  52. 178.  90. 164. 135. 103. 200. 178. 261.  64.  59.\n",
      "  79.  47. 107.  39. 151. 104. 217. 232.  55. 245. 131.  64. 222. 249.\n",
      " 128. 293. 138. 273. 158. 168. 103.]\n",
      "[[125.0745  ]\n",
      " [224.22446 ]\n",
      " [179.23975 ]\n",
      " [172.83662 ]\n",
      " [164.24661 ]\n",
      " [223.81847 ]\n",
      " [271.4907  ]\n",
      " [ 70.836   ]\n",
      " [ 68.682434]\n",
      " [140.10384 ]\n",
      " [122.616455]\n",
      " [142.08665 ]\n",
      " [214.57256 ]\n",
      " [115.468925]\n",
      " [332.984   ]\n",
      " [209.30206 ]\n",
      " [ 80.57237 ]\n",
      " [161.39658 ]\n",
      " [ 98.32536 ]\n",
      " [262.12445 ]\n",
      " [153.91379 ]\n",
      " [278.53232 ]\n",
      " [137.5272  ]\n",
      " [ 42.7295  ]\n",
      " [ 73.80136 ]\n",
      " [195.03877 ]\n",
      " [105.66486 ]\n",
      " [ 60.8308  ]\n",
      " [158.88882 ]\n",
      " [185.15083 ]\n",
      " [113.51724 ]\n",
      " [195.02446 ]\n",
      " [184.65569 ]\n",
      " [247.15688 ]\n",
      " [178.71846 ]\n",
      " [112.74681 ]\n",
      " [ 63.484272]\n",
      " [ 83.68    ]\n",
      " [266.1062  ]\n",
      " [153.12572 ]\n",
      " [227.47673 ]\n",
      " [ 75.37234 ]\n",
      " [107.1051  ]\n",
      " [168.5837  ]\n",
      " [ 67.70903 ]\n",
      " [183.28636 ]\n",
      " [122.79845 ]\n",
      " [ 93.68456 ]\n",
      " [ 45.71091 ]\n",
      " [217.72995 ]\n",
      " [117.91769 ]\n",
      " [ 98.3749  ]\n",
      " [197.63936 ]\n",
      " [258.28516 ]\n",
      " [ 80.92626 ]\n",
      " [ 73.15789 ]\n",
      " [192.76472 ]\n",
      " [210.91609 ]\n",
      " [165.70448 ]\n",
      " [207.65633 ]\n",
      " [ 72.44804 ]\n",
      " [ 78.185616]\n",
      " [290.9889  ]\n",
      " [184.98512 ]\n",
      " [ 93.709854]\n",
      " [ 48.935463]\n",
      " [ 69.335556]\n",
      " [222.26862 ]\n",
      " [100.37378 ]\n",
      " [ 77.77598 ]\n",
      " [ 82.61511 ]\n",
      " [ 67.69273 ]\n",
      " [278.15857 ]\n",
      " [127.267784]\n",
      " [118.54848 ]\n",
      " [180.09097 ]\n",
      " [110.10129 ]\n",
      " [ 89.81152 ]\n",
      " [126.58644 ]\n",
      " [ 67.03171 ]\n",
      " [ 65.87603 ]\n",
      " [147.95143 ]\n",
      " [160.70998 ]\n",
      " [284.607   ]\n",
      " [261.8357  ]\n",
      " [174.33727 ]\n",
      " [178.06816 ]\n",
      " [ 88.24032 ]\n",
      " [117.533875]\n",
      " [198.24615 ]\n",
      " [190.07744 ]\n",
      " [ 60.8308  ]\n",
      " [150.57686 ]\n",
      " [123.90344 ]\n",
      " [247.33902 ]\n",
      " [254.73694 ]\n",
      " [202.28056 ]\n",
      " [147.31856 ]\n",
      " [109.429436]\n",
      " [188.0547  ]\n",
      " [ 62.746563]\n",
      " [ 64.393   ]\n",
      " [160.78745 ]\n",
      " [129.85536 ]\n",
      " [ 96.21086 ]\n",
      " [ 48.935463]\n",
      " [ 67.868576]\n",
      " [143.52068 ]\n",
      " [162.04152 ]\n",
      " [213.59978 ]\n",
      " [ 64.22669 ]\n",
      " [181.76566 ]\n",
      " [118.1534  ]\n",
      " [ 71.030045]\n",
      " [ 70.60618 ]\n",
      " [ 67.03125 ]\n",
      " [236.56572 ]\n",
      " [ 98.31116 ]\n",
      " [155.49304 ]\n",
      " [239.01732 ]\n",
      " [135.40793 ]\n",
      " [114.84184 ]\n",
      " [137.26727 ]\n",
      " [ 76.33733 ]\n",
      " [234.94157 ]\n",
      " [198.02623 ]\n",
      " [237.09448 ]\n",
      " [211.33296 ]\n",
      " [ 60.830803]\n",
      " [278.90405 ]\n",
      " [ 64.391556]\n",
      " [223.77791 ]\n",
      " [153.2139  ]]\n",
      "=================\n",
      "R2 :  0.33816029875039955\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.9060\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.3549\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 17.6644\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.0532\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.8275\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.9522\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.3166\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 17.8931\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.6278\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.1143\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.2083\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.3560\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.8773\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.1599\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 17.2759\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.9271\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.4962\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.1239\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.5797\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.0597\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 18.4275\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.2102\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.8248\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.1948\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.4890\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.9732\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.3933\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 18.3387\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.4739\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.4361\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.9094\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.3735\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.8597\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 18.1719\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.2173\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.8704\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.5908\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.8460\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.9798\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 18.9350\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.6021\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.9029\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.9226\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.3156\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 18.3196\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.6355\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.1432\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.7366\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 18.6953\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.9325\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.4781\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.9700\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.8842\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 17.3176\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.6724\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.0776\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.0273\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.4816\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.1381\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 18.6032\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.0455\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.9972\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.7616\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.8918\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.4401\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.9051\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 17.1691\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.4042\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.3274\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.2139\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.1860\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.6507\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 18.7005\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.6340\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.6887\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.7456\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.2445\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.1868\n",
      "Epoch 79/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 90us/step - loss: 18.1868\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 50.6205\n",
      "loss :  50.620460510253906\n",
      "5/5 [==============================] - 0s 997us/step\n",
      "=================\n",
      "[185. 150. 246. 184. 110. 202. 336.  69.  69.  87.  66. 164. 265. 198.\n",
      " 248. 171. 102. 182. 262. 233. 151. 275. 230.  39.  42. 122.  81.  31.\n",
      " 156. 161.  80. 215. 310. 163. 265.  84.  54. 137. 248.  72. 248.  59.\n",
      "  97.  61.  72. 296.  55.  75.  53. 173. 158.  96. 140. 186.  93. 123.\n",
      " 237. 138. 292.  78. 182. 127. 321. 109. 212.  45.  96. 109.  89.  96.\n",
      "  60.  51. 200. 265.  68.  91. 172. 115. 125.  53.  63. 259. 214. 195.\n",
      " 258. 235. 173.  59. 219. 170.  77.  49.  66. 144. 113. 233. 162. 121.\n",
      "  88. 302. 128.  52. 178.  90. 164. 135. 103. 200. 178. 261.  64.  59.\n",
      "  79.  47. 107.  39. 151. 104. 217. 232.  55. 245. 131.  64. 222. 249.\n",
      " 128. 293. 138. 273. 158. 168. 103.]\n",
      "[[173.54413 ]\n",
      " [232.91136 ]\n",
      " [191.4303  ]\n",
      " [188.1862  ]\n",
      " [174.91504 ]\n",
      " [224.85416 ]\n",
      " [280.45258 ]\n",
      " [ 76.20512 ]\n",
      " [ 73.41692 ]\n",
      " [157.61212 ]\n",
      " [144.74911 ]\n",
      " [146.98808 ]\n",
      " [212.10403 ]\n",
      " [124.96483 ]\n",
      " [315.9723  ]\n",
      " [204.23782 ]\n",
      " [ 93.37708 ]\n",
      " [183.3533  ]\n",
      " [103.94387 ]\n",
      " [278.7572  ]\n",
      " [161.81503 ]\n",
      " [285.93277 ]\n",
      " [123.642235]\n",
      " [ 42.895702]\n",
      " [ 76.88151 ]\n",
      " [199.53384 ]\n",
      " [116.284676]\n",
      " [ 69.43483 ]\n",
      " [171.83853 ]\n",
      " [173.3959  ]\n",
      " [134.12593 ]\n",
      " [210.0105  ]\n",
      " [200.11337 ]\n",
      " [252.04984 ]\n",
      " [187.39413 ]\n",
      " [118.03427 ]\n",
      " [ 66.23875 ]\n",
      " [ 89.82789 ]\n",
      " [262.08496 ]\n",
      " [144.35527 ]\n",
      " [234.12221 ]\n",
      " [ 78.16201 ]\n",
      " [117.008446]\n",
      " [181.99759 ]\n",
      " [ 70.07054 ]\n",
      " [194.71193 ]\n",
      " [124.583374]\n",
      " [104.15878 ]\n",
      " [ 42.895702]\n",
      " [209.23695 ]\n",
      " [124.952644]\n",
      " [133.26807 ]\n",
      " [213.80608 ]\n",
      " [282.15024 ]\n",
      " [ 81.83137 ]\n",
      " [ 68.8825  ]\n",
      " [208.75172 ]\n",
      " [210.54565 ]\n",
      " [165.99905 ]\n",
      " [229.22493 ]\n",
      " [ 73.17678 ]\n",
      " [ 90.523735]\n",
      " [301.5143  ]\n",
      " [196.89406 ]\n",
      " [135.4761  ]\n",
      " [ 42.895702]\n",
      " [ 71.93159 ]\n",
      " [236.56627 ]\n",
      " [105.49922 ]\n",
      " [110.76078 ]\n",
      " [108.62374 ]\n",
      " [ 69.76864 ]\n",
      " [272.5059  ]\n",
      " [135.20918 ]\n",
      " [112.663414]\n",
      " [194.48645 ]\n",
      " [117.31627 ]\n",
      " [ 93.328705]\n",
      " [135.83374 ]\n",
      " [ 69.66657 ]\n",
      " [ 68.57284 ]\n",
      " [151.81635 ]\n",
      " [162.09541 ]\n",
      " [285.50995 ]\n",
      " [283.11942 ]\n",
      " [187.80745 ]\n",
      " [190.11934 ]\n",
      " [ 96.82643 ]\n",
      " [156.2414  ]\n",
      " [217.64754 ]\n",
      " [202.34695 ]\n",
      " [ 63.297638]\n",
      " [155.35376 ]\n",
      " [114.27584 ]\n",
      " [246.53696 ]\n",
      " [269.55334 ]\n",
      " [199.14267 ]\n",
      " [162.5372  ]\n",
      " [143.48636 ]\n",
      " [192.74896 ]\n",
      " [ 64.80192 ]\n",
      " [ 67.18041 ]\n",
      " [172.32132 ]\n",
      " [131.74193 ]\n",
      " [ 87.79379 ]\n",
      " [ 50.521748]\n",
      " [ 75.790405]\n",
      " [150.10469 ]\n",
      " [178.4997  ]\n",
      " [206.71043 ]\n",
      " [ 66.922745]\n",
      " [179.81953 ]\n",
      " [125.23119 ]\n",
      " [ 73.05607 ]\n",
      " [ 75.180176]\n",
      " [ 69.46183 ]\n",
      " [247.93756 ]\n",
      " [102.094894]\n",
      " [178.95403 ]\n",
      " [237.30037 ]\n",
      " [148.44107 ]\n",
      " [125.056725]\n",
      " [135.79546 ]\n",
      " [ 92.48632 ]\n",
      " [251.51495 ]\n",
      " [200.76848 ]\n",
      " [246.72986 ]\n",
      " [222.2667  ]\n",
      " [ 63.297638]\n",
      " [289.76688 ]\n",
      " [ 67.081856]\n",
      " [224.99878 ]\n",
      " [179.21634 ]]\n",
      "=================\n",
      "R2 :  0.32461168540538676\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.6518\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.3336\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.0061\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.6231\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 18.7231\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.2482\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.6124\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.9459\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 19.1448\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.2403\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.3538\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.4538\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.2104\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 17.0417\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.6536\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.3233\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.9253\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.8237\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 18.1508\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.0355\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.9848\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.5135\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.7430\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 19.5589\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.2096\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.2152\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.5242\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.0562\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.8029\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 18.7518\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.5280\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.5682\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.6200\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.1866\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.3915\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 18.7012\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.9097\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.6353\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.8132\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.3977\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 17.5805\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.4857\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.8089\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.5447\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 16.6706\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.8909\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.7618\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.2987\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.6967\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 17.0864\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.8540\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.1673\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.9518\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 17.5182\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.8952\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.7011\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.7744\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.1155\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 19.0520\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.5821\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.7694\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.4645\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.8094\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 16.2748\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.8461\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.5631\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.5547\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.7773\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 17.7422\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.1298\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.8472\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.5413\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.1931\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 16.2400\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.3982\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.3453\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.2992\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 16.6466\n",
      "Epoch 79/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 102us/step - loss: 16.6466\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 51.2276\n",
      "loss :  51.227622985839844\n",
      "5/5 [==============================] - 0s 887us/step\n",
      "=================\n",
      "[185. 150. 246. 184. 110. 202. 336.  69.  69.  87.  66. 164. 265. 198.\n",
      " 248. 171. 102. 182. 262. 233. 151. 275. 230.  39.  42. 122.  81.  31.\n",
      " 156. 161.  80. 215. 310. 163. 265.  84.  54. 137. 248.  72. 248.  59.\n",
      "  97.  61.  72. 296.  55.  75.  53. 173. 158.  96. 140. 186.  93. 123.\n",
      " 237. 138. 292.  78. 182. 127. 321. 109. 212.  45.  96. 109.  89.  96.\n",
      "  60.  51. 200. 265.  68.  91. 172. 115. 125.  53.  63. 259. 214. 195.\n",
      " 258. 235. 173.  59. 219. 170.  77.  49.  66. 144. 113. 233. 162. 121.\n",
      "  88. 302. 128.  52. 178.  90. 164. 135. 103. 200. 178. 261.  64.  59.\n",
      "  79.  47. 107.  39. 151. 104. 217. 232.  55. 245. 131.  64. 222. 249.\n",
      " 128. 293. 138. 273. 158. 168. 103.]\n",
      "[[114.986916]\n",
      " [231.43701 ]\n",
      " [190.18959 ]\n",
      " [190.24011 ]\n",
      " [162.19086 ]\n",
      " [204.46391 ]\n",
      " [265.33475 ]\n",
      " [ 69.97853 ]\n",
      " [ 73.228424]\n",
      " [141.95421 ]\n",
      " [127.30574 ]\n",
      " [144.25484 ]\n",
      " [198.86378 ]\n",
      " [129.25453 ]\n",
      " [306.95743 ]\n",
      " [206.974   ]\n",
      " [ 82.891556]\n",
      " [172.68752 ]\n",
      " [ 94.09955 ]\n",
      " [260.79367 ]\n",
      " [178.74754 ]\n",
      " [263.00418 ]\n",
      " [114.41168 ]\n",
      " [ 42.19918 ]\n",
      " [ 74.6826  ]\n",
      " [224.15962 ]\n",
      " [107.73256 ]\n",
      " [ 62.91932 ]\n",
      " [159.92761 ]\n",
      " [178.03096 ]\n",
      " [135.23967 ]\n",
      " [217.14925 ]\n",
      " [210.58687 ]\n",
      " [230.19955 ]\n",
      " [183.08492 ]\n",
      " [112.12976 ]\n",
      " [ 64.942474]\n",
      " [ 85.63878 ]\n",
      " [267.7566  ]\n",
      " [152.6605  ]\n",
      " [229.23067 ]\n",
      " [ 79.648026]\n",
      " [108.36034 ]\n",
      " [167.3561  ]\n",
      " [ 74.62132 ]\n",
      " [180.36382 ]\n",
      " [121.403625]\n",
      " [ 94.33998 ]\n",
      " [ 46.807453]\n",
      " [220.82668 ]\n",
      " [127.56205 ]\n",
      " [136.34016 ]\n",
      " [208.80919 ]\n",
      " [271.1592  ]\n",
      " [ 98.02454 ]\n",
      " [ 65.93228 ]\n",
      " [194.30432 ]\n",
      " [201.22995 ]\n",
      " [184.18459 ]\n",
      " [224.57886 ]\n",
      " [ 71.444244]\n",
      " [ 74.212685]\n",
      " [281.64618 ]\n",
      " [213.15099 ]\n",
      " [114.617645]\n",
      " [ 49.594627]\n",
      " [ 70.2775  ]\n",
      " [211.92839 ]\n",
      " [101.57191 ]\n",
      " [ 80.692024]\n",
      " [ 88.30511 ]\n",
      " [ 68.95395 ]\n",
      " [305.6719  ]\n",
      " [152.58743 ]\n",
      " [132.2595  ]\n",
      " [182.80489 ]\n",
      " [115.27037 ]\n",
      " [ 89.30545 ]\n",
      " [126.004105]\n",
      " [ 68.72208 ]\n",
      " [ 68.15047 ]\n",
      " [135.0866  ]\n",
      " [175.89792 ]\n",
      " [296.68933 ]\n",
      " [273.82755 ]\n",
      " [169.0854  ]\n",
      " [199.50366 ]\n",
      " [ 87.42252 ]\n",
      " [139.96251 ]\n",
      " [194.78214 ]\n",
      " [188.91264 ]\n",
      " [ 62.91932 ]\n",
      " [171.5002  ]\n",
      " [116.730774]\n",
      " [266.368   ]\n",
      " [255.05269 ]\n",
      " [218.27979 ]\n",
      " [193.05592 ]\n",
      " [ 85.90915 ]\n",
      " [195.5281  ]\n",
      " [ 63.774277]\n",
      " [ 66.75542 ]\n",
      " [149.14784 ]\n",
      " [123.86551 ]\n",
      " [ 89.08353 ]\n",
      " [ 49.59173 ]\n",
      " [ 69.24577 ]\n",
      " [165.34206 ]\n",
      " [158.38124 ]\n",
      " [175.99243 ]\n",
      " [ 66.11982 ]\n",
      " [193.43901 ]\n",
      " [121.41378 ]\n",
      " [ 73.919426]\n",
      " [ 74.16503 ]\n",
      " [ 69.24829 ]\n",
      " [227.48195 ]\n",
      " [110.728195]\n",
      " [165.0893  ]\n",
      " [216.15468 ]\n",
      " [143.66898 ]\n",
      " [114.93605 ]\n",
      " [104.98901 ]\n",
      " [ 73.50864 ]\n",
      " [239.99995 ]\n",
      " [207.46815 ]\n",
      " [255.96254 ]\n",
      " [207.46024 ]\n",
      " [ 62.919327]\n",
      " [271.75424 ]\n",
      " [ 68.79108 ]\n",
      " [190.93137 ]\n",
      " [174.3149  ]]\n",
      "=================\n",
      "R2 :  0.29890826999640285\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.7903\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.3889\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 18.3671\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.6043\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.1198\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.9916\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.6280\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.9877\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 17.5153\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.2481\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.3648\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.0693\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.3730\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 16.5838\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.6933\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.4504\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.7209\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.0745\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.5648\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 17.0491\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.0142\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.0520\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.8476\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 16.3173\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.6601\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.0458\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.3912\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.6561\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.4024\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 17.0213\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.0076\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.8768\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.9648\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.1546\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.9761\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 16.4902\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.9437\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.0850\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.8480\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.7803\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.4322\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 17.5070\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.9163\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.1694\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.8809\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.4367\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.0994\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 17.2813\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.9080\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.5694\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.8702\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.1223\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 17.1644\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.7821\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.0997\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.6222\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.1290\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.1730\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.8491\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 16.6729\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.0157\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.0964\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.8899\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.0434\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.9038\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.7134\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.9596\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.7013\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.8253\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.6292\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.4475\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 15.9862\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.6386\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.0929\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.6483\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 15.8708\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.1097\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.5437\n",
      "Epoch 79/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 90us/step - loss: 17.5437\n",
      "5/5 [==============================] - 0s 997us/step - loss: 49.9949\n",
      "loss :  49.9948616027832\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "=================\n",
      "[185. 150. 246. 184. 110. 202. 336.  69.  69.  87.  66. 164. 265. 198.\n",
      " 248. 171. 102. 182. 262. 233. 151. 275. 230.  39.  42. 122.  81.  31.\n",
      " 156. 161.  80. 215. 310. 163. 265.  84.  54. 137. 248.  72. 248.  59.\n",
      "  97.  61.  72. 296.  55.  75.  53. 173. 158.  96. 140. 186.  93. 123.\n",
      " 237. 138. 292.  78. 182. 127. 321. 109. 212.  45.  96. 109.  89.  96.\n",
      "  60.  51. 200. 265.  68.  91. 172. 115. 125.  53.  63. 259. 214. 195.\n",
      " 258. 235. 173.  59. 219. 170.  77.  49.  66. 144. 113. 233. 162. 121.\n",
      "  88. 302. 128.  52. 178.  90. 164. 135. 103. 200. 178. 261.  64.  59.\n",
      "  79.  47. 107.  39. 151. 104. 217. 232.  55. 245. 131.  64. 222. 249.\n",
      " 128. 293. 138. 273. 158. 168. 103.]\n",
      "[[216.00249 ]\n",
      " [227.99425 ]\n",
      " [195.43724 ]\n",
      " [185.69757 ]\n",
      " [166.65204 ]\n",
      " [209.10905 ]\n",
      " [274.18207 ]\n",
      " [ 65.437805]\n",
      " [ 76.80278 ]\n",
      " [138.26894 ]\n",
      " [123.337616]\n",
      " [164.06107 ]\n",
      " [218.42479 ]\n",
      " [132.22266 ]\n",
      " [307.25513 ]\n",
      " [199.36426 ]\n",
      " [ 72.21191 ]\n",
      " [180.39502 ]\n",
      " [ 89.680046]\n",
      " [262.32748 ]\n",
      " [143.8438  ]\n",
      " [268.9576  ]\n",
      " [131.2494  ]\n",
      " [ 42.000324]\n",
      " [ 72.2733  ]\n",
      " [191.92146 ]\n",
      " [102.85465 ]\n",
      " [ 59.956196]\n",
      " [162.7348  ]\n",
      " [235.32776 ]\n",
      " [117.89795 ]\n",
      " [210.25876 ]\n",
      " [209.8882  ]\n",
      " [234.28496 ]\n",
      " [188.56566 ]\n",
      " [ 90.04947 ]\n",
      " [ 62.383823]\n",
      " [ 80.60336 ]\n",
      " [260.02    ]\n",
      " [145.16519 ]\n",
      " [228.91315 ]\n",
      " [ 74.2815  ]\n",
      " [110.52396 ]\n",
      " [189.63469 ]\n",
      " [ 64.15028 ]\n",
      " [184.15715 ]\n",
      " [137.16548 ]\n",
      " [ 89.16834 ]\n",
      " [ 42.000324]\n",
      " [208.95119 ]\n",
      " [126.84383 ]\n",
      " [125.9485  ]\n",
      " [213.96223 ]\n",
      " [255.70653 ]\n",
      " [ 84.14958 ]\n",
      " [ 58.380344]\n",
      " [189.38814 ]\n",
      " [196.72003 ]\n",
      " [162.68718 ]\n",
      " [232.0939  ]\n",
      " [ 68.6223  ]\n",
      " [ 70.38144 ]\n",
      " [282.0624  ]\n",
      " [211.30196 ]\n",
      " [142.16252 ]\n",
      " [ 48.12673 ]\n",
      " [ 68.1552  ]\n",
      " [203.41438 ]\n",
      " [ 95.23621 ]\n",
      " [102.36322 ]\n",
      " [ 94.99636 ]\n",
      " [ 64.72005 ]\n",
      " [275.44653 ]\n",
      " [171.0302  ]\n",
      " [117.96146 ]\n",
      " [187.11366 ]\n",
      " [105.634514]\n",
      " [ 83.815384]\n",
      " [123.42872 ]\n",
      " [ 66.28418 ]\n",
      " [109.62903 ]\n",
      " [104.53815 ]\n",
      " [134.25769 ]\n",
      " [290.17868 ]\n",
      " [256.51584 ]\n",
      " [207.79225 ]\n",
      " [195.63402 ]\n",
      " [ 82.28744 ]\n",
      " [171.39233 ]\n",
      " [194.42145 ]\n",
      " [191.5327  ]\n",
      " [ 59.147034]\n",
      " [172.99022 ]\n",
      " [ 88.76007 ]\n",
      " [267.03452 ]\n",
      " [259.9805  ]\n",
      " [194.7228  ]\n",
      " [164.82327 ]\n",
      " [145.81184 ]\n",
      " [189.68475 ]\n",
      " [ 59.687473]\n",
      " [ 64.969536]\n",
      " [140.82028 ]\n",
      " [130.34656 ]\n",
      " [ 84.06453 ]\n",
      " [ 48.12673 ]\n",
      " [ 96.268234]\n",
      " [141.51122 ]\n",
      " [163.2736  ]\n",
      " [163.4918  ]\n",
      " [ 65.3457  ]\n",
      " [184.8491  ]\n",
      " [115.294876]\n",
      " [ 68.98253 ]\n",
      " [ 72.59225 ]\n",
      " [ 65.38571 ]\n",
      " [231.40816 ]\n",
      " [100.09346 ]\n",
      " [170.94865 ]\n",
      " [213.54607 ]\n",
      " [146.20619 ]\n",
      " [124.13611 ]\n",
      " [117.256874]\n",
      " [ 83.834946]\n",
      " [225.796   ]\n",
      " [207.52591 ]\n",
      " [257.9765  ]\n",
      " [205.5806  ]\n",
      " [ 59.204746]\n",
      " [256.95816 ]\n",
      " [ 64.81978 ]\n",
      " [196.30345 ]\n",
      " [155.7285  ]]\n",
      "=================\n",
      "R2 :  0.31135646693402186\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 17.6972\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.0818\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.1742\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.8890\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.1677\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.9596\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 16.9114\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.2234\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.5014\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.9114\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.2941\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 16.5087\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.2609\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.9492\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.7938\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.1043\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.5514\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 16.8634\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.4567\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.8391\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.2636\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.9728\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.1460\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.7480\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.7932\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.6711\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.0009\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.2189\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.8626\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.5896\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.0615\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.1039\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.7235\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.5058\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.3569\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.3883\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.5954\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.6432\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.0786\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.7213\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.3724\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 16.3375\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.1214\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.5033\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.2519\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 15.0467\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.9495\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.4372\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.5214\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.9527\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 16.7836\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.7281\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.0358\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.2554\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.8259\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.2368\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 17.3181\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.2643\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.4396\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.3912\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.1614\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.7856\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.9399\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.0690\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.3306\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.8512\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 15.3605\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.2591\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.5585\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.5294\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.6635\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 15.7541\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.2354\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.4228\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.1114\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.3887\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.8037\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.2877\n",
      "Epoch 79/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 103us/step - loss: 15.2877\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 51.8806\n",
      "loss :  51.880645751953125\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "=================\n",
      "[185. 150. 246. 184. 110. 202. 336.  69.  69.  87.  66. 164. 265. 198.\n",
      " 248. 171. 102. 182. 262. 233. 151. 275. 230.  39.  42. 122.  81.  31.\n",
      " 156. 161.  80. 215. 310. 163. 265.  84.  54. 137. 248.  72. 248.  59.\n",
      "  97.  61.  72. 296.  55.  75.  53. 173. 158.  96. 140. 186.  93. 123.\n",
      " 237. 138. 292.  78. 182. 127. 321. 109. 212.  45.  96. 109.  89.  96.\n",
      "  60.  51. 200. 265.  68.  91. 172. 115. 125.  53.  63. 259. 214. 195.\n",
      " 258. 235. 173.  59. 219. 170.  77.  49.  66. 144. 113. 233. 162. 121.\n",
      "  88. 302. 128.  52. 178.  90. 164. 135. 103. 200. 178. 261.  64.  59.\n",
      "  79.  47. 107.  39. 151. 104. 217. 232.  55. 245. 131.  64. 222. 249.\n",
      " 128. 293. 138. 273. 158. 168. 103.]\n",
      "[[173.82019 ]\n",
      " [228.1274  ]\n",
      " [190.50467 ]\n",
      " [195.23032 ]\n",
      " [155.61636 ]\n",
      " [220.71384 ]\n",
      " [294.9437  ]\n",
      " [ 65.28958 ]\n",
      " [ 83.443016]\n",
      " [151.87866 ]\n",
      " [140.69214 ]\n",
      " [154.92387 ]\n",
      " [216.08798 ]\n",
      " [112.411804]\n",
      " [312.95325 ]\n",
      " [199.30975 ]\n",
      " [ 75.68916 ]\n",
      " [175.1849  ]\n",
      " [ 97.08963 ]\n",
      " [272.89682 ]\n",
      " [112.99591 ]\n",
      " [283.97852 ]\n",
      " [116.94565 ]\n",
      " [ 42.86253 ]\n",
      " [ 73.63266 ]\n",
      " [219.89114 ]\n",
      " [105.9132  ]\n",
      " [ 63.61276 ]\n",
      " [151.12097 ]\n",
      " [149.676   ]\n",
      " [127.596466]\n",
      " [199.36646 ]\n",
      " [195.14107 ]\n",
      " [239.9219  ]\n",
      " [180.89006 ]\n",
      " [107.32096 ]\n",
      " [ 63.905216]\n",
      " [ 78.39533 ]\n",
      " [266.72327 ]\n",
      " [136.29529 ]\n",
      " [225.76294 ]\n",
      " [ 77.441505]\n",
      " [101.11853 ]\n",
      " [190.99757 ]\n",
      " [ 77.63768 ]\n",
      " [175.38713 ]\n",
      " [129.65564 ]\n",
      " [ 94.56433 ]\n",
      " [ 47.350597]\n",
      " [208.21234 ]\n",
      " [110.084625]\n",
      " [131.3451  ]\n",
      " [228.73944 ]\n",
      " [277.77933 ]\n",
      " [ 75.708954]\n",
      " [ 69.33139 ]\n",
      " [193.28609 ]\n",
      " [199.51654 ]\n",
      " [143.58386 ]\n",
      " [236.66602 ]\n",
      " [ 67.83002 ]\n",
      " [ 63.62676 ]\n",
      " [289.1649  ]\n",
      " [217.23999 ]\n",
      " [118.25113 ]\n",
      " [ 47.44461 ]\n",
      " [ 70.293045]\n",
      " [216.41351 ]\n",
      " [106.166565]\n",
      " [ 98.05243 ]\n",
      " [ 85.17807 ]\n",
      " [ 65.99646 ]\n",
      " [297.40924 ]\n",
      " [145.33087 ]\n",
      " [127.659485]\n",
      " [179.91548 ]\n",
      " [118.55445 ]\n",
      " [ 88.332184]\n",
      " [115.36462 ]\n",
      " [ 67.00963 ]\n",
      " [ 81.991394]\n",
      " [105.06635 ]\n",
      " [175.75389 ]\n",
      " [280.01376 ]\n",
      " [261.28806 ]\n",
      " [165.02513 ]\n",
      " [199.9844  ]\n",
      " [ 87.05166 ]\n",
      " [168.31734 ]\n",
      " [202.77534 ]\n",
      " [180.82954 ]\n",
      " [ 54.58417 ]\n",
      " [173.53021 ]\n",
      " [ 93.021034]\n",
      " [261.28116 ]\n",
      " [259.34525 ]\n",
      " [209.2514  ]\n",
      " [170.28061 ]\n",
      " [120.773026]\n",
      " [183.56291 ]\n",
      " [ 63.319584]\n",
      " [ 66.290054]\n",
      " [164.6788  ]\n",
      " [125.32585 ]\n",
      " [ 82.85342 ]\n",
      " [ 52.477924]\n",
      " [ 70.376724]\n",
      " [136.25694 ]\n",
      " [158.20604 ]\n",
      " [196.27592 ]\n",
      " [ 65.069626]\n",
      " [179.79091 ]\n",
      " [115.90105 ]\n",
      " [ 72.781235]\n",
      " [ 76.77878 ]\n",
      " [ 66.63652 ]\n",
      " [234.16629 ]\n",
      " [111.37014 ]\n",
      " [168.14539 ]\n",
      " [231.0564  ]\n",
      " [141.04033 ]\n",
      " [115.40054 ]\n",
      " [120.19844 ]\n",
      " [ 74.47602 ]\n",
      " [220.75705 ]\n",
      " [182.8009  ]\n",
      " [251.49425 ]\n",
      " [199.62439 ]\n",
      " [ 63.319576]\n",
      " [258.2173  ]\n",
      " [ 65.19161 ]\n",
      " [206.4899  ]\n",
      " [174.0416  ]]\n",
      "=================\n",
      "R2 :  0.26798440636612275\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.4914\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 16.3641\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.0985\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.1270\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.5115\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.4168\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.1503\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 16.5094\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.6155\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.6400\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.0136\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 15.6173\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.0582\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.8168\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.9156\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.6710\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.4963\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.6515\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.3245\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.9856\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 15.5216\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.8725\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.2183\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.2431\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.2387\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.7275\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.4960\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.3998\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.6486\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 15.3360\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.6633\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.6556\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.7314\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.4206\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 15.8638\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.8215\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.3388\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.9629\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 15.3591\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.8294\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.7383\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.5885\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.4701\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.8812\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.6637\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.3988\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.5461\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.3836\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 16.8765\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.6424\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.1978\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.4594\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.9310\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.9159\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.9108\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.7687\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.8655\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.4438\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.9417\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 18.2738\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.9558\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.6996\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.8742\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 15.4342\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.5848\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.6107\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.0555\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.3576\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.5311\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 16.4587\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.3560\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.8551\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.8239\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.2044\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.3894\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.7616\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.5532\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.5702\n",
      "Epoch 79/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 104us/step - loss: 14.5702\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 51.3864\n",
      "loss :  51.38643264770508\n",
      "5/5 [==============================] - 0s 748us/step\n",
      "=================\n",
      "[185. 150. 246. 184. 110. 202. 336.  69.  69.  87.  66. 164. 265. 198.\n",
      " 248. 171. 102. 182. 262. 233. 151. 275. 230.  39.  42. 122.  81.  31.\n",
      " 156. 161.  80. 215. 310. 163. 265.  84.  54. 137. 248.  72. 248.  59.\n",
      "  97.  61.  72. 296.  55.  75.  53. 173. 158.  96. 140. 186.  93. 123.\n",
      " 237. 138. 292.  78. 182. 127. 321. 109. 212.  45.  96. 109.  89.  96.\n",
      "  60.  51. 200. 265.  68.  91. 172. 115. 125.  53.  63. 259. 214. 195.\n",
      " 258. 235. 173.  59. 219. 170.  77.  49.  66. 144. 113. 233. 162. 121.\n",
      "  88. 302. 128.  52. 178.  90. 164. 135. 103. 200. 178. 261.  64.  59.\n",
      "  79.  47. 107.  39. 151. 104. 217. 232.  55. 245. 131.  64. 222. 249.\n",
      " 128. 293. 138. 273. 158. 168. 103.]\n",
      "[[217.79019 ]\n",
      " [231.2726  ]\n",
      " [202.48907 ]\n",
      " [179.492   ]\n",
      " [172.29921 ]\n",
      " [216.24565 ]\n",
      " [286.33102 ]\n",
      " [ 67.65251 ]\n",
      " [105.85098 ]\n",
      " [148.68845 ]\n",
      " [154.03346 ]\n",
      " [170.10071 ]\n",
      " [198.92184 ]\n",
      " [135.66684 ]\n",
      " [285.79034 ]\n",
      " [217.43993 ]\n",
      " [ 77.99115 ]\n",
      " [176.69226 ]\n",
      " [104.3576  ]\n",
      " [260.38287 ]\n",
      " [150.05852 ]\n",
      " [278.0629  ]\n",
      " [123.45654 ]\n",
      " [ 41.48713 ]\n",
      " [ 74.41814 ]\n",
      " [209.27979 ]\n",
      " [105.97058 ]\n",
      " [ 67.61648 ]\n",
      " [157.00995 ]\n",
      " [222.91432 ]\n",
      " [128.15225 ]\n",
      " [205.07465 ]\n",
      " [207.28148 ]\n",
      " [234.17616 ]\n",
      " [194.99452 ]\n",
      " [ 86.05533 ]\n",
      " [ 62.241913]\n",
      " [ 77.81701 ]\n",
      " [258.01407 ]\n",
      " [154.0227  ]\n",
      " [237.20543 ]\n",
      " [ 76.778114]\n",
      " [105.98878 ]\n",
      " [194.68872 ]\n",
      " [ 66.92386 ]\n",
      " [184.10059 ]\n",
      " [149.84258 ]\n",
      " [ 96.17081 ]\n",
      " [ 42.76085 ]\n",
      " [200.44359 ]\n",
      " [127.49243 ]\n",
      " [125.741196]\n",
      " [209.09105 ]\n",
      " [270.26532 ]\n",
      " [ 89.79764 ]\n",
      " [ 65.51333 ]\n",
      " [188.09279 ]\n",
      " [206.74408 ]\n",
      " [150.25291 ]\n",
      " [197.52156 ]\n",
      " [ 67.02162 ]\n",
      " [ 70.26578 ]\n",
      " [280.34662 ]\n",
      " [226.5576  ]\n",
      " [128.87071 ]\n",
      " [ 48.23247 ]\n",
      " [ 71.98359 ]\n",
      " [201.36456 ]\n",
      " [102.685585]\n",
      " [ 99.64455 ]\n",
      " [ 87.22221 ]\n",
      " [ 64.182594]\n",
      " [288.21262 ]\n",
      " [166.639   ]\n",
      " [126.67546 ]\n",
      " [194.89284 ]\n",
      " [125.138916]\n",
      " [ 89.651886]\n",
      " [114.17699 ]\n",
      " [ 67.22144 ]\n",
      " [ 93.8385  ]\n",
      " [ 97.67157 ]\n",
      " [151.03087 ]\n",
      " [280.8186  ]\n",
      " [240.43134 ]\n",
      " [158.29305 ]\n",
      " [190.15312 ]\n",
      " [ 82.40405 ]\n",
      " [180.02434 ]\n",
      " [202.05687 ]\n",
      " [198.21596 ]\n",
      " [ 57.91468 ]\n",
      " [174.41951 ]\n",
      " [ 73.868034]\n",
      " [260.55692 ]\n",
      " [237.37132 ]\n",
      " [216.20741 ]\n",
      " [175.25288 ]\n",
      " [132.72939 ]\n",
      " [203.167   ]\n",
      " [ 62.299202]\n",
      " [ 65.50462 ]\n",
      " [153.25916 ]\n",
      " [143.17397 ]\n",
      " [ 73.26221 ]\n",
      " [ 52.860676]\n",
      " [116.831696]\n",
      " [106.180145]\n",
      " [164.27977 ]\n",
      " [162.36528 ]\n",
      " [ 64.67742 ]\n",
      " [177.80264 ]\n",
      " [114.467545]\n",
      " [ 72.20065 ]\n",
      " [ 75.38872 ]\n",
      " [ 71.19997 ]\n",
      " [229.4268  ]\n",
      " [115.01921 ]\n",
      " [172.6639  ]\n",
      " [225.88957 ]\n",
      " [123.04132 ]\n",
      " [131.4976  ]\n",
      " [118.52127 ]\n",
      " [ 82.32475 ]\n",
      " [240.2547  ]\n",
      " [204.84367 ]\n",
      " [254.46587 ]\n",
      " [203.40987 ]\n",
      " [ 62.148155]\n",
      " [237.26653 ]\n",
      " [ 66.73019 ]\n",
      " [200.60555 ]\n",
      " [155.83942 ]]\n",
      "=================\n",
      "R2 :  0.29144847089581083\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.4309\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.8420\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.5324\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 16.7805\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.4526\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.7204\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.6950\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.4555\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 15.5515\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.4756\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.3385\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.0510\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.0712\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 15.5576\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.1780\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.0607\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.7156\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 13.4680\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.1342\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.6816\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.4577\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.0615\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.7027\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.5293\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.9510\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.8833\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.3941\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.8569\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 16.2577\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.2876\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.8425\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.1292\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.2933\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 15.3862\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.7406\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.0030\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.1408\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.3504\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.5204\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.0794\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 13.8115\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.4226\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.0439\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.2644\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 15.1073\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.7069\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 15.4569\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.4896\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.6580\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.2909\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.8165\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.1228\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 13.9314\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.3865\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 15.0440\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.7922\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.6639\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.8305\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.0263\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.3884\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 16.4383\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.8210\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.5428\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.9489\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 15.2841\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.3776\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.1096\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.6055\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 15.0830\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.3795\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.4788\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.5080\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 15.9909\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.6243\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.1836\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.6823\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.4602\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.6048\n",
      "Epoch 79/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 97us/step - loss: 14.6048\n",
      "5/5 [==============================] - 0s 998us/step - loss: 51.0579\n",
      "loss :  51.057899475097656\n",
      "5/5 [==============================] - 0s 998us/step\n",
      "=================\n",
      "[185. 150. 246. 184. 110. 202. 336.  69.  69.  87.  66. 164. 265. 198.\n",
      " 248. 171. 102. 182. 262. 233. 151. 275. 230.  39.  42. 122.  81.  31.\n",
      " 156. 161.  80. 215. 310. 163. 265.  84.  54. 137. 248.  72. 248.  59.\n",
      "  97.  61.  72. 296.  55.  75.  53. 173. 158.  96. 140. 186.  93. 123.\n",
      " 237. 138. 292.  78. 182. 127. 321. 109. 212.  45.  96. 109.  89.  96.\n",
      "  60.  51. 200. 265.  68.  91. 172. 115. 125.  53.  63. 259. 214. 195.\n",
      " 258. 235. 173.  59. 219. 170.  77.  49.  66. 144. 113. 233. 162. 121.\n",
      "  88. 302. 128.  52. 178.  90. 164. 135. 103. 200. 178. 261.  64.  59.\n",
      "  79.  47. 107.  39. 151. 104. 217. 232.  55. 245. 131.  64. 222. 249.\n",
      " 128. 293. 138. 273. 158. 168. 103.]\n",
      "[[214.26596 ]\n",
      " [222.7594  ]\n",
      " [212.64517 ]\n",
      " [181.88986 ]\n",
      " [162.19418 ]\n",
      " [216.90643 ]\n",
      " [299.62146 ]\n",
      " [ 67.197525]\n",
      " [ 83.31912 ]\n",
      " [160.92325 ]\n",
      " [154.73398 ]\n",
      " [153.71681 ]\n",
      " [209.9548  ]\n",
      " [149.86577 ]\n",
      " [298.19537 ]\n",
      " [220.78326 ]\n",
      " [ 78.506004]\n",
      " [187.91084 ]\n",
      " [126.82914 ]\n",
      " [272.97913 ]\n",
      " [148.30484 ]\n",
      " [293.67938 ]\n",
      " [132.88881 ]\n",
      " [ 42.680138]\n",
      " [ 71.57167 ]\n",
      " [224.69699 ]\n",
      " [106.835365]\n",
      " [ 63.368584]\n",
      " [156.27151 ]\n",
      " [229.52783 ]\n",
      " [149.07822 ]\n",
      " [210.60735 ]\n",
      " [208.12949 ]\n",
      " [244.89935 ]\n",
      " [198.77092 ]\n",
      " [ 91.837746]\n",
      " [ 63.264877]\n",
      " [ 74.7183  ]\n",
      " [270.1072  ]\n",
      " [159.9874  ]\n",
      " [239.6812  ]\n",
      " [ 80.058136]\n",
      " [ 98.26775 ]\n",
      " [195.55373 ]\n",
      " [ 68.302   ]\n",
      " [197.1081  ]\n",
      " [128.73814 ]\n",
      " [ 94.86919 ]\n",
      " [ 43.80094 ]\n",
      " [238.26811 ]\n",
      " [125.667595]\n",
      " [115.467445]\n",
      " [223.21603 ]\n",
      " [281.4     ]\n",
      " [ 92.21776 ]\n",
      " [ 71.41154 ]\n",
      " [208.2742  ]\n",
      " [205.27893 ]\n",
      " [194.8345  ]\n",
      " [241.68605 ]\n",
      " [ 66.15604 ]\n",
      " [ 73.70729 ]\n",
      " [291.2162  ]\n",
      " [231.10779 ]\n",
      " [115.36225 ]\n",
      " [ 47.170605]\n",
      " [ 70.94205 ]\n",
      " [207.51483 ]\n",
      " [103.42268 ]\n",
      " [ 90.28546 ]\n",
      " [ 84.99926 ]\n",
      " [ 64.61411 ]\n",
      " [301.71213 ]\n",
      " [179.20818 ]\n",
      " [121.27068 ]\n",
      " [184.11996 ]\n",
      " [124.51627 ]\n",
      " [ 91.79101 ]\n",
      " [113.83869 ]\n",
      " [ 66.85227 ]\n",
      " [ 66.53115 ]\n",
      " [ 99.52685 ]\n",
      " [157.64005 ]\n",
      " [295.0148  ]\n",
      " [248.48386 ]\n",
      " [166.2649  ]\n",
      " [196.96051 ]\n",
      " [ 83.76773 ]\n",
      " [175.0992  ]\n",
      " [215.43195 ]\n",
      " [194.86937 ]\n",
      " [ 59.090805]\n",
      " [181.46877 ]\n",
      " [ 92.048325]\n",
      " [261.67416 ]\n",
      " [267.73288 ]\n",
      " [218.1     ]\n",
      " [192.7278  ]\n",
      " [114.8805  ]\n",
      " [186.0626  ]\n",
      " [ 63.432575]\n",
      " [ 66.29308 ]\n",
      " [158.72699 ]\n",
      " [144.73494 ]\n",
      " [ 80.63088 ]\n",
      " [ 51.437977]\n",
      " [ 76.36726 ]\n",
      " [136.32178 ]\n",
      " [175.02461 ]\n",
      " [174.44269 ]\n",
      " [ 65.63583 ]\n",
      " [184.51456 ]\n",
      " [118.66071 ]\n",
      " [ 69.07672 ]\n",
      " [ 80.981544]\n",
      " [ 68.78205 ]\n",
      " [239.0568  ]\n",
      " [114.336685]\n",
      " [181.06914 ]\n",
      " [233.76587 ]\n",
      " [138.27557 ]\n",
      " [126.695   ]\n",
      " [124.82633 ]\n",
      " [ 92.65281 ]\n",
      " [244.44778 ]\n",
      " [213.03546 ]\n",
      " [263.2989  ]\n",
      " [209.33453 ]\n",
      " [ 63.34169 ]\n",
      " [250.93    ]\n",
      " [ 69.29717 ]\n",
      " [212.30734 ]\n",
      " [145.23386 ]]\n",
      "=================\n",
      "R2 :  0.29069967957111487\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 13.7629\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.0576\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.1508\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.3251\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.4693\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.5648\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.5473\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.1339\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.1308\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.2174\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.1293\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.8435\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.1995\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 16.9211\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.3817\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.1609\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.8222\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.8897\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.4330\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.3620\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.4082\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.7376\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.9815\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.8321\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.7561\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.2084\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.2740\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.4959\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.8679\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.1614\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.2569\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.0064\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.7922\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.4945\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.7479\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.1476\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.2591\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.5429\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 15.2651\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.3617\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.6697\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.8277\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 15.5318\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.8292\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.4528\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.8862\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 15.7659\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.7425\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.7881\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.1093\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 13.8977\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.4748\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.6596\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.2012\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 16.2848\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.1516\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.6404\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.9781\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 17.3828\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.4906\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.0213\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.0023\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 13.9368\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.7536\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.6778\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 13.9776\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.4995\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.1377\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.5551\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.5625\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.0072\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.1937\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.2142\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.3354\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 15.0847\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.7163\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.5305\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.4003\n",
      "Epoch 79/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 90us/step - loss: 15.4003\n",
      "5/5 [==============================] - 0s 997us/step - loss: 51.0869\n",
      "loss :  51.086856842041016\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "=================\n",
      "[185. 150. 246. 184. 110. 202. 336.  69.  69.  87.  66. 164. 265. 198.\n",
      " 248. 171. 102. 182. 262. 233. 151. 275. 230.  39.  42. 122.  81.  31.\n",
      " 156. 161.  80. 215. 310. 163. 265.  84.  54. 137. 248.  72. 248.  59.\n",
      "  97.  61.  72. 296.  55.  75.  53. 173. 158.  96. 140. 186.  93. 123.\n",
      " 237. 138. 292.  78. 182. 127. 321. 109. 212.  45.  96. 109.  89.  96.\n",
      "  60.  51. 200. 265.  68.  91. 172. 115. 125.  53.  63. 259. 214. 195.\n",
      " 258. 235. 173.  59. 219. 170.  77.  49.  66. 144. 113. 233. 162. 121.\n",
      "  88. 302. 128.  52. 178.  90. 164. 135. 103. 200. 178. 261.  64.  59.\n",
      "  79.  47. 107.  39. 151. 104. 217. 232.  55. 245. 131.  64. 222. 249.\n",
      " 128. 293. 138. 273. 158. 168. 103.]\n",
      "[[196.62161 ]\n",
      " [220.14752 ]\n",
      " [202.79965 ]\n",
      " [187.79907 ]\n",
      " [146.78674 ]\n",
      " [211.82214 ]\n",
      " [292.3825  ]\n",
      " [ 63.934986]\n",
      " [103.74733 ]\n",
      " [160.52837 ]\n",
      " [160.93645 ]\n",
      " [146.67961 ]\n",
      " [216.21686 ]\n",
      " [ 95.16212 ]\n",
      " [300.56042 ]\n",
      " [225.40295 ]\n",
      " [ 80.71882 ]\n",
      " [193.46815 ]\n",
      " [138.71338 ]\n",
      " [271.28436 ]\n",
      " [120.35508 ]\n",
      " [285.3443  ]\n",
      " [121.454315]\n",
      " [ 44.68468 ]\n",
      " [ 69.59747 ]\n",
      " [221.79962 ]\n",
      " [106.60493 ]\n",
      " [ 63.626408]\n",
      " [146.57071 ]\n",
      " [259.57697 ]\n",
      " [137.90196 ]\n",
      " [206.59976 ]\n",
      " [208.36845 ]\n",
      " [236.0932  ]\n",
      " [186.08096 ]\n",
      " [ 92.05709 ]\n",
      " [ 63.292557]\n",
      " [ 73.924355]\n",
      " [266.8703  ]\n",
      " [154.42996 ]\n",
      " [225.75018 ]\n",
      " [ 79.285034]\n",
      " [ 92.73288 ]\n",
      " [170.2283  ]\n",
      " [ 74.19729 ]\n",
      " [169.39734 ]\n",
      " [129.76451 ]\n",
      " [ 94.963974]\n",
      " [ 47.711304]\n",
      " [220.90326 ]\n",
      " [119.45702 ]\n",
      " [116.84257 ]\n",
      " [214.95755 ]\n",
      " [281.86108 ]\n",
      " [ 88.4501  ]\n",
      " [ 69.96964 ]\n",
      " [197.39502 ]\n",
      " [196.62425 ]\n",
      " [141.71692 ]\n",
      " [227.97961 ]\n",
      " [ 66.49293 ]\n",
      " [ 74.88006 ]\n",
      " [299.3796  ]\n",
      " [197.32513 ]\n",
      " [125.60642 ]\n",
      " [ 47.711304]\n",
      " [ 67.02943 ]\n",
      " [212.16895 ]\n",
      " [105.2605  ]\n",
      " [ 90.20905 ]\n",
      " [ 87.900764]\n",
      " [ 64.61108 ]\n",
      " [286.99356 ]\n",
      " [123.87765 ]\n",
      " [122.14541 ]\n",
      " [167.19518 ]\n",
      " [117.84728 ]\n",
      " [ 90.46616 ]\n",
      " [108.47047 ]\n",
      " [ 66.47055 ]\n",
      " [ 66.17837 ]\n",
      " [104.746574]\n",
      " [177.64536 ]\n",
      " [247.0347  ]\n",
      " [257.0522  ]\n",
      " [156.28745 ]\n",
      " [200.03386 ]\n",
      " [ 81.86682 ]\n",
      " [183.1971  ]\n",
      " [198.07388 ]\n",
      " [178.6744  ]\n",
      " [ 63.72517 ]\n",
      " [159.10883 ]\n",
      " [126.53589 ]\n",
      " [258.6077  ]\n",
      " [266.31177 ]\n",
      " [215.22656 ]\n",
      " [165.45834 ]\n",
      " [127.219444]\n",
      " [185.106   ]\n",
      " [ 63.605675]\n",
      " [ 66.24061 ]\n",
      " [157.3458  ]\n",
      " [132.09042 ]\n",
      " [ 79.27494 ]\n",
      " [ 63.763878]\n",
      " [ 75.94452 ]\n",
      " [ 95.53296 ]\n",
      " [166.30826 ]\n",
      " [200.87735 ]\n",
      " [ 65.57139 ]\n",
      " [182.023   ]\n",
      " [116.79713 ]\n",
      " [ 68.13644 ]\n",
      " [ 79.41225 ]\n",
      " [ 69.16684 ]\n",
      " [233.32257 ]\n",
      " [113.17286 ]\n",
      " [170.08713 ]\n",
      " [224.46524 ]\n",
      " [130.58115 ]\n",
      " [127.11138 ]\n",
      " [127.381386]\n",
      " [ 88.8005  ]\n",
      " [235.74489 ]\n",
      " [171.40843 ]\n",
      " [249.8151  ]\n",
      " [200.12561 ]\n",
      " [ 63.681305]\n",
      " [253.8739  ]\n",
      " [ 65.629364]\n",
      " [203.2077  ]\n",
      " [165.18799 ]]\n",
      "=================\n",
      "R2 :  0.2968568740136227\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.9303\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.5145\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.6913\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.9246\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.5244\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.6003\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.9217\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.9569\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.5513\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.5342\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 15.0561\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.8039\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.8058\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.9904\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.3739\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.6700\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.3860\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.1256\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 15.2021\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.2696\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.4488\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 15.6269\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.3136\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.4145\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.6350\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 15.2215\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.1400\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.9724\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.1374\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.1896\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.2911\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.4289\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.3096\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 15.5556\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.3939\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.6553\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 13.7349\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.7008\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 16.9297\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.5134\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.4383\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.6034\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.0828\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.9026\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.0356\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.4890\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 13.5087\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.7806\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.8435\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 16.3177\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.2192\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.3209\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.1048\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.7143\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 15.5025\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.7964\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.7945\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.7909\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.4589\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.3040\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.8028\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.4660\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.3815\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.4143\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.9435\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.8538\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.9876\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 15.1504\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.1674\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.3075\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.7986\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.1545\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.1624\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.3529\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.2209\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.6694\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.6572\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.4099\n",
      "Epoch 79/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 100us/step - loss: 14.4099\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 52.2889\n",
      "loss :  52.28889846801758\n",
      "5/5 [==============================] - 0s 997us/step\n",
      "=================\n",
      "[185. 150. 246. 184. 110. 202. 336.  69.  69.  87.  66. 164. 265. 198.\n",
      " 248. 171. 102. 182. 262. 233. 151. 275. 230.  39.  42. 122.  81.  31.\n",
      " 156. 161.  80. 215. 310. 163. 265.  84.  54. 137. 248.  72. 248.  59.\n",
      "  97.  61.  72. 296.  55.  75.  53. 173. 158.  96. 140. 186.  93. 123.\n",
      " 237. 138. 292.  78. 182. 127. 321. 109. 212.  45.  96. 109.  89.  96.\n",
      "  60.  51. 200. 265.  68.  91. 172. 115. 125.  53.  63. 259. 214. 195.\n",
      " 258. 235. 173.  59. 219. 170.  77.  49.  66. 144. 113. 233. 162. 121.\n",
      "  88. 302. 128.  52. 178.  90. 164. 135. 103. 200. 178. 261.  64.  59.\n",
      "  79.  47. 107.  39. 151. 104. 217. 232.  55. 245. 131.  64. 222. 249.\n",
      " 128. 293. 138. 273. 158. 168. 103.]\n",
      "[[211.06622 ]\n",
      " [227.60902 ]\n",
      " [214.84344 ]\n",
      " [199.4548  ]\n",
      " [157.33461 ]\n",
      " [217.7648  ]\n",
      " [306.89163 ]\n",
      " [ 67.108955]\n",
      " [123.47729 ]\n",
      " [155.39877 ]\n",
      " [173.65807 ]\n",
      " [182.9543  ]\n",
      " [197.14142 ]\n",
      " [171.24582 ]\n",
      " [303.07928 ]\n",
      " [211.6557  ]\n",
      " [ 79.978966]\n",
      " [186.97305 ]\n",
      " [118.483574]\n",
      " [273.0748  ]\n",
      " [132.6282  ]\n",
      " [291.56552 ]\n",
      " [141.18631 ]\n",
      " [ 42.35635 ]\n",
      " [ 71.720955]\n",
      " [223.6077  ]\n",
      " [107.6458  ]\n",
      " [ 68.08054 ]\n",
      " [160.51292 ]\n",
      " [209.72075 ]\n",
      " [148.38414 ]\n",
      " [197.75421 ]\n",
      " [200.50807 ]\n",
      " [243.41867 ]\n",
      " [191.64781 ]\n",
      " [ 87.66482 ]\n",
      " [ 67.870995]\n",
      " [ 79.187325]\n",
      " [266.65347 ]\n",
      " [157.8807  ]\n",
      " [242.2566  ]\n",
      " [ 80.13213 ]\n",
      " [100.05245 ]\n",
      " [205.18224 ]\n",
      " [ 69.310455]\n",
      " [165.25098 ]\n",
      " [132.93147 ]\n",
      " [ 94.39668 ]\n",
      " [ 46.3579  ]\n",
      " [237.91824 ]\n",
      " [114.30399 ]\n",
      " [148.04033 ]\n",
      " [206.43127 ]\n",
      " [287.7522  ]\n",
      " [ 90.61681 ]\n",
      " [ 70.87456 ]\n",
      " [199.21997 ]\n",
      " [195.51096 ]\n",
      " [219.9848  ]\n",
      " [255.89249 ]\n",
      " [ 68.16305 ]\n",
      " [ 71.70048 ]\n",
      " [305.6306  ]\n",
      " [250.25034 ]\n",
      " [130.49698 ]\n",
      " [ 46.613224]\n",
      " [ 69.67869 ]\n",
      " [219.38863 ]\n",
      " [108.102806]\n",
      " [ 93.61273 ]\n",
      " [100.75182 ]\n",
      " [ 67.30621 ]\n",
      " [293.0665  ]\n",
      " [198.46698 ]\n",
      " [110.6751  ]\n",
      " [168.51144 ]\n",
      " [132.48538 ]\n",
      " [ 92.150856]\n",
      " [114.74054 ]\n",
      " [ 68.27413 ]\n",
      " [ 68.47359 ]\n",
      " [117.40476 ]\n",
      " [184.07079 ]\n",
      " [309.85934 ]\n",
      " [283.04977 ]\n",
      " [130.39696 ]\n",
      " [216.8152  ]\n",
      " [ 87.564865]\n",
      " [168.1057  ]\n",
      " [202.59496 ]\n",
      " [183.30678 ]\n",
      " [ 63.61105 ]\n",
      " [189.28877 ]\n",
      " [121.36604 ]\n",
      " [259.9081  ]\n",
      " [292.64822 ]\n",
      " [212.50513 ]\n",
      " [182.29382 ]\n",
      " [125.31436 ]\n",
      " [178.95209 ]\n",
      " [ 67.87804 ]\n",
      " [ 68.469864]\n",
      " [143.50914 ]\n",
      " [137.21825 ]\n",
      " [ 69.51597 ]\n",
      " [ 55.636486]\n",
      " [ 79.22313 ]\n",
      " [174.8364  ]\n",
      " [163.64421 ]\n",
      " [192.82758 ]\n",
      " [ 67.78232 ]\n",
      " [165.02208 ]\n",
      " [121.47477 ]\n",
      " [ 73.26924 ]\n",
      " [ 83.57126 ]\n",
      " [ 74.460884]\n",
      " [241.15659 ]\n",
      " [107.326065]\n",
      " [173.05847 ]\n",
      " [225.52582 ]\n",
      " [166.26723 ]\n",
      " [124.04378 ]\n",
      " [133.8431  ]\n",
      " [ 99.53611 ]\n",
      " [249.87341 ]\n",
      " [192.96175 ]\n",
      " [267.06415 ]\n",
      " [190.3417  ]\n",
      " [ 68.07411 ]\n",
      " [276.93256 ]\n",
      " [ 64.07924 ]\n",
      " [207.36537 ]\n",
      " [155.29425 ]]\n",
      "=================\n",
      "R2 :  0.2620621814322145\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.6487\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.6540\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.0849\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.4438\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 13.9262\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.6568\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.3619\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.9991\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 13.4067\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.7927\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.4226\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.7260\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 15.8010\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.4077\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.6437\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 15.9178\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.9471\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.8629\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.6429\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.2807\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.5588\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.0743\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.7689\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 12.8588\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.4608\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.1434\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.8231\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 15.4174\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.9633\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.0460\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.0996\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.7370\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 13.5607\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.7706\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.9558\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.6587\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.0229\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.5730\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.9133\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.3639\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 15.0562\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.1543\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.1852\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.4173\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 15.0069\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.0435\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 13.0955\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 16.1242\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 18.7736\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.3744\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.6486\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.5118\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 11.9536\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.9792\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.9956\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 15.0004\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.1295\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.7590\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.5309\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.6235\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.1294\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.3476\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.8609\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.1192\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.6259\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.2097\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.1645\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.9645\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.8797\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 13.7447\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 15.0613\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.8075\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.6360\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.2320\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.5674\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.7239\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.9348\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.3019\n",
      "Epoch 79/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 90us/step - loss: 15.3019\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 51.9231\n",
      "loss :  51.92312240600586\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "=================\n",
      "[185. 150. 246. 184. 110. 202. 336.  69.  69.  87.  66. 164. 265. 198.\n",
      " 248. 171. 102. 182. 262. 233. 151. 275. 230.  39.  42. 122.  81.  31.\n",
      " 156. 161.  80. 215. 310. 163. 265.  84.  54. 137. 248.  72. 248.  59.\n",
      "  97.  61.  72. 296.  55.  75.  53. 173. 158.  96. 140. 186.  93. 123.\n",
      " 237. 138. 292.  78. 182. 127. 321. 109. 212.  45.  96. 109.  89.  96.\n",
      "  60.  51. 200. 265.  68.  91. 172. 115. 125.  53.  63. 259. 214. 195.\n",
      " 258. 235. 173.  59. 219. 170.  77.  49.  66. 144. 113. 233. 162. 121.\n",
      "  88. 302. 128.  52. 178.  90. 164. 135. 103. 200. 178. 261.  64.  59.\n",
      "  79.  47. 107.  39. 151. 104. 217. 232.  55. 245. 131.  64. 222. 249.\n",
      " 128. 293. 138. 273. 158. 168. 103.]\n",
      "[[193.85423 ]\n",
      " [234.03319 ]\n",
      " [206.53325 ]\n",
      " [185.56447 ]\n",
      " [143.69856 ]\n",
      " [212.511   ]\n",
      " [285.57327 ]\n",
      " [ 65.673386]\n",
      " [111.78817 ]\n",
      " [149.69598 ]\n",
      " [165.85378 ]\n",
      " [180.1332  ]\n",
      " [206.12674 ]\n",
      " [129.0143  ]\n",
      " [300.79233 ]\n",
      " [229.71938 ]\n",
      " [ 83.02884 ]\n",
      " [171.91342 ]\n",
      " [125.701996]\n",
      " [260.94556 ]\n",
      " [135.90582 ]\n",
      " [278.86948 ]\n",
      " [124.980804]\n",
      " [ 42.148754]\n",
      " [ 73.45033 ]\n",
      " [220.30815 ]\n",
      " [108.35213 ]\n",
      " [ 66.73909 ]\n",
      " [136.79082 ]\n",
      " [257.37433 ]\n",
      " [133.60396 ]\n",
      " [208.20924 ]\n",
      " [210.26541 ]\n",
      " [228.73692 ]\n",
      " [178.38676 ]\n",
      " [ 93.03621 ]\n",
      " [ 65.55363 ]\n",
      " [ 77.09802 ]\n",
      " [280.81873 ]\n",
      " [171.80042 ]\n",
      " [233.18451 ]\n",
      " [ 77.66082 ]\n",
      " [ 91.49133 ]\n",
      " [193.21349 ]\n",
      " [ 67.441605]\n",
      " [162.55502 ]\n",
      " [143.51546 ]\n",
      " [ 96.75813 ]\n",
      " [ 48.060627]\n",
      " [243.45558 ]\n",
      " [124.14659 ]\n",
      " [116.23892 ]\n",
      " [240.56279 ]\n",
      " [266.21057 ]\n",
      " [ 95.11124 ]\n",
      " [ 87.824554]\n",
      " [186.31914 ]\n",
      " [191.4105  ]\n",
      " [157.68288 ]\n",
      " [230.82825 ]\n",
      " [ 65.95825 ]\n",
      " [ 65.814354]\n",
      " [286.80438 ]\n",
      " [224.04807 ]\n",
      " [119.30436 ]\n",
      " [ 47.26517 ]\n",
      " [ 72.85362 ]\n",
      " [209.999   ]\n",
      " [105.88341 ]\n",
      " [ 96.664154]\n",
      " [ 82.62033 ]\n",
      " [ 65.505875]\n",
      " [288.98434 ]\n",
      " [173.93086 ]\n",
      " [116.86225 ]\n",
      " [159.82033 ]\n",
      " [125.93483 ]\n",
      " [101.11126 ]\n",
      " [102.45877 ]\n",
      " [ 66.68488 ]\n",
      " [ 70.491104]\n",
      " [128.07184 ]\n",
      " [183.10904 ]\n",
      " [283.87408 ]\n",
      " [241.19676 ]\n",
      " [134.75453 ]\n",
      " [195.53221 ]\n",
      " [ 83.31532 ]\n",
      " [169.84442 ]\n",
      " [200.38472 ]\n",
      " [170.19794 ]\n",
      " [ 65.76497 ]\n",
      " [176.03584 ]\n",
      " [115.12201 ]\n",
      " [258.83194 ]\n",
      " [256.07782 ]\n",
      " [217.4728  ]\n",
      " [180.1333  ]\n",
      " [137.97153 ]\n",
      " [204.63785 ]\n",
      " [ 65.669556]\n",
      " [ 66.82115 ]\n",
      " [126.96446 ]\n",
      " [135.08815 ]\n",
      " [ 92.71051 ]\n",
      " [ 58.631905]\n",
      " [103.92411 ]\n",
      " [114.450165]\n",
      " [142.09991 ]\n",
      " [174.16321 ]\n",
      " [ 66.304535]\n",
      " [168.31471 ]\n",
      " [113.209694]\n",
      " [ 73.13223 ]\n",
      " [ 80.27428 ]\n",
      " [ 74.68228 ]\n",
      " [224.92784 ]\n",
      " [118.23309 ]\n",
      " [157.83347 ]\n",
      " [219.284   ]\n",
      " [130.48897 ]\n",
      " [154.41635 ]\n",
      " [126.46251 ]\n",
      " [100.03018 ]\n",
      " [230.76537 ]\n",
      " [198.289   ]\n",
      " [266.7782  ]\n",
      " [184.38704 ]\n",
      " [ 65.64282 ]\n",
      " [237.00993 ]\n",
      " [ 73.324776]\n",
      " [201.92465 ]\n",
      " [162.81067 ]]\n",
      "=================\n",
      "R2 :  0.2907466523619845\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.1190\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.3440\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.5482\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.5537\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.8678\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.7155\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.1964\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 16.1165\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.5628\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.0554\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.4882\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.9195\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.9594\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.0802\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.2792\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.5789\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.9845\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.6224\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.6180\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.1754\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.2859\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.9619\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 13.5235\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.7503\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.5181\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.1048\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.4460\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 13.0653\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.8649\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.9767\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.1035\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.6194\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.7096\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 16.1841\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.1290\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.4182\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.2809\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.1459\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.2492\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.9259\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.1298\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.9856\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.7590\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.5762\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.0821\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.6904\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.5636\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 13.0243\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.0388\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.4717\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 13.0506\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.3482\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.2620\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 13.8528\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 12.7916\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.8909\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.3987\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.4795\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.0950\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.8340\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 17.3136\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.3187\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.3242\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.0570\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.4491\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.0374\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.5649\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.3034\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.7978\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.9817\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.3581\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.4559\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.4040\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.1444\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.1959\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.1446\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.7500\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.1588\n",
      "Epoch 79/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 99us/step - loss: 14.1588\n",
      "5/5 [==============================] - 0s 748us/step - loss: 50.7857\n",
      "loss :  50.78567123413086\n",
      "5/5 [==============================] - 0s 724us/step\n",
      "=================\n",
      "[185. 150. 246. 184. 110. 202. 336.  69.  69.  87.  66. 164. 265. 198.\n",
      " 248. 171. 102. 182. 262. 233. 151. 275. 230.  39.  42. 122.  81.  31.\n",
      " 156. 161.  80. 215. 310. 163. 265.  84.  54. 137. 248.  72. 248.  59.\n",
      "  97.  61.  72. 296.  55.  75.  53. 173. 158.  96. 140. 186.  93. 123.\n",
      " 237. 138. 292.  78. 182. 127. 321. 109. 212.  45.  96. 109.  89.  96.\n",
      "  60.  51. 200. 265.  68.  91. 172. 115. 125.  53.  63. 259. 214. 195.\n",
      " 258. 235. 173.  59. 219. 170.  77.  49.  66. 144. 113. 233. 162. 121.\n",
      "  88. 302. 128.  52. 178.  90. 164. 135. 103. 200. 178. 261.  64.  59.\n",
      "  79.  47. 107.  39. 151. 104. 217. 232.  55. 245. 131.  64. 222. 249.\n",
      " 128. 293. 138. 273. 158. 168. 103.]\n",
      "[[211.62973 ]\n",
      " [229.02646 ]\n",
      " [196.03665 ]\n",
      " [176.8279  ]\n",
      " [145.0467  ]\n",
      " [216.69693 ]\n",
      " [289.48184 ]\n",
      " [ 65.99143 ]\n",
      " [105.17497 ]\n",
      " [143.00769 ]\n",
      " [178.68106 ]\n",
      " [149.54405 ]\n",
      " [198.1672  ]\n",
      " [100.04445 ]\n",
      " [295.842   ]\n",
      " [201.56262 ]\n",
      " [ 76.44922 ]\n",
      " [198.59885 ]\n",
      " [135.10233 ]\n",
      " [261.84818 ]\n",
      " [131.28992 ]\n",
      " [281.29297 ]\n",
      " [156.78494 ]\n",
      " [ 41.153057]\n",
      " [ 70.186165]\n",
      " [227.80391 ]\n",
      " [100.186104]\n",
      " [ 69.82907 ]\n",
      " [139.43819 ]\n",
      " [148.08763 ]\n",
      " [121.62917 ]\n",
      " [213.48189 ]\n",
      " [213.39777 ]\n",
      " [238.28937 ]\n",
      " [204.31273 ]\n",
      " [ 95.346985]\n",
      " [ 69.56262 ]\n",
      " [ 70.241554]\n",
      " [268.23    ]\n",
      " [159.77335 ]\n",
      " [238.7737  ]\n",
      " [ 80.10479 ]\n",
      " [ 99.07184 ]\n",
      " [198.2484  ]\n",
      " [ 78.15021 ]\n",
      " [194.4028  ]\n",
      " [133.1293  ]\n",
      " [ 90.046295]\n",
      " [ 46.95531 ]\n",
      " [227.33334 ]\n",
      " [107.44789 ]\n",
      " [108.313126]\n",
      " [236.55264 ]\n",
      " [262.56732 ]\n",
      " [ 91.14342 ]\n",
      " [ 82.7206  ]\n",
      " [205.54266 ]\n",
      " [181.69244 ]\n",
      " [145.24683 ]\n",
      " [239.62497 ]\n",
      " [ 65.86702 ]\n",
      " [ 67.49241 ]\n",
      " [289.30035 ]\n",
      " [217.03491 ]\n",
      " [121.438614]\n",
      " [ 47.90935 ]\n",
      " [ 67.03854 ]\n",
      " [217.5712  ]\n",
      " [ 99.89218 ]\n",
      " [ 82.36841 ]\n",
      " [ 82.20918 ]\n",
      " [ 65.55327 ]\n",
      " [298.11908 ]\n",
      " [121.60617 ]\n",
      " [136.15094 ]\n",
      " [156.01538 ]\n",
      " [130.60129 ]\n",
      " [ 96.23895 ]\n",
      " [ 97.84977 ]\n",
      " [ 66.569695]\n",
      " [ 66.16399 ]\n",
      " [137.95648 ]\n",
      " [219.60715 ]\n",
      " [281.0287  ]\n",
      " [233.97443 ]\n",
      " [134.25165 ]\n",
      " [191.0844  ]\n",
      " [ 80.28511 ]\n",
      " [137.74196 ]\n",
      " [195.56284 ]\n",
      " [164.23552 ]\n",
      " [ 55.56838 ]\n",
      " [169.09236 ]\n",
      " [121.07024 ]\n",
      " [263.17755 ]\n",
      " [273.31482 ]\n",
      " [222.61214 ]\n",
      " [166.92877 ]\n",
      " [111.09653 ]\n",
      " [204.02895 ]\n",
      " [ 67.97209 ]\n",
      " [ 66.56372 ]\n",
      " [130.87123 ]\n",
      " [137.61224 ]\n",
      " [ 89.37875 ]\n",
      " [ 55.56838 ]\n",
      " [ 85.34288 ]\n",
      " [102.132935]\n",
      " [145.19244 ]\n",
      " [172.23787 ]\n",
      " [ 66.57283 ]\n",
      " [192.0137  ]\n",
      " [108.3573  ]\n",
      " [ 67.09353 ]\n",
      " [ 77.22974 ]\n",
      " [ 74.21123 ]\n",
      " [234.97946 ]\n",
      " [105.20762 ]\n",
      " [167.4455  ]\n",
      " [207.13821 ]\n",
      " [130.57603 ]\n",
      " [130.91417 ]\n",
      " [125.518005]\n",
      " [ 90.034805]\n",
      " [225.9296  ]\n",
      " [224.1737  ]\n",
      " [262.9636  ]\n",
      " [205.28732 ]\n",
      " [ 69.86691 ]\n",
      " [221.75633 ]\n",
      " [ 67.1736  ]\n",
      " [190.8023  ]\n",
      " [158.49846 ]]\n",
      "=================\n",
      "R2 :  0.2958777204422647\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.8033\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.6478\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.1988\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.1144\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 13.6837\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.3455\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.0776\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.2557\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.9326\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 13.1404\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.1777\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.7641\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 12.7432\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.9491\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.4956\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 13.9776\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.1198\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.0394\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.7260\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.4872\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.9378\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.3785\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.8316\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.2210\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 13.2075\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 13.8385\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.0596\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 12.6547\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.1680\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.0035\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.5997\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 15.7405\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.8496\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 16.2258\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 13.1637\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.0764\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.8477\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.5151\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 13.3769\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 13.5304\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.1730\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.5050\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 13.0633\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.4153\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.1255\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 15.5042\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.0693\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.7621\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.2506\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 16.5991\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.3675\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.8129\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.9007\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 12.9719\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.8584\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.2513\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.1180\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.5536\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.7160\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.0998\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 13.6477\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.7153\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.2411\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.4248\n",
      "Epoch 65/100\n",
      "  1/100 [..............................] - ETA: 0s - loss: 5.8129"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5676\\32265385.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# 4. 모델 컴파일\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"loss : \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\bitcamp\\anaconda3\\envs\\tf27\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\bitcamp\\anaconda3\\envs\\tf27\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1562\u001b[0m                         ):\n\u001b[0;32m   1563\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1564\u001b[1;33m                             \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1565\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1566\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\bitcamp\\anaconda3\\envs\\tf27\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\bitcamp\\anaconda3\\envs\\tf27\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\bitcamp\\anaconda3\\envs\\tf27\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\bitcamp\\anaconda3\\envs\\tf27\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2494\u001b[0m       (graph_function,\n\u001b[0;32m   2495\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2497\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2498\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\bitcamp\\anaconda3\\envs\\tf27\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1860\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1861\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1862\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1863\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1864\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mc:\\Users\\bitcamp\\anaconda3\\envs\\tf27\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\bitcamp\\anaconda3\\envs\\tf27\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from sklearn.metrics import r2_score\n",
    "now = datetime.now()\n",
    "model.compile(loss=\"mae\",optimizer=\"adam\")\n",
    "f = open(\"C:\\study\\keras\\diabets.txt\",'a')\n",
    "\n",
    "# 4. 모델 컴파일\n",
    "while (True):\n",
    "    model.fit(x_train,y_train,epochs=100,batch_size=4,steps_per_epoch=100)\n",
    "    loss = model.evaluate(x_test,y_test)\n",
    "    print(\"loss : \",loss)\n",
    "    y_predict =model.predict(x_test)\n",
    "    print(\"=================\")\n",
    "    print(y_test)\n",
    "    print(y_predict)\n",
    "    print(\"=================\")\n",
    "    r2 = r2_score(y_test,y_predict)\n",
    "    print(\"R2 : \",r2)\n",
    "    \n",
    "    f.write(str(now)+str(r2)+\"\\n\") \n",
    "    \n",
    "    if r2 >= 0.62 :\n",
    "        f.write(str(now)+str(r2)+\"\\n\") \n",
    "        model.save(\"diabets.h5\")\n",
    "        f.close()\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf27",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b47fb4e6c68d4941015efb0bbf71549277582fe8531338196fc3c7fa71b6aab8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
