{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "dataset = load_diabetes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(442, 10)\n",
      "(442,)\n"
     ]
    }
   ],
   "source": [
    "x = dataset.data\n",
    "y = dataset.target\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# 사이킥 런의 칼럼 조회기능\n",
    "print(dataset.feature_names)\n",
    "print(len(dataset.feature_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _diabetes_dataset:\n",
      "\n",
      "Diabetes dataset\n",
      "----------------\n",
      "\n",
      "Ten baseline variables, age, sex, body mass index, average blood\n",
      "pressure, and six blood serum measurements were obtained for each of n =\n",
      "442 diabetes patients, as well as the response of interest, a\n",
      "quantitative measure of disease progression one year after baseline.\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "  :Number of Instances: 442\n",
      "\n",
      "  :Number of Attributes: First 10 columns are numeric predictive values\n",
      "\n",
      "  :Target: Column 11 is a quantitative measure of disease progression one year after baseline\n",
      "\n",
      "  :Attribute Information:\n",
      "      - age     age in years\n",
      "      - sex\n",
      "      - bmi     body mass index\n",
      "      - bp      average blood pressure\n",
      "      - s1      tc, total serum cholesterol\n",
      "      - s2      ldl, low-density lipoproteins\n",
      "      - s3      hdl, high-density lipoproteins\n",
      "      - s4      tch, total cholesterol / HDL\n",
      "      - s5      ltg, possibly log of serum triglycerides level\n",
      "      - s6      glu, blood sugar level\n",
      "\n",
      "Note: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times the square root of `n_samples` (i.e. the sum of squares of each column totals 1).\n",
      "\n",
      "Source URL:\n",
      "https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\n",
      "\n",
      "For more information see:\n",
      "Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\n",
      "(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 사이킥런의 데이터 요약\n",
    "print(dataset.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309\n",
      "133\n"
     ]
    }
   ],
   "source": [
    "# 3. 모델구성\n",
    "# 실습 train 0.7 이상\n",
    "# 평가지표 R2 : 0.8 이상으로 뽑아내보기 / RMSE 사용\n",
    "\n",
    "x_train, x_test,y_train,y_test = train_test_split(x,y,\n",
    "    train_size=0.7,\n",
    "    shuffle = True,\n",
    "    random_state= 123\n",
    ")\n",
    "\n",
    "print(len(x_train))\n",
    "print(len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_30 (Dense)            (None, 8)                 88        \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 9)                 81        \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 10)                100       \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 11)                121       \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 12)                144       \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 13)                169       \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 14)                196       \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 14)                210       \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 13)                195       \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 12)                168       \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 11)                143       \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 10)                120       \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 8)                 88        \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 4)                 36        \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,864\n",
      "Trainable params: 1,864\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from random import randrange\n",
    "number1 = randrange(1,10,1)\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(8,input_dim = 10),\n",
    "    Dense(9,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(11,activation=\"relu\"),\n",
    "    Dense(12,activation=\"relu\"),\n",
    "    Dense(13,activation=\"relu\"),\n",
    "    Dense(14,activation=\"relu\"),\n",
    "    Dense(14,activation=\"relu\"),\n",
    "    Dense(13,activation=\"relu\"),\n",
    "    Dense(12,activation=\"relu\"),\n",
    "    Dense(11,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(8,activation=\"relu\"),\n",
    "    Dense(4,activation=\"relu\"),\n",
    "\n",
    "\n",
    "    Dense(1)\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "100/100 [==============================] - 1s 2ms/step - loss: 144.4152\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 63.4522\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 59.8938\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 54.3067\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 51.5013\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 50.2051\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 46.5355\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 44.1509\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 45.1446\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 45.5715\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 43.4138\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 43.5610\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 45.3794\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 43.9072\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 43.2003\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 42.8354\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 45.3341\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 42.5338\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 43.1156\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 44.1379\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 43.1902\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 44.6779\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 42.6275\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 44.2038\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 42.0517\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 42.6516\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 44.7195\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 41.2451\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 43.9813\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 41.3549\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 42.2074\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 44.2088\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 42.9719\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 41.4565\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 43.4645\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 41.9382\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 44.2100\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 44.2315\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 41.0470\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 43.2640\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 40.7537\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 43.5262\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 42.6744\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 41.7967\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 42.4417\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 42.6996\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 42.1032\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 42.8082\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 41.8578\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 42.3681\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 44.7142\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 40.6455\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 42.2769\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 41.9093\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 43.5850\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 42.2652\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 44.5890\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 40.2472\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 43.7789\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 41.8186\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 41.3900\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 42.9914\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 43.2342\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 40.6793\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 42.1600\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 42.1595\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 40.7739\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 42.2117\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 42.3417\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 40.2522\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 42.4688\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 41.9691\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 41.5794\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 41.5260\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 41.4550\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 42.9622\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 40.1193\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 41.2962\n",
      "Epoch 79/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 130us/step - loss: 41.2962\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 44.1987\n",
      "loss :  44.19873809814453\n",
      "5/5 [==============================] - 0s 997us/step\n",
      "=================\n",
      "[185. 150. 246. 184. 110. 202. 336.  69.  69.  87.  66. 164. 265. 198.\n",
      " 248. 171. 102. 182. 262. 233. 151. 275. 230.  39.  42. 122.  81.  31.\n",
      " 156. 161.  80. 215. 310. 163. 265.  84.  54. 137. 248.  72. 248.  59.\n",
      "  97.  61.  72. 296.  55.  75.  53. 173. 158.  96. 140. 186.  93. 123.\n",
      " 237. 138. 292.  78. 182. 127. 321. 109. 212.  45.  96. 109.  89.  96.\n",
      "  60.  51. 200. 265.  68.  91. 172. 115. 125.  53.  63. 259. 214. 195.\n",
      " 258. 235. 173.  59. 219. 170.  77.  49.  66. 144. 113. 233. 162. 121.\n",
      "  88. 302. 128.  52. 178.  90. 164. 135. 103. 200. 178. 261.  64.  59.\n",
      "  79.  47. 107.  39. 151. 104. 217. 232.  55. 245. 131.  64. 222. 249.\n",
      " 128. 293. 138. 273. 158. 168. 103.]\n",
      "[[137.47395 ]\n",
      " [123.75771 ]\n",
      " [245.51743 ]\n",
      " [172.89359 ]\n",
      " [139.51721 ]\n",
      " [151.1723  ]\n",
      " [269.7172  ]\n",
      " [102.61814 ]\n",
      " [ 82.06708 ]\n",
      " [104.640594]\n",
      " [125.99234 ]\n",
      " [169.50912 ]\n",
      " [141.2435  ]\n",
      " [210.65721 ]\n",
      " [241.12723 ]\n",
      " [151.96713 ]\n",
      " [107.07725 ]\n",
      " [158.23602 ]\n",
      " [183.34729 ]\n",
      " [190.06783 ]\n",
      " [172.6401  ]\n",
      " [239.28882 ]\n",
      " [140.6173  ]\n",
      " [ 70.66221 ]\n",
      " [101.06704 ]\n",
      " [190.7755  ]\n",
      " [ 98.81089 ]\n",
      " [115.65228 ]\n",
      " [126.906364]\n",
      " [170.96977 ]\n",
      " [103.50696 ]\n",
      " [258.6719  ]\n",
      " [219.25943 ]\n",
      " [212.77162 ]\n",
      " [197.66049 ]\n",
      " [ 91.22398 ]\n",
      " [ 77.902534]\n",
      " [128.96008 ]\n",
      " [225.62843 ]\n",
      " [100.40217 ]\n",
      " [203.65294 ]\n",
      " [ 93.521454]\n",
      " [137.32123 ]\n",
      " [126.60635 ]\n",
      " [ 96.919945]\n",
      " [235.46574 ]\n",
      " [115.46957 ]\n",
      " [102.7969  ]\n",
      " [ 86.535995]\n",
      " [242.65057 ]\n",
      " [125.68205 ]\n",
      " [ 89.94391 ]\n",
      " [187.51675 ]\n",
      " [202.90718 ]\n",
      " [163.43245 ]\n",
      " [198.05072 ]\n",
      " [240.63554 ]\n",
      " [161.04799 ]\n",
      " [190.31294 ]\n",
      " [183.9468  ]\n",
      " [131.1019  ]\n",
      " [113.71326 ]\n",
      " [241.78648 ]\n",
      " [211.36024 ]\n",
      " [185.59914 ]\n",
      " [ 77.727394]\n",
      " [ 87.25064 ]\n",
      " [167.34221 ]\n",
      " [126.02256 ]\n",
      " [ 90.46409 ]\n",
      " [102.99198 ]\n",
      " [ 75.13008 ]\n",
      " [169.03348 ]\n",
      " [201.7732  ]\n",
      " [134.7586  ]\n",
      " [152.5135  ]\n",
      " [148.78189 ]\n",
      " [136.65286 ]\n",
      " [124.77301 ]\n",
      " [107.59556 ]\n",
      " [ 88.7622  ]\n",
      " [145.67079 ]\n",
      " [152.9572  ]\n",
      " [236.21114 ]\n",
      " [325.4509  ]\n",
      " [164.94331 ]\n",
      " [202.87326 ]\n",
      " [ 87.053444]\n",
      " [120.23334 ]\n",
      " [139.97928 ]\n",
      " [150.30296 ]\n",
      " [ 71.82607 ]\n",
      " [163.25862 ]\n",
      " [159.40453 ]\n",
      " [130.62126 ]\n",
      " [273.94815 ]\n",
      " [156.2733  ]\n",
      " [226.55325 ]\n",
      " [128.29497 ]\n",
      " [142.29341 ]\n",
      " [ 73.96306 ]\n",
      " [ 73.93602 ]\n",
      " [100.834526]\n",
      " [170.1636  ]\n",
      " [197.68576 ]\n",
      " [ 90.573265]\n",
      " [136.96736 ]\n",
      " [161.98431 ]\n",
      " [183.2085  ]\n",
      " [258.40582 ]\n",
      " [ 95.96553 ]\n",
      " [134.45987 ]\n",
      " [122.68309 ]\n",
      " [ 91.38492 ]\n",
      " [105.505325]\n",
      " [ 93.4868  ]\n",
      " [196.65828 ]\n",
      " [ 88.79302 ]\n",
      " [172.8367  ]\n",
      " [189.89355 ]\n",
      " [146.63815 ]\n",
      " [139.28476 ]\n",
      " [145.456   ]\n",
      " [108.08242 ]\n",
      " [191.27415 ]\n",
      " [217.88518 ]\n",
      " [240.3121  ]\n",
      " [193.80762 ]\n",
      " [ 71.23047 ]\n",
      " [290.1346  ]\n",
      " [102.21084 ]\n",
      " [155.59058 ]\n",
      " [130.65854 ]]\n",
      "=================\n",
      "R2 :  0.5116383438890524\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 39.7139\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 43.4944\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 41.9649\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 42.5609\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 41.4865\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 41.5655\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 41.5505\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 40.8912\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 41.1256\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 42.4264\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 41.7826\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 40.4768\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 41.0874\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 42.8699\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 41.2144\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 41.4499\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 40.8785\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 40.9829\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 40.3983\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 43.2018\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 41.7964\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 39.5802\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 40.2821\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 42.0583\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 40.0644\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 42.3148\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 41.4182\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 40.6888\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 42.7488\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 40.8878\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 41.6381\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 39.9072\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 42.0079\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 40.8109\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 41.4213\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 41.1344\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 41.1211\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 39.7208\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 41.2063\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 40.5065\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 41.6136\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 40.2913\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 40.3031\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 41.7058\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 41.3018\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 39.3361\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 42.3769\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 40.5778\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 39.7173\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 39.7384\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 42.0257\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 40.4527\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 42.1279\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 40.7773\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 40.8525\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 40.0440\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 42.9299\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 40.8585\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 41.5738\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 41.1928\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 39.9676\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 41.0554\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 41.3203\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 41.0564\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 40.4748\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 40.2408\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 41.9164\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 40.9208\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 40.8159\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 40.0645\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 42.0906\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 42.4643\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.9525\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 42.5881\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 41.6374\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 38.8877\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 43.3854\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 38.8281\n",
      "Epoch 79/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 140us/step - loss: 38.8281\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 49.1576\n",
      "loss :  49.15761184692383\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "=================\n",
      "[185. 150. 246. 184. 110. 202. 336.  69.  69.  87.  66. 164. 265. 198.\n",
      " 248. 171. 102. 182. 262. 233. 151. 275. 230.  39.  42. 122.  81.  31.\n",
      " 156. 161.  80. 215. 310. 163. 265.  84.  54. 137. 248.  72. 248.  59.\n",
      "  97.  61.  72. 296.  55.  75.  53. 173. 158.  96. 140. 186.  93. 123.\n",
      " 237. 138. 292.  78. 182. 127. 321. 109. 212.  45.  96. 109.  89.  96.\n",
      "  60.  51. 200. 265.  68.  91. 172. 115. 125.  53.  63. 259. 214. 195.\n",
      " 258. 235. 173.  59. 219. 170.  77.  49.  66. 144. 113. 233. 162. 121.\n",
      "  88. 302. 128.  52. 178.  90. 164. 135. 103. 200. 178. 261.  64.  59.\n",
      "  79.  47. 107.  39. 151. 104. 217. 232.  55. 245. 131.  64. 222. 249.\n",
      " 128. 293. 138. 273. 158. 168. 103.]\n",
      "[[151.51329 ]\n",
      " [139.43813 ]\n",
      " [283.87198 ]\n",
      " [195.73535 ]\n",
      " [157.54645 ]\n",
      " [166.2942  ]\n",
      " [316.55527 ]\n",
      " [110.06543 ]\n",
      " [ 85.41151 ]\n",
      " [123.54181 ]\n",
      " [141.6235  ]\n",
      " [200.96512 ]\n",
      " [159.45874 ]\n",
      " [245.0177  ]\n",
      " [271.85666 ]\n",
      " [164.19835 ]\n",
      " [115.44806 ]\n",
      " [175.06285 ]\n",
      " [203.03279 ]\n",
      " [217.17308 ]\n",
      " [200.35402 ]\n",
      " [280.45557 ]\n",
      " [159.4452  ]\n",
      " [ 70.74802 ]\n",
      " [104.43649 ]\n",
      " [214.10233 ]\n",
      " [112.99349 ]\n",
      " [122.26182 ]\n",
      " [143.20203 ]\n",
      " [191.01645 ]\n",
      " [112.501236]\n",
      " [302.08646 ]\n",
      " [245.78976 ]\n",
      " [246.11766 ]\n",
      " [221.10318 ]\n",
      " [ 94.376396]\n",
      " [ 74.81023 ]\n",
      " [137.59558 ]\n",
      " [269.74854 ]\n",
      " [104.25342 ]\n",
      " [231.35045 ]\n",
      " [ 96.05858 ]\n",
      " [145.40298 ]\n",
      " [135.56982 ]\n",
      " [107.8365  ]\n",
      " [275.0962  ]\n",
      " [121.89195 ]\n",
      " [107.27685 ]\n",
      " [ 86.279915]\n",
      " [283.25385 ]\n",
      " [131.07755 ]\n",
      " [ 92.91488 ]\n",
      " [223.87256 ]\n",
      " [241.87498 ]\n",
      " [187.58752 ]\n",
      " [229.75494 ]\n",
      " [280.60977 ]\n",
      " [190.47281 ]\n",
      " [215.93002 ]\n",
      " [209.07265 ]\n",
      " [139.30215 ]\n",
      " [131.42876 ]\n",
      " [286.62738 ]\n",
      " [251.37587 ]\n",
      " [217.46442 ]\n",
      " [ 92.21352 ]\n",
      " [ 86.96487 ]\n",
      " [200.24324 ]\n",
      " [146.18892 ]\n",
      " [ 95.5196  ]\n",
      " [105.996254]\n",
      " [ 69.85527 ]\n",
      " [199.55235 ]\n",
      " [232.88193 ]\n",
      " [150.44608 ]\n",
      " [178.83789 ]\n",
      " [163.06525 ]\n",
      " [148.07793 ]\n",
      " [131.37508 ]\n",
      " [111.6451  ]\n",
      " [ 85.5149  ]\n",
      " [167.98433 ]\n",
      " [174.14816 ]\n",
      " [275.06003 ]\n",
      " [379.15424 ]\n",
      " [190.27698 ]\n",
      " [238.39583 ]\n",
      " [ 87.62562 ]\n",
      " [131.8608  ]\n",
      " [160.55768 ]\n",
      " [178.91098 ]\n",
      " [ 64.191086]\n",
      " [182.69116 ]\n",
      " [185.29393 ]\n",
      " [146.50215 ]\n",
      " [322.89816 ]\n",
      " [176.98329 ]\n",
      " [262.65457 ]\n",
      " [140.77736 ]\n",
      " [151.49754 ]\n",
      " [ 72.12863 ]\n",
      " [ 76.608154]\n",
      " [ 99.408264]\n",
      " [189.86868 ]\n",
      " [228.54301 ]\n",
      " [ 91.41306 ]\n",
      " [143.82025 ]\n",
      " [182.63373 ]\n",
      " [215.2243  ]\n",
      " [301.46722 ]\n",
      " [106.35578 ]\n",
      " [146.99086 ]\n",
      " [136.64854 ]\n",
      " [101.06504 ]\n",
      " [115.17163 ]\n",
      " [105.177246]\n",
      " [230.67957 ]\n",
      " [ 93.729004]\n",
      " [206.03777 ]\n",
      " [218.64708 ]\n",
      " [156.96652 ]\n",
      " [156.5191  ]\n",
      " [164.52448 ]\n",
      " [110.42143 ]\n",
      " [229.03299 ]\n",
      " [250.98068 ]\n",
      " [282.61823 ]\n",
      " [225.26524 ]\n",
      " [ 66.30648 ]\n",
      " [333.72064 ]\n",
      " [116.1203  ]\n",
      " [176.76457 ]\n",
      " [158.83755 ]]\n",
      "=================\n",
      "R2 :  0.3835067446873701\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 41.6468\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 39.6351\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 40.0333\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 40.5901\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 40.3902\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 40.7219\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 41.5135\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 39.4761\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 39.5031\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 40.9111\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 40.6823\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 41.3939\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 39.2686\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 40.3116\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 40.6792\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 40.3603\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 39.4538\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 41.0679\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 39.7538\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 40.5811\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 40.7205\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 40.6728\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 38.8614\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 41.1968\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 39.7985\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 39.4876\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 41.2028\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 39.8152\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 40.4205\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 37.7428\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 41.8216\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 39.6722\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 42.0837\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 39.5892\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 40.3012\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 38.8720\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 38.2377\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 41.2933\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 38.7138\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 39.7639\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 38.4254\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 39.0631\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 40.2101\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 40.9885\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 37.3067\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 40.4941\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 39.3445\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 40.6128\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 39.0107\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 40.7038\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 39.0777\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 38.6152\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 39.4787\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 39.7803\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 40.7616\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 38.6990\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 38.8931\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 38.9388\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 38.2755\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 40.4537\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 40.1603\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 38.3165\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 39.7339\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 39.1699\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 40.0985\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 37.1740\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 39.0248\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 39.6668\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 38.3909\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 38.3866\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 39.4192\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 39.0582\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 38.3474\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 39.5593\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 39.6768\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 39.1697\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 38.8557\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 39.6344\n",
      "Epoch 79/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 170us/step - loss: 39.6344\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 45.9299\n",
      "loss :  45.92988204956055\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "=================\n",
      "[185. 150. 246. 184. 110. 202. 336.  69.  69.  87.  66. 164. 265. 198.\n",
      " 248. 171. 102. 182. 262. 233. 151. 275. 230.  39.  42. 122.  81.  31.\n",
      " 156. 161.  80. 215. 310. 163. 265.  84.  54. 137. 248.  72. 248.  59.\n",
      "  97.  61.  72. 296.  55.  75.  53. 173. 158.  96. 140. 186.  93. 123.\n",
      " 237. 138. 292.  78. 182. 127. 321. 109. 212.  45.  96. 109.  89.  96.\n",
      "  60.  51. 200. 265.  68.  91. 172. 115. 125.  53.  63. 259. 214. 195.\n",
      " 258. 235. 173.  59. 219. 170.  77.  49.  66. 144. 113. 233. 162. 121.\n",
      "  88. 302. 128.  52. 178.  90. 164. 135. 103. 200. 178. 261.  64.  59.\n",
      "  79.  47. 107.  39. 151. 104. 217. 232.  55. 245. 131.  64. 222. 249.\n",
      " 128. 293. 138. 273. 158. 168. 103.]\n",
      "[[128.60739 ]\n",
      " [125.94513 ]\n",
      " [257.68402 ]\n",
      " [173.89555 ]\n",
      " [148.31075 ]\n",
      " [147.44633 ]\n",
      " [287.38763 ]\n",
      " [ 98.36137 ]\n",
      " [ 83.204384]\n",
      " [122.6663  ]\n",
      " [131.20744 ]\n",
      " [185.72478 ]\n",
      " [143.9286  ]\n",
      " [227.55554 ]\n",
      " [241.98715 ]\n",
      " [140.33986 ]\n",
      " [ 93.70402 ]\n",
      " [163.14    ]\n",
      " [173.75064 ]\n",
      " [185.60632 ]\n",
      " [189.8075  ]\n",
      " [256.96268 ]\n",
      " [150.78528 ]\n",
      " [ 61.556458]\n",
      " [ 81.89967 ]\n",
      " [175.68434 ]\n",
      " [109.59099 ]\n",
      " [115.12979 ]\n",
      " [135.30695 ]\n",
      " [161.81667 ]\n",
      " [ 91.76316 ]\n",
      " [276.9031  ]\n",
      " [204.33891 ]\n",
      " [225.26187 ]\n",
      " [204.52097 ]\n",
      " [ 92.43174 ]\n",
      " [ 66.48459 ]\n",
      " [124.236   ]\n",
      " [253.62222 ]\n",
      " [105.23717 ]\n",
      " [218.51096 ]\n",
      " [ 87.193146]\n",
      " [133.94012 ]\n",
      " [105.3379  ]\n",
      " [104.31374 ]\n",
      " [245.67213 ]\n",
      " [111.30884 ]\n",
      " [ 90.887924]\n",
      " [ 70.0798  ]\n",
      " [261.08627 ]\n",
      " [116.032265]\n",
      " [ 75.5688  ]\n",
      " [211.79646 ]\n",
      " [230.46758 ]\n",
      " [174.8325  ]\n",
      " [214.62196 ]\n",
      " [257.57352 ]\n",
      " [179.26949 ]\n",
      " [189.94548 ]\n",
      " [164.94362 ]\n",
      " [107.20215 ]\n",
      " [127.855896]\n",
      " [264.1508  ]\n",
      " [241.43207 ]\n",
      " [202.18248 ]\n",
      " [ 83.25853 ]\n",
      " [ 76.47791 ]\n",
      " [179.94592 ]\n",
      " [133.11006 ]\n",
      " [ 91.57556 ]\n",
      " [ 81.13377 ]\n",
      " [ 58.960835]\n",
      " [197.98097 ]\n",
      " [208.31859 ]\n",
      " [139.05408 ]\n",
      " [173.42554 ]\n",
      " [144.68996 ]\n",
      " [137.70778 ]\n",
      " [118.42248 ]\n",
      " [ 98.7042  ]\n",
      " [ 73.60084 ]\n",
      " [164.44882 ]\n",
      " [163.54713 ]\n",
      " [247.25331 ]\n",
      " [350.59177 ]\n",
      " [175.24335 ]\n",
      " [219.07741 ]\n",
      " [ 77.90047 ]\n",
      " [115.98606 ]\n",
      " [146.54024 ]\n",
      " [169.96957 ]\n",
      " [ 50.44664 ]\n",
      " [163.60847 ]\n",
      " [178.10773 ]\n",
      " [143.35307 ]\n",
      " [309.7329  ]\n",
      " [162.44785 ]\n",
      " [241.93217 ]\n",
      " [130.32716 ]\n",
      " [121.46692 ]\n",
      " [ 67.477356]\n",
      " [ 76.27371 ]\n",
      " [ 89.522415]\n",
      " [183.76778 ]\n",
      " [214.30794 ]\n",
      " [ 75.38523 ]\n",
      " [120.02182 ]\n",
      " [161.01147 ]\n",
      " [196.76653 ]\n",
      " [269.18658 ]\n",
      " [103.086334]\n",
      " [133.98216 ]\n",
      " [125.3659  ]\n",
      " [ 85.16034 ]\n",
      " [101.92472 ]\n",
      " [ 96.2311  ]\n",
      " [215.0188  ]\n",
      " [ 86.650444]\n",
      " [188.0465  ]\n",
      " [197.22769 ]\n",
      " [125.65344 ]\n",
      " [138.25204 ]\n",
      " [152.70491 ]\n",
      " [ 97.98421 ]\n",
      " [218.2925  ]\n",
      " [235.12039 ]\n",
      " [253.75053 ]\n",
      " [196.05646 ]\n",
      " [ 57.04724 ]\n",
      " [307.315   ]\n",
      " [107.11847 ]\n",
      " [163.20157 ]\n",
      " [153.78906 ]]\n",
      "=================\n",
      "R2 :  0.4556044188999082\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 38.9391\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 39.8372\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 38.5347\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 38.6847\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 38.8294\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 38.1309\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 39.9057\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 38.4052\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 39.3089\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 37.9469\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 40.1149\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 39.5795\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 38.9724\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 38.4673\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 39.9707\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 38.6012\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 39.3726\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 38.6441\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 38.5432\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 37.3415\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 40.5054\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 38.6494\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 39.0363\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 39.4388\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 40.2104\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 37.4881\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 38.7278\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 38.4020\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 38.2675\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 38.1464\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 39.7888\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 38.0730\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 37.8132\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 39.1484\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 38.3874\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 38.2748\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 38.3375\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 38.8898\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 39.8092\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 38.6135\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 37.1915\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 37.9636\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 37.9870\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 37.6178\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 38.1716\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 38.5877\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 38.3266\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 39.6125\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 38.7182\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 37.6184\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 39.6386\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 38.4112\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.4061\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 37.6553\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 37.0335\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 38.2636\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 39.4206\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 38.0345\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 37.5869\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 38.4218\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 38.6006\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 37.8466\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 37.8530\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.8863\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 38.0510\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 38.1822\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.6287\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 37.7063\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.9438\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 38.4584\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 38.2269\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 37.6935\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.8962\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 39.6243\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.3449\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 38.0791\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 38.3211\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 37.3494\n",
      "Epoch 79/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 229us/step - loss: 37.3494\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 45.4336\n",
      "loss :  45.433563232421875\n",
      "5/5 [==============================] - 0s 997us/step\n",
      "=================\n",
      "[185. 150. 246. 184. 110. 202. 336.  69.  69.  87.  66. 164. 265. 198.\n",
      " 248. 171. 102. 182. 262. 233. 151. 275. 230.  39.  42. 122.  81.  31.\n",
      " 156. 161.  80. 215. 310. 163. 265.  84.  54. 137. 248.  72. 248.  59.\n",
      "  97.  61.  72. 296.  55.  75.  53. 173. 158.  96. 140. 186.  93. 123.\n",
      " 237. 138. 292.  78. 182. 127. 321. 109. 212.  45.  96. 109.  89.  96.\n",
      "  60.  51. 200. 265.  68.  91. 172. 115. 125.  53.  63. 259. 214. 195.\n",
      " 258. 235. 173.  59. 219. 170.  77.  49.  66. 144. 113. 233. 162. 121.\n",
      "  88. 302. 128.  52. 178.  90. 164. 135. 103. 200. 178. 261.  64.  59.\n",
      "  79.  47. 107.  39. 151. 104. 217. 232.  55. 245. 131.  64. 222. 249.\n",
      " 128. 293. 138. 273. 158. 168. 103.]\n",
      "[[126.088104]\n",
      " [118.3153  ]\n",
      " [236.66524 ]\n",
      " [149.76408 ]\n",
      " [151.40146 ]\n",
      " [151.1317  ]\n",
      " [262.66455 ]\n",
      " [ 94.21114 ]\n",
      " [ 68.36322 ]\n",
      " [125.95097 ]\n",
      " [133.3054  ]\n",
      " [172.98628 ]\n",
      " [151.85301 ]\n",
      " [222.18436 ]\n",
      " [210.60106 ]\n",
      " [122.119064]\n",
      " [ 87.57237 ]\n",
      " [163.951   ]\n",
      " [171.35757 ]\n",
      " [202.76076 ]\n",
      " [180.31825 ]\n",
      " [235.72855 ]\n",
      " [137.62885 ]\n",
      " [ 50.67172 ]\n",
      " [ 74.52029 ]\n",
      " [146.44464 ]\n",
      " [105.42846 ]\n",
      " [116.28005 ]\n",
      " [133.18175 ]\n",
      " [154.5959  ]\n",
      " [ 80.60882 ]\n",
      " [273.75272 ]\n",
      " [177.26118 ]\n",
      " [206.11139 ]\n",
      " [194.13542 ]\n",
      " [ 88.91909 ]\n",
      " [ 63.796738]\n",
      " [121.67426 ]\n",
      " [227.20042 ]\n",
      " [104.28849 ]\n",
      " [201.68652 ]\n",
      " [ 82.12299 ]\n",
      " [131.50687 ]\n",
      " [ 89.14962 ]\n",
      " [101.27218 ]\n",
      " [222.90572 ]\n",
      " [112.93882 ]\n",
      " [ 82.5857  ]\n",
      " [ 61.99402 ]\n",
      " [240.59415 ]\n",
      " [110.70424 ]\n",
      " [ 60.75663 ]\n",
      " [210.39595 ]\n",
      " [209.83983 ]\n",
      " [167.98578 ]\n",
      " [194.5364  ]\n",
      " [242.73187 ]\n",
      " [163.66548 ]\n",
      " [165.60149 ]\n",
      " [134.41333 ]\n",
      " [ 79.21902 ]\n",
      " [117.58888 ]\n",
      " [245.1452  ]\n",
      " [235.0876  ]\n",
      " [184.095   ]\n",
      " [ 82.65632 ]\n",
      " [ 69.81832 ]\n",
      " [175.56808 ]\n",
      " [120.24248 ]\n",
      " [ 80.42049 ]\n",
      " [ 61.96803 ]\n",
      " [ 58.36732 ]\n",
      " [195.31226 ]\n",
      " [182.69302 ]\n",
      " [134.19785 ]\n",
      " [164.24094 ]\n",
      " [135.3364  ]\n",
      " [136.99048 ]\n",
      " [113.780594]\n",
      " [ 90.49257 ]\n",
      " [ 67.4053  ]\n",
      " [151.634   ]\n",
      " [158.06346 ]\n",
      " [237.07664 ]\n",
      " [327.5218  ]\n",
      " [170.63431 ]\n",
      " [205.01271 ]\n",
      " [ 67.07817 ]\n",
      " [112.780716]\n",
      " [131.79056 ]\n",
      " [163.05032 ]\n",
      " [ 43.529472]\n",
      " [145.54291 ]\n",
      " [176.0514  ]\n",
      " [143.37895 ]\n",
      " [293.17273 ]\n",
      " [157.19786 ]\n",
      " [221.79836 ]\n",
      " [121.362015]\n",
      " [ 99.43706 ]\n",
      " [ 57.39395 ]\n",
      " [ 65.51998 ]\n",
      " [ 87.57839 ]\n",
      " [164.78537 ]\n",
      " [198.478   ]\n",
      " [ 66.63057 ]\n",
      " [ 98.516884]\n",
      " [135.1086  ]\n",
      " [183.84045 ]\n",
      " [244.30243 ]\n",
      " [ 85.80675 ]\n",
      " [117.16183 ]\n",
      " [113.71681 ]\n",
      " [ 77.48229 ]\n",
      " [ 85.62232 ]\n",
      " [ 92.26115 ]\n",
      " [204.38484 ]\n",
      " [ 81.40322 ]\n",
      " [190.70236 ]\n",
      " [189.62598 ]\n",
      " [113.67962 ]\n",
      " [126.788765]\n",
      " [144.05453 ]\n",
      " [ 83.73461 ]\n",
      " [199.57295 ]\n",
      " [213.11688 ]\n",
      " [242.60631 ]\n",
      " [180.59224 ]\n",
      " [ 53.206963]\n",
      " [283.17538 ]\n",
      " [ 98.23764 ]\n",
      " [154.30121 ]\n",
      " [158.24579 ]]\n",
      "=================\n",
      "R2 :  0.4508745030006387\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 37.0464\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 39.4835\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.1700\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 38.0667\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 39.7230\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 37.9005\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 35.9936\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.8674\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 37.4091\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.3262\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 37.9066\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 37.4556\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 37.7602\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 37.3086\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 37.6259\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 37.2204\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.4270\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 37.6281\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 38.9011\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.4600\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.2120\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.7771\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 38.5645\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.7563\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 37.7450\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 37.6993\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 37.5140\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 37.0619\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 37.1023\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 37.2036\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.1263\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 37.4831\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 38.9139\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 34.8224\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 38.3287\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 37.3145\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 35.9285\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.8512\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 37.0706\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.4650\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.1006\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 37.9515\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.0233\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 37.9565\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 35.6412\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.5659\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.5320\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 38.1048\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 35.4018\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 37.1919\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.8596\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.2936\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.3223\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.5179\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 37.1781\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.3534\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.2780\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.9804\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 37.4465\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.7947\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 35.7742\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 35.5480\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.7381\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.7120\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 35.4365\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 37.1284\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 37.1403\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.7930\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 37.0686\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 35.2283\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 37.2056\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.4460\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 34.7089\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 35.6204\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.5618\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.7883\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 35.8456\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 37.2977\n",
      "Epoch 79/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 138us/step - loss: 37.2977\n",
      "5/5 [==============================] - 0s 997us/step - loss: 45.2611\n",
      "loss :  45.26112747192383\n",
      "5/5 [==============================] - 0s 997us/step\n",
      "=================\n",
      "[185. 150. 246. 184. 110. 202. 336.  69.  69.  87.  66. 164. 265. 198.\n",
      " 248. 171. 102. 182. 262. 233. 151. 275. 230.  39.  42. 122.  81.  31.\n",
      " 156. 161.  80. 215. 310. 163. 265.  84.  54. 137. 248.  72. 248.  59.\n",
      "  97.  61.  72. 296.  55.  75.  53. 173. 158.  96. 140. 186.  93. 123.\n",
      " 237. 138. 292.  78. 182. 127. 321. 109. 212.  45.  96. 109.  89.  96.\n",
      "  60.  51. 200. 265.  68.  91. 172. 115. 125.  53.  63. 259. 214. 195.\n",
      " 258. 235. 173.  59. 219. 170.  77.  49.  66. 144. 113. 233. 162. 121.\n",
      "  88. 302. 128.  52. 178.  90. 164. 135. 103. 200. 178. 261.  64.  59.\n",
      "  79.  47. 107.  39. 151. 104. 217. 232.  55. 245. 131.  64. 222. 249.\n",
      " 128. 293. 138. 273. 158. 168. 103.]\n",
      "[[121.78324 ]\n",
      " [117.35212 ]\n",
      " [220.61163 ]\n",
      " [155.33153 ]\n",
      " [145.11813 ]\n",
      " [141.11453 ]\n",
      " [243.40826 ]\n",
      " [ 84.52056 ]\n",
      " [ 93.88633 ]\n",
      " [131.26419 ]\n",
      " [132.61531 ]\n",
      " [163.95995 ]\n",
      " [149.34988 ]\n",
      " [209.41537 ]\n",
      " [202.56175 ]\n",
      " [162.57967 ]\n",
      " [ 77.729416]\n",
      " [157.86711 ]\n",
      " [164.7975  ]\n",
      " [206.43886 ]\n",
      " [181.24104 ]\n",
      " [220.10231 ]\n",
      " [127.205154]\n",
      " [ 49.115612]\n",
      " [ 75.90533 ]\n",
      " [153.7974  ]\n",
      " [ 87.37022 ]\n",
      " [110.15969 ]\n",
      " [132.28015 ]\n",
      " [143.1159  ]\n",
      " [ 75.36235 ]\n",
      " [260.70654 ]\n",
      " [187.1841  ]\n",
      " [195.00038 ]\n",
      " [182.49303 ]\n",
      " [ 82.039764]\n",
      " [ 63.341476]\n",
      " [114.51712 ]\n",
      " [209.81416 ]\n",
      " [ 96.177246]\n",
      " [189.45247 ]\n",
      " [ 74.901054]\n",
      " [125.34959 ]\n",
      " [ 91.857864]\n",
      " [ 93.15391 ]\n",
      " [207.87407 ]\n",
      " [104.68691 ]\n",
      " [ 77.37823 ]\n",
      " [ 58.7026  ]\n",
      " [221.1339  ]\n",
      " [101.97332 ]\n",
      " [ 68.193115]\n",
      " [199.83324 ]\n",
      " [192.05435 ]\n",
      " [157.44987 ]\n",
      " [180.99472 ]\n",
      " [226.57898 ]\n",
      " [153.82619 ]\n",
      " [167.11581 ]\n",
      " [158.47144 ]\n",
      " [ 74.890114]\n",
      " [101.97704 ]\n",
      " [228.9069  ]\n",
      " [223.4021  ]\n",
      " [171.95679 ]\n",
      " [ 82.19826 ]\n",
      " [ 61.540066]\n",
      " [182.79169 ]\n",
      " [ 99.46189 ]\n",
      " [ 73.520256]\n",
      " [ 70.18439 ]\n",
      " [ 59.51082 ]\n",
      " [184.2183  ]\n",
      " [170.06909 ]\n",
      " [124.939766]\n",
      " [158.1306  ]\n",
      " [157.7527  ]\n",
      " [126.13409 ]\n",
      " [108.04603 ]\n",
      " [ 80.66699 ]\n",
      " [ 62.12328 ]\n",
      " [141.8047  ]\n",
      " [147.62596 ]\n",
      " [238.0193  ]\n",
      " [305.78284 ]\n",
      " [163.5013  ]\n",
      " [193.576   ]\n",
      " [ 61.003414]\n",
      " [103.95382 ]\n",
      " [123.4656  ]\n",
      " [158.2969  ]\n",
      " [ 46.0917  ]\n",
      " [138.4064  ]\n",
      " [183.92897 ]\n",
      " [134.81927 ]\n",
      " [270.73477 ]\n",
      " [145.77722 ]\n",
      " [231.37155 ]\n",
      " [116.363365]\n",
      " [100.36199 ]\n",
      " [ 68.68547 ]\n",
      " [ 58.14102 ]\n",
      " [102.41871 ]\n",
      " [151.5998  ]\n",
      " [189.92365 ]\n",
      " [ 63.85522 ]\n",
      " [101.22036 ]\n",
      " [137.70628 ]\n",
      " [175.50104 ]\n",
      " [225.23657 ]\n",
      " [ 75.25344 ]\n",
      " [115.275085]\n",
      " [104.856316]\n",
      " [ 83.27026 ]\n",
      " [ 90.44477 ]\n",
      " [ 92.63281 ]\n",
      " [193.51634 ]\n",
      " [ 72.0324  ]\n",
      " [202.3395  ]\n",
      " [190.2659  ]\n",
      " [133.53812 ]\n",
      " [124.93607 ]\n",
      " [133.31612 ]\n",
      " [101.52357 ]\n",
      " [186.84908 ]\n",
      " [192.75778 ]\n",
      " [267.4877  ]\n",
      " [187.34586 ]\n",
      " [ 56.342728]\n",
      " [265.3407  ]\n",
      " [ 93.84189 ]\n",
      " [151.49664 ]\n",
      " [150.63069 ]]\n",
      "=================\n",
      "R2 :  0.43817628715366386\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 35.3081\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.8140\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 37.3385\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.0880\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 35.8415\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.5298\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.0026\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 34.3749\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 37.1563\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.3526\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 37.6476\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 35.7655\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.7959\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 37.2686\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 37.0056\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.5195\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.9560\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 35.6916\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.4120\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.6134\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 35.8150\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 37.4572\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 35.1386\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 35.5587\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 37.0614\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.5562\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 37.1883\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 35.1369\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 35.6115\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 35.4394\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 37.9107\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 35.1725\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 35.9066\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.4496\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 35.3166\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 35.6830\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 38.5284\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.0350\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 37.0237\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 37.4798\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 37.1468\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 34.7739\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.7253\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 35.9914\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 37.4934\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 35.6937\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 35.5182\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 35.5649\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 35.7735\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 35.8367\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 35.3729\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.4513\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.4462\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.4653\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 37.3867\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 35.2778\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 35.4632\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 37.2298\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.4116\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 35.3629\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 37.2897\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.7591\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 37.6893\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.1676\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.0195\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 35.6009\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 35.2840\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.2639\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 35.4295\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.8875\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 35.5299\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 34.1886\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 37.2938\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 34.9060\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 35.3673\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 35.1666\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 37.2812\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 34.6967\n",
      "Epoch 79/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 130us/step - loss: 34.6967\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 46.9331\n",
      "loss :  46.93312454223633\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "=================\n",
      "[185. 150. 246. 184. 110. 202. 336.  69.  69.  87.  66. 164. 265. 198.\n",
      " 248. 171. 102. 182. 262. 233. 151. 275. 230.  39.  42. 122.  81.  31.\n",
      " 156. 161.  80. 215. 310. 163. 265.  84.  54. 137. 248.  72. 248.  59.\n",
      "  97.  61.  72. 296.  55.  75.  53. 173. 158.  96. 140. 186.  93. 123.\n",
      " 237. 138. 292.  78. 182. 127. 321. 109. 212.  45.  96. 109.  89.  96.\n",
      "  60.  51. 200. 265.  68.  91. 172. 115. 125.  53.  63. 259. 214. 195.\n",
      " 258. 235. 173.  59. 219. 170.  77.  49.  66. 144. 113. 233. 162. 121.\n",
      "  88. 302. 128.  52. 178.  90. 164. 135. 103. 200. 178. 261.  64.  59.\n",
      "  79.  47. 107.  39. 151. 104. 217. 232.  55. 245. 131.  64. 222. 249.\n",
      " 128. 293. 138. 273. 158. 168. 103.]\n",
      "[[124.055115]\n",
      " [109.7359  ]\n",
      " [239.0296  ]\n",
      " [147.44609 ]\n",
      " [153.26917 ]\n",
      " [158.08417 ]\n",
      " [264.52936 ]\n",
      " [ 88.68844 ]\n",
      " [102.00937 ]\n",
      " [132.35805 ]\n",
      " [147.89215 ]\n",
      " [177.64223 ]\n",
      " [158.94078 ]\n",
      " [222.48825 ]\n",
      " [220.3693  ]\n",
      " [189.07266 ]\n",
      " [ 87.1068  ]\n",
      " [171.71155 ]\n",
      " [178.24542 ]\n",
      " [214.85652 ]\n",
      " [192.24635 ]\n",
      " [233.45515 ]\n",
      " [140.12369 ]\n",
      " [ 48.530735]\n",
      " [ 74.714554]\n",
      " [137.90454 ]\n",
      " [ 96.36435 ]\n",
      " [117.62282 ]\n",
      " [143.54088 ]\n",
      " [144.1558  ]\n",
      " [ 94.74051 ]\n",
      " [277.52435 ]\n",
      " [179.31827 ]\n",
      " [211.83669 ]\n",
      " [194.20016 ]\n",
      " [ 91.3934  ]\n",
      " [ 70.10128 ]\n",
      " [123.40851 ]\n",
      " [225.37813 ]\n",
      " [103.592   ]\n",
      " [204.72656 ]\n",
      " [ 80.52866 ]\n",
      " [133.222   ]\n",
      " [ 87.33077 ]\n",
      " [104.81956 ]\n",
      " [222.85477 ]\n",
      " [114.514366]\n",
      " [ 80.18832 ]\n",
      " [ 59.240536]\n",
      " [238.4497  ]\n",
      " [108.245834]\n",
      " [ 80.574936]\n",
      " [215.17554 ]\n",
      " [201.5844  ]\n",
      " [169.31575 ]\n",
      " [193.73232 ]\n",
      " [242.83876 ]\n",
      " [164.89388 ]\n",
      " [156.59436 ]\n",
      " [147.26178 ]\n",
      " [ 69.870255]\n",
      " [114.34204 ]\n",
      " [240.65875 ]\n",
      " [241.35861 ]\n",
      " [185.20097 ]\n",
      " [ 75.87888 ]\n",
      " [ 65.14578 ]\n",
      " [206.57924 ]\n",
      " [113.46363 ]\n",
      " [ 81.99084 ]\n",
      " [ 74.26614 ]\n",
      " [ 66.38198 ]\n",
      " [182.34778 ]\n",
      " [159.33047 ]\n",
      " [134.52892 ]\n",
      " [170.44984 ]\n",
      " [149.988   ]\n",
      " [137.91994 ]\n",
      " [116.47    ]\n",
      " [ 86.75064 ]\n",
      " [ 66.72061 ]\n",
      " [153.7624  ]\n",
      " [157.14407 ]\n",
      " [226.63414 ]\n",
      " [328.2062  ]\n",
      " [172.73886 ]\n",
      " [213.14383 ]\n",
      " [ 65.18053 ]\n",
      " [ 94.99792 ]\n",
      " [133.06313 ]\n",
      " [172.15211 ]\n",
      " [ 48.066418]\n",
      " [144.57884 ]\n",
      " [184.75385 ]\n",
      " [142.45581 ]\n",
      " [286.62958 ]\n",
      " [156.76749 ]\n",
      " [248.8469  ]\n",
      " [121.042244]\n",
      " [ 91.86853 ]\n",
      " [ 61.428833]\n",
      " [ 78.15082 ]\n",
      " [ 94.85094 ]\n",
      " [165.78502 ]\n",
      " [184.06577 ]\n",
      " [ 63.569733]\n",
      " [ 90.18187 ]\n",
      " [127.68976 ]\n",
      " [185.62172 ]\n",
      " [244.01506 ]\n",
      " [ 83.565506]\n",
      " [103.76422 ]\n",
      " [115.29327 ]\n",
      " [ 92.109215]\n",
      " [102.86308 ]\n",
      " [107.8017  ]\n",
      " [207.0461  ]\n",
      " [ 76.44062 ]\n",
      " [212.46063 ]\n",
      " [208.65265 ]\n",
      " [126.69985 ]\n",
      " [124.34919 ]\n",
      " [146.10056 ]\n",
      " [ 89.041954]\n",
      " [199.50536 ]\n",
      " [196.6602  ]\n",
      " [259.67087 ]\n",
      " [169.32779 ]\n",
      " [ 44.71656 ]\n",
      " [255.488   ]\n",
      " [104.903175]\n",
      " [176.50368 ]\n",
      " [175.41957 ]]\n",
      "=================\n",
      "R2 :  0.3966430622917776\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.6555\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 34.0454\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.6071\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 34.2253\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.6556\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 34.7745\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 34.7846\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.3489\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 35.9870\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 34.9633\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 34.5131\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 33.7235\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.9718\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 35.9710\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 34.7539\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.9362\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.2834\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 35.3574\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.9931\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 34.2308\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.3288\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.7450\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 34.8912\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.9273\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 35.8639\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 35.7384\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 35.5251\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.2501\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.9345\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 35.0073\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.1759\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 35.2385\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 34.4139\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 35.8285\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 34.3834\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 35.2987\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 37.0982\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 34.5616\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 35.1239\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.3568\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.4531\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 35.4569\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.4406\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.2836\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 35.3336\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 34.9781\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 35.3179\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 34.2314\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.6003\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 35.7185\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 35.3560\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.2046\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 35.4410\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.9098\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 35.8686\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 35.7961\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.3785\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.0242\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 37.5909\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.4363\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 34.6403\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 35.2951\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.7727\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 35.2424\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 35.5828\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.5380\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 34.6310\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 35.6786\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 35.0949\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.9025\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 35.0839\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 34.7105\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 34.2961\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.4916\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.4005\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 35.6009\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.6268\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.7455\n",
      "Epoch 79/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 160us/step - loss: 34.7455\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 47.0147\n",
      "loss :  47.01469802856445\n",
      "5/5 [==============================] - 0s 997us/step\n",
      "=================\n",
      "[185. 150. 246. 184. 110. 202. 336.  69.  69.  87.  66. 164. 265. 198.\n",
      " 248. 171. 102. 182. 262. 233. 151. 275. 230.  39.  42. 122.  81.  31.\n",
      " 156. 161.  80. 215. 310. 163. 265.  84.  54. 137. 248.  72. 248.  59.\n",
      "  97.  61.  72. 296.  55.  75.  53. 173. 158.  96. 140. 186.  93. 123.\n",
      " 237. 138. 292.  78. 182. 127. 321. 109. 212.  45.  96. 109.  89.  96.\n",
      "  60.  51. 200. 265.  68.  91. 172. 115. 125.  53.  63. 259. 214. 195.\n",
      " 258. 235. 173.  59. 219. 170.  77.  49.  66. 144. 113. 233. 162. 121.\n",
      "  88. 302. 128.  52. 178.  90. 164. 135. 103. 200. 178. 261.  64.  59.\n",
      "  79.  47. 107.  39. 151. 104. 217. 232.  55. 245. 131.  64. 222. 249.\n",
      " 128. 293. 138. 273. 158. 168. 103.]\n",
      "[[113.40138 ]\n",
      " [ 97.45932 ]\n",
      " [240.90694 ]\n",
      " [152.58817 ]\n",
      " [138.46817 ]\n",
      " [133.88152 ]\n",
      " [272.38068 ]\n",
      " [ 74.75111 ]\n",
      " [105.942406]\n",
      " [123.080795]\n",
      " [136.14668 ]\n",
      " [170.27284 ]\n",
      " [152.0114  ]\n",
      " [198.19315 ]\n",
      " [219.67194 ]\n",
      " [184.5454  ]\n",
      " [ 68.65494 ]\n",
      " [178.16853 ]\n",
      " [175.21457 ]\n",
      " [212.32574 ]\n",
      " [188.80527 ]\n",
      " [221.77469 ]\n",
      " [131.58125 ]\n",
      " [ 49.150406]\n",
      " [ 68.37884 ]\n",
      " [134.61102 ]\n",
      " [ 92.99051 ]\n",
      " [120.17206 ]\n",
      " [146.2214  ]\n",
      " [133.69865 ]\n",
      " [ 85.78539 ]\n",
      " [249.5949  ]\n",
      " [186.47514 ]\n",
      " [211.75148 ]\n",
      " [182.90648 ]\n",
      " [ 95.6548  ]\n",
      " [ 65.433235]\n",
      " [128.20694 ]\n",
      " [209.42592 ]\n",
      " [102.40865 ]\n",
      " [198.94713 ]\n",
      " [ 80.57407 ]\n",
      " [139.35698 ]\n",
      " [ 92.70573 ]\n",
      " [104.31083 ]\n",
      " [213.80006 ]\n",
      " [116.20185 ]\n",
      " [ 72.91263 ]\n",
      " [ 53.264343]\n",
      " [237.9356  ]\n",
      " [109.17251 ]\n",
      " [ 76.10901 ]\n",
      " [216.55019 ]\n",
      " [191.41142 ]\n",
      " [169.78777 ]\n",
      " [187.49051 ]\n",
      " [240.60037 ]\n",
      " [148.93813 ]\n",
      " [145.99207 ]\n",
      " [154.07272 ]\n",
      " [ 73.43238 ]\n",
      " [111.75069 ]\n",
      " [231.36255 ]\n",
      " [241.84541 ]\n",
      " [173.46733 ]\n",
      " [ 64.20432 ]\n",
      " [ 62.79027 ]\n",
      " [206.6352  ]\n",
      " [ 93.212555]\n",
      " [ 81.95853 ]\n",
      " [ 71.77487 ]\n",
      " [ 64.01161 ]\n",
      " [186.79681 ]\n",
      " [151.90509 ]\n",
      " [138.10365 ]\n",
      " [161.40427 ]\n",
      " [154.69974 ]\n",
      " [133.52641 ]\n",
      " [120.98234 ]\n",
      " [ 83.13906 ]\n",
      " [ 63.83962 ]\n",
      " [145.41882 ]\n",
      " [155.76349 ]\n",
      " [197.84105 ]\n",
      " [325.20978 ]\n",
      " [158.37195 ]\n",
      " [214.72215 ]\n",
      " [ 63.718662]\n",
      " [ 83.96258 ]\n",
      " [109.14826 ]\n",
      " [164.80853 ]\n",
      " [ 47.499954]\n",
      " [132.33905 ]\n",
      " [185.48798 ]\n",
      " [144.0319  ]\n",
      " [278.35144 ]\n",
      " [153.70177 ]\n",
      " [248.40677 ]\n",
      " [112.04981 ]\n",
      " [ 99.733086]\n",
      " [ 53.841267]\n",
      " [ 85.945496]\n",
      " [103.34722 ]\n",
      " [159.4576  ]\n",
      " [171.16661 ]\n",
      " [ 53.048073]\n",
      " [ 96.04577 ]\n",
      " [129.00981 ]\n",
      " [175.90219 ]\n",
      " [253.606   ]\n",
      " [ 77.85511 ]\n",
      " [102.10408 ]\n",
      " [113.90103 ]\n",
      " [ 86.03114 ]\n",
      " [ 81.18115 ]\n",
      " [107.1818  ]\n",
      " [205.07831 ]\n",
      " [ 70.44832 ]\n",
      " [195.43956 ]\n",
      " [203.69029 ]\n",
      " [135.505   ]\n",
      " [117.64646 ]\n",
      " [138.99707 ]\n",
      " [ 79.87399 ]\n",
      " [189.19673 ]\n",
      " [182.66832 ]\n",
      " [254.39304 ]\n",
      " [163.1894  ]\n",
      " [ 47.630493]\n",
      " [205.86746 ]\n",
      " [ 80.57494 ]\n",
      " [168.16142 ]\n",
      " [166.26955 ]]\n",
      "=================\n",
      "R2 :  0.37157331551558315\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 34.0330\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 35.9261\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 34.5801\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.9835\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.5360\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.4176\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 34.8096\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 34.3304\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 34.0355\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.2777\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.4677\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.8774\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.7850\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.2328\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.6704\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.3388\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 34.2025\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 34.9589\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.9229\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 34.9290\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 34.2539\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.6972\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.2341\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.0915\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.7252\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.5953\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.0229\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.9058\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 34.2278\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 34.2605\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.1980\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.9815\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 34.1304\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 34.3642\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 34.7171\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 34.1526\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.7928\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 35.3207\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.8253\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.5212\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.7799\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.3719\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.5452\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 35.6513\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.9876\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.0715\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 34.6621\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 34.1207\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 34.0669\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 34.5076\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 34.6282\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.0558\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.5568\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.6405\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 34.7953\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.7868\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.5837\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 35.3459\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.6138\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.9376\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.2881\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.1079\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 34.0176\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 34.3577\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.7011\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.0330\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.9238\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.7848\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 34.7727\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.4219\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 34.6075\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.4082\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.8741\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.9269\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.3640\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.2759\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 34.4622\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.4280\n",
      "Epoch 79/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 125us/step - loss: 33.4280\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 48.3718\n",
      "loss :  48.371761322021484\n",
      "5/5 [==============================] - 0s 997us/step\n",
      "=================\n",
      "[185. 150. 246. 184. 110. 202. 336.  69.  69.  87.  66. 164. 265. 198.\n",
      " 248. 171. 102. 182. 262. 233. 151. 275. 230.  39.  42. 122.  81.  31.\n",
      " 156. 161.  80. 215. 310. 163. 265.  84.  54. 137. 248.  72. 248.  59.\n",
      "  97.  61.  72. 296.  55.  75.  53. 173. 158.  96. 140. 186.  93. 123.\n",
      " 237. 138. 292.  78. 182. 127. 321. 109. 212.  45.  96. 109.  89.  96.\n",
      "  60.  51. 200. 265.  68.  91. 172. 115. 125.  53.  63. 259. 214. 195.\n",
      " 258. 235. 173.  59. 219. 170.  77.  49.  66. 144. 113. 233. 162. 121.\n",
      "  88. 302. 128.  52. 178.  90. 164. 135. 103. 200. 178. 261.  64.  59.\n",
      "  79.  47. 107.  39. 151. 104. 217. 232.  55. 245. 131.  64. 222. 249.\n",
      " 128. 293. 138. 273. 158. 168. 103.]\n",
      "[[116.57952 ]\n",
      " [ 88.45415 ]\n",
      " [237.96532 ]\n",
      " [147.61714 ]\n",
      " [127.8843  ]\n",
      " [122.4718  ]\n",
      " [273.49518 ]\n",
      " [ 69.709145]\n",
      " [100.26049 ]\n",
      " [130.42575 ]\n",
      " [141.92996 ]\n",
      " [164.34343 ]\n",
      " [146.63892 ]\n",
      " [228.45488 ]\n",
      " [229.82562 ]\n",
      " [181.81972 ]\n",
      " [ 68.644424]\n",
      " [178.03731 ]\n",
      " [175.7448  ]\n",
      " [210.57358 ]\n",
      " [186.28407 ]\n",
      " [220.0279  ]\n",
      " [125.83534 ]\n",
      " [ 43.87102 ]\n",
      " [ 66.63656 ]\n",
      " [127.91443 ]\n",
      " [ 89.91312 ]\n",
      " [120.775734]\n",
      " [146.93404 ]\n",
      " [133.8177  ]\n",
      " [115.235695]\n",
      " [270.08316 ]\n",
      " [182.72998 ]\n",
      " [218.65524 ]\n",
      " [194.8511  ]\n",
      " [ 98.221016]\n",
      " [ 65.87825 ]\n",
      " [126.12261 ]\n",
      " [197.70284 ]\n",
      " [101.287865]\n",
      " [194.21687 ]\n",
      " [ 76.220436]\n",
      " [140.17856 ]\n",
      " [ 88.88067 ]\n",
      " [103.74172 ]\n",
      " [203.03976 ]\n",
      " [118.42735 ]\n",
      " [ 70.8704  ]\n",
      " [ 52.438046]\n",
      " [237.10657 ]\n",
      " [107.60839 ]\n",
      " [ 73.976585]\n",
      " [216.7033  ]\n",
      " [186.94608 ]\n",
      " [168.21007 ]\n",
      " [185.17786 ]\n",
      " [233.73224 ]\n",
      " [131.56831 ]\n",
      " [132.72653 ]\n",
      " [155.85295 ]\n",
      " [ 73.56605 ]\n",
      " [108.836365]\n",
      " [227.4629  ]\n",
      " [234.59814 ]\n",
      " [161.35263 ]\n",
      " [ 63.83942 ]\n",
      " [ 59.945553]\n",
      " [211.74867 ]\n",
      " [ 84.7143  ]\n",
      " [ 79.90002 ]\n",
      " [ 67.62979 ]\n",
      " [ 60.1469  ]\n",
      " [174.0127  ]\n",
      " [150.93301 ]\n",
      " [140.74571 ]\n",
      " [153.45763 ]\n",
      " [155.87656 ]\n",
      " [130.2246  ]\n",
      " [118.46287 ]\n",
      " [ 72.27129 ]\n",
      " [ 55.055622]\n",
      " [139.37143 ]\n",
      " [154.59741 ]\n",
      " [210.02853 ]\n",
      " [304.0711  ]\n",
      " [158.75441 ]\n",
      " [214.95943 ]\n",
      " [ 59.305378]\n",
      " [ 88.88257 ]\n",
      " [101.7229  ]\n",
      " [158.38095 ]\n",
      " [ 45.66428 ]\n",
      " [143.05058 ]\n",
      " [194.99223 ]\n",
      " [140.03246 ]\n",
      " [262.52084 ]\n",
      " [149.67032 ]\n",
      " [246.52304 ]\n",
      " [127.90084 ]\n",
      " [100.35804 ]\n",
      " [ 57.77906 ]\n",
      " [ 86.73521 ]\n",
      " [117.270676]\n",
      " [152.59581 ]\n",
      " [218.30753 ]\n",
      " [ 51.370674]\n",
      " [ 99.07093 ]\n",
      " [122.15948 ]\n",
      " [175.5934  ]\n",
      " [250.75148 ]\n",
      " [ 72.686066]\n",
      " [ 97.86031 ]\n",
      " [109.290276]\n",
      " [ 77.931984]\n",
      " [ 81.38685 ]\n",
      " [120.6388  ]\n",
      " [201.9344  ]\n",
      " [ 55.10904 ]\n",
      " [193.01118 ]\n",
      " [209.50987 ]\n",
      " [138.72992 ]\n",
      " [123.11048 ]\n",
      " [137.31522 ]\n",
      " [109.16554 ]\n",
      " [181.44899 ]\n",
      " [214.55571 ]\n",
      " [265.6395  ]\n",
      " [169.14304 ]\n",
      " [ 43.91244 ]\n",
      " [208.89844 ]\n",
      " [ 74.20979 ]\n",
      " [171.15642 ]\n",
      " [169.67812 ]]\n",
      "=================\n",
      "R2 :  0.3472283405871569\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 35.3709\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.6275\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 34.3323\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.5849\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.0895\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.2537\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 35.1970\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.7588\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 36.7083\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.8681\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.3307\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.3254\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.9727\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.3589\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.9252\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.3273\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 34.8451\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.4350\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.4801\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.9522\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 34.2786\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.9946\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.6155\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.7136\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.0057\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.3611\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.9700\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.4233\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.4065\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.6747\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.1629\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.0743\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.3024\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 34.8334\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.8863\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.2323\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.6089\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.2275\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.1575\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.1339\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.5121\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.2639\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.7403\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.7263\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.2123\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.5963\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.9493\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.8215\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 34.3553\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.2495\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.0217\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.8801\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.7190\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.0190\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.2704\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.8757\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.5351\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.0091\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.2638\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.6051\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.0113\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.8005\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.7535\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.1991\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.5820\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.9382\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.0141\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.2387\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.8935\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.3975\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.9579\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.6692\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.3070\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.6327\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.0441\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.6488\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.8833\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.2384\n",
      "Epoch 79/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 140us/step - loss: 33.2384\n",
      "5/5 [==============================] - 0s 997us/step - loss: 49.7583\n",
      "loss :  49.75825881958008\n",
      "5/5 [==============================] - 0s 997us/step\n",
      "=================\n",
      "[185. 150. 246. 184. 110. 202. 336.  69.  69.  87.  66. 164. 265. 198.\n",
      " 248. 171. 102. 182. 262. 233. 151. 275. 230.  39.  42. 122.  81.  31.\n",
      " 156. 161.  80. 215. 310. 163. 265.  84.  54. 137. 248.  72. 248.  59.\n",
      "  97.  61.  72. 296.  55.  75.  53. 173. 158.  96. 140. 186.  93. 123.\n",
      " 237. 138. 292.  78. 182. 127. 321. 109. 212.  45.  96. 109.  89.  96.\n",
      "  60.  51. 200. 265.  68.  91. 172. 115. 125.  53.  63. 259. 214. 195.\n",
      " 258. 235. 173.  59. 219. 170.  77.  49.  66. 144. 113. 233. 162. 121.\n",
      "  88. 302. 128.  52. 178.  90. 164. 135. 103. 200. 178. 261.  64.  59.\n",
      "  79.  47. 107.  39. 151. 104. 217. 232.  55. 245. 131.  64. 222. 249.\n",
      " 128. 293. 138. 273. 158. 168. 103.]\n",
      "[[129.98787 ]\n",
      " [ 89.35949 ]\n",
      " [264.49338 ]\n",
      " [169.08582 ]\n",
      " [142.2713  ]\n",
      " [111.82735 ]\n",
      " [287.9771  ]\n",
      " [ 72.496895]\n",
      " [103.947266]\n",
      " [138.92067 ]\n",
      " [139.33415 ]\n",
      " [184.2897  ]\n",
      " [162.76956 ]\n",
      " [209.02077 ]\n",
      " [273.4254  ]\n",
      " [166.10019 ]\n",
      " [ 73.22894 ]\n",
      " [198.38618 ]\n",
      " [194.37012 ]\n",
      " [229.32509 ]\n",
      " [210.48917 ]\n",
      " [241.82578 ]\n",
      " [129.91719 ]\n",
      " [ 47.60741 ]\n",
      " [ 74.37256 ]\n",
      " [129.65033 ]\n",
      " [ 92.64701 ]\n",
      " [128.9315  ]\n",
      " [163.60547 ]\n",
      " [150.45676 ]\n",
      " [143.12254 ]\n",
      " [237.18349 ]\n",
      " [211.23347 ]\n",
      " [251.41328 ]\n",
      " [218.06178 ]\n",
      " [110.23604 ]\n",
      " [ 67.633575]\n",
      " [128.04996 ]\n",
      " [214.38231 ]\n",
      " [102.41622 ]\n",
      " [212.97284 ]\n",
      " [ 74.890114]\n",
      " [146.09853 ]\n",
      " [109.01783 ]\n",
      " [113.033775]\n",
      " [218.22765 ]\n",
      " [125.78846 ]\n",
      " [ 74.56813 ]\n",
      " [ 56.10287 ]\n",
      " [261.0807  ]\n",
      " [113.40459 ]\n",
      " [ 62.71978 ]\n",
      " [232.72395 ]\n",
      " [208.59752 ]\n",
      " [182.32137 ]\n",
      " [213.82823 ]\n",
      " [254.96642 ]\n",
      " [136.32964 ]\n",
      " [155.72247 ]\n",
      " [177.56525 ]\n",
      " [ 78.32845 ]\n",
      " [115.7022  ]\n",
      " [242.37141 ]\n",
      " [251.98691 ]\n",
      " [173.79797 ]\n",
      " [ 71.63914 ]\n",
      " [ 65.993965]\n",
      " [219.85478 ]\n",
      " [ 83.65334 ]\n",
      " [ 83.18091 ]\n",
      " [ 70.74744 ]\n",
      " [ 64.92673 ]\n",
      " [196.75276 ]\n",
      " [177.3429  ]\n",
      " [153.90431 ]\n",
      " [171.04262 ]\n",
      " [194.45802 ]\n",
      " [133.10423 ]\n",
      " [127.81827 ]\n",
      " [ 72.70757 ]\n",
      " [ 57.741116]\n",
      " [152.31996 ]\n",
      " [165.22937 ]\n",
      " [183.40695 ]\n",
      " [328.7193  ]\n",
      " [179.04724 ]\n",
      " [240.06651 ]\n",
      " [ 62.41675 ]\n",
      " [ 94.30435 ]\n",
      " [ 95.082886]\n",
      " [178.1921  ]\n",
      " [ 47.63045 ]\n",
      " [162.08179 ]\n",
      " [208.98982 ]\n",
      " [146.61607 ]\n",
      " [279.78738 ]\n",
      " [160.64618 ]\n",
      " [270.82468 ]\n",
      " [149.81795 ]\n",
      " [119.72099 ]\n",
      " [ 80.21956 ]\n",
      " [ 90.28258 ]\n",
      " [128.47737 ]\n",
      " [169.69244 ]\n",
      " [207.44357 ]\n",
      " [ 54.723003]\n",
      " [116.39285 ]\n",
      " [139.69826 ]\n",
      " [198.24141 ]\n",
      " [259.5549  ]\n",
      " [ 76.57928 ]\n",
      " [114.45245 ]\n",
      " [113.75625 ]\n",
      " [ 82.27845 ]\n",
      " [ 77.50305 ]\n",
      " [121.61473 ]\n",
      " [225.76373 ]\n",
      " [ 56.808838]\n",
      " [212.82819 ]\n",
      " [234.96071 ]\n",
      " [159.40675 ]\n",
      " [143.41743 ]\n",
      " [160.23    ]\n",
      " [139.82115 ]\n",
      " [200.92538 ]\n",
      " [194.43785 ]\n",
      " [261.99875 ]\n",
      " [159.1887  ]\n",
      " [ 59.543484]\n",
      " [196.58597 ]\n",
      " [ 80.72502 ]\n",
      " [188.5002  ]\n",
      " [163.61594 ]]\n",
      "=================\n",
      "R2 :  0.3322319322557382\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.1640\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.2460\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.4235\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.7027\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.5194\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.1041\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.0713\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.2868\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.4747\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.2291\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.5801\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.0628\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.1721\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.0333\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.2822\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.5484\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.6379\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.5551\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.2308\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.9113\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.7963\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.3584\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.2774\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.1536\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.6916\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.3747\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.4551\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.0926\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.8313\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.0223\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.5759\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.8763\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.8418\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.9293\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.2311\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.2931\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.6597\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.5761\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.0391\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.4946\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.8069\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.1761\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 34.0566\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.3649\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.3548\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.7962\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.0227\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.7502\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.4733\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.8115\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.0451\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.3369\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.4307\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.1493\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.3811\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.2687\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.4345\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.9562\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.3657\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.0627\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.9651\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.9799\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.7426\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.2388\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.6660\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.8532\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.5991\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.6684\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.1325\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.6750\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.1887\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.5312\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.7279\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.8784\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.6277\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.2225\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.9158\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.0937\n",
      "Epoch 79/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 127us/step - loss: 33.0937\n",
      "5/5 [==============================] - 0s 997us/step - loss: 51.3828\n",
      "loss :  51.38279342651367\n",
      "5/5 [==============================] - 0s 748us/step\n",
      "=================\n",
      "[185. 150. 246. 184. 110. 202. 336.  69.  69.  87.  66. 164. 265. 198.\n",
      " 248. 171. 102. 182. 262. 233. 151. 275. 230.  39.  42. 122.  81.  31.\n",
      " 156. 161.  80. 215. 310. 163. 265.  84.  54. 137. 248.  72. 248.  59.\n",
      "  97.  61.  72. 296.  55.  75.  53. 173. 158.  96. 140. 186.  93. 123.\n",
      " 237. 138. 292.  78. 182. 127. 321. 109. 212.  45.  96. 109.  89.  96.\n",
      "  60.  51. 200. 265.  68.  91. 172. 115. 125.  53.  63. 259. 214. 195.\n",
      " 258. 235. 173.  59. 219. 170.  77.  49.  66. 144. 113. 233. 162. 121.\n",
      "  88. 302. 128.  52. 178.  90. 164. 135. 103. 200. 178. 261.  64.  59.\n",
      "  79.  47. 107.  39. 151. 104. 217. 232.  55. 245. 131.  64. 222. 249.\n",
      " 128. 293. 138. 273. 158. 168. 103.]\n",
      "[[135.5613  ]\n",
      " [ 94.65097 ]\n",
      " [266.0715  ]\n",
      " [170.51501 ]\n",
      " [132.01695 ]\n",
      " [109.07447 ]\n",
      " [277.2775  ]\n",
      " [ 84.12688 ]\n",
      " [102.20772 ]\n",
      " [133.3353  ]\n",
      " [129.39816 ]\n",
      " [183.28537 ]\n",
      " [163.74673 ]\n",
      " [252.2286  ]\n",
      " [275.48187 ]\n",
      " [193.96056 ]\n",
      " [126.386566]\n",
      " [209.42761 ]\n",
      " [198.54973 ]\n",
      " [235.42465 ]\n",
      " [212.20274 ]\n",
      " [240.90504 ]\n",
      " [124.01963 ]\n",
      " [ 49.26908 ]\n",
      " [ 76.94842 ]\n",
      " [142.95406 ]\n",
      " [ 94.344246]\n",
      " [134.54887 ]\n",
      " [158.80898 ]\n",
      " [153.35873 ]\n",
      " [146.68845 ]\n",
      " [289.8262  ]\n",
      " [212.9535  ]\n",
      " [247.46997 ]\n",
      " [214.96855 ]\n",
      " [110.60802 ]\n",
      " [ 70.593475]\n",
      " [133.27916 ]\n",
      " [219.16795 ]\n",
      " [103.80432 ]\n",
      " [210.14738 ]\n",
      " [ 76.73559 ]\n",
      " [151.09404 ]\n",
      " [106.137794]\n",
      " [111.318634]\n",
      " [212.49841 ]\n",
      " [134.82773 ]\n",
      " [ 76.96028 ]\n",
      " [ 58.60541 ]\n",
      " [268.1182  ]\n",
      " [125.79519 ]\n",
      " [ 70.396416]\n",
      " [242.46565 ]\n",
      " [218.09575 ]\n",
      " [186.49565 ]\n",
      " [222.38219 ]\n",
      " [265.77628 ]\n",
      " [129.60446 ]\n",
      " [140.05954 ]\n",
      " [184.29921 ]\n",
      " [ 83.00669 ]\n",
      " [111.907394]\n",
      " [241.43861 ]\n",
      " [252.53133 ]\n",
      " [168.92851 ]\n",
      " [ 71.74213 ]\n",
      " [ 68.36397 ]\n",
      " [206.66931 ]\n",
      " [ 76.58797 ]\n",
      " [ 81.246735]\n",
      " [ 74.49288 ]\n",
      " [ 70.86109 ]\n",
      " [206.40672 ]\n",
      " [162.79369 ]\n",
      " [158.24686 ]\n",
      " [170.88759 ]\n",
      " [185.78098 ]\n",
      " [120.42004 ]\n",
      " [134.67065 ]\n",
      " [ 73.13059 ]\n",
      " [ 57.411797]\n",
      " [151.34634 ]\n",
      " [170.02272 ]\n",
      " [205.11703 ]\n",
      " [329.50174 ]\n",
      " [171.28947 ]\n",
      " [239.9967  ]\n",
      " [ 63.954655]\n",
      " [ 99.220085]\n",
      " [ 98.68232 ]\n",
      " [175.72803 ]\n",
      " [ 49.32207 ]\n",
      " [146.25165 ]\n",
      " [213.20479 ]\n",
      " [155.44789 ]\n",
      " [286.7466  ]\n",
      " [168.02788 ]\n",
      " [277.2094  ]\n",
      " [146.09572 ]\n",
      " [127.92642 ]\n",
      " [ 83.9474  ]\n",
      " [ 86.38105 ]\n",
      " [125.38854 ]\n",
      " [165.58577 ]\n",
      " [259.10822 ]\n",
      " [ 56.200237]\n",
      " [123.59529 ]\n",
      " [136.58403 ]\n",
      " [190.82619 ]\n",
      " [258.28937 ]\n",
      " [ 74.82915 ]\n",
      " [116.10193 ]\n",
      " [113.07957 ]\n",
      " [ 83.964455]\n",
      " [ 89.72736 ]\n",
      " [134.17628 ]\n",
      " [228.20964 ]\n",
      " [ 53.35917 ]\n",
      " [210.08202 ]\n",
      " [228.23628 ]\n",
      " [169.40872 ]\n",
      " [147.50172 ]\n",
      " [149.83682 ]\n",
      " [148.65698 ]\n",
      " [206.18785 ]\n",
      " [248.33066 ]\n",
      " [290.05814 ]\n",
      " [178.7742  ]\n",
      " [ 55.74438 ]\n",
      " [196.83846 ]\n",
      " [ 83.074585]\n",
      " [179.23743 ]\n",
      " [158.64919 ]]\n",
      "=================\n",
      "R2 :  0.2938359207688436\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.5559\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.9451\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.5271\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.3679\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.6776\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.3644\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.0419\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.1858\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.9986\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.1048\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 34.1807\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.5707\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.3683\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.0472\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.1870\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.0625\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.0997\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.1219\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.7171\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.9615\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.3254\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.7219\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.3604\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.6874\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.2315\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.6404\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.4513\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.4973\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.4688\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.7837\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.4588\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.6524\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.4373\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.8531\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.9528\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.2229\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.3362\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.2520\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.2045\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.7235\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.5810\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.4540\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.3792\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.9087\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.5594\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.8978\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.4197\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.8422\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.2550\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.3904\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.0882\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.1442\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.0874\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.7673\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.1832\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.1584\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.7271\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.8157\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.9124\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.4423\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.0707\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.5432\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.4771\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.7053\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.4172\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.0153\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.4903\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.3822\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.6884\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.1559\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.7163\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.1676\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.3846\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.3916\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.9503\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.4193\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.6479\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.2942\n",
      "Epoch 79/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 120us/step - loss: 32.2942\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 50.8473\n",
      "loss :  50.84725570678711\n",
      "5/5 [==============================] - 0s 997us/step\n",
      "=================\n",
      "[185. 150. 246. 184. 110. 202. 336.  69.  69.  87.  66. 164. 265. 198.\n",
      " 248. 171. 102. 182. 262. 233. 151. 275. 230.  39.  42. 122.  81.  31.\n",
      " 156. 161.  80. 215. 310. 163. 265.  84.  54. 137. 248.  72. 248.  59.\n",
      "  97.  61.  72. 296.  55.  75.  53. 173. 158.  96. 140. 186.  93. 123.\n",
      " 237. 138. 292.  78. 182. 127. 321. 109. 212.  45.  96. 109.  89.  96.\n",
      "  60.  51. 200. 265.  68.  91. 172. 115. 125.  53.  63. 259. 214. 195.\n",
      " 258. 235. 173.  59. 219. 170.  77.  49.  66. 144. 113. 233. 162. 121.\n",
      "  88. 302. 128.  52. 178.  90. 164. 135. 103. 200. 178. 261.  64.  59.\n",
      "  79.  47. 107.  39. 151. 104. 217. 232.  55. 245. 131.  64. 222. 249.\n",
      " 128. 293. 138. 273. 158. 168. 103.]\n",
      "[[129.5297  ]\n",
      " [ 96.43164 ]\n",
      " [260.49936 ]\n",
      " [159.74866 ]\n",
      " [131.30435 ]\n",
      " [111.18859 ]\n",
      " [273.40216 ]\n",
      " [ 86.15408 ]\n",
      " [104.48673 ]\n",
      " [128.72566 ]\n",
      " [120.78017 ]\n",
      " [183.1329  ]\n",
      " [164.63687 ]\n",
      " [243.42422 ]\n",
      " [299.82205 ]\n",
      " [188.12971 ]\n",
      " [135.5473  ]\n",
      " [205.48497 ]\n",
      " [195.85432 ]\n",
      " [231.99207 ]\n",
      " [196.80367 ]\n",
      " [244.83781 ]\n",
      " [117.58327 ]\n",
      " [ 52.349007]\n",
      " [ 71.39742 ]\n",
      " [136.71101 ]\n",
      " [ 94.855576]\n",
      " [133.4484  ]\n",
      " [161.20033 ]\n",
      " [141.3199  ]\n",
      " [158.38582 ]\n",
      " [274.43323 ]\n",
      " [206.93591 ]\n",
      " [262.08252 ]\n",
      " [205.22327 ]\n",
      " [120.71867 ]\n",
      " [ 72.516945]\n",
      " [113.978645]\n",
      " [222.37386 ]\n",
      " [ 98.68573 ]\n",
      " [205.02815 ]\n",
      " [ 74.8771  ]\n",
      " [129.05345 ]\n",
      " [100.268745]\n",
      " [111.34543 ]\n",
      " [202.12157 ]\n",
      " [120.93066 ]\n",
      " [ 72.88415 ]\n",
      " [ 56.91545 ]\n",
      " [263.17538 ]\n",
      " [123.82342 ]\n",
      " [ 71.92805 ]\n",
      " [240.07768 ]\n",
      " [222.4693  ]\n",
      " [169.3181  ]\n",
      " [222.89732 ]\n",
      " [264.88467 ]\n",
      " [125.42501 ]\n",
      " [126.597404]\n",
      " [177.22597 ]\n",
      " [ 79.350784]\n",
      " [114.94238 ]\n",
      " [240.1593  ]\n",
      " [243.49904 ]\n",
      " [167.46858 ]\n",
      " [ 74.9716  ]\n",
      " [ 66.09645 ]\n",
      " [198.69064 ]\n",
      " [ 85.3828  ]\n",
      " [ 84.287125]\n",
      " [ 72.95522 ]\n",
      " [ 73.38821 ]\n",
      " [194.76231 ]\n",
      " [149.70032 ]\n",
      " [141.80013 ]\n",
      " [169.66354 ]\n",
      " [176.07811 ]\n",
      " [113.274414]\n",
      " [134.45035 ]\n",
      " [ 69.267105]\n",
      " [ 52.785004]\n",
      " [151.21754 ]\n",
      " [152.65094 ]\n",
      " [193.16216 ]\n",
      " [321.44434 ]\n",
      " [178.87659 ]\n",
      " [233.98708 ]\n",
      " [ 58.029625]\n",
      " [ 81.27079 ]\n",
      " [103.201904]\n",
      " [172.38322 ]\n",
      " [ 48.88959 ]\n",
      " [128.87929 ]\n",
      " [204.92659 ]\n",
      " [142.7779  ]\n",
      " [288.64777 ]\n",
      " [150.5947  ]\n",
      " [270.7311  ]\n",
      " [135.99695 ]\n",
      " [122.61617 ]\n",
      " [ 84.31192 ]\n",
      " [102.349335]\n",
      " [129.96446 ]\n",
      " [161.04024 ]\n",
      " [247.94594 ]\n",
      " [ 58.889553]\n",
      " [114.777756]\n",
      " [125.01228 ]\n",
      " [195.8768  ]\n",
      " [256.8761  ]\n",
      " [ 72.36145 ]\n",
      " [107.155624]\n",
      " [111.61025 ]\n",
      " [ 84.13913 ]\n",
      " [ 92.287125]\n",
      " [129.00551 ]\n",
      " [228.3143  ]\n",
      " [ 50.74009 ]\n",
      " [225.2296  ]\n",
      " [238.01428 ]\n",
      " [162.90698 ]\n",
      " [139.47638 ]\n",
      " [150.0887  ]\n",
      " [136.25058 ]\n",
      " [209.83228 ]\n",
      " [239.87946 ]\n",
      " [281.6631  ]\n",
      " [167.90973 ]\n",
      " [ 49.14229 ]\n",
      " [188.81146 ]\n",
      " [ 84.02913 ]\n",
      " [192.78654 ]\n",
      " [142.83777 ]]\n",
      "=================\n",
      "R2 :  0.3030477401441758\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.6067\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.9603\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.9481\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.1821\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.2544\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 34.5633\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.5660\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.8565\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.1566\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.0069\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.5513\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.9275\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.7136\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.1386\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.5578\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.7680\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.9368\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 33.5951\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.8074\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.8074\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.7649\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.4688\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.6168\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.2708\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.7451\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.2062\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.7319\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.4813\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.7288\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.9258\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.4640\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.1499\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.3101\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.4329\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.3683\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.0804\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.9671\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.0735\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.4065\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.4135\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.1701\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.7780\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.5933\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.0835\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.6045\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.5527\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.8185\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.2604\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.2401\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.6055\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.3862\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.6950\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.6894\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.0869\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.8654\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.4420\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.6918\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.3353\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.5437\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.6514\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.4552\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.2755\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.2444\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.9435\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.2658\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.9846\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.9016\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.5632\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.6804\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.7700\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.1602\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.7498\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.3890\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.9422\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.4587\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.9309\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.4122\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.5361\n",
      "Epoch 79/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 130us/step - loss: 31.5361\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 55.4225\n",
      "loss :  55.422508239746094\n",
      "5/5 [==============================] - 0s 997us/step\n",
      "=================\n",
      "[185. 150. 246. 184. 110. 202. 336.  69.  69.  87.  66. 164. 265. 198.\n",
      " 248. 171. 102. 182. 262. 233. 151. 275. 230.  39.  42. 122.  81.  31.\n",
      " 156. 161.  80. 215. 310. 163. 265.  84.  54. 137. 248.  72. 248.  59.\n",
      "  97.  61.  72. 296.  55.  75.  53. 173. 158.  96. 140. 186.  93. 123.\n",
      " 237. 138. 292.  78. 182. 127. 321. 109. 212.  45.  96. 109.  89.  96.\n",
      "  60.  51. 200. 265.  68.  91. 172. 115. 125.  53.  63. 259. 214. 195.\n",
      " 258. 235. 173.  59. 219. 170.  77.  49.  66. 144. 113. 233. 162. 121.\n",
      "  88. 302. 128.  52. 178.  90. 164. 135. 103. 200. 178. 261.  64.  59.\n",
      "  79.  47. 107.  39. 151. 104. 217. 232.  55. 245. 131.  64. 222. 249.\n",
      " 128. 293. 138. 273. 158. 168. 103.]\n",
      "[[146.45534 ]\n",
      " [ 95.282425]\n",
      " [283.76953 ]\n",
      " [182.66328 ]\n",
      " [148.06627 ]\n",
      " [118.95578 ]\n",
      " [293.90097 ]\n",
      " [ 86.88244 ]\n",
      " [105.472725]\n",
      " [140.86331 ]\n",
      " [118.89209 ]\n",
      " [191.29582 ]\n",
      " [179.34381 ]\n",
      " [263.83923 ]\n",
      " [318.0529  ]\n",
      " [196.26323 ]\n",
      " [109.00758 ]\n",
      " [238.20384 ]\n",
      " [214.0746  ]\n",
      " [250.79015 ]\n",
      " [222.08179 ]\n",
      " [271.4547  ]\n",
      " [120.32838 ]\n",
      " [ 52.830715]\n",
      " [ 71.95444 ]\n",
      " [145.32973 ]\n",
      " [102.189384]\n",
      " [144.28418 ]\n",
      " [167.6166  ]\n",
      " [162.82957 ]\n",
      " [170.28801 ]\n",
      " [304.56033 ]\n",
      " [234.63283 ]\n",
      " [286.09753 ]\n",
      " [262.7552  ]\n",
      " [130.93025 ]\n",
      " [ 69.34951 ]\n",
      " [125.91639 ]\n",
      " [232.73122 ]\n",
      " [102.70867 ]\n",
      " [223.95685 ]\n",
      " [ 77.16109 ]\n",
      " [147.58691 ]\n",
      " [108.725845]\n",
      " [117.94915 ]\n",
      " [207.82983 ]\n",
      " [148.53313 ]\n",
      " [ 73.41786 ]\n",
      " [ 56.080475]\n",
      " [289.0935  ]\n",
      " [138.60938 ]\n",
      " [ 68.37317 ]\n",
      " [275.83438 ]\n",
      " [241.74004 ]\n",
      " [195.8016  ]\n",
      " [237.76628 ]\n",
      " [278.46283 ]\n",
      " [126.36497 ]\n",
      " [133.59863 ]\n",
      " [197.27296 ]\n",
      " [ 87.95157 ]\n",
      " [127.7807  ]\n",
      " [261.68713 ]\n",
      " [268.40848 ]\n",
      " [175.78404 ]\n",
      " [ 70.428795]\n",
      " [ 69.27194 ]\n",
      " [214.90654 ]\n",
      " [ 91.41478 ]\n",
      " [ 88.30282 ]\n",
      " [ 77.90355 ]\n",
      " [ 73.7334  ]\n",
      " [223.79659 ]\n",
      " [158.22821 ]\n",
      " [162.36407 ]\n",
      " [178.82312 ]\n",
      " [217.89304 ]\n",
      " [117.41398 ]\n",
      " [145.19882 ]\n",
      " [ 74.6036  ]\n",
      " [ 55.214134]\n",
      " [155.15567 ]\n",
      " [180.26619 ]\n",
      " [217.61378 ]\n",
      " [356.18066 ]\n",
      " [198.74925 ]\n",
      " [249.71736 ]\n",
      " [ 59.454876]\n",
      " [ 83.23853 ]\n",
      " [102.90199 ]\n",
      " [175.48245 ]\n",
      " [ 50.98818 ]\n",
      " [164.77553 ]\n",
      " [237.51442 ]\n",
      " [166.30136 ]\n",
      " [318.53503 ]\n",
      " [181.01828 ]\n",
      " [298.5955  ]\n",
      " [165.96558 ]\n",
      " [138.69054 ]\n",
      " [ 89.57229 ]\n",
      " [ 96.467514]\n",
      " [138.12743 ]\n",
      " [177.3729  ]\n",
      " [281.23895 ]\n",
      " [ 56.318237]\n",
      " [128.49411 ]\n",
      " [139.55634 ]\n",
      " [216.95067 ]\n",
      " [274.69656 ]\n",
      " [ 74.15719 ]\n",
      " [118.61413 ]\n",
      " [117.00844 ]\n",
      " [ 91.27161 ]\n",
      " [ 96.010864]\n",
      " [134.41225 ]\n",
      " [247.10963 ]\n",
      " [ 50.066006]\n",
      " [247.80396 ]\n",
      " [256.59216 ]\n",
      " [184.42484 ]\n",
      " [159.32808 ]\n",
      " [160.14859 ]\n",
      " [145.905   ]\n",
      " [227.29327 ]\n",
      " [256.3153  ]\n",
      " [310.7151  ]\n",
      " [186.49849 ]\n",
      " [ 42.094112]\n",
      " [230.70424 ]\n",
      " [ 85.369026]\n",
      " [202.63751 ]\n",
      " [144.02666 ]]\n",
      "=================\n",
      "R2 :  0.1792335425244257\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.9794\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.1911\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.9161\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.9415\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.6546\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.0363\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.0399\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.7280\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.1471\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.6458\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.1512\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.9836\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.9927\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.8508\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.5763\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.7003\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.4030\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.0601\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.4342\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.5433\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.8888\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.9076\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.6305\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.4142\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.2317\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.8046\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.4304\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.1965\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.8984\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.7123\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.8066\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.5204\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.3357\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.3356\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.0348\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.6308\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.5688\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.5152\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.6740\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.7124\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.7651\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.1553\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.4569\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.3530\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.4683\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.5257\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.0099\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.9915\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.9717\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.7171\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.0248\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.0273\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.9388\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.4346\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.4964\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.3244\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.0554\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.7924\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.2798\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.5847\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.8211\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.8870\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.5860\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.4334\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.6443\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.8600\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.0194\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.9635\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.5122\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.7801\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.2841\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.6580\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.7137\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.0698\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.3440\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.0554\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.7171\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.5320\n",
      "Epoch 79/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 110us/step - loss: 31.5320\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 55.0318\n",
      "loss :  55.031768798828125\n",
      "5/5 [==============================] - 0s 997us/step\n",
      "=================\n",
      "[185. 150. 246. 184. 110. 202. 336.  69.  69.  87.  66. 164. 265. 198.\n",
      " 248. 171. 102. 182. 262. 233. 151. 275. 230.  39.  42. 122.  81.  31.\n",
      " 156. 161.  80. 215. 310. 163. 265.  84.  54. 137. 248.  72. 248.  59.\n",
      "  97.  61.  72. 296.  55.  75.  53. 173. 158.  96. 140. 186.  93. 123.\n",
      " 237. 138. 292.  78. 182. 127. 321. 109. 212.  45.  96. 109.  89.  96.\n",
      "  60.  51. 200. 265.  68.  91. 172. 115. 125.  53.  63. 259. 214. 195.\n",
      " 258. 235. 173.  59. 219. 170.  77.  49.  66. 144. 113. 233. 162. 121.\n",
      "  88. 302. 128.  52. 178.  90. 164. 135. 103. 200. 178. 261.  64.  59.\n",
      "  79.  47. 107.  39. 151. 104. 217. 232.  55. 245. 131.  64. 222. 249.\n",
      " 128. 293. 138. 273. 158. 168. 103.]\n",
      "[[137.23949 ]\n",
      " [ 97.09968 ]\n",
      " [275.5656  ]\n",
      " [163.62    ]\n",
      " [140.51622 ]\n",
      " [111.514336]\n",
      " [281.8541  ]\n",
      " [ 89.44193 ]\n",
      " [107.95403 ]\n",
      " [133.61177 ]\n",
      " [ 96.26147 ]\n",
      " [191.2013  ]\n",
      " [176.29433 ]\n",
      " [254.28453 ]\n",
      " [317.55008 ]\n",
      " [188.82434 ]\n",
      " [115.32637 ]\n",
      " [249.99414 ]\n",
      " [218.1909  ]\n",
      " [242.80467 ]\n",
      " [215.70316 ]\n",
      " [264.51968 ]\n",
      " [115.96207 ]\n",
      " [ 56.559868]\n",
      " [ 63.532227]\n",
      " [132.00778 ]\n",
      " [102.46668 ]\n",
      " [151.32825 ]\n",
      " [169.32071 ]\n",
      " [137.32353 ]\n",
      " [173.77068 ]\n",
      " [290.2448  ]\n",
      " [213.6205  ]\n",
      " [290.75864 ]\n",
      " [245.4942  ]\n",
      " [134.57216 ]\n",
      " [ 74.47045 ]\n",
      " [115.0157  ]\n",
      " [224.51352 ]\n",
      " [ 97.693756]\n",
      " [216.66028 ]\n",
      " [ 75.56434 ]\n",
      " [142.24377 ]\n",
      " [ 96.489586]\n",
      " [120.33989 ]\n",
      " [197.98517 ]\n",
      " [145.19463 ]\n",
      " [ 72.33513 ]\n",
      " [ 55.76078 ]\n",
      " [278.51715 ]\n",
      " [131.06657 ]\n",
      " [ 60.955864]\n",
      " [275.0637  ]\n",
      " [239.13441 ]\n",
      " [192.69312 ]\n",
      " [231.37141 ]\n",
      " [276.7619  ]\n",
      " [112.07199 ]\n",
      " [109.774895]\n",
      " [175.28555 ]\n",
      " [ 83.94491 ]\n",
      " [132.43149 ]\n",
      " [252.24954 ]\n",
      " [257.14014 ]\n",
      " [165.40504 ]\n",
      " [ 60.138634]\n",
      " [ 68.990005]\n",
      " [207.30925 ]\n",
      " [ 86.16225 ]\n",
      " [ 88.491844]\n",
      " [ 75.85143 ]\n",
      " [ 78.44737 ]\n",
      " [223.19154 ]\n",
      " [131.3145  ]\n",
      " [156.65671 ]\n",
      " [176.56757 ]\n",
      " [200.61874 ]\n",
      " [113.85624 ]\n",
      " [147.8865  ]\n",
      " [ 74.55655 ]\n",
      " [ 55.47946 ]\n",
      " [147.50143 ]\n",
      " [180.8376  ]\n",
      " [198.24089 ]\n",
      " [341.15665 ]\n",
      " [192.35359 ]\n",
      " [247.42226 ]\n",
      " [ 56.115387]\n",
      " [ 73.76713 ]\n",
      " [ 94.68327 ]\n",
      " [171.87508 ]\n",
      " [ 48.25979 ]\n",
      " [142.32922 ]\n",
      " [237.24994 ]\n",
      " [167.98409 ]\n",
      " [319.69272 ]\n",
      " [179.18507 ]\n",
      " [292.28174 ]\n",
      " [160.41805 ]\n",
      " [131.96075 ]\n",
      " [ 89.87092 ]\n",
      " [100.09199 ]\n",
      " [147.6878  ]\n",
      " [174.13835 ]\n",
      " [276.14093 ]\n",
      " [ 55.635513]\n",
      " [115.435234]\n",
      " [122.267654]\n",
      " [212.93776 ]\n",
      " [274.4218  ]\n",
      " [ 73.3196  ]\n",
      " [110.63942 ]\n",
      " [115.41186 ]\n",
      " [ 90.27424 ]\n",
      " [ 98.84254 ]\n",
      " [116.6237  ]\n",
      " [240.09937 ]\n",
      " [ 47.743607]\n",
      " [246.70203 ]\n",
      " [256.156   ]\n",
      " [168.11865 ]\n",
      " [149.0143  ]\n",
      " [151.33823 ]\n",
      " [170.28322 ]\n",
      " [224.82167 ]\n",
      " [247.33038 ]\n",
      " [292.41312 ]\n",
      " [175.26689 ]\n",
      " [ 43.157562]\n",
      " [224.65454 ]\n",
      " [ 87.2218  ]\n",
      " [198.77307 ]\n",
      " [107.44561 ]]\n",
      "=================\n",
      "R2 :  0.1852004860028429\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.6011\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.8365\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.6334\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.5753\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.2948\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.4795\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.8525\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.3630\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.9402\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.6732\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.7968\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.6062\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.3840\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.9046\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.0385\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.9238\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.5619\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.2888\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.1482\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.9747\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.6284\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.3864\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.2204\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.3444\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.3965\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.5576\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.0883\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.6490\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.3083\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.4617\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.2991\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.2928\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.1682\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 33.0442\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.6011\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.7033\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.9089\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.6346\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.7472\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.6283\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.9723\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.2852\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.7830\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.3952\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.3253\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.2670\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.9419\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.7448\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.4421\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.2421\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.5739\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.8224\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.6479\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.8494\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.2214\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.3501\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.9947\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.3965\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.9618\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.5735\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.0793\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.0467\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.7698\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.2942\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.7207\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.9797\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.6380\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.3928\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.1500\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.4357\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.2235\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.6084\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.8891\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.2405\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.5788\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.1870\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.4674\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.5230\n",
      "Epoch 79/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 359us/step - loss: 30.5230\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 51.5295\n",
      "loss :  51.52949142456055\n",
      "5/5 [==============================] - 0s 997us/step\n",
      "=================\n",
      "[185. 150. 246. 184. 110. 202. 336.  69.  69.  87.  66. 164. 265. 198.\n",
      " 248. 171. 102. 182. 262. 233. 151. 275. 230.  39.  42. 122.  81.  31.\n",
      " 156. 161.  80. 215. 310. 163. 265.  84.  54. 137. 248.  72. 248.  59.\n",
      "  97.  61.  72. 296.  55.  75.  53. 173. 158.  96. 140. 186.  93. 123.\n",
      " 237. 138. 292.  78. 182. 127. 321. 109. 212.  45.  96. 109.  89.  96.\n",
      "  60.  51. 200. 265.  68.  91. 172. 115. 125.  53.  63. 259. 214. 195.\n",
      " 258. 235. 173.  59. 219. 170.  77.  49.  66. 144. 113. 233. 162. 121.\n",
      "  88. 302. 128.  52. 178.  90. 164. 135. 103. 200. 178. 261.  64.  59.\n",
      "  79.  47. 107.  39. 151. 104. 217. 232.  55. 245. 131.  64. 222. 249.\n",
      " 128. 293. 138. 273. 158. 168. 103.]\n",
      "[[135.05891 ]\n",
      " [116.06829 ]\n",
      " [252.14742 ]\n",
      " [158.62073 ]\n",
      " [135.66985 ]\n",
      " [ 93.873665]\n",
      " [242.59926 ]\n",
      " [ 85.67587 ]\n",
      " [106.12813 ]\n",
      " [120.07417 ]\n",
      " [ 82.58967 ]\n",
      " [194.25108 ]\n",
      " [179.16933 ]\n",
      " [232.27608 ]\n",
      " [287.66556 ]\n",
      " [175.47006 ]\n",
      " [ 97.64191 ]\n",
      " [243.03384 ]\n",
      " [218.52457 ]\n",
      " [222.14238 ]\n",
      " [197.07959 ]\n",
      " [243.19237 ]\n",
      " [109.05396 ]\n",
      " [ 40.848286]\n",
      " [ 58.647755]\n",
      " [137.74057 ]\n",
      " [ 99.98775 ]\n",
      " [139.06528 ]\n",
      " [169.16806 ]\n",
      " [129.2865  ]\n",
      " [157.40027 ]\n",
      " [275.47202 ]\n",
      " [201.7865  ]\n",
      " [272.46    ]\n",
      " [226.45415 ]\n",
      " [132.24258 ]\n",
      " [ 63.454422]\n",
      " [110.867714]\n",
      " [223.28929 ]\n",
      " [ 92.17822 ]\n",
      " [207.47508 ]\n",
      " [ 67.17756 ]\n",
      " [127.08995 ]\n",
      " [100.50309 ]\n",
      " [118.648285]\n",
      " [184.53424 ]\n",
      " [152.86949 ]\n",
      " [ 63.254868]\n",
      " [ 48.78226 ]\n",
      " [255.00015 ]\n",
      " [137.51564 ]\n",
      " [ 63.374325]\n",
      " [268.79123 ]\n",
      " [228.96526 ]\n",
      " [177.15068 ]\n",
      " [209.35448 ]\n",
      " [267.1337  ]\n",
      " [106.39065 ]\n",
      " [100.56991 ]\n",
      " [172.0794  ]\n",
      " [ 86.380486]\n",
      " [128.37804 ]\n",
      " [237.76651 ]\n",
      " [235.96318 ]\n",
      " [159.2025  ]\n",
      " [ 43.661148]\n",
      " [ 66.33103 ]\n",
      " [185.03264 ]\n",
      " [ 76.59661 ]\n",
      " [ 82.04561 ]\n",
      " [ 79.23266 ]\n",
      " [ 70.790344]\n",
      " [212.43614 ]\n",
      " [119.81189 ]\n",
      " [137.2621  ]\n",
      " [179.8416  ]\n",
      " [187.23962 ]\n",
      " [101.10463 ]\n",
      " [140.0406  ]\n",
      " [ 70.71609 ]\n",
      " [ 51.61405 ]\n",
      " [147.18468 ]\n",
      " [171.88672 ]\n",
      " [180.94386 ]\n",
      " [314.1069  ]\n",
      " [177.77692 ]\n",
      " [237.03773 ]\n",
      " [ 50.226223]\n",
      " [ 75.480415]\n",
      " [ 89.26168 ]\n",
      " [170.04918 ]\n",
      " [ 51.553787]\n",
      " [126.45465 ]\n",
      " [233.77272 ]\n",
      " [165.04018 ]\n",
      " [301.01953 ]\n",
      " [173.14296 ]\n",
      " [276.79666 ]\n",
      " [120.22472 ]\n",
      " [135.98508 ]\n",
      " [ 85.190834]\n",
      " [ 89.15294 ]\n",
      " [154.74654 ]\n",
      " [166.76318 ]\n",
      " [261.59607 ]\n",
      " [ 42.716908]\n",
      " [118.99798 ]\n",
      " [119.0384  ]\n",
      " [199.76807 ]\n",
      " [243.52586 ]\n",
      " [ 66.45638 ]\n",
      " [112.19821 ]\n",
      " [112.12315 ]\n",
      " [ 82.08989 ]\n",
      " [ 96.47995 ]\n",
      " [ 97.02807 ]\n",
      " [227.03618 ]\n",
      " [ 45.53513 ]\n",
      " [234.6208  ]\n",
      " [238.75613 ]\n",
      " [170.67326 ]\n",
      " [136.29265 ]\n",
      " [136.18172 ]\n",
      " [126.09667 ]\n",
      " [215.97772 ]\n",
      " [229.89056 ]\n",
      " [270.82205 ]\n",
      " [156.76178 ]\n",
      " [ 40.792774]\n",
      " [207.61981 ]\n",
      " [ 81.02976 ]\n",
      " [182.53511 ]\n",
      " [ 90.710655]]\n",
      "=================\n",
      "R2 :  0.2598752309541802\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.1415\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.3765\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.2987\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.2153\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.1879\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.9395\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.8878\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.7868\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.3958\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.5520\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.5580\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.4833\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.3533\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.9142\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.0751\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.9311\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.0643\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 31.0481\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.8577\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.5576\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.1705\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.9179\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.0398\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.7702\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.7171\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.7781\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.8414\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.2406\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.0676\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.6199\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.0999\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.1582\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.4382\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.5356\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.9699\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.1564\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.3136\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.9324\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.0742\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.9367\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.3493\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.0837\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.9829\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.1352\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 27.8095\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.4012\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.0834\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.5121\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 30.7184\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.1710\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.3012\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 27.9988\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.2620\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.0963\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.9720\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.0334\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.5084\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.8146\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.4421\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.0446\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 27.8347\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.8126\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 27.7381\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 32.0744\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.3882\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.9718\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.7989\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.2242\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.2433\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.0208\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.2271\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.0904\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.0339\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.2997\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.6647\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.0120\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.3450\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.5624\n",
      "Epoch 79/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 120us/step - loss: 29.5624\n",
      "5/5 [==============================] - 0s 997us/step - loss: 52.4846\n",
      "loss :  52.484554290771484\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "=================\n",
      "[185. 150. 246. 184. 110. 202. 336.  69.  69.  87.  66. 164. 265. 198.\n",
      " 248. 171. 102. 182. 262. 233. 151. 275. 230.  39.  42. 122.  81.  31.\n",
      " 156. 161.  80. 215. 310. 163. 265.  84.  54. 137. 248.  72. 248.  59.\n",
      "  97.  61.  72. 296.  55.  75.  53. 173. 158.  96. 140. 186.  93. 123.\n",
      " 237. 138. 292.  78. 182. 127. 321. 109. 212.  45.  96. 109.  89.  96.\n",
      "  60.  51. 200. 265.  68.  91. 172. 115. 125.  53.  63. 259. 214. 195.\n",
      " 258. 235. 173.  59. 219. 170.  77.  49.  66. 144. 113. 233. 162. 121.\n",
      "  88. 302. 128.  52. 178.  90. 164. 135. 103. 200. 178. 261.  64.  59.\n",
      "  79.  47. 107.  39. 151. 104. 217. 232.  55. 245. 131.  64. 222. 249.\n",
      " 128. 293. 138. 273. 158. 168. 103.]\n",
      "[[152.55077 ]\n",
      " [102.93077 ]\n",
      " [251.22198 ]\n",
      " [159.0427  ]\n",
      " [136.946   ]\n",
      " [ 95.273994]\n",
      " [257.61694 ]\n",
      " [ 96.33681 ]\n",
      " [124.72289 ]\n",
      " [119.52272 ]\n",
      " [ 81.57657 ]\n",
      " [207.23134 ]\n",
      " [183.60155 ]\n",
      " [228.73662 ]\n",
      " [306.29385 ]\n",
      " [190.28233 ]\n",
      " [ 98.818565]\n",
      " [239.27841 ]\n",
      " [228.8464  ]\n",
      " [228.64452 ]\n",
      " [189.81456 ]\n",
      " [260.54504 ]\n",
      " [120.92196 ]\n",
      " [ 46.728626]\n",
      " [ 63.105457]\n",
      " [136.76215 ]\n",
      " [107.04008 ]\n",
      " [132.55367 ]\n",
      " [173.56232 ]\n",
      " [131.45352 ]\n",
      " [183.81601 ]\n",
      " [277.51007 ]\n",
      " [206.05672 ]\n",
      " [283.973   ]\n",
      " [240.13231 ]\n",
      " [145.14085 ]\n",
      " [ 79.72213 ]\n",
      " [108.49472 ]\n",
      " [246.97168 ]\n",
      " [ 93.59213 ]\n",
      " [222.4128  ]\n",
      " [ 64.291214]\n",
      " [130.12752 ]\n",
      " [101.30513 ]\n",
      " [128.85146 ]\n",
      " [189.03853 ]\n",
      " [166.02975 ]\n",
      " [ 65.024284]\n",
      " [ 57.484097]\n",
      " [255.33498 ]\n",
      " [139.61963 ]\n",
      " [ 63.322094]\n",
      " [268.35452 ]\n",
      " [250.32909 ]\n",
      " [167.35492 ]\n",
      " [219.25638 ]\n",
      " [281.0328  ]\n",
      " [118.57446 ]\n",
      " [ 94.52437 ]\n",
      " [176.33456 ]\n",
      " [ 89.62214 ]\n",
      " [135.3326  ]\n",
      " [254.64764 ]\n",
      " [227.0984  ]\n",
      " [165.81654 ]\n",
      " [ 44.29444 ]\n",
      " [ 66.826225]\n",
      " [181.42145 ]\n",
      " [ 97.41751 ]\n",
      " [ 97.96644 ]\n",
      " [ 81.1142  ]\n",
      " [ 82.38507 ]\n",
      " [223.10391 ]\n",
      " [116.36888 ]\n",
      " [118.853775]\n",
      " [189.60269 ]\n",
      " [181.01915 ]\n",
      " [ 93.203255]\n",
      " [142.21915 ]\n",
      " [ 67.044785]\n",
      " [ 48.27087 ]\n",
      " [156.8879  ]\n",
      " [167.63016 ]\n",
      " [180.13742 ]\n",
      " [318.3355  ]\n",
      " [185.33258 ]\n",
      " [241.2139  ]\n",
      " [ 46.236656]\n",
      " [ 58.676487]\n",
      " [ 76.75415 ]\n",
      " [177.56036 ]\n",
      " [ 51.722317]\n",
      " [135.33597 ]\n",
      " [227.52701 ]\n",
      " [176.4777  ]\n",
      " [304.71484 ]\n",
      " [165.92226 ]\n",
      " [286.1003  ]\n",
      " [129.56493 ]\n",
      " [138.07394 ]\n",
      " [ 93.16952 ]\n",
      " [ 93.34745 ]\n",
      " [172.45692 ]\n",
      " [174.13327 ]\n",
      " [266.15723 ]\n",
      " [ 48.81795 ]\n",
      " [117.81909 ]\n",
      " [118.437775]\n",
      " [204.8343  ]\n",
      " [248.23936 ]\n",
      " [ 69.01324 ]\n",
      " [113.21365 ]\n",
      " [118.77158 ]\n",
      " [ 90.99136 ]\n",
      " [106.44974 ]\n",
      " [ 89.05563 ]\n",
      " [236.37782 ]\n",
      " [ 50.382446]\n",
      " [249.58627 ]\n",
      " [253.11674 ]\n",
      " [175.45074 ]\n",
      " [156.00449 ]\n",
      " [141.26053 ]\n",
      " [108.508194]\n",
      " [237.99927 ]\n",
      " [232.26566 ]\n",
      " [279.24252 ]\n",
      " [161.3124  ]\n",
      " [ 43.369823]\n",
      " [187.83755 ]\n",
      " [ 87.893654]\n",
      " [193.89708 ]\n",
      " [ 91.10608 ]]\n",
      "=================\n",
      "R2 :  0.23575743710135688\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.3777\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.5789\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.5617\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.3275\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.6267\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.2530\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 26.8109\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.4142\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.8400\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.6986\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 31.1603\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.7262\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.9040\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.5864\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.6652\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.3244\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.7700\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 26.9496\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.2078\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 27.8651\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.3528\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.3114\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.6539\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.6347\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.1225\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.1710\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.0540\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.3749\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 26.9429\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.9332\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 27.5812\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.6616\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.3357\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.3913\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.8907\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.9615\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.2499\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 27.8021\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.1308\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.2611\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.9392\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.9028\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.6012\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.8279\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.7451\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 27.8741\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 27.3201\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.9015\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 27.5579\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 27.9065\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.7755\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.2062\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 26.8921\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.3214\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.0633\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.1147\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.7234\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.7346\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.9201\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.2218\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.6672\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.1373\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.7577\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.0068\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.1870\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.5985\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.1755\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.2782\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.2028\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.5495\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.1233\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.1690\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.8164\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 27.1836\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 27.9317\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.5774\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 27.5851\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.6169\n",
      "Epoch 79/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 130us/step - loss: 29.6169\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 54.7548\n",
      "loss :  54.75484848022461\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "=================\n",
      "[185. 150. 246. 184. 110. 202. 336.  69.  69.  87.  66. 164. 265. 198.\n",
      " 248. 171. 102. 182. 262. 233. 151. 275. 230.  39.  42. 122.  81.  31.\n",
      " 156. 161.  80. 215. 310. 163. 265.  84.  54. 137. 248.  72. 248.  59.\n",
      "  97.  61.  72. 296.  55.  75.  53. 173. 158.  96. 140. 186.  93. 123.\n",
      " 237. 138. 292.  78. 182. 127. 321. 109. 212.  45.  96. 109.  89.  96.\n",
      "  60.  51. 200. 265.  68.  91. 172. 115. 125.  53.  63. 259. 214. 195.\n",
      " 258. 235. 173.  59. 219. 170.  77.  49.  66. 144. 113. 233. 162. 121.\n",
      "  88. 302. 128.  52. 178.  90. 164. 135. 103. 200. 178. 261.  64.  59.\n",
      "  79.  47. 107.  39. 151. 104. 217. 232.  55. 245. 131.  64. 222. 249.\n",
      " 128. 293. 138. 273. 158. 168. 103.]\n",
      "[[159.49829 ]\n",
      " [ 83.47244 ]\n",
      " [254.87979 ]\n",
      " [164.70686 ]\n",
      " [135.77208 ]\n",
      " [ 95.38838 ]\n",
      " [263.448   ]\n",
      " [100.251465]\n",
      " [124.84907 ]\n",
      " [116.900055]\n",
      " [ 81.50493 ]\n",
      " [208.2485  ]\n",
      " [187.7412  ]\n",
      " [238.03587 ]\n",
      " [316.9178  ]\n",
      " [194.54727 ]\n",
      " [109.16325 ]\n",
      " [240.66432 ]\n",
      " [227.86803 ]\n",
      " [234.63857 ]\n",
      " [203.52757 ]\n",
      " [262.14673 ]\n",
      " [124.54585 ]\n",
      " [ 55.60779 ]\n",
      " [ 61.130527]\n",
      " [131.90611 ]\n",
      " [112.94978 ]\n",
      " [144.58035 ]\n",
      " [178.93977 ]\n",
      " [133.01645 ]\n",
      " [184.35463 ]\n",
      " [293.79755 ]\n",
      " [218.19978 ]\n",
      " [287.81604 ]\n",
      " [265.93878 ]\n",
      " [155.88907 ]\n",
      " [ 79.66693 ]\n",
      " [117.466644]\n",
      " [240.71709 ]\n",
      " [ 94.32238 ]\n",
      " [226.26218 ]\n",
      " [ 65.10492 ]\n",
      " [150.45523 ]\n",
      " [100.62555 ]\n",
      " [135.90175 ]\n",
      " [191.18248 ]\n",
      " [194.0129  ]\n",
      " [ 63.54866 ]\n",
      " [ 59.32366 ]\n",
      " [256.02368 ]\n",
      " [152.87431 ]\n",
      " [ 60.885082]\n",
      " [275.40936 ]\n",
      " [254.64482 ]\n",
      " [185.23584 ]\n",
      " [223.12976 ]\n",
      " [281.44562 ]\n",
      " [121.261894]\n",
      " [ 93.620865]\n",
      " [182.12877 ]\n",
      " [ 94.114525]\n",
      " [137.12143 ]\n",
      " [254.94077 ]\n",
      " [226.96985 ]\n",
      " [163.87155 ]\n",
      " [ 46.859673]\n",
      " [ 72.92354 ]\n",
      " [166.83826 ]\n",
      " [ 96.21926 ]\n",
      " [115.541084]\n",
      " [ 83.94828 ]\n",
      " [ 85.402954]\n",
      " [238.40924 ]\n",
      " [111.36442 ]\n",
      " [128.71149 ]\n",
      " [193.57881 ]\n",
      " [189.36737 ]\n",
      " [101.01502 ]\n",
      " [148.24641 ]\n",
      " [ 63.877907]\n",
      " [ 47.83978 ]\n",
      " [145.80377 ]\n",
      " [175.34991 ]\n",
      " [184.46341 ]\n",
      " [334.2917  ]\n",
      " [178.364   ]\n",
      " [236.56567 ]\n",
      " [ 46.772694]\n",
      " [ 57.030773]\n",
      " [ 71.22689 ]\n",
      " [184.66473 ]\n",
      " [ 53.57914 ]\n",
      " [147.67006 ]\n",
      " [236.65175 ]\n",
      " [188.85133 ]\n",
      " [302.00867 ]\n",
      " [193.95714 ]\n",
      " [292.63556 ]\n",
      " [137.02242 ]\n",
      " [142.49669 ]\n",
      " [ 99.84059 ]\n",
      " [ 89.56849 ]\n",
      " [142.58913 ]\n",
      " [176.21967 ]\n",
      " [278.93195 ]\n",
      " [ 48.127975]\n",
      " [122.24206 ]\n",
      " [119.03538 ]\n",
      " [200.19849 ]\n",
      " [230.82826 ]\n",
      " [ 78.29386 ]\n",
      " [109.74994 ]\n",
      " [136.28468 ]\n",
      " [101.75994 ]\n",
      " [106.4015  ]\n",
      " [ 77.413216]\n",
      " [241.03084 ]\n",
      " [ 51.73615 ]\n",
      " [252.30768 ]\n",
      " [254.40245 ]\n",
      " [181.36668 ]\n",
      " [164.17807 ]\n",
      " [139.12006 ]\n",
      " [ 75.3638  ]\n",
      " [239.39026 ]\n",
      " [234.75615 ]\n",
      " [283.40955 ]\n",
      " [169.7012  ]\n",
      " [ 45.405   ]\n",
      " [196.43929 ]\n",
      " [ 90.48679 ]\n",
      " [194.06071 ]\n",
      " [ 90.99737 ]]\n",
      "=================\n",
      "R2 :  0.18184349228650343\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.8342\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.8762\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.4070\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.8208\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.0641\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.0621\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.2456\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.0149\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.6516\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.9461\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.3024\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.4266\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.1639\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.6358\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.4189\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 27.5600\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.2255\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 27.0165\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.2040\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 27.8233\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.1731\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.8617\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.0576\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.4265\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.1261\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.6543\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.3382\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.0972\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.9626\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.7322\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.7212\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.4101\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.8105\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.7832\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 27.9408\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.8903\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.0545\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.8800\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 27.6500\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.0317\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.2072\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.5377\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.9369\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 26.7502\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.0988\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.6772\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.4942\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.4672\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 27.8699\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.6641\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 27.6347\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.9552\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 27.0796\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.3342\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.0710\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 26.7837\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.5043\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.0012\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.3853\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.1228\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.7622\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.9764\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.1108\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.8828\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.9220\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.9662\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 27.2596\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.3934\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 27.3933\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 27.3999\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 27.0949\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 26.6769\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.9166\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.2042\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.1535\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 26.9042\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.8599\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.9451\n",
      "Epoch 79/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 120us/step - loss: 28.9451\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 52.9535\n",
      "loss :  52.953487396240234\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "=================\n",
      "[185. 150. 246. 184. 110. 202. 336.  69.  69.  87.  66. 164. 265. 198.\n",
      " 248. 171. 102. 182. 262. 233. 151. 275. 230.  39.  42. 122.  81.  31.\n",
      " 156. 161.  80. 215. 310. 163. 265.  84.  54. 137. 248.  72. 248.  59.\n",
      "  97.  61.  72. 296.  55.  75.  53. 173. 158.  96. 140. 186.  93. 123.\n",
      " 237. 138. 292.  78. 182. 127. 321. 109. 212.  45.  96. 109.  89.  96.\n",
      "  60.  51. 200. 265.  68.  91. 172. 115. 125.  53.  63. 259. 214. 195.\n",
      " 258. 235. 173.  59. 219. 170.  77.  49.  66. 144. 113. 233. 162. 121.\n",
      "  88. 302. 128.  52. 178.  90. 164. 135. 103. 200. 178. 261.  64.  59.\n",
      "  79.  47. 107.  39. 151. 104. 217. 232.  55. 245. 131.  64. 222. 249.\n",
      " 128. 293. 138. 273. 158. 168. 103.]\n",
      "[[147.99538 ]\n",
      " [109.77254 ]\n",
      " [236.552   ]\n",
      " [164.66534 ]\n",
      " [133.52734 ]\n",
      " [ 88.8632  ]\n",
      " [265.10052 ]\n",
      " [ 99.66928 ]\n",
      " [126.016914]\n",
      " [111.16169 ]\n",
      " [ 77.715   ]\n",
      " [203.63408 ]\n",
      " [184.11632 ]\n",
      " [235.1871  ]\n",
      " [305.95123 ]\n",
      " [198.27045 ]\n",
      " [129.70094 ]\n",
      " [214.02922 ]\n",
      " [223.59358 ]\n",
      " [237.40735 ]\n",
      " [194.88058 ]\n",
      " [264.10376 ]\n",
      " [117.69008 ]\n",
      " [ 44.758327]\n",
      " [ 56.292908]\n",
      " [128.73558 ]\n",
      " [106.52064 ]\n",
      " [124.22315 ]\n",
      " [170.17902 ]\n",
      " [117.21945 ]\n",
      " [184.52397 ]\n",
      " [289.44363 ]\n",
      " [213.35005 ]\n",
      " [277.77118 ]\n",
      " [229.71213 ]\n",
      " [153.5741  ]\n",
      " [ 71.877686]\n",
      " [117.75175 ]\n",
      " [230.20486 ]\n",
      " [ 91.85834 ]\n",
      " [202.2461  ]\n",
      " [ 63.120274]\n",
      " [144.52882 ]\n",
      " [103.30319 ]\n",
      " [135.665   ]\n",
      " [178.1258  ]\n",
      " [196.10686 ]\n",
      " [ 61.310425]\n",
      " [ 53.130245]\n",
      " [257.71698 ]\n",
      " [158.8883  ]\n",
      " [ 59.266502]\n",
      " [255.36688 ]\n",
      " [254.4135  ]\n",
      " [176.94753 ]\n",
      " [225.97243 ]\n",
      " [258.6727  ]\n",
      " [122.00142 ]\n",
      " [ 89.38945 ]\n",
      " [176.50761 ]\n",
      " [ 91.86418 ]\n",
      " [122.80351 ]\n",
      " [260.23898 ]\n",
      " [229.80048 ]\n",
      " [161.01764 ]\n",
      " [ 45.725147]\n",
      " [ 76.158585]\n",
      " [158.62416 ]\n",
      " [ 99.37961 ]\n",
      " [110.26915 ]\n",
      " [ 81.32819 ]\n",
      " [ 81.87524 ]\n",
      " [233.46628 ]\n",
      " [106.59611 ]\n",
      " [120.11992 ]\n",
      " [191.07996 ]\n",
      " [192.4123  ]\n",
      " [ 94.56505 ]\n",
      " [127.34679 ]\n",
      " [ 66.26651 ]\n",
      " [ 47.795532]\n",
      " [140.15884 ]\n",
      " [181.71713 ]\n",
      " [181.12512 ]\n",
      " [327.30936 ]\n",
      " [172.06451 ]\n",
      " [226.10378 ]\n",
      " [ 48.0933  ]\n",
      " [ 55.147858]\n",
      " [ 76.25699 ]\n",
      " [180.72887 ]\n",
      " [ 50.535027]\n",
      " [123.54672 ]\n",
      " [221.78249 ]\n",
      " [185.7273  ]\n",
      " [304.98453 ]\n",
      " [207.64464 ]\n",
      " [288.30374 ]\n",
      " [110.52725 ]\n",
      " [138.36066 ]\n",
      " [ 90.94876 ]\n",
      " [ 72.13345 ]\n",
      " [170.34225 ]\n",
      " [160.80098 ]\n",
      " [276.7515  ]\n",
      " [ 46.225132]\n",
      " [120.01072 ]\n",
      " [120.82036 ]\n",
      " [185.27475 ]\n",
      " [210.97342 ]\n",
      " [ 73.73037 ]\n",
      " [111.82333 ]\n",
      " [127.368546]\n",
      " [ 96.79856 ]\n",
      " [ 95.52696 ]\n",
      " [ 69.444626]\n",
      " [243.07646 ]\n",
      " [ 50.030876]\n",
      " [246.44191 ]\n",
      " [244.74994 ]\n",
      " [176.56522 ]\n",
      " [150.34827 ]\n",
      " [133.67207 ]\n",
      " [ 65.80382 ]\n",
      " [240.28784 ]\n",
      " [239.28159 ]\n",
      " [282.19287 ]\n",
      " [166.0536  ]\n",
      " [ 44.59982 ]\n",
      " [172.61707 ]\n",
      " [ 85.16678 ]\n",
      " [187.98755 ]\n",
      " [ 82.30847 ]]\n",
      "=================\n",
      "R2 :  0.20656823258416013\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 26.7051\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 27.9146\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.6260\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.1464\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.3646\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.2172\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.5595\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.6823\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.3223\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 27.1790\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.8903\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.8600\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.4026\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 26.1498\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.1280\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.5126\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.0924\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.7654\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 27.2996\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.9732\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.3805\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.5457\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 27.4566\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.4503\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.3846\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.7172\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.6503\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 26.4342\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.1993\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 26.1353\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 27.7350\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.7859\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 26.0908\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.8764\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 27.7123\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 27.6352\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 27.3066\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.6074\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 26.5594\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.4883\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.0734\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.3626\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.8569\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 27.5292\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.0892\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.5411\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.8448\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.9304\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.0418\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.6774\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.4302\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.0000\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.5625\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 27.4185\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 27.1993\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.3658\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.1011\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.5781\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.0515\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.4707\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 27.2701\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.4001\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 30.3486\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.2869\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 27.0815\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 27.5281\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.4167\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.9523\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.3682\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.0487\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.1036\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 27.0317\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.0214\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.8444\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.9166\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.5822\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.2720\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.0403\n",
      "Epoch 79/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 120us/step - loss: 28.0403\n",
      "5/5 [==============================] - 0s 997us/step - loss: 50.2430\n",
      "loss :  50.242984771728516\n",
      "5/5 [==============================] - 0s 997us/step\n",
      "=================\n",
      "[185. 150. 246. 184. 110. 202. 336.  69.  69.  87.  66. 164. 265. 198.\n",
      " 248. 171. 102. 182. 262. 233. 151. 275. 230.  39.  42. 122.  81.  31.\n",
      " 156. 161.  80. 215. 310. 163. 265.  84.  54. 137. 248.  72. 248.  59.\n",
      "  97.  61.  72. 296.  55.  75.  53. 173. 158.  96. 140. 186.  93. 123.\n",
      " 237. 138. 292.  78. 182. 127. 321. 109. 212.  45.  96. 109.  89.  96.\n",
      "  60.  51. 200. 265.  68.  91. 172. 115. 125.  53.  63. 259. 214. 195.\n",
      " 258. 235. 173.  59. 219. 170.  77.  49.  66. 144. 113. 233. 162. 121.\n",
      "  88. 302. 128.  52. 178.  90. 164. 135. 103. 200. 178. 261.  64.  59.\n",
      "  79.  47. 107.  39. 151. 104. 217. 232.  55. 245. 131.  64. 222. 249.\n",
      " 128. 293. 138. 273. 158. 168. 103.]\n",
      "[[137.09389 ]\n",
      " [106.43774 ]\n",
      " [212.79114 ]\n",
      " [156.048   ]\n",
      " [126.561455]\n",
      " [ 81.117775]\n",
      " [229.84636 ]\n",
      " [ 94.718864]\n",
      " [118.32732 ]\n",
      " [106.33867 ]\n",
      " [ 79.103806]\n",
      " [191.04663 ]\n",
      " [177.94048 ]\n",
      " [213.3456  ]\n",
      " [284.9344  ]\n",
      " [162.49057 ]\n",
      " [ 81.51296 ]\n",
      " [199.92503 ]\n",
      " [209.49779 ]\n",
      " [200.32742 ]\n",
      " [170.0084  ]\n",
      " [233.7503  ]\n",
      " [108.5915  ]\n",
      " [ 43.037518]\n",
      " [ 55.41155 ]\n",
      " [117.82619 ]\n",
      " [ 98.33743 ]\n",
      " [ 98.24558 ]\n",
      " [155.50398 ]\n",
      " [135.69122 ]\n",
      " [176.35376 ]\n",
      " [235.22006 ]\n",
      " [201.34479 ]\n",
      " [261.294   ]\n",
      " [224.61491 ]\n",
      " [142.44632 ]\n",
      " [ 71.81009 ]\n",
      " [ 96.33396 ]\n",
      " [220.8017  ]\n",
      " [ 78.3111  ]\n",
      " [193.38992 ]\n",
      " [ 50.798836]\n",
      " [129.49825 ]\n",
      " [101.314476]\n",
      " [128.36435 ]\n",
      " [165.22107 ]\n",
      " [152.96913 ]\n",
      " [ 61.549915]\n",
      " [ 51.86907 ]\n",
      " [223.31186 ]\n",
      " [123.977715]\n",
      " [ 53.849144]\n",
      " [199.82317 ]\n",
      " [221.71162 ]\n",
      " [158.14331 ]\n",
      " [194.66727 ]\n",
      " [219.79054 ]\n",
      " [117.86378 ]\n",
      " [ 76.819496]\n",
      " [168.92548 ]\n",
      " [ 84.33647 ]\n",
      " [113.870384]\n",
      " [234.00957 ]\n",
      " [178.95334 ]\n",
      " [154.50644 ]\n",
      " [ 42.698814]\n",
      " [ 72.77386 ]\n",
      " [144.19313 ]\n",
      " [ 98.23595 ]\n",
      " [100.33751 ]\n",
      " [ 74.272865]\n",
      " [ 81.63505 ]\n",
      " [197.5286  ]\n",
      " [ 96.87957 ]\n",
      " [109.91096 ]\n",
      " [180.83989 ]\n",
      " [159.3826  ]\n",
      " [ 88.002464]\n",
      " [121.737526]\n",
      " [ 54.52783 ]\n",
      " [ 43.133244]\n",
      " [129.59677 ]\n",
      " [135.03433 ]\n",
      " [150.80305 ]\n",
      " [306.90387 ]\n",
      " [154.19272 ]\n",
      " [195.21492 ]\n",
      " [ 44.161827]\n",
      " [ 55.243443]\n",
      " [ 66.045044]\n",
      " [178.19502 ]\n",
      " [ 45.597855]\n",
      " [136.39294 ]\n",
      " [173.45538 ]\n",
      " [172.3857  ]\n",
      " [267.1022  ]\n",
      " [179.51012 ]\n",
      " [227.36691 ]\n",
      " [135.66309 ]\n",
      " [132.8462  ]\n",
      " [ 74.94513 ]\n",
      " [ 84.46644 ]\n",
      " [174.96889 ]\n",
      " [157.67114 ]\n",
      " [240.30853 ]\n",
      " [ 44.95693 ]\n",
      " [115.54585 ]\n",
      " [112.62649 ]\n",
      " [170.08116 ]\n",
      " [185.55487 ]\n",
      " [ 72.46287 ]\n",
      " [104.775085]\n",
      " [126.747604]\n",
      " [ 92.351166]\n",
      " [ 98.90886 ]\n",
      " [ 70.923874]\n",
      " [214.43906 ]\n",
      " [ 48.201588]\n",
      " [230.97752 ]\n",
      " [220.16603 ]\n",
      " [168.48624 ]\n",
      " [163.15025 ]\n",
      " [122.41895 ]\n",
      " [154.72769 ]\n",
      " [210.7511  ]\n",
      " [209.15405 ]\n",
      " [256.63452 ]\n",
      " [136.86484 ]\n",
      " [ 42.536648]\n",
      " [160.69266 ]\n",
      " [ 80.148735]\n",
      " [170.31387 ]\n",
      " [ 81.917786]]\n",
      "=================\n",
      "R2 :  0.27205763304401176\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.0488\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.5918\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.8575\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.6394\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.3608\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.1072\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 25.6328\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.2119\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.4085\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.0329\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.0853\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 26.8337\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.6009\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.0349\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.0336\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.2209\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 25.9316\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 27.3724\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 25.0456\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 29.3911\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 27.0310\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 26.6447\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 27.5339\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 27.0241\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 27.8387\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 26.1097\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.4800\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 26.3254\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 27.6627\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 27.9736\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.3268\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.7514\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 26.8110\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 25.7736\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 26.8181\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.9171\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.5297\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.4883\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 27.2836\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.0069\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.7136\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.4022\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.5654\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 27.3589\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.1749\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.2994\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.8115\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.6756\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 27.0055\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.7115\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 26.2456\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.4863\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 26.3933\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 26.9958\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 26.3397\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 26.0529\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 27.0861\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 26.7689\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 26.2052\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 26.3406\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 26.2422\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.5755\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.2957\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.1722\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 27.1390\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 26.7263\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 26.6151\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 26.1022\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 26.2436\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 27.0531\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 25.7365\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 25.4970\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 25.5681\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 27.5952\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.4260\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.8698\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.8460\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.1706\n",
      "Epoch 79/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 110us/step - loss: 25.1706\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 52.7794\n",
      "loss :  52.77939987182617\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "=================\n",
      "[185. 150. 246. 184. 110. 202. 336.  69.  69.  87.  66. 164. 265. 198.\n",
      " 248. 171. 102. 182. 262. 233. 151. 275. 230.  39.  42. 122.  81.  31.\n",
      " 156. 161.  80. 215. 310. 163. 265.  84.  54. 137. 248.  72. 248.  59.\n",
      "  97.  61.  72. 296.  55.  75.  53. 173. 158.  96. 140. 186.  93. 123.\n",
      " 237. 138. 292.  78. 182. 127. 321. 109. 212.  45.  96. 109.  89.  96.\n",
      "  60.  51. 200. 265.  68.  91. 172. 115. 125.  53.  63. 259. 214. 195.\n",
      " 258. 235. 173.  59. 219. 170.  77.  49.  66. 144. 113. 233. 162. 121.\n",
      "  88. 302. 128.  52. 178.  90. 164. 135. 103. 200. 178. 261.  64.  59.\n",
      "  79.  47. 107.  39. 151. 104. 217. 232.  55. 245. 131.  64. 222. 249.\n",
      " 128. 293. 138. 273. 158. 168. 103.]\n",
      "[[166.62105 ]\n",
      " [145.89503 ]\n",
      " [235.24457 ]\n",
      " [167.18053 ]\n",
      " [145.67433 ]\n",
      " [ 75.63653 ]\n",
      " [246.79263 ]\n",
      " [ 94.16987 ]\n",
      " [128.25937 ]\n",
      " [122.61876 ]\n",
      " [ 78.26488 ]\n",
      " [212.37479 ]\n",
      " [194.66066 ]\n",
      " [248.10197 ]\n",
      " [296.31827 ]\n",
      " [199.64026 ]\n",
      " [139.51836 ]\n",
      " [212.52782 ]\n",
      " [241.20314 ]\n",
      " [239.40839 ]\n",
      " [196.72302 ]\n",
      " [265.82803 ]\n",
      " [120.871315]\n",
      " [ 43.78484 ]\n",
      " [ 58.610184]\n",
      " [136.8696  ]\n",
      " [109.02419 ]\n",
      " [107.84341 ]\n",
      " [165.7459  ]\n",
      " [146.27478 ]\n",
      " [172.7133  ]\n",
      " [306.81705 ]\n",
      " [213.8373  ]\n",
      " [270.81415 ]\n",
      " [246.13869 ]\n",
      " [156.59898 ]\n",
      " [ 78.396835]\n",
      " [103.33512 ]\n",
      " [242.63036 ]\n",
      " [ 81.56645 ]\n",
      " [208.90076 ]\n",
      " [ 53.87136 ]\n",
      " [146.27911 ]\n",
      " [103.33361 ]\n",
      " [144.47736 ]\n",
      " [160.4236  ]\n",
      " [196.74622 ]\n",
      " [ 61.468544]\n",
      " [ 54.511826]\n",
      " [244.74112 ]\n",
      " [155.36139 ]\n",
      " [ 55.079132]\n",
      " [215.01276 ]\n",
      " [253.40756 ]\n",
      " [183.31865 ]\n",
      " [226.75836 ]\n",
      " [256.0302  ]\n",
      " [126.82652 ]\n",
      " [ 84.251755]\n",
      " [178.786   ]\n",
      " [ 85.145325]\n",
      " [118.66705 ]\n",
      " [253.35037 ]\n",
      " [204.51651 ]\n",
      " [160.71005 ]\n",
      " [ 43.8878  ]\n",
      " [ 86.770035]\n",
      " [153.97688 ]\n",
      " [102.8306  ]\n",
      " [107.004005]\n",
      " [ 74.60938 ]\n",
      " [ 85.99497 ]\n",
      " [209.94557 ]\n",
      " [104.547165]\n",
      " [122.32065 ]\n",
      " [201.49376 ]\n",
      " [184.56178 ]\n",
      " [ 95.74866 ]\n",
      " [124.15191 ]\n",
      " [ 62.58107 ]\n",
      " [ 43.246628]\n",
      " [134.657   ]\n",
      " [171.4965  ]\n",
      " [176.14717 ]\n",
      " [358.01917 ]\n",
      " [152.85962 ]\n",
      " [208.1809  ]\n",
      " [ 47.046688]\n",
      " [ 57.70126 ]\n",
      " [ 91.64092 ]\n",
      " [204.60442 ]\n",
      " [ 45.2157  ]\n",
      " [144.24542 ]\n",
      " [188.69193 ]\n",
      " [181.82086 ]\n",
      " [281.42947 ]\n",
      " [231.83891 ]\n",
      " [250.83968 ]\n",
      " [134.14052 ]\n",
      " [135.53172 ]\n",
      " [ 83.31949 ]\n",
      " [ 95.57288 ]\n",
      " [192.77023 ]\n",
      " [169.49957 ]\n",
      " [273.94266 ]\n",
      " [ 46.641796]\n",
      " [117.522484]\n",
      " [118.66336 ]\n",
      " [187.28676 ]\n",
      " [212.87317 ]\n",
      " [ 73.23743 ]\n",
      " [111.21916 ]\n",
      " [149.74287 ]\n",
      " [ 98.14994 ]\n",
      " [100.52961 ]\n",
      " [ 63.514385]\n",
      " [252.2676  ]\n",
      " [ 49.5617  ]\n",
      " [234.80032 ]\n",
      " [226.30511 ]\n",
      " [176.75638 ]\n",
      " [183.16103 ]\n",
      " [125.368675]\n",
      " [149.16096 ]\n",
      " [236.80377 ]\n",
      " [236.77544 ]\n",
      " [285.8923  ]\n",
      " [162.84596 ]\n",
      " [ 42.79659 ]\n",
      " [186.22261 ]\n",
      " [ 91.44459 ]\n",
      " [169.33214 ]\n",
      " [ 83.88232 ]]\n",
      "=================\n",
      "R2 :  0.20335180460241387\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.5993\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.5211\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.4027\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.9522\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.9355\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.4595\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.1667\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.8582\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.6336\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.6065\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.8659\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.0788\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 27.2003\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.0219\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.1020\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.9559\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.1009\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 25.5968\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.2372\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.7179\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.4000\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 25.2425\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.0845\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.2943\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.6488\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.5123\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 25.9701\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.4829\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.9504\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.0458\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.0012\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 27.2437\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 25.8061\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 28.3276\n",
      "Epoch 35/100\n",
      " 78/100 [======================>.......] - ETA: 0s - loss: 24.7260"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11492\\4080315373.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# 4. 모델 컴파일\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"loss : \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\bitcamp\\anaconda3\\envs\\tf27\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\bitcamp\\anaconda3\\envs\\tf27\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1562\u001b[0m                         ):\n\u001b[0;32m   1563\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1564\u001b[1;33m                             \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1565\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1566\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\bitcamp\\anaconda3\\envs\\tf27\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\bitcamp\\anaconda3\\envs\\tf27\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\bitcamp\\anaconda3\\envs\\tf27\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\bitcamp\\anaconda3\\envs\\tf27\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2494\u001b[0m       (graph_function,\n\u001b[1;32m-> 2495\u001b[1;33m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[0;32m   2496\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m   2497\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
      "\u001b[1;32mc:\\Users\\bitcamp\\anaconda3\\envs\\tf27\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2723\u001b[0m     \u001b[1;31m# only active captures should be saved.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2724\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_signature\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2725\u001b[1;33m       func_cache_key, _ = function_context.make_cache_key(\n\u001b[0m\u001b[0;32m   2726\u001b[0m           (args, kwargs), captures)\n\u001b[0;32m   2727\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\bitcamp\\anaconda3\\envs\\tf27\\lib\\site-packages\\tensorflow\\python\\eager\\function_context.py\u001b[0m in \u001b[0;36mmake_cache_key\u001b[1;34m(args, captures)\u001b[0m\n\u001b[0;32m    129\u001b[0m     \u001b[0mcaptures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m   \u001b[0msignature_context\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrace_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInternalTracingContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m   args_signature = trace_type.from_object(\n\u001b[0m\u001b[0;32m    132\u001b[0m       args, signature_context)\n\u001b[0;32m    133\u001b[0m   captures_dict_tracetype = trace_type.from_object(\n",
      "\u001b[1;32mc:\\Users\\bitcamp\\anaconda3\\envs\\tf27\\lib\\site-packages\\tensorflow\\core\\function\\trace_type\\trace_type_builder.py\u001b[0m in \u001b[0;36mfrom_object\u001b[1;34m(obj, context)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_namedtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m       \u001b[0mnamed_tuple_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m       return default_types.NamedTuple.from_type_and_attributes(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "model.compile(loss=\"mae\",optimizer=\"adam\")\n",
    "from sklearn.metrics import r2_score\n",
    "# 4. 모델 컴파일\n",
    "while (True):\n",
    "    model.fit(x_train,y_train,epochs=100,batch_size=4,steps_per_epoch=100)\n",
    "    loss = model.evaluate(x_test,y_test)\n",
    "    print(\"loss : \",loss)\n",
    "    y_predict =model.predict(x_test)\n",
    "    print(\"=================\")\n",
    "    print(y_test)\n",
    "    print(y_predict)\n",
    "    print(\"=================\")\n",
    "    r2 = r2_score(y_test,y_predict)\n",
    "    print(\"R2 : \",r2)\n",
    "    f = open(\"C:\\study\\keras\\diagetslog.txt\",'a')\n",
    "    f.write(str(r2)+\"\\n\") \n",
    "    if r2 >= 0.62 :\n",
    "        model.save(\"diabets.h5\")\n",
    "        f.cloes()\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf27",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b47fb4e6c68d4941015efb0bbf71549277582fe8531338196fc3c7fa71b6aab8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
