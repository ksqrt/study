{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_boston\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(506, 13)\n",
            "(506,)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\bitcamp\\anaconda3\\envs\\tf274gpu\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
            "\n",
            "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
            "    the documentation of this function for further details.\n",
            "\n",
            "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
            "    dataset unless the purpose of the code is to study and educate about\n",
            "    ethical issues in data science and machine learning.\n",
            "\n",
            "    In this special case, you can fetch the dataset from the original\n",
            "    source::\n",
            "\n",
            "        import pandas as pd\n",
            "        import numpy as np\n",
            "\n",
            "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
            "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
            "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
            "        target = raw_df.values[1::2, 2]\n",
            "\n",
            "    Alternative datasets include the California housing dataset (i.e.\n",
            "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
            "    dataset. You can load the datasets as follows::\n",
            "\n",
            "        from sklearn.datasets import fetch_california_housing\n",
            "        housing = fetch_california_housing()\n",
            "\n",
            "    for the California housing dataset and::\n",
            "\n",
            "        from sklearn.datasets import fetch_openml\n",
            "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
            "\n",
            "    for the Ames housing dataset.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "# 1. 데이터 \n",
        "datasets = load_boston()\n",
        "\n",
        "x = datasets.data\n",
        "y = datasets.target\n",
        "\n",
        "print(x.shape)\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2. train ,test 분리\n",
        "\n",
        "x_train, x_test, y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 10)                140       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                110       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                110       \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                110       \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 10)                110       \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                110       \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 10)                110       \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 811\n",
            "Trainable params: 811\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# 3. 모델구성\n",
        "\n",
        "model = Sequential(\n",
        "    [\n",
        "    # input_dim 은 행과 열만 앞으로 다차원이 나오면 input_shape 로 합니다\n",
        "    # ex (100,10,5 ) 의 input_shape = (10,5)\n",
        "    Dense(10,input_shape=(13,),activation=\"relu\"),\n",
        "    Dense(10 ,activation=\"relu\"),\n",
        "    Dense(10 ,activation=\"relu\"),\n",
        "    Dense(10 ,activation=\"relu\"),\n",
        "    Dense(10 ,activation=\"relu\"),\n",
        "    Dense(10 ,activation=\"relu\"),\n",
        "    Dense(10 ,activation=\"relu\"),\n",
        "    Dense(1)\n",
        "    ]\n",
        ")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "108/108 [==============================] - 2s 6ms/step - loss: 111.8069 - val_loss: 94.7624\n",
            "Epoch 2/100\n",
            "108/108 [==============================] - 0s 4ms/step - loss: 80.8864 - val_loss: 88.0932\n",
            "Epoch 3/100\n",
            "108/108 [==============================] - 0s 4ms/step - loss: 72.8865 - val_loss: 77.2611\n",
            "Epoch 4/100\n",
            "108/108 [==============================] - 0s 4ms/step - loss: 71.6071 - val_loss: 77.4752\n",
            "Epoch 5/100\n",
            "108/108 [==============================] - 0s 4ms/step - loss: 66.7383 - val_loss: 74.0717\n",
            "Epoch 6/100\n",
            "108/108 [==============================] - 0s 4ms/step - loss: 63.3723 - val_loss: 72.0417\n",
            "Epoch 7/100\n",
            "108/108 [==============================] - 0s 4ms/step - loss: 60.6148 - val_loss: 65.8584\n",
            "Epoch 8/100\n",
            "108/108 [==============================] - 0s 3ms/step - loss: 61.9850 - val_loss: 73.4109\n",
            "Epoch 9/100\n",
            "108/108 [==============================] - 0s 4ms/step - loss: 62.2812 - val_loss: 67.1430\n",
            "Epoch 10/100\n",
            "108/108 [==============================] - 0s 4ms/step - loss: 58.2615 - val_loss: 74.1523\n",
            "Epoch 11/100\n",
            "108/108 [==============================] - 0s 4ms/step - loss: 59.8402 - val_loss: 62.8436\n",
            "Epoch 12/100\n",
            "108/108 [==============================] - 0s 4ms/step - loss: 55.3696 - val_loss: 65.2789\n",
            "Epoch 13/100\n",
            "108/108 [==============================] - 0s 4ms/step - loss: 54.6333 - val_loss: 58.2352\n",
            "Epoch 14/100\n",
            "108/108 [==============================] - 0s 4ms/step - loss: 54.7421 - val_loss: 56.3232\n",
            "Epoch 15/100\n",
            "108/108 [==============================] - 0s 4ms/step - loss: 52.2157 - val_loss: 55.7298\n",
            "Epoch 16/100\n",
            "108/108 [==============================] - 0s 4ms/step - loss: 53.3472 - val_loss: 54.4380\n",
            "Epoch 17/100\n",
            "108/108 [==============================] - 0s 4ms/step - loss: 49.8125 - val_loss: 56.5540\n",
            "Epoch 18/100\n",
            "108/108 [==============================] - 0s 4ms/step - loss: 50.4668 - val_loss: 52.2774\n",
            "Epoch 19/100\n",
            "108/108 [==============================] - 0s 4ms/step - loss: 48.5687 - val_loss: 50.9945\n",
            "Epoch 20/100\n",
            "108/108 [==============================] - 0s 4ms/step - loss: 47.9612 - val_loss: 48.6306\n",
            "Epoch 21/100\n",
            "108/108 [==============================] - 0s 4ms/step - loss: 47.8285 - val_loss: 50.4376\n",
            "Epoch 22/100\n",
            "108/108 [==============================] - 0s 4ms/step - loss: 47.4699 - val_loss: 47.5755\n",
            "Epoch 23/100\n",
            "108/108 [==============================] - 0s 4ms/step - loss: 46.7096 - val_loss: 47.1354\n",
            "Epoch 24/100\n",
            "108/108 [==============================] - 0s 4ms/step - loss: 45.0510 - val_loss: 51.2077\n",
            "Epoch 25/100\n",
            "108/108 [==============================] - 0s 4ms/step - loss: 44.1275 - val_loss: 49.5979\n",
            "Epoch 26/100\n",
            "108/108 [==============================] - 0s 4ms/step - loss: 44.4429 - val_loss: 43.7801\n",
            "Epoch 27/100\n",
            "108/108 [==============================] - 0s 4ms/step - loss: 43.0684 - val_loss: 46.1432\n",
            "Epoch 28/100\n",
            "108/108 [==============================] - 0s 4ms/step - loss: 41.9396 - val_loss: 42.8817\n",
            "Epoch 29/100\n",
            "108/108 [==============================] - 0s 4ms/step - loss: 41.3127 - val_loss: 40.4557\n",
            "Epoch 30/100\n",
            "108/108 [==============================] - 0s 4ms/step - loss: 40.9078 - val_loss: 40.3448\n",
            "Epoch 31/100\n",
            "108/108 [==============================] - 0s 4ms/step - loss: 40.9337 - val_loss: 37.7738\n",
            "Epoch 32/100\n",
            "108/108 [==============================] - 0s 4ms/step - loss: 38.3675 - val_loss: 40.0075\n",
            "Epoch 33/100\n",
            "108/108 [==============================] - 0s 4ms/step - loss: 38.0649 - val_loss: 40.6041\n",
            "Epoch 34/100\n",
            "108/108 [==============================] - 0s 4ms/step - loss: 37.8157 - val_loss: 41.9068\n",
            "Epoch 35/100\n",
            "108/108 [==============================] - 0s 4ms/step - loss: 37.2926 - val_loss: 41.4645\n",
            "Epoch 36/100\n",
            "108/108 [==============================] - 0s 4ms/step - loss: 34.5799 - val_loss: 34.6804\n",
            "Epoch 37/100\n",
            "108/108 [==============================] - 0s 4ms/step - loss: 34.4592 - val_loss: 35.9076\n",
            "Epoch 38/100\n",
            "108/108 [==============================] - 0s 4ms/step - loss: 33.3077 - val_loss: 30.5751\n",
            "Epoch 39/100\n",
            "108/108 [==============================] - 0s 4ms/step - loss: 32.5218 - val_loss: 31.7383\n",
            "Epoch 40/100\n",
            "108/108 [==============================] - 0s 4ms/step - loss: 32.0871 - val_loss: 29.4958\n",
            "Epoch 41/100\n",
            "108/108 [==============================] - 0s 4ms/step - loss: 31.5482 - val_loss: 29.0661\n",
            "Epoch 42/100\n",
            "108/108 [==============================] - 0s 4ms/step - loss: 30.8879 - val_loss: 30.0024\n",
            "Epoch 43/100\n",
            "108/108 [==============================] - 0s 4ms/step - loss: 30.8553 - val_loss: 29.5409\n",
            "Epoch 44/100\n",
            "108/108 [==============================] - 0s 4ms/step - loss: 30.0724 - val_loss: 32.9806\n",
            "Epoch 45/100\n",
            "108/108 [==============================] - 0s 4ms/step - loss: 28.4457 - val_loss: 28.0058\n",
            "Epoch 46/100\n",
            "108/108 [==============================] - 0s 4ms/step - loss: 28.4847 - val_loss: 31.1852\n",
            "Epoch 47/100\n",
            "108/108 [==============================] - 0s 4ms/step - loss: 31.0541 - val_loss: 27.0069\n",
            "Epoch 48/100\n",
            "108/108 [==============================] - 0s 4ms/step - loss: 27.5322 - val_loss: 26.8178\n",
            "Epoch 49/100\n",
            "108/108 [==============================] - 0s 4ms/step - loss: 27.2478 - val_loss: 32.9503\n",
            "Epoch 50/100\n",
            "108/108 [==============================] - 0s 4ms/step - loss: 29.5432 - val_loss: 36.7262\n",
            "Epoch 51/100\n",
            "108/108 [==============================] - 0s 4ms/step - loss: 26.5715 - val_loss: 27.2945\n",
            "Epoch 52/100\n",
            "108/108 [==============================] - 0s 4ms/step - loss: 26.4514 - val_loss: 26.0261\n",
            "Epoch 53/100\n",
            "108/108 [==============================] - 0s 4ms/step - loss: 27.8757 - val_loss: 27.4762\n",
            "Epoch 54/100\n",
            "108/108 [==============================] - 0s 4ms/step - loss: 25.6870 - val_loss: 28.6496\n",
            "Epoch 55/100\n",
            "108/108 [==============================] - 0s 4ms/step - loss: 26.6303 - val_loss: 24.3912\n",
            "Epoch 56/100\n",
            "108/108 [==============================] - 0s 4ms/step - loss: 25.7330 - val_loss: 26.2797\n",
            "Epoch 57/100\n",
            "108/108 [==============================] - 0s 4ms/step - loss: 24.6949 - val_loss: 23.8975\n",
            "Epoch 58/100\n",
            "108/108 [==============================] - 0s 4ms/step - loss: 24.4779 - val_loss: 23.8212\n",
            "Epoch 59/100\n",
            "108/108 [==============================] - 0s 4ms/step - loss: 25.4346 - val_loss: 30.4937\n",
            "Epoch 60/100\n",
            "108/108 [==============================] - 0s 4ms/step - loss: 24.4045 - val_loss: 22.8724\n",
            "Epoch 61/100\n",
            "108/108 [==============================] - 0s 4ms/step - loss: 25.6065 - val_loss: 25.1279\n",
            "Epoch 62/100\n",
            "108/108 [==============================] - 0s 4ms/step - loss: 26.7032 - val_loss: 25.1061\n",
            "Epoch 63/100\n",
            "108/108 [==============================] - 0s 4ms/step - loss: 24.6737 - val_loss: 24.4127\n",
            "Epoch 64/100\n",
            "108/108 [==============================] - 0s 4ms/step - loss: 23.1969 - val_loss: 23.0896\n",
            "Epoch 65/100\n",
            "108/108 [==============================] - 0s 4ms/step - loss: 24.2719 - val_loss: 24.3858\n",
            "Epoch 66/100\n",
            "108/108 [==============================] - 0s 4ms/step - loss: 24.4951 - val_loss: 22.4895\n",
            "Epoch 67/100\n",
            "108/108 [==============================] - 0s 4ms/step - loss: 22.1374 - val_loss: 23.2751\n",
            "Epoch 68/100\n",
            "108/108 [==============================] - 0s 4ms/step - loss: 23.6296 - val_loss: 31.0915\n",
            "Epoch 69/100\n",
            " 17/108 [===>..........................] - ETA: 0s - loss: 28.4374"
          ]
        }
      ],
      "source": [
        "# 3.모델 컴파일\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "# 모니터 : val_loss 를 관찰\n",
        "# mode : 값이 커질때 멈춤 , 값이 작아져야함\n",
        "# patience : 개선이 안된다고 바로 종료시키지 않고 에폭을 기다림\n",
        "# \n",
        "earlyStopping = EarlyStopping(monitor=\"val_loss\",\n",
        "                              mode=\"min\",patience =10,\n",
        "                              restore_best_weights=True,\n",
        "                              verbose=1\n",
        "                              \n",
        "                              )\n",
        "\n",
        "model.compile(loss=\"mse\",optimizer=\"adam\")\n",
        "\n",
        "# model.fit 이 반환한 기록을 저장\n",
        "hist = model.fit(\n",
        "                x_train,\n",
        "                y_train,\n",
        "                epochs=100,\n",
        "                batch_size=3,\n",
        "                validation_split=0.2,\n",
        "                verbose=1,\n",
        "                callbacks = [earlyStopping]\n",
        "                )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 0s 3ms/step - loss: 24.5093\n",
            "loss :  24.509262084960938\n"
          ]
        }
      ],
      "source": [
        "# 평가 예측\n",
        "loss = model.evaluate(x_test,y_test)\n",
        "\n",
        "print(\"loss : \",loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[46.7601203918457, 44.30381393432617, 46.68405532836914, 43.5411262512207, 41.270904541015625, 40.881168365478516, 41.140846252441406, 40.258914947509766, 39.376251220703125, 37.632259368896484, 36.21417236328125, 32.530643463134766, 34.70029067993164, 33.58757781982422, 31.07977867126465, 32.0745849609375, 32.22232437133789, 29.38474464416504, 28.83738899230957, 28.452421188354492, 31.35308074951172, 29.285444259643555, 31.30075454711914, 27.676658630371094, 27.716140747070312, 27.516284942626953, 30.210275650024414, 26.40801239013672, 23.577238082885742, 25.349056243896484, 25.707067489624023, 24.11040687561035, 25.181171417236328, 27.590452194213867, 25.88873291015625, 25.261518478393555, 26.278635025024414, 24.174997329711914, 24.3726806640625, 27.221567153930664, 23.94792366027832, 22.83549690246582, 25.53072166442871, 25.063865661621094, 23.801597595214844]\n",
            "=============================================================\n",
            "[54.12196731567383, 53.300540924072266, 45.65068435668945, 45.74800491333008, 46.021244049072266, 40.86571502685547, 41.547760009765625, 39.11024856567383, 42.794246673583984, 39.418365478515625, 40.122711181640625, 43.55500411987305, 34.65077209472656, 35.484066009521484, 42.152320861816406, 32.54503631591797, 32.53819274902344, 30.325387954711914, 31.731294631958008, 33.75641632080078, 33.87763977050781, 34.881465911865234, 42.03809356689453, 36.861854553222656, 33.384437561035156, 30.131507873535156, 27.150453567504883, 28.29889488220215, 28.01932716369629, 39.08130645751953, 26.653730392456055, 28.86894989013672, 26.01947784423828, 28.071855545043945, 23.91181182861328, 27.605321884155273, 27.99370574951172, 24.442415237426758, 30.968358993530273, 24.763425827026367, 25.464086532592773, 27.78460693359375, 33.69343948364258, 34.68769836425781, 24.750322341918945]\n"
          ]
        }
      ],
      "source": [
        "# hist.history 는 딕셔너리형으로 구성\n",
        "\n",
        "print(hist.history['loss'])\n",
        "print(\"=============================================================\")\n",
        "print(hist.history['val_loss'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'hist' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6736\\41250010.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"loss\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;34m\"red\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"loss\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"val_loss\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"green\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"val_loss\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 격자 표시\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'hist' is not defined"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 900x600 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 시각화\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 필롯의 사이즈\n",
        "plt.figure(figsize =(9,6))\n",
        "\n",
        "plt.plot(hist.history[\"loss\"],c =\"red\",label=\"loss\")\n",
        "plt.plot(hist.history[\"val_loss\"],c=\"green\",label=\"val_loss\")\n",
        "plt.grid() # 격자 표시\n",
        "plt.xlabel(\"epochs\") # x 라벨 표시 \n",
        "plt.ylabel(\"loss\") # y 라벨 표시\n",
        "plt.title(\"boston loss\") # 그래프의 타이틀 표시\n",
        "plt.legend(loc = \"upper right\") # 그래프의 범주 표시\n",
        "plt.show() # 그래프를 보여줘"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "tf274gpu",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "10848e9bd3f5e7d93542d388001135334854454e7336dcf54c4ef52885ee0fb0"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
