{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "dataset = load_diabetes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(442, 10)\n",
      "(442,)\n"
     ]
    }
   ],
   "source": [
    "x = dataset.data\n",
    "y = dataset.target\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# 사이킥 런의 칼럼 조회기능\n",
    "print(dataset.feature_names)\n",
    "print(len(dataset.feature_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _diabetes_dataset:\n",
      "\n",
      "Diabetes dataset\n",
      "----------------\n",
      "\n",
      "Ten baseline variables, age, sex, body mass index, average blood\n",
      "pressure, and six blood serum measurements were obtained for each of n =\n",
      "442 diabetes patients, as well as the response of interest, a\n",
      "quantitative measure of disease progression one year after baseline.\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "  :Number of Instances: 442\n",
      "\n",
      "  :Number of Attributes: First 10 columns are numeric predictive values\n",
      "\n",
      "  :Target: Column 11 is a quantitative measure of disease progression one year after baseline\n",
      "\n",
      "  :Attribute Information:\n",
      "      - age     age in years\n",
      "      - sex\n",
      "      - bmi     body mass index\n",
      "      - bp      average blood pressure\n",
      "      - s1      tc, total serum cholesterol\n",
      "      - s2      ldl, low-density lipoproteins\n",
      "      - s3      hdl, high-density lipoproteins\n",
      "      - s4      tch, total cholesterol / HDL\n",
      "      - s5      ltg, possibly log of serum triglycerides level\n",
      "      - s6      glu, blood sugar level\n",
      "\n",
      "Note: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times the square root of `n_samples` (i.e. the sum of squares of each column totals 1).\n",
      "\n",
      "Source URL:\n",
      "https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\n",
      "\n",
      "For more information see:\n",
      "Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\n",
      "(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 사이킥런의 데이터 요약\n",
    "print(dataset.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309\n",
      "133\n"
     ]
    }
   ],
   "source": [
    "# 3. 모델구성\n",
    "# 실습 train 0.7 이상\n",
    "# 평가지표 R2 : 0.8 이상으로 뽑아내보기 / RMSE 사용\n",
    "\n",
    "x_train, x_test,y_train,y_test = train_test_split(x,y,\n",
    "    train_size=0.7,\n",
    "    shuffle = True,\n",
    "    random_state= 123\n",
    ")\n",
    "\n",
    "print(len(x_train))\n",
    "print(len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_18 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,881\n",
      "Trainable params: 1,881\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from random import randrange\n",
    "number1 = randrange(1,10,1)\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(10,input_dim = 10),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(1)\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "100/100 [==============================] - 1s 1ms/step - loss: 129.6865\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 64.5403\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 56.3080\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 52.4257\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 50.2461\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 48.0925\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 47.1047\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 45.4532\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 45.6680\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 44.7967\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 44.3957\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 47.0546\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 42.4556\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 45.9865\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 44.2340\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 42.1007\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 45.4274\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 44.9519\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 43.7721\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 43.4564\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 44.8382\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 43.4797\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 43.3505\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 43.9138\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 43.8752\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 45.0928\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 43.0068\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 44.0108\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 43.5382\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 42.6594\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 43.2971\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 44.2862\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 43.0382\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 43.6119\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 43.4321\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 44.4040\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 42.8807\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 43.5573\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 43.4952\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 42.0770\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 44.1540\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 43.6732\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 42.7927\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 42.8350\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 42.8180\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 43.7471\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 42.8707\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 42.3143\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 43.7049\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 42.6952\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 42.2626\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 41.8637\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 42.5413\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 42.3013\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 43.8430\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 41.8902\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 41.7579\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 42.4246\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 42.6523\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 43.9535\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 43.6616\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 41.9063\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 42.1131\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 43.0564\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 42.6613\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 42.9591\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 42.4228\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 42.1963\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 42.4460\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 41.7948\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 41.7073\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 43.8787\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 41.9086\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 40.3774\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 41.4222\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 43.0475\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 40.0175\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 41.9797\n",
      "Epoch 79/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 91us/step - loss: 41.9797\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 42.7704\n",
      "loss :  42.77037811279297\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "=================\n",
      "[185. 150. 246. 184. 110. 202. 336.  69.  69.  87.  66. 164. 265. 198.\n",
      " 248. 171. 102. 182. 262. 233. 151. 275. 230.  39.  42. 122.  81.  31.\n",
      " 156. 161.  80. 215. 310. 163. 265.  84.  54. 137. 248.  72. 248.  59.\n",
      "  97.  61.  72. 296.  55.  75.  53. 173. 158.  96. 140. 186.  93. 123.\n",
      " 237. 138. 292.  78. 182. 127. 321. 109. 212.  45.  96. 109.  89.  96.\n",
      "  60.  51. 200. 265.  68.  91. 172. 115. 125.  53.  63. 259. 214. 195.\n",
      " 258. 235. 173.  59. 219. 170.  77.  49.  66. 144. 113. 233. 162. 121.\n",
      "  88. 302. 128.  52. 178.  90. 164. 135. 103. 200. 178. 261.  64.  59.\n",
      "  79.  47. 107.  39. 151. 104. 217. 232.  55. 245. 131.  64. 222. 249.\n",
      " 128. 293. 138. 273. 158. 168. 103.]\n",
      "[[156.81818 ]\n",
      " [138.01285 ]\n",
      " [238.98111 ]\n",
      " [197.71832 ]\n",
      " [156.55022 ]\n",
      " [148.31068 ]\n",
      " [267.89328 ]\n",
      " [102.57944 ]\n",
      " [ 89.2557  ]\n",
      " [113.70582 ]\n",
      " [111.89144 ]\n",
      " [183.27007 ]\n",
      " [152.36891 ]\n",
      " [216.12514 ]\n",
      " [231.71426 ]\n",
      " [173.0044  ]\n",
      " [100.500175]\n",
      " [142.79262 ]\n",
      " [179.63673 ]\n",
      " [191.40065 ]\n",
      " [174.30559 ]\n",
      " [245.9078  ]\n",
      " [133.61581 ]\n",
      " [ 73.87312 ]\n",
      " [106.97258 ]\n",
      " [196.08177 ]\n",
      " [ 90.543236]\n",
      " [ 85.57766 ]\n",
      " [150.0785  ]\n",
      " [184.44348 ]\n",
      " [ 81.95396 ]\n",
      " [250.80833 ]\n",
      " [246.27039 ]\n",
      " [222.72194 ]\n",
      " [203.13405 ]\n",
      " [ 86.46984 ]\n",
      " [ 80.186584]\n",
      " [122.56755 ]\n",
      " [227.19055 ]\n",
      " [ 87.70645 ]\n",
      " [209.47218 ]\n",
      " [ 78.1848  ]\n",
      " [120.95942 ]\n",
      " [126.50941 ]\n",
      " [ 98.13186 ]\n",
      " [236.04988 ]\n",
      " [123.11058 ]\n",
      " [ 81.226524]\n",
      " [ 85.2402  ]\n",
      " [231.29747 ]\n",
      " [106.258804]\n",
      " [ 89.419815]\n",
      " [174.11807 ]\n",
      " [199.09952 ]\n",
      " [153.80225 ]\n",
      " [199.54637 ]\n",
      " [234.97835 ]\n",
      " [169.03595 ]\n",
      " [198.66896 ]\n",
      " [210.19391 ]\n",
      " [119.736916]\n",
      " [104.34109 ]\n",
      " [239.11185 ]\n",
      " [212.884   ]\n",
      " [197.2459  ]\n",
      " [ 75.114044]\n",
      " [ 72.24956 ]\n",
      " [154.67336 ]\n",
      " [112.99205 ]\n",
      " [ 82.09225 ]\n",
      " [108.34189 ]\n",
      " [ 73.790764]\n",
      " [177.14888 ]\n",
      " [206.35878 ]\n",
      " [107.11428 ]\n",
      " [169.98398 ]\n",
      " [159.66084 ]\n",
      " [132.46642 ]\n",
      " [ 95.2104  ]\n",
      " [ 77.231575]\n",
      " [ 79.03995 ]\n",
      " [150.18297 ]\n",
      " [134.6468  ]\n",
      " [241.83888 ]\n",
      " [301.66708 ]\n",
      " [167.0353  ]\n",
      " [211.58076 ]\n",
      " [ 73.50892 ]\n",
      " [115.465614]\n",
      " [124.982056]\n",
      " [168.47112 ]\n",
      " [ 74.11094 ]\n",
      " [180.92839 ]\n",
      " [164.41289 ]\n",
      " [124.13672 ]\n",
      " [257.40472 ]\n",
      " [161.04358 ]\n",
      " [221.33456 ]\n",
      " [127.693794]\n",
      " [134.24034 ]\n",
      " [ 77.76609 ]\n",
      " [ 72.60584 ]\n",
      " [103.95339 ]\n",
      " [174.03188 ]\n",
      " [194.92809 ]\n",
      " [ 91.52693 ]\n",
      " [119.440605]\n",
      " [177.95207 ]\n",
      " [193.82445 ]\n",
      " [251.63441 ]\n",
      " [ 81.872   ]\n",
      " [119.15737 ]\n",
      " [100.199646]\n",
      " [ 80.37685 ]\n",
      " [ 95.71101 ]\n",
      " [ 75.726845]\n",
      " [206.40654 ]\n",
      " [ 72.850105]\n",
      " [175.87721 ]\n",
      " [191.19685 ]\n",
      " [155.07716 ]\n",
      " [155.99376 ]\n",
      " [150.55156 ]\n",
      " [108.55379 ]\n",
      " [200.10013 ]\n",
      " [213.65067 ]\n",
      " [261.47638 ]\n",
      " [201.98769 ]\n",
      " [ 73.06208 ]\n",
      " [274.1791  ]\n",
      " [ 94.4748  ]\n",
      " [144.52281 ]\n",
      " [142.18538 ]]\n",
      "=================\n",
      "R2 :  0.5204197041674494\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 40.9102\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 41.3022\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 39.6431\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 41.3308\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 42.1504\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 40.8583\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 40.0037\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 39.3583\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 41.0200\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 41.0942\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 40.4878\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 39.8890\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 40.1679\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 39.7775\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 40.2750\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 40.5186\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 39.5719\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 39.4484\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 38.5135\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 41.6350\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 39.2295\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 38.2112\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 39.9334\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 42.7922\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 37.6700\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 37.8307\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 41.0397\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 38.7410\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 38.2793\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 38.7216\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 38.2489\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 37.6915\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 38.6543\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 41.2875\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 38.6426\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 39.7395\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 38.3666\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 38.3766\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 38.1730\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 38.2757\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 38.3143\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 39.2490\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 38.7151\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.9725\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 38.1964\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 39.0375\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 39.6549\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 35.0693\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 39.1010\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 38.1182\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 37.3372\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 37.4727\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 37.9441\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.8143\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 38.7539\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.4768\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 37.2858\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.9654\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 37.0487\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 37.3381\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 37.0154\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.0138\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 38.4351\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.3433\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 37.1491\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 38.4377\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 35.8989\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 37.5400\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 35.7315\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.3449\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 35.6184\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 37.7466\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 35.9479\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.6163\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 35.2331\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 37.5232\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 35.4111\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.9923\n",
      "Epoch 79/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 89us/step - loss: 36.9923\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 45.8876\n",
      "loss :  45.88755416870117\n",
      "5/5 [==============================] - 0s 998us/step\n",
      "=================\n",
      "[185. 150. 246. 184. 110. 202. 336.  69.  69.  87.  66. 164. 265. 198.\n",
      " 248. 171. 102. 182. 262. 233. 151. 275. 230.  39.  42. 122.  81.  31.\n",
      " 156. 161.  80. 215. 310. 163. 265.  84.  54. 137. 248.  72. 248.  59.\n",
      "  97.  61.  72. 296.  55.  75.  53. 173. 158.  96. 140. 186.  93. 123.\n",
      " 237. 138. 292.  78. 182. 127. 321. 109. 212.  45.  96. 109.  89.  96.\n",
      "  60.  51. 200. 265.  68.  91. 172. 115. 125.  53.  63. 259. 214. 195.\n",
      " 258. 235. 173.  59. 219. 170.  77.  49.  66. 144. 113. 233. 162. 121.\n",
      "  88. 302. 128.  52. 178.  90. 164. 135. 103. 200. 178. 261.  64.  59.\n",
      "  79.  47. 107.  39. 151. 104. 217. 232.  55. 245. 131.  64. 222. 249.\n",
      " 128. 293. 138. 273. 158. 168. 103.]\n",
      "[[197.20457 ]\n",
      " [129.3928  ]\n",
      " [249.37833 ]\n",
      " [215.15746 ]\n",
      " [198.78897 ]\n",
      " [182.91405 ]\n",
      " [314.75314 ]\n",
      " [ 98.45513 ]\n",
      " [121.79971 ]\n",
      " [119.48352 ]\n",
      " [115.16728 ]\n",
      " [199.08919 ]\n",
      " [167.0336  ]\n",
      " [255.4188  ]\n",
      " [210.30785 ]\n",
      " [157.07912 ]\n",
      " [ 96.88649 ]\n",
      " [138.47162 ]\n",
      " [204.73955 ]\n",
      " [216.8843  ]\n",
      " [177.24141 ]\n",
      " [289.7935  ]\n",
      " [136.87535 ]\n",
      " [ 74.93086 ]\n",
      " [ 95.12311 ]\n",
      " [208.07785 ]\n",
      " [ 88.45634 ]\n",
      " [ 89.47412 ]\n",
      " [172.2901  ]\n",
      " [183.89772 ]\n",
      " [ 81.79088 ]\n",
      " [249.29315 ]\n",
      " [231.02296 ]\n",
      " [270.11893 ]\n",
      " [203.32703 ]\n",
      " [ 86.04204 ]\n",
      " [ 78.61443 ]\n",
      " [153.71669 ]\n",
      " [222.26906 ]\n",
      " [ 90.86539 ]\n",
      " [239.51704 ]\n",
      " [ 82.00441 ]\n",
      " [141.49359 ]\n",
      " [122.33159 ]\n",
      " [ 93.6357  ]\n",
      " [269.32925 ]\n",
      " [149.67717 ]\n",
      " [ 82.47566 ]\n",
      " [ 80.112785]\n",
      " [270.33643 ]\n",
      " [130.8805  ]\n",
      " [ 87.518845]\n",
      " [180.60704 ]\n",
      " [206.02206 ]\n",
      " [154.65842 ]\n",
      " [199.5561  ]\n",
      " [217.4906  ]\n",
      " [161.6946  ]\n",
      " [203.98871 ]\n",
      " [228.64714 ]\n",
      " [108.098434]\n",
      " [ 98.32388 ]\n",
      " [263.25546 ]\n",
      " [197.89445 ]\n",
      " [211.03766 ]\n",
      " [ 74.49506 ]\n",
      " [ 72.0506  ]\n",
      " [115.98969 ]\n",
      " [127.10989 ]\n",
      " [ 81.60578 ]\n",
      " [ 94.38006 ]\n",
      " [ 74.13238 ]\n",
      " [225.50006 ]\n",
      " [230.12015 ]\n",
      " [110.535446]\n",
      " [189.87157 ]\n",
      " [185.87604 ]\n",
      " [144.18127 ]\n",
      " [ 87.22032 ]\n",
      " [ 80.24485 ]\n",
      " [ 73.49654 ]\n",
      " [141.24786 ]\n",
      " [156.71747 ]\n",
      " [258.26346 ]\n",
      " [278.60898 ]\n",
      " [188.40237 ]\n",
      " [225.75378 ]\n",
      " [ 76.95863 ]\n",
      " [118.139175]\n",
      " [120.27535 ]\n",
      " [175.4711  ]\n",
      " [ 76.61826 ]\n",
      " [208.09502 ]\n",
      " [187.30043 ]\n",
      " [203.65167 ]\n",
      " [257.16876 ]\n",
      " [183.84526 ]\n",
      " [226.16722 ]\n",
      " [107.41495 ]\n",
      " [119.301765]\n",
      " [ 82.571945]\n",
      " [ 74.88988 ]\n",
      " [119.92254 ]\n",
      " [187.38129 ]\n",
      " [192.7687  ]\n",
      " [ 86.850975]\n",
      " [106.875854]\n",
      " [193.1682  ]\n",
      " [234.53186 ]\n",
      " [233.29314 ]\n",
      " [ 86.111824]\n",
      " [117.24152 ]\n",
      " [105.79404 ]\n",
      " [ 85.43787 ]\n",
      " [ 88.67201 ]\n",
      " [ 81.0743  ]\n",
      " [237.95305 ]\n",
      " [ 72.82982 ]\n",
      " [223.67015 ]\n",
      " [225.51506 ]\n",
      " [140.74016 ]\n",
      " [150.04834 ]\n",
      " [144.92377 ]\n",
      " [124.87827 ]\n",
      " [205.75768 ]\n",
      " [203.71599 ]\n",
      " [319.9266  ]\n",
      " [193.133   ]\n",
      " [ 72.455765]\n",
      " [189.64677 ]\n",
      " [ 92.267715]\n",
      " [142.0853  ]\n",
      " [161.3109  ]]\n",
      "=================\n",
      "R2 :  0.4273318725157459\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.0043\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.8672\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.3899\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 37.2380\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.4773\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.2313\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 38.0619\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.3380\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.8686\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 35.8305\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 37.9149\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.3037\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 35.5940\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.3981\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 38.0388\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 35.0562\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.6496\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 35.5795\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.7806\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.1149\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.3304\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.3900\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 37.3085\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.8953\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 37.5172\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 35.8468\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.9879\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.1130\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 35.3880\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 35.7729\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.4644\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 35.7710\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.4121\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.8704\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.9933\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.8729\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.2207\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.3645\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.5850\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.2610\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.4360\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.1108\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.9859\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 35.1681\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.0600\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 35.4780\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 35.3585\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.4167\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 35.4550\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.2490\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.3186\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 37.0766\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.4728\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 35.2176\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.9942\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.3642\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.2844\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 36.1613\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.3516\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.6417\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.6761\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.0251\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.8479\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.9725\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.4231\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.8067\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.5762\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.6250\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.0100\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.1233\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.6931\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.5485\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.9602\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.9257\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.5622\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.0403\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.1383\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.0999\n",
      "Epoch 79/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 90us/step - loss: 33.0999\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 50.2287\n",
      "loss :  50.2287483215332\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "=================\n",
      "[185. 150. 246. 184. 110. 202. 336.  69.  69.  87.  66. 164. 265. 198.\n",
      " 248. 171. 102. 182. 262. 233. 151. 275. 230.  39.  42. 122.  81.  31.\n",
      " 156. 161.  80. 215. 310. 163. 265.  84.  54. 137. 248.  72. 248.  59.\n",
      "  97.  61.  72. 296.  55.  75.  53. 173. 158.  96. 140. 186.  93. 123.\n",
      " 237. 138. 292.  78. 182. 127. 321. 109. 212.  45.  96. 109.  89.  96.\n",
      "  60.  51. 200. 265.  68.  91. 172. 115. 125.  53.  63. 259. 214. 195.\n",
      " 258. 235. 173.  59. 219. 170.  77.  49.  66. 144. 113. 233. 162. 121.\n",
      "  88. 302. 128.  52. 178.  90. 164. 135. 103. 200. 178. 261.  64.  59.\n",
      "  79.  47. 107.  39. 151. 104. 217. 232.  55. 245. 131.  64. 222. 249.\n",
      " 128. 293. 138. 273. 158. 168. 103.]\n",
      "[[219.73444 ]\n",
      " [114.60446 ]\n",
      " [278.47736 ]\n",
      " [246.79424 ]\n",
      " [219.78787 ]\n",
      " [182.77527 ]\n",
      " [321.56363 ]\n",
      " [116.65858 ]\n",
      " [146.56956 ]\n",
      " [ 93.52953 ]\n",
      " [140.3491  ]\n",
      " [204.42082 ]\n",
      " [210.71234 ]\n",
      " [295.68716 ]\n",
      " [250.80171 ]\n",
      " [182.41922 ]\n",
      " [ 98.20469 ]\n",
      " [139.28047 ]\n",
      " [239.43942 ]\n",
      " [276.37567 ]\n",
      " [177.58728 ]\n",
      " [304.43814 ]\n",
      " [189.58345 ]\n",
      " [ 75.73885 ]\n",
      " [ 86.84626 ]\n",
      " [221.241   ]\n",
      " [ 96.99875 ]\n",
      " [ 90.3231  ]\n",
      " [172.69473 ]\n",
      " [175.8633  ]\n",
      " [106.733246]\n",
      " [258.49054 ]\n",
      " [193.31601 ]\n",
      " [299.827   ]\n",
      " [215.63034 ]\n",
      " [ 85.94505 ]\n",
      " [ 74.97909 ]\n",
      " [180.50351 ]\n",
      " [251.20348 ]\n",
      " [ 89.7644  ]\n",
      " [262.93948 ]\n",
      " [ 77.02514 ]\n",
      " [164.82391 ]\n",
      " [119.94335 ]\n",
      " [ 91.18628 ]\n",
      " [308.79123 ]\n",
      " [156.59343 ]\n",
      " [ 95.91924 ]\n",
      " [ 76.88089 ]\n",
      " [303.77573 ]\n",
      " [137.99808 ]\n",
      " [ 86.575676]\n",
      " [186.31442 ]\n",
      " [268.32147 ]\n",
      " [155.25476 ]\n",
      " [196.93951 ]\n",
      " [261.78308 ]\n",
      " [168.79755 ]\n",
      " [200.01294 ]\n",
      " [280.16263 ]\n",
      " [106.88169 ]\n",
      " [101.98515 ]\n",
      " [315.7113  ]\n",
      " [219.37558 ]\n",
      " [228.01183 ]\n",
      " [ 75.89014 ]\n",
      " [ 73.2672  ]\n",
      " [110.63882 ]\n",
      " [150.35489 ]\n",
      " [ 79.56458 ]\n",
      " [ 87.769066]\n",
      " [ 73.86762 ]\n",
      " [216.38431 ]\n",
      " [242.75395 ]\n",
      " [139.91922 ]\n",
      " [198.49289 ]\n",
      " [216.95346 ]\n",
      " [171.43774 ]\n",
      " [ 89.25779 ]\n",
      " [ 88.803246]\n",
      " [ 71.9698  ]\n",
      " [137.89441 ]\n",
      " [164.8899  ]\n",
      " [272.26993 ]\n",
      " [280.2958  ]\n",
      " [194.3995  ]\n",
      " [206.26588 ]\n",
      " [ 75.03027 ]\n",
      " [117.04449 ]\n",
      " [158.78984 ]\n",
      " [160.45132 ]\n",
      " [ 76.26339 ]\n",
      " [234.35298 ]\n",
      " [210.19072 ]\n",
      " [223.98901 ]\n",
      " [274.28113 ]\n",
      " [176.60893 ]\n",
      " [239.9313  ]\n",
      " [102.80655 ]\n",
      " [151.81194 ]\n",
      " [ 83.21395 ]\n",
      " [ 75.58213 ]\n",
      " [110.93538 ]\n",
      " [188.27303 ]\n",
      " [203.5066  ]\n",
      " [ 78.0627  ]\n",
      " [117.75095 ]\n",
      " [216.1828  ]\n",
      " [277.55377 ]\n",
      " [256.2547  ]\n",
      " [107.03678 ]\n",
      " [140.87897 ]\n",
      " [131.3027  ]\n",
      " [ 87.322105]\n",
      " [ 97.34698 ]\n",
      " [ 97.23374 ]\n",
      " [288.75986 ]\n",
      " [ 72.252754]\n",
      " [284.9424  ]\n",
      " [257.91946 ]\n",
      " [142.11371 ]\n",
      " [140.56589 ]\n",
      " [137.9786  ]\n",
      " [131.12741 ]\n",
      " [242.69196 ]\n",
      " [238.56131 ]\n",
      " [341.88104 ]\n",
      " [245.86252 ]\n",
      " [ 71.75083 ]\n",
      " [202.59924 ]\n",
      " [100.72255 ]\n",
      " [150.90585 ]\n",
      " [124.52712 ]]\n",
      "=================\n",
      "R2 :  0.2938643872686466\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.1722\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.8577\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.4112\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.9025\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.3994\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.7091\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.3690\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.3823\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.1423\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.0423\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.3385\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.0448\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.7614\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.6510\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.0608\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.5860\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.0212\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.4650\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.2388\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.6210\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.8243\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.2234\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.0015\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.9676\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.0675\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.6657\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.1968\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.1947\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.3531\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.0689\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.4665\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.9317\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.1125\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.5880\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.5737\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.7389\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.5916\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.1402\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.4249\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.1395\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.7262\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.2023\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.3739\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.5263\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.1958\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 34.7428\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.7737\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.0602\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.1845\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.5157\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.4217\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.1673\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.0463\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.9220\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.3354\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.1797\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.5759\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.9923\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.8483\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.4313\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.1673\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.3630\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.3429\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.5825\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.3781\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.3324\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.2522\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.6971\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.9826\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.8667\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.2366\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.1445\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.6591\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.6971\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.4034\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.5797\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.0993\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.5476\n",
      "Epoch 79/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 110us/step - loss: 30.5476\n",
      "5/5 [==============================] - 0s 889us/step - loss: 48.7830\n",
      "loss :  48.78297805786133\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "=================\n",
      "[185. 150. 246. 184. 110. 202. 336.  69.  69.  87.  66. 164. 265. 198.\n",
      " 248. 171. 102. 182. 262. 233. 151. 275. 230.  39.  42. 122.  81.  31.\n",
      " 156. 161.  80. 215. 310. 163. 265.  84.  54. 137. 248.  72. 248.  59.\n",
      "  97.  61.  72. 296.  55.  75.  53. 173. 158.  96. 140. 186.  93. 123.\n",
      " 237. 138. 292.  78. 182. 127. 321. 109. 212.  45.  96. 109.  89.  96.\n",
      "  60.  51. 200. 265.  68.  91. 172. 115. 125.  53.  63. 259. 214. 195.\n",
      " 258. 235. 173.  59. 219. 170.  77.  49.  66. 144. 113. 233. 162. 121.\n",
      "  88. 302. 128.  52. 178.  90. 164. 135. 103. 200. 178. 261.  64.  59.\n",
      "  79.  47. 107.  39. 151. 104. 217. 232.  55. 245. 131.  64. 222. 249.\n",
      " 128. 293. 138. 273. 158. 168. 103.]\n",
      "[[233.83893 ]\n",
      " [ 89.49113 ]\n",
      " [260.22772 ]\n",
      " [243.44928 ]\n",
      " [232.75758 ]\n",
      " [194.49225 ]\n",
      " [290.93915 ]\n",
      " [100.64163 ]\n",
      " [143.70406 ]\n",
      " [103.29966 ]\n",
      " [147.92096 ]\n",
      " [215.21948 ]\n",
      " [186.34482 ]\n",
      " [292.42273 ]\n",
      " [245.74467 ]\n",
      " [202.92767 ]\n",
      " [ 94.28244 ]\n",
      " [141.15265 ]\n",
      " [203.71927 ]\n",
      " [276.5395  ]\n",
      " [169.98805 ]\n",
      " [292.70544 ]\n",
      " [112.38908 ]\n",
      " [ 72.131966]\n",
      " [ 72.65576 ]\n",
      " [188.7564  ]\n",
      " [ 99.30451 ]\n",
      " [ 85.79737 ]\n",
      " [202.2615  ]\n",
      " [163.9128  ]\n",
      " [ 99.10168 ]\n",
      " [269.1077  ]\n",
      " [166.70142 ]\n",
      " [289.6832  ]\n",
      " [208.86404 ]\n",
      " [ 83.21179 ]\n",
      " [ 72.730064]\n",
      " [165.45845 ]\n",
      " [244.13495 ]\n",
      " [ 89.352806]\n",
      " [250.80815 ]\n",
      " [ 72.40669 ]\n",
      " [151.99211 ]\n",
      " [120.04534 ]\n",
      " [ 91.08721 ]\n",
      " [275.13513 ]\n",
      " [160.43127 ]\n",
      " [ 92.9041  ]\n",
      " [ 73.11036 ]\n",
      " [266.6433  ]\n",
      " [146.83331 ]\n",
      " [ 89.89944 ]\n",
      " [109.89823 ]\n",
      " [266.3385  ]\n",
      " [140.42566 ]\n",
      " [190.44595 ]\n",
      " [214.18304 ]\n",
      " [171.12982 ]\n",
      " [203.621   ]\n",
      " [290.21606 ]\n",
      " [103.51756 ]\n",
      " [103.21757 ]\n",
      " [298.63855 ]\n",
      " [148.01547 ]\n",
      " [226.45479 ]\n",
      " [ 74.46674 ]\n",
      " [ 72.230865]\n",
      " [100.74101 ]\n",
      " [114.251274]\n",
      " [ 82.7718  ]\n",
      " [ 82.99125 ]\n",
      " [ 73.04495 ]\n",
      " [219.66623 ]\n",
      " [254.44464 ]\n",
      " [129.47998 ]\n",
      " [183.07103 ]\n",
      " [190.12048 ]\n",
      " [145.21066 ]\n",
      " [ 96.97521 ]\n",
      " [ 91.6628  ]\n",
      " [ 72.69027 ]\n",
      " [130.99876 ]\n",
      " [151.9203  ]\n",
      " [269.66473 ]\n",
      " [272.03076 ]\n",
      " [197.42252 ]\n",
      " [183.67276 ]\n",
      " [ 73.8566  ]\n",
      " [128.98444 ]\n",
      " [158.57956 ]\n",
      " [152.62593 ]\n",
      " [ 72.013054]\n",
      " [243.22913 ]\n",
      " [169.94588 ]\n",
      " [252.7236  ]\n",
      " [258.34265 ]\n",
      " [151.56815 ]\n",
      " [195.09344 ]\n",
      " [ 97.37643 ]\n",
      " [132.70558 ]\n",
      " [ 82.54311 ]\n",
      " [ 76.3692  ]\n",
      " [121.12281 ]\n",
      " [176.53929 ]\n",
      " [191.16151 ]\n",
      " [ 71.9983  ]\n",
      " [115.86538 ]\n",
      " [181.88057 ]\n",
      " [271.36438 ]\n",
      " [156.4205  ]\n",
      " [ 98.14271 ]\n",
      " [129.21265 ]\n",
      " [128.64209 ]\n",
      " [ 86.97964 ]\n",
      " [ 88.11159 ]\n",
      " [101.48742 ]\n",
      " [276.59814 ]\n",
      " [ 75.85327 ]\n",
      " [266.75766 ]\n",
      " [265.09393 ]\n",
      " [118.60546 ]\n",
      " [135.04596 ]\n",
      " [130.38387 ]\n",
      " [110.25639 ]\n",
      " [240.94666 ]\n",
      " [261.03235 ]\n",
      " [330.48083 ]\n",
      " [220.38734 ]\n",
      " [ 71.39585 ]\n",
      " [197.02025 ]\n",
      " [ 95.87262 ]\n",
      " [139.36472 ]\n",
      " [128.17351 ]]\n",
      "=================\n",
      "R2 :  0.31090812392416756\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.2861\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.9587\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.1485\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.5936\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.4506\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.3833\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.0553\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.3365\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.9780\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.4789\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.2440\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.0294\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.1123\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.0641\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.2101\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.6169\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 33.1811\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.8069\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.9192\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.8117\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.0662\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.5039\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.6693\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.6976\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.4929\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.4109\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.4805\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.3811\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.7657\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.3890\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.4903\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 31.7517\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.2038\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.8443\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.4221\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.4250\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.4766\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.3802\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.7782\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.9320\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.0263\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.5069\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.2765\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.7549\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.5626\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.6009\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.6525\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.1925\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.4860\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.4251\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.6181\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.6503\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.6821\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.1032\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.6215\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.9754\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.1172\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.8335\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.2072\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.1808\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.4605\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.6236\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.5315\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.8382\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.4105\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.5766\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.7962\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.2651\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.4497\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.7289\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.7236\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.5218\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.4967\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.5475\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.6553\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.1112\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.0139\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.0574\n",
      "Epoch 79/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 100us/step - loss: 29.0574\n",
      "5/5 [==============================] - 0s 998us/step - loss: 49.0279\n",
      "loss :  49.02789306640625\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "=================\n",
      "[185. 150. 246. 184. 110. 202. 336.  69.  69.  87.  66. 164. 265. 198.\n",
      " 248. 171. 102. 182. 262. 233. 151. 275. 230.  39.  42. 122.  81.  31.\n",
      " 156. 161.  80. 215. 310. 163. 265.  84.  54. 137. 248.  72. 248.  59.\n",
      "  97.  61.  72. 296.  55.  75.  53. 173. 158.  96. 140. 186.  93. 123.\n",
      " 237. 138. 292.  78. 182. 127. 321. 109. 212.  45.  96. 109.  89.  96.\n",
      "  60.  51. 200. 265.  68.  91. 172. 115. 125.  53.  63. 259. 214. 195.\n",
      " 258. 235. 173.  59. 219. 170.  77.  49.  66. 144. 113. 233. 162. 121.\n",
      "  88. 302. 128.  52. 178.  90. 164. 135. 103. 200. 178. 261.  64.  59.\n",
      "  79.  47. 107.  39. 151. 104. 217. 232.  55. 245. 131.  64. 222. 249.\n",
      " 128. 293. 138. 273. 158. 168. 103.]\n",
      "[[229.99501 ]\n",
      " [ 82.32194 ]\n",
      " [257.92282 ]\n",
      " [239.27176 ]\n",
      " [243.99677 ]\n",
      " [202.15196 ]\n",
      " [286.1439  ]\n",
      " [ 93.02162 ]\n",
      " [181.41344 ]\n",
      " [106.82079 ]\n",
      " [160.68602 ]\n",
      " [229.81541 ]\n",
      " [195.67406 ]\n",
      " [303.64932 ]\n",
      " [250.2731  ]\n",
      " [201.62589 ]\n",
      " [ 97.55184 ]\n",
      " [159.6299  ]\n",
      " [238.20776 ]\n",
      " [280.9284  ]\n",
      " [154.16049 ]\n",
      " [296.5379  ]\n",
      " [105.69451 ]\n",
      " [ 72.56611 ]\n",
      " [ 73.39885 ]\n",
      " [180.73506 ]\n",
      " [101.37777 ]\n",
      " [ 75.66481 ]\n",
      " [237.74    ]\n",
      " [151.67757 ]\n",
      " [115.728424]\n",
      " [246.33119 ]\n",
      " [101.09785 ]\n",
      " [297.29514 ]\n",
      " [194.23734 ]\n",
      " [ 77.01589 ]\n",
      " [ 73.10903 ]\n",
      " [158.0161  ]\n",
      " [251.43437 ]\n",
      " [ 92.4084  ]\n",
      " [243.16165 ]\n",
      " [ 72.367035]\n",
      " [170.77638 ]\n",
      " [107.25316 ]\n",
      " [ 88.97724 ]\n",
      " [291.76688 ]\n",
      " [136.4266  ]\n",
      " [ 94.26906 ]\n",
      " [ 73.249985]\n",
      " [267.9138  ]\n",
      " [149.46977 ]\n",
      " [101.89653 ]\n",
      " [ 76.74362 ]\n",
      " [227.70114 ]\n",
      " [136.11855 ]\n",
      " [177.89134 ]\n",
      " [170.00046 ]\n",
      " [151.73912 ]\n",
      " [210.39714 ]\n",
      " [274.61362 ]\n",
      " [100.06361 ]\n",
      " [107.237076]\n",
      " [297.30307 ]\n",
      " [126.863434]\n",
      " [228.67632 ]\n",
      " [ 72.358635]\n",
      " [ 72.71533 ]\n",
      " [ 97.30459 ]\n",
      " [137.3248  ]\n",
      " [ 78.3639  ]\n",
      " [ 81.23541 ]\n",
      " [ 73.61333 ]\n",
      " [207.24144 ]\n",
      " [243.23991 ]\n",
      " [108.987564]\n",
      " [164.59523 ]\n",
      " [178.70149 ]\n",
      " [144.31328 ]\n",
      " [ 94.644905]\n",
      " [ 85.38149 ]\n",
      " [ 72.79033 ]\n",
      " [121.95999 ]\n",
      " [135.85564 ]\n",
      " [276.53748 ]\n",
      " [277.23483 ]\n",
      " [196.09605 ]\n",
      " [185.18074 ]\n",
      " [ 72.81439 ]\n",
      " [137.52963 ]\n",
      " [159.73271 ]\n",
      " [133.14546 ]\n",
      " [ 72.358635]\n",
      " [241.09624 ]\n",
      " [157.44154 ]\n",
      " [255.29774 ]\n",
      " [253.40897 ]\n",
      " [147.13866 ]\n",
      " [153.63036 ]\n",
      " [ 89.86521 ]\n",
      " [135.03554 ]\n",
      " [ 78.97687 ]\n",
      " [ 72.504036]\n",
      " [171.81206 ]\n",
      " [171.28493 ]\n",
      " [174.93303 ]\n",
      " [ 72.358635]\n",
      " [124.27541 ]\n",
      " [166.08371 ]\n",
      " [278.99155 ]\n",
      " [127.52093 ]\n",
      " [ 95.79189 ]\n",
      " [152.5694  ]\n",
      " [126.63299 ]\n",
      " [ 89.26327 ]\n",
      " [ 92.43926 ]\n",
      " [113.143074]\n",
      " [283.8222  ]\n",
      " [ 87.12231 ]\n",
      " [266.86798 ]\n",
      " [279.59592 ]\n",
      " [112.85326 ]\n",
      " [113.81319 ]\n",
      " [109.15386 ]\n",
      " [ 90.353584]\n",
      " [206.82184 ]\n",
      " [272.2095  ]\n",
      " [311.35004 ]\n",
      " [186.15605 ]\n",
      " [ 72.35863 ]\n",
      " [169.14096 ]\n",
      " [116.808014]\n",
      " [130.39618 ]\n",
      " [114.879456]]\n",
      "=================\n",
      "R2 :  0.26219898529085794\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.5365\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 30.8351\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.6273\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.9685\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.2143\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.9914\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.1519\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.5648\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.3701\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.4155\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.6131\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.7889\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.6850\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.7005\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.8485\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.8456\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.1547\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.8494\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.7624\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.2765\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 29.1278\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.3224\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.1535\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.5844\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.4744\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.9394\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.5084\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.1384\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.7707\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.0105\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.1815\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.8750\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.6593\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.6545\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.1867\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.3218\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.1806\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.4329\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.9323\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.3822\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.1332\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.1844\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.1036\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.4359\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.2003\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.2790\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.5638\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.7091\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.8308\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.4803\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.5874\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.2318\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.5220\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.3752\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.3355\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.0661\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.4196\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.1415\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.9058\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.9668\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 26.3417\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.3921\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.8938\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.7041\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.6778\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.0195\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.1877\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.4695\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.0014\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.9652\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.9489\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.2450\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.1493\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.9470\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.2140\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.9523\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.3408\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.2154\n",
      "Epoch 79/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 100us/step - loss: 25.2154\n",
      "5/5 [==============================] - 0s 998us/step - loss: 47.0037\n",
      "loss :  47.00372314453125\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "=================\n",
      "[185. 150. 246. 184. 110. 202. 336.  69.  69.  87.  66. 164. 265. 198.\n",
      " 248. 171. 102. 182. 262. 233. 151. 275. 230.  39.  42. 122.  81.  31.\n",
      " 156. 161.  80. 215. 310. 163. 265.  84.  54. 137. 248.  72. 248.  59.\n",
      "  97.  61.  72. 296.  55.  75.  53. 173. 158.  96. 140. 186.  93. 123.\n",
      " 237. 138. 292.  78. 182. 127. 321. 109. 212.  45.  96. 109.  89.  96.\n",
      "  60.  51. 200. 265.  68.  91. 172. 115. 125.  53.  63. 259. 214. 195.\n",
      " 258. 235. 173.  59. 219. 170.  77.  49.  66. 144. 113. 233. 162. 121.\n",
      "  88. 302. 128.  52. 178.  90. 164. 135. 103. 200. 178. 261.  64.  59.\n",
      "  79.  47. 107.  39. 151. 104. 217. 232.  55. 245. 131.  64. 222. 249.\n",
      " 128. 293. 138. 273. 158. 168. 103.]\n",
      "[[215.53111 ]\n",
      " [ 80.13418 ]\n",
      " [268.0975  ]\n",
      " [216.56258 ]\n",
      " [229.07846 ]\n",
      " [206.8403  ]\n",
      " [290.5859  ]\n",
      " [ 82.47065 ]\n",
      " [180.41608 ]\n",
      " [ 84.91682 ]\n",
      " [134.56512 ]\n",
      " [210.59286 ]\n",
      " [193.86894 ]\n",
      " [281.5682  ]\n",
      " [240.59213 ]\n",
      " [194.7738  ]\n",
      " [ 71.71363 ]\n",
      " [145.82004 ]\n",
      " [225.48233 ]\n",
      " [274.56454 ]\n",
      " [136.15567 ]\n",
      " [299.47873 ]\n",
      " [ 95.430435]\n",
      " [ 69.02822 ]\n",
      " [ 69.02822 ]\n",
      " [178.65004 ]\n",
      " [ 74.85775 ]\n",
      " [ 69.02822 ]\n",
      " [219.47751 ]\n",
      " [137.43864 ]\n",
      " [112.39127 ]\n",
      " [227.0164  ]\n",
      " [ 89.20484 ]\n",
      " [290.00998 ]\n",
      " [198.77188 ]\n",
      " [ 69.02822 ]\n",
      " [ 69.02822 ]\n",
      " [116.60045 ]\n",
      " [243.00198 ]\n",
      " [ 69.02822 ]\n",
      " [226.70865 ]\n",
      " [ 69.02822 ]\n",
      " [201.0533  ]\n",
      " [ 88.5687  ]\n",
      " [ 69.02822 ]\n",
      " [302.54065 ]\n",
      " [160.4975  ]\n",
      " [ 70.1954  ]\n",
      " [ 69.02822 ]\n",
      " [255.55551 ]\n",
      " [184.81793 ]\n",
      " [ 94.31095 ]\n",
      " [ 72.64834 ]\n",
      " [205.57275 ]\n",
      " [106.235344]\n",
      " [182.30199 ]\n",
      " [195.32845 ]\n",
      " [124.277435]\n",
      " [203.63715 ]\n",
      " [267.80142 ]\n",
      " [ 84.874855]\n",
      " [ 92.5364  ]\n",
      " [308.1124  ]\n",
      " [111.00274 ]\n",
      " [216.9143  ]\n",
      " [ 69.02822 ]\n",
      " [ 69.02822 ]\n",
      " [ 78.328804]\n",
      " [151.49701 ]\n",
      " [ 69.02822 ]\n",
      " [ 70.78733 ]\n",
      " [ 69.02822 ]\n",
      " [202.0256  ]\n",
      " [237.1173  ]\n",
      " [ 84.89779 ]\n",
      " [134.95264 ]\n",
      " [168.28815 ]\n",
      " [145.2339  ]\n",
      " [ 83.32572 ]\n",
      " [ 72.05726 ]\n",
      " [ 69.02822 ]\n",
      " [117.11734 ]\n",
      " [133.32086 ]\n",
      " [255.95732 ]\n",
      " [276.19833 ]\n",
      " [194.93478 ]\n",
      " [140.29993 ]\n",
      " [ 69.02822 ]\n",
      " [103.099434]\n",
      " [155.41702 ]\n",
      " [112.78695 ]\n",
      " [ 69.02822 ]\n",
      " [225.23401 ]\n",
      " [143.26859 ]\n",
      " [221.68234 ]\n",
      " [250.97008 ]\n",
      " [108.40866 ]\n",
      " [163.1134  ]\n",
      " [ 71.732864]\n",
      " [148.41565 ]\n",
      " [ 69.02822 ]\n",
      " [ 69.02822 ]\n",
      " [129.09573 ]\n",
      " [167.93607 ]\n",
      " [154.4903  ]\n",
      " [ 69.02822 ]\n",
      " [154.81537 ]\n",
      " [146.71626 ]\n",
      " [263.77887 ]\n",
      " [130.78954 ]\n",
      " [ 80.41105 ]\n",
      " [146.32965 ]\n",
      " [104.29622 ]\n",
      " [ 69.34699 ]\n",
      " [ 72.962814]\n",
      " [ 82.56479 ]\n",
      " [271.71902 ]\n",
      " [ 75.47634 ]\n",
      " [235.31023 ]\n",
      " [262.4376  ]\n",
      " [117.81173 ]\n",
      " [102.48817 ]\n",
      " [ 93.33663 ]\n",
      " [ 69.02822 ]\n",
      " [192.17863 ]\n",
      " [243.61221 ]\n",
      " [289.59528 ]\n",
      " [201.72928 ]\n",
      " [ 69.02822 ]\n",
      " [155.99217 ]\n",
      " [115.32372 ]\n",
      " [114.809   ]\n",
      " [108.941   ]]\n",
      "=================\n",
      "R2 :  0.30942761403705166\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.4730\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.3721\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.8379\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.1634\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.2530\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.6511\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.5220\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.6887\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.5194\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.8989\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.1372\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.7317\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.0943\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.4004\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.9676\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.6982\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.0718\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.7092\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.7806\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.1902\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.6735\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.8568\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.7822\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.1892\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.1258\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.7808\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.6469\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.4994\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.7013\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.0585\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.5107\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.5850\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.9609\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.5366\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.2006\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.7159\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.4638\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.9583\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.5165\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.9980\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.1418\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 26.8709\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.8437\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.2010\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.9079\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.6516\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.9649\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.5576\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.9802\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.7571\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.4142\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.0346\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.8549\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.2473\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.5173\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.5740\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.0920\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.4850\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.2655\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.8749\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.5219\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.1398\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.5996\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.0105\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.1420\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.4824\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.2391\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.3796\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.0027\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.1161\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.5754\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.5527\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.2744\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.9656\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.7010\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.3762\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.6515\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 27.1138\n",
      "Epoch 79/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 110us/step - loss: 27.1138\n",
      "5/5 [==============================] - 0s 990us/step - loss: 50.0277\n",
      "loss :  50.02773666381836\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "=================\n",
      "[185. 150. 246. 184. 110. 202. 336.  69.  69.  87.  66. 164. 265. 198.\n",
      " 248. 171. 102. 182. 262. 233. 151. 275. 230.  39.  42. 122.  81.  31.\n",
      " 156. 161.  80. 215. 310. 163. 265.  84.  54. 137. 248.  72. 248.  59.\n",
      "  97.  61.  72. 296.  55.  75.  53. 173. 158.  96. 140. 186.  93. 123.\n",
      " 237. 138. 292.  78. 182. 127. 321. 109. 212.  45.  96. 109.  89.  96.\n",
      "  60.  51. 200. 265.  68.  91. 172. 115. 125.  53.  63. 259. 214. 195.\n",
      " 258. 235. 173.  59. 219. 170.  77.  49.  66. 144. 113. 233. 162. 121.\n",
      "  88. 302. 128.  52. 178.  90. 164. 135. 103. 200. 178. 261.  64.  59.\n",
      "  79.  47. 107.  39. 151. 104. 217. 232.  55. 245. 131.  64. 222. 249.\n",
      " 128. 293. 138. 273. 158. 168. 103.]\n",
      "[[214.36095 ]\n",
      " [ 86.18584 ]\n",
      " [279.46112 ]\n",
      " [227.92226 ]\n",
      " [235.5183  ]\n",
      " [215.34781 ]\n",
      " [296.58383 ]\n",
      " [ 90.42236 ]\n",
      " [203.7109  ]\n",
      " [109.70173 ]\n",
      " [134.4972  ]\n",
      " [213.12964 ]\n",
      " [202.51602 ]\n",
      " [301.86945 ]\n",
      " [241.9408  ]\n",
      " [215.70335 ]\n",
      " [ 73.3843  ]\n",
      " [168.4776  ]\n",
      " [267.82816 ]\n",
      " [278.5733  ]\n",
      " [146.59619 ]\n",
      " [294.06186 ]\n",
      " [ 84.523186]\n",
      " [ 72.01053 ]\n",
      " [ 83.94876 ]\n",
      " [207.881   ]\n",
      " [ 86.15214 ]\n",
      " [ 73.99102 ]\n",
      " [213.89014 ]\n",
      " [136.13312 ]\n",
      " [131.37082 ]\n",
      " [257.2819  ]\n",
      " [101.009   ]\n",
      " [291.52777 ]\n",
      " [200.08946 ]\n",
      " [ 75.72438 ]\n",
      " [ 72.01053 ]\n",
      " [137.13196 ]\n",
      " [240.47516 ]\n",
      " [ 76.89266 ]\n",
      " [231.59712 ]\n",
      " [ 76.973076]\n",
      " [231.26276 ]\n",
      " [107.74208 ]\n",
      " [ 80.25067 ]\n",
      " [301.62082 ]\n",
      " [180.52858 ]\n",
      " [ 74.94301 ]\n",
      " [ 72.01053 ]\n",
      " [261.6837  ]\n",
      " [194.7982  ]\n",
      " [102.70192 ]\n",
      " [ 97.33852 ]\n",
      " [214.75227 ]\n",
      " [127.84275 ]\n",
      " [200.13353 ]\n",
      " [220.55771 ]\n",
      " [135.24062 ]\n",
      " [216.44258 ]\n",
      " [294.21588 ]\n",
      " [ 88.60366 ]\n",
      " [ 83.674866]\n",
      " [307.8385  ]\n",
      " [136.97293 ]\n",
      " [233.38344 ]\n",
      " [ 72.01053 ]\n",
      " [ 81.09815 ]\n",
      " [ 96.762794]\n",
      " [152.96231 ]\n",
      " [ 81.93032 ]\n",
      " [ 69.06385 ]\n",
      " [ 72.01053 ]\n",
      " [212.8594  ]\n",
      " [266.58673 ]\n",
      " [ 94.39284 ]\n",
      " [196.22226 ]\n",
      " [188.50273 ]\n",
      " [166.20679 ]\n",
      " [ 80.34908 ]\n",
      " [ 78.75686 ]\n",
      " [ 82.43032 ]\n",
      " [117.829124]\n",
      " [138.1558  ]\n",
      " [266.25766 ]\n",
      " [285.23386 ]\n",
      " [213.94662 ]\n",
      " [167.54387 ]\n",
      " [ 79.893005]\n",
      " [110.03611 ]\n",
      " [184.34541 ]\n",
      " [134.53964 ]\n",
      " [ 72.01053 ]\n",
      " [242.57976 ]\n",
      " [181.95804 ]\n",
      " [209.15549 ]\n",
      " [251.38821 ]\n",
      " [116.612724]\n",
      " [171.55032 ]\n",
      " [ 69.59713 ]\n",
      " [183.35222 ]\n",
      " [ 70.215866]\n",
      " [ 74.65864 ]\n",
      " [124.28847 ]\n",
      " [189.82416 ]\n",
      " [170.41347 ]\n",
      " [ 72.01053 ]\n",
      " [176.91704 ]\n",
      " [149.31674 ]\n",
      " [266.97247 ]\n",
      " [167.82193 ]\n",
      " [ 79.28141 ]\n",
      " [165.24889 ]\n",
      " [125.694435]\n",
      " [ 76.906845]\n",
      " [ 86.37245 ]\n",
      " [ 95.11561 ]\n",
      " [276.74643 ]\n",
      " [ 82.28519 ]\n",
      " [255.73532 ]\n",
      " [277.3816  ]\n",
      " [135.69594 ]\n",
      " [132.22011 ]\n",
      " [113.1209  ]\n",
      " [ 67.01288 ]\n",
      " [272.58673 ]\n",
      " [249.26105 ]\n",
      " [293.53506 ]\n",
      " [206.282   ]\n",
      " [ 72.01053 ]\n",
      " [165.57088 ]\n",
      " [140.84273 ]\n",
      " [119.577896]\n",
      " [137.73882 ]]\n",
      "=================\n",
      "R2 :  0.25049437187057133\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.8567\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.1712\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.9407\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.5132\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.1382\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.8309\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.4446\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.3056\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.5517\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.7170\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.5535\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.7647\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.1251\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.2608\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.4348\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.9864\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.2121\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 23.8984\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.5595\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.9860\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.3586\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.7381\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 26.3843\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.9478\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.7188\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.4616\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.2092\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.8975\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.1286\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.7928\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.7400\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.1565\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.7409\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.9357\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.1404\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.8754\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.5755\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.8183\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 23.6000\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.3770\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.9807\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.7055\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.2672\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.5336\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.0813\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.9602\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.9048\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.3015\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.6803\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 22.9890\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.6935\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.9245\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.0856\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.4944\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.2865\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.5694\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.2083\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.8240\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.6620\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.2298\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.2269\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.2034\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.0581\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.5736\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.0912\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.7691\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.9185\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.6066\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.9161\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.7817\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.2195\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.5327\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 23.1229\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.0898\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.9440\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.6202\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.4020\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.2358\n",
      "Epoch 79/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 110us/step - loss: 24.2358\n",
      "5/5 [==============================] - 0s 997us/step - loss: 54.0397\n",
      "loss :  54.03965377807617\n",
      "5/5 [==============================] - 0s 929us/step\n",
      "=================\n",
      "[185. 150. 246. 184. 110. 202. 336.  69.  69.  87.  66. 164. 265. 198.\n",
      " 248. 171. 102. 182. 262. 233. 151. 275. 230.  39.  42. 122.  81.  31.\n",
      " 156. 161.  80. 215. 310. 163. 265.  84.  54. 137. 248.  72. 248.  59.\n",
      "  97.  61.  72. 296.  55.  75.  53. 173. 158.  96. 140. 186.  93. 123.\n",
      " 237. 138. 292.  78. 182. 127. 321. 109. 212.  45.  96. 109.  89.  96.\n",
      "  60.  51. 200. 265.  68.  91. 172. 115. 125.  53.  63. 259. 214. 195.\n",
      " 258. 235. 173.  59. 219. 170.  77.  49.  66. 144. 113. 233. 162. 121.\n",
      "  88. 302. 128.  52. 178.  90. 164. 135. 103. 200. 178. 261.  64.  59.\n",
      "  79.  47. 107.  39. 151. 104. 217. 232.  55. 245. 131.  64. 222. 249.\n",
      " 128. 293. 138. 273. 158. 168. 103.]\n",
      "[[225.77892 ]\n",
      " [ 77.861946]\n",
      " [294.98462 ]\n",
      " [264.8751  ]\n",
      " [239.05261 ]\n",
      " [218.13281 ]\n",
      " [345.66327 ]\n",
      " [ 98.21716 ]\n",
      " [176.37744 ]\n",
      " [132.35309 ]\n",
      " [150.56967 ]\n",
      " [229.04672 ]\n",
      " [217.9751  ]\n",
      " [330.6404  ]\n",
      " [256.27545 ]\n",
      " [220.48161 ]\n",
      " [ 74.42785 ]\n",
      " [205.83769 ]\n",
      " [224.35162 ]\n",
      " [302.54636 ]\n",
      " [156.8443  ]\n",
      " [314.27524 ]\n",
      " [ 79.5356  ]\n",
      " [ 75.91952 ]\n",
      " [ 78.4316  ]\n",
      " [177.3627  ]\n",
      " [ 82.292404]\n",
      " [ 70.25615 ]\n",
      " [229.87227 ]\n",
      " [145.56088 ]\n",
      " [132.1038  ]\n",
      " [284.76828 ]\n",
      " [112.62277 ]\n",
      " [307.8221  ]\n",
      " [221.66394 ]\n",
      " [ 77.93804 ]\n",
      " [ 72.7761  ]\n",
      " [160.7174  ]\n",
      " [265.6617  ]\n",
      " [ 77.122955]\n",
      " [247.6255  ]\n",
      " [ 84.24191 ]\n",
      " [264.5887  ]\n",
      " [108.28141 ]\n",
      " [ 74.978424]\n",
      " [328.07556 ]\n",
      " [190.99954 ]\n",
      " [ 71.69161 ]\n",
      " [ 69.4918  ]\n",
      " [289.15808 ]\n",
      " [202.57654 ]\n",
      " [110.64299 ]\n",
      " [ 93.46498 ]\n",
      " [212.84355 ]\n",
      " [104.62378 ]\n",
      " [220.88283 ]\n",
      " [243.98886 ]\n",
      " [133.07713 ]\n",
      " [223.55399 ]\n",
      " [291.41388 ]\n",
      " [ 91.19346 ]\n",
      " [ 77.93626 ]\n",
      " [359.47305 ]\n",
      " [141.78696 ]\n",
      " [229.36736 ]\n",
      " [ 75.91952 ]\n",
      " [ 98.707855]\n",
      " [ 87.51367 ]\n",
      " [220.22842 ]\n",
      " [ 93.53258 ]\n",
      " [ 87.74231 ]\n",
      " [ 77.81965 ]\n",
      " [220.41537 ]\n",
      " [300.82755 ]\n",
      " [ 98.96326 ]\n",
      " [148.98819 ]\n",
      " [203.34074 ]\n",
      " [133.30762 ]\n",
      " [ 75.6855  ]\n",
      " [ 83.04427 ]\n",
      " [ 72.62537 ]\n",
      " [117.86265 ]\n",
      " [143.93912 ]\n",
      " [288.9055  ]\n",
      " [306.36768 ]\n",
      " [216.35303 ]\n",
      " [125.20738 ]\n",
      " [ 94.083374]\n",
      " [124.76607 ]\n",
      " [194.51982 ]\n",
      " [134.6564  ]\n",
      " [ 75.91952 ]\n",
      " [262.29108 ]\n",
      " [173.63156 ]\n",
      " [220.62827 ]\n",
      " [274.89395 ]\n",
      " [107.498085]\n",
      " [186.43161 ]\n",
      " [ 62.906586]\n",
      " [178.87112 ]\n",
      " [ 60.141552]\n",
      " [ 80.5565  ]\n",
      " [108.33826 ]\n",
      " [200.72836 ]\n",
      " [167.82059 ]\n",
      " [ 75.91952 ]\n",
      " [180.87498 ]\n",
      " [154.50858 ]\n",
      " [288.49863 ]\n",
      " [150.78746 ]\n",
      " [ 71.284065]\n",
      " [156.12102 ]\n",
      " [121.406235]\n",
      " [ 79.22126 ]\n",
      " [ 89.38248 ]\n",
      " [ 95.3902  ]\n",
      " [299.5131  ]\n",
      " [ 86.01654 ]\n",
      " [237.32233 ]\n",
      " [271.74756 ]\n",
      " [118.657585]\n",
      " [154.52069 ]\n",
      " [115.33901 ]\n",
      " [ 59.699966]\n",
      " [181.67264 ]\n",
      " [256.93832 ]\n",
      " [313.12405 ]\n",
      " [231.83444 ]\n",
      " [ 75.91952 ]\n",
      " [170.04327 ]\n",
      " [141.87349 ]\n",
      " [117.971115]\n",
      " [127.920334]]\n",
      "=================\n",
      "R2 :  0.15521436225330687\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.1525\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.5252\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.5191\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.9638\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.6658\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.1848\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.5710\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.0929\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.5624\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.5886\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.8593\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.4087\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.4029\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.9827\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.8704\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.4702\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.4197\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.8161\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.6868\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.8741\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.4456\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.2473\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 25.1388\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.3955\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.9190\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.1651\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.4571\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.1138\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.7726\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.9537\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.3076\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.0400\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.0976\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.5448\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.3277\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.9727\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.5062\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.8461\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.1590\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.1061\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.1215\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.0394\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.6555\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.8935\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.8188\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.0019\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.6978\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.5222\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.0386\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.6959\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.2773\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.4374\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.4218\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.6784\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.9381\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.3313\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.6430\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.6681\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.8457\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.5729\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.1605\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.4685\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.1910\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.5991\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.5780\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.7734\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.9303\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.7824\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.2331\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.4398\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.3561\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.1444\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.2099\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.6830\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.6888\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.4157\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.4255\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.6648\n",
      "Epoch 79/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 109us/step - loss: 22.6648\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 50.3743\n",
      "loss :  50.37433624267578\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "=================\n",
      "[185. 150. 246. 184. 110. 202. 336.  69.  69.  87.  66. 164. 265. 198.\n",
      " 248. 171. 102. 182. 262. 233. 151. 275. 230.  39.  42. 122.  81.  31.\n",
      " 156. 161.  80. 215. 310. 163. 265.  84.  54. 137. 248.  72. 248.  59.\n",
      "  97.  61.  72. 296.  55.  75.  53. 173. 158.  96. 140. 186.  93. 123.\n",
      " 237. 138. 292.  78. 182. 127. 321. 109. 212.  45.  96. 109.  89.  96.\n",
      "  60.  51. 200. 265.  68.  91. 172. 115. 125.  53.  63. 259. 214. 195.\n",
      " 258. 235. 173.  59. 219. 170.  77.  49.  66. 144. 113. 233. 162. 121.\n",
      "  88. 302. 128.  52. 178.  90. 164. 135. 103. 200. 178. 261.  64.  59.\n",
      "  79.  47. 107.  39. 151. 104. 217. 232.  55. 245. 131.  64. 222. 249.\n",
      " 128. 293. 138. 273. 158. 168. 103.]\n",
      "[[218.76666 ]\n",
      " [ 71.42777 ]\n",
      " [277.78677 ]\n",
      " [189.33174 ]\n",
      " [221.3402  ]\n",
      " [219.82515 ]\n",
      " [301.5858  ]\n",
      " [ 83.851395]\n",
      " [165.47086 ]\n",
      " [105.02304 ]\n",
      " [140.16344 ]\n",
      " [217.8267  ]\n",
      " [201.38803 ]\n",
      " [313.5339  ]\n",
      " [256.66168 ]\n",
      " [215.93665 ]\n",
      " [ 66.50542 ]\n",
      " [ 87.290985]\n",
      " [244.34843 ]\n",
      " [285.15808 ]\n",
      " [160.22981 ]\n",
      " [296.05582 ]\n",
      " [ 72.98355 ]\n",
      " [ 68.41541 ]\n",
      " [ 67.703026]\n",
      " [164.32384 ]\n",
      " [ 80.40513 ]\n",
      " [ 55.536278]\n",
      " [211.7143  ]\n",
      " [141.92421 ]\n",
      " [132.54135 ]\n",
      " [277.53198 ]\n",
      " [ 93.444176]\n",
      " [289.7654  ]\n",
      " [214.77898 ]\n",
      " [ 68.892586]\n",
      " [ 70.34525 ]\n",
      " [122.60577 ]\n",
      " [263.42642 ]\n",
      " [ 67.13824 ]\n",
      " [240.55754 ]\n",
      " [ 81.79225 ]\n",
      " [173.33388 ]\n",
      " [103.46026 ]\n",
      " [ 74.11729 ]\n",
      " [299.00928 ]\n",
      " [180.0012  ]\n",
      " [ 63.693985]\n",
      " [ 57.787983]\n",
      " [267.54428 ]\n",
      " [196.87648 ]\n",
      " [107.806854]\n",
      " [ 89.469604]\n",
      " [211.43214 ]\n",
      " [ 98.198425]\n",
      " [216.17764 ]\n",
      " [186.40686 ]\n",
      " [123.865364]\n",
      " [222.3441  ]\n",
      " [213.6004  ]\n",
      " [ 77.950096]\n",
      " [ 93.101425]\n",
      " [310.12503 ]\n",
      " [117.048706]\n",
      " [221.23514 ]\n",
      " [ 70.34525 ]\n",
      " [ 88.263756]\n",
      " [ 72.807205]\n",
      " [204.67729 ]\n",
      " [ 86.454445]\n",
      " [ 89.026924]\n",
      " [ 70.34525 ]\n",
      " [224.97426 ]\n",
      " [300.0065  ]\n",
      " [ 94.08402 ]\n",
      " [142.00676 ]\n",
      " [166.98206 ]\n",
      " [126.158775]\n",
      " [ 79.05614 ]\n",
      " [ 74.04189 ]\n",
      " [ 56.51693 ]\n",
      " [115.11492 ]\n",
      " [141.4016  ]\n",
      " [292.32013 ]\n",
      " [297.1065  ]\n",
      " [213.74953 ]\n",
      " [103.62561 ]\n",
      " [ 89.943054]\n",
      " [ 99.12685 ]\n",
      " [196.08383 ]\n",
      " [154.81703 ]\n",
      " [ 70.34525 ]\n",
      " [261.2845  ]\n",
      " [165.28221 ]\n",
      " [213.17632 ]\n",
      " [269.45352 ]\n",
      " [ 96.15099 ]\n",
      " [167.37369 ]\n",
      " [ 59.29373 ]\n",
      " [160.53773 ]\n",
      " [ 53.702652]\n",
      " [ 70.34525 ]\n",
      " [122.00244 ]\n",
      " [196.71704 ]\n",
      " [146.35416 ]\n",
      " [ 70.34525 ]\n",
      " [150.99435 ]\n",
      " [120.93476 ]\n",
      " [282.66565 ]\n",
      " [102.475494]\n",
      " [ 74.539764]\n",
      " [137.75012 ]\n",
      " [129.61421 ]\n",
      " [ 65.86751 ]\n",
      " [ 86.48463 ]\n",
      " [ 88.41455 ]\n",
      " [286.8254  ]\n",
      " [ 80.739784]\n",
      " [232.99315 ]\n",
      " [271.68256 ]\n",
      " [ 85.8768  ]\n",
      " [153.82475 ]\n",
      " [120.8406  ]\n",
      " [ 53.97384 ]\n",
      " [191.1806  ]\n",
      " [246.564   ]\n",
      " [288.048   ]\n",
      " [200.4788  ]\n",
      " [ 70.34525 ]\n",
      " [166.45311 ]\n",
      " [137.11163 ]\n",
      " [111.67086 ]\n",
      " [ 92.290596]]\n",
      "=================\n",
      "R2 :  0.24521273799139232\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.8832\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.9881\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.1743\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.9999\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.0432\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.3395\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.1099\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.6029\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.5906\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.1156\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.3389\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.4261\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 20.8243\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.8809\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.2385\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.4259\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.9174\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.8125\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.1685\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.2372\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.5239\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.9226\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.8505\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.8796\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.3855\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.5212\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.3275\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.1365\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.7307\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.4312\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.0016\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.1893\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.6247\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.3180\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.3428\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.3902\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.2480\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.5503\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.4079\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.6101\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 21.3830\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.5105\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.2485\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.5094\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.5880\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.4959\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.6073\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.4907\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.3949\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 21.1049\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.3112\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.8878\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.2905\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.4427\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.5247\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.3338\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.5411\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.4631\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.7064\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.8986\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.7706\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.6288\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.6942\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.1474\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.6873\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.8107\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.5624\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.4874\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.4550\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 19.3781\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.2056\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.2904\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.2209\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.0199\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.9883\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.7613\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.1192\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.9164\n",
      "Epoch 79/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 100us/step - loss: 21.9164\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 48.3314\n",
      "loss :  48.331356048583984\n",
      "5/5 [==============================] - 0s 751us/step\n",
      "=================\n",
      "[185. 150. 246. 184. 110. 202. 336.  69.  69.  87.  66. 164. 265. 198.\n",
      " 248. 171. 102. 182. 262. 233. 151. 275. 230.  39.  42. 122.  81.  31.\n",
      " 156. 161.  80. 215. 310. 163. 265.  84.  54. 137. 248.  72. 248.  59.\n",
      "  97.  61.  72. 296.  55.  75.  53. 173. 158.  96. 140. 186.  93. 123.\n",
      " 237. 138. 292.  78. 182. 127. 321. 109. 212.  45.  96. 109.  89.  96.\n",
      "  60.  51. 200. 265.  68.  91. 172. 115. 125.  53.  63. 259. 214. 195.\n",
      " 258. 235. 173.  59. 219. 170.  77.  49.  66. 144. 113. 233. 162. 121.\n",
      "  88. 302. 128.  52. 178.  90. 164. 135. 103. 200. 178. 261.  64.  59.\n",
      "  79.  47. 107.  39. 151. 104. 217. 232.  55. 245. 131.  64. 222. 249.\n",
      " 128. 293. 138. 273. 158. 168. 103.]\n",
      "[[211.51144 ]\n",
      " [ 75.82613 ]\n",
      " [274.29926 ]\n",
      " [221.14575 ]\n",
      " [231.94478 ]\n",
      " [206.65353 ]\n",
      " [303.9242  ]\n",
      " [ 84.91465 ]\n",
      " [191.83748 ]\n",
      " [140.88081 ]\n",
      " [158.3539  ]\n",
      " [227.11186 ]\n",
      " [210.3428  ]\n",
      " [301.89282 ]\n",
      " [245.0975  ]\n",
      " [205.87178 ]\n",
      " [ 78.79195 ]\n",
      " [215.02948 ]\n",
      " [253.31644 ]\n",
      " [279.5978  ]\n",
      " [131.72102 ]\n",
      " [278.00943 ]\n",
      " [ 75.52475 ]\n",
      " [ 74.83681 ]\n",
      " [ 74.06215 ]\n",
      " [193.46004 ]\n",
      " [ 70.924965]\n",
      " [ 53.392387]\n",
      " [210.46457 ]\n",
      " [151.38266 ]\n",
      " [138.59145 ]\n",
      " [227.64545 ]\n",
      " [103.76578 ]\n",
      " [271.32    ]\n",
      " [211.87839 ]\n",
      " [ 71.127556]\n",
      " [ 74.83681 ]\n",
      " [188.1841  ]\n",
      " [254.16876 ]\n",
      " [ 61.8556  ]\n",
      " [228.58092 ]\n",
      " [ 79.25993 ]\n",
      " [209.21341 ]\n",
      " [119.076904]\n",
      " [ 59.6096  ]\n",
      " [292.96875 ]\n",
      " [147.51593 ]\n",
      " [ 78.23245 ]\n",
      " [ 59.61576 ]\n",
      " [256.3702  ]\n",
      " [167.40434 ]\n",
      " [103.02495 ]\n",
      " [ 90.40622 ]\n",
      " [193.10951 ]\n",
      " [120.43942 ]\n",
      " [200.52814 ]\n",
      " [253.12152 ]\n",
      " [128.36353 ]\n",
      " [199.6416  ]\n",
      " [275.25272 ]\n",
      " [ 85.84526 ]\n",
      " [116.39211 ]\n",
      " [309.449   ]\n",
      " [128.96933 ]\n",
      " [218.62172 ]\n",
      " [ 74.83681 ]\n",
      " [ 84.410034]\n",
      " [ 80.11372 ]\n",
      " [132.15929 ]\n",
      " [ 81.63364 ]\n",
      " [ 70.61736 ]\n",
      " [ 74.83681 ]\n",
      " [180.09386 ]\n",
      " [273.69516 ]\n",
      " [ 96.16356 ]\n",
      " [189.94135 ]\n",
      " [147.1463  ]\n",
      " [112.46883 ]\n",
      " [122.42312 ]\n",
      " [ 83.91534 ]\n",
      " [ 71.56965 ]\n",
      " [120.204   ]\n",
      " [108.51336 ]\n",
      " [259.1126  ]\n",
      " [280.26047 ]\n",
      " [194.57709 ]\n",
      " [124.859406]\n",
      " [ 88.71781 ]\n",
      " [131.02017 ]\n",
      " [185.81786 ]\n",
      " [134.4454  ]\n",
      " [ 74.83681 ]\n",
      " [250.34113 ]\n",
      " [129.31003 ]\n",
      " [210.5724  ]\n",
      " [250.27081 ]\n",
      " [131.87677 ]\n",
      " [162.76584 ]\n",
      " [ 54.658413]\n",
      " [159.68198 ]\n",
      " [ 53.202873]\n",
      " [ 74.83681 ]\n",
      " [107.06001 ]\n",
      " [191.48405 ]\n",
      " [131.43979 ]\n",
      " [ 68.63979 ]\n",
      " [179.42136 ]\n",
      " [132.55405 ]\n",
      " [268.00467 ]\n",
      " [190.7104  ]\n",
      " [ 88.85941 ]\n",
      " [176.31999 ]\n",
      " [111.37892 ]\n",
      " [ 73.58608 ]\n",
      " [ 85.11004 ]\n",
      " [ 86.03248 ]\n",
      " [269.97775 ]\n",
      " [102.77138 ]\n",
      " [256.15048 ]\n",
      " [283.68658 ]\n",
      " [ 92.69858 ]\n",
      " [185.52437 ]\n",
      " [140.39711 ]\n",
      " [ 52.54167 ]\n",
      " [191.81236 ]\n",
      " [231.32819 ]\n",
      " [277.1753  ]\n",
      " [175.30368 ]\n",
      " [ 74.83681 ]\n",
      " [162.32037 ]\n",
      " [133.6083  ]\n",
      " [113.64242 ]\n",
      " [123.54451 ]]\n",
      "=================\n",
      "R2 :  0.2915445926936665\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.2521\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.6146\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.9290\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.0458\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.4118\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.8617\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.3585\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.4758\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.4461\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.1754\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.4110\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.7381\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.5378\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.1008\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.9708\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.2268\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.8628\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.3119\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.2044\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.6221\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.0026\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.4232\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.4740\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.0262\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.5925\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.8303\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.7141\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.4593\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.8501\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.7023\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.4546\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.3592\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.5634\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.0065\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.4229\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.0285\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.3476\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.6611\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.4235\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.6466\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.7019\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.6412\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.3206\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.3077\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.2980\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.8291\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 20.0436\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.3048\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.3779\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.3967\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.3518\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.5954\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.1474\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.5216\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.1780\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.3311\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.3204\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.5153\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.4160\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.1411\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.5966\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.5650\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.4994\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.9332\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.4039\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.9160\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.9563\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.3885\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.3977\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.4776\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.8606\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.4667\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.8509\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.0025\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.3238\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.4324\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.8997\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.1621\n",
      "Epoch 79/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 100us/step - loss: 20.1621\n",
      "5/5 [==============================] - 0s 997us/step - loss: 50.5820\n",
      "loss :  50.58198547363281\n",
      "5/5 [==============================] - 0s 998us/step\n",
      "=================\n",
      "[185. 150. 246. 184. 110. 202. 336.  69.  69.  87.  66. 164. 265. 198.\n",
      " 248. 171. 102. 182. 262. 233. 151. 275. 230.  39.  42. 122.  81.  31.\n",
      " 156. 161.  80. 215. 310. 163. 265.  84.  54. 137. 248.  72. 248.  59.\n",
      "  97.  61.  72. 296.  55.  75.  53. 173. 158.  96. 140. 186.  93. 123.\n",
      " 237. 138. 292.  78. 182. 127. 321. 109. 212.  45.  96. 109.  89.  96.\n",
      "  60.  51. 200. 265.  68.  91. 172. 115. 125.  53.  63. 259. 214. 195.\n",
      " 258. 235. 173.  59. 219. 170.  77.  49.  66. 144. 113. 233. 162. 121.\n",
      "  88. 302. 128.  52. 178.  90. 164. 135. 103. 200. 178. 261.  64.  59.\n",
      "  79.  47. 107.  39. 151. 104. 217. 232.  55. 245. 131.  64. 222. 249.\n",
      " 128. 293. 138. 273. 158. 168. 103.]\n",
      "[[215.43967 ]\n",
      " [ 62.88458 ]\n",
      " [296.48218 ]\n",
      " [224.02405 ]\n",
      " [230.16794 ]\n",
      " [217.47447 ]\n",
      " [323.32672 ]\n",
      " [ 60.044594]\n",
      " [186.55983 ]\n",
      " [110.77951 ]\n",
      " [150.2441  ]\n",
      " [236.33514 ]\n",
      " [223.91559 ]\n",
      " [327.64227 ]\n",
      " [253.51085 ]\n",
      " [211.10065 ]\n",
      " [ 57.561543]\n",
      " [205.08035 ]\n",
      " [281.35974 ]\n",
      " [332.2767  ]\n",
      " [156.0845  ]\n",
      " [290.75616 ]\n",
      " [ 78.003815]\n",
      " [ 70.57298 ]\n",
      " [ 74.22354 ]\n",
      " [169.13264 ]\n",
      " [ 64.69772 ]\n",
      " [ 58.09399 ]\n",
      " [215.5055  ]\n",
      " [184.64557 ]\n",
      " [124.322464]\n",
      " [269.9676  ]\n",
      " [ 86.778656]\n",
      " [277.69662 ]\n",
      " [234.31926 ]\n",
      " [ 68.69872 ]\n",
      " [ 70.65863 ]\n",
      " [161.39394 ]\n",
      " [261.65552 ]\n",
      " [ 73.80702 ]\n",
      " [235.58904 ]\n",
      " [ 87.60225 ]\n",
      " [228.99696 ]\n",
      " [131.56087 ]\n",
      " [ 66.22596 ]\n",
      " [309.26828 ]\n",
      " [172.52055 ]\n",
      " [ 64.487465]\n",
      " [ 63.381195]\n",
      " [280.9005  ]\n",
      " [206.34813 ]\n",
      " [109.055664]\n",
      " [100.14125 ]\n",
      " [217.82903 ]\n",
      " [101.558624]\n",
      " [212.42114 ]\n",
      " [248.01279 ]\n",
      " [131.41939 ]\n",
      " [215.06842 ]\n",
      " [291.92822 ]\n",
      " [ 89.1558  ]\n",
      " [123.281006]\n",
      " [330.8579  ]\n",
      " [166.90459 ]\n",
      " [231.3421  ]\n",
      " [ 70.57298 ]\n",
      " [ 93.8482  ]\n",
      " [ 86.0734  ]\n",
      " [114.42221 ]\n",
      " [ 90.1176  ]\n",
      " [102.98673 ]\n",
      " [ 70.57298 ]\n",
      " [219.96312 ]\n",
      " [293.55365 ]\n",
      " [ 87.5146  ]\n",
      " [199.24666 ]\n",
      " [181.80376 ]\n",
      " [ 72.576035]\n",
      " [117.52704 ]\n",
      " [ 82.44481 ]\n",
      " [ 60.80288 ]\n",
      " [115.730804]\n",
      " [132.10835 ]\n",
      " [277.9376  ]\n",
      " [298.26425 ]\n",
      " [202.38167 ]\n",
      " [116.678444]\n",
      " [ 93.89106 ]\n",
      " [111.308716]\n",
      " [192.64937 ]\n",
      " [123.30225 ]\n",
      " [ 70.57298 ]\n",
      " [259.4823  ]\n",
      " [155.25618 ]\n",
      " [210.25296 ]\n",
      " [261.51447 ]\n",
      " [113.35817 ]\n",
      " [179.27278 ]\n",
      " [ 61.010258]\n",
      " [185.6799  ]\n",
      " [ 52.712994]\n",
      " [ 70.57298 ]\n",
      " [199.89296 ]\n",
      " [205.00085 ]\n",
      " [127.52713 ]\n",
      " [ 70.57298 ]\n",
      " [215.06693 ]\n",
      " [127.934555]\n",
      " [271.9256  ]\n",
      " [162.25372 ]\n",
      " [101.51558 ]\n",
      " [133.3658  ]\n",
      " [133.33138 ]\n",
      " [ 65.352165]\n",
      " [ 78.661194]\n",
      " [ 71.18803 ]\n",
      " [279.5893  ]\n",
      " [ 83.32634 ]\n",
      " [250.97743 ]\n",
      " [266.95108 ]\n",
      " [112.05948 ]\n",
      " [231.3181  ]\n",
      " [130.08595 ]\n",
      " [ 52.810986]\n",
      " [179.76674 ]\n",
      " [241.93782 ]\n",
      " [293.8888  ]\n",
      " [220.55016 ]\n",
      " [ 70.57298 ]\n",
      " [175.27577 ]\n",
      " [128.52138 ]\n",
      " [101.84241 ]\n",
      " [116.2371  ]]\n",
      "=================\n",
      "R2 :  0.22689045175758316\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.6946\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.1877\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 21.5717\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.8920\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.7314\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.2583\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.4244\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.9220\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.8052\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.0963\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.4274\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.5103\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.5931\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.4168\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.5208\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.1357\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.5483\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.9512\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.3120\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.0654\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.3005\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.3464\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.0565\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.5171\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.3665\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.5004\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.9678\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.0012\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.6452\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.6293\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.4985\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.7980\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.0511\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.8900\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.5822\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.1798\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.5187\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 22.0200\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.4837\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.8505\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.5310\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.4628\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.5097\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.1825\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.3400\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.6053\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.0724\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.0710\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.3650\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.0722\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.3780\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.5168\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.0164\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.5690\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.7504\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.9084\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.7527\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.3560\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.4872\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.8774\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.3588\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.0353\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 19.9674\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.0417\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.8363\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.2469\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.9914\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.2980\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.1560\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.4327\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.5644\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.5589\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.2851\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.7634\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.4029\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.7151\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.6907\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.2396\n",
      "Epoch 79/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 100us/step - loss: 19.2396\n",
      "5/5 [==============================] - 0s 997us/step - loss: 47.8789\n",
      "loss :  47.87887191772461\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "=================\n",
      "[185. 150. 246. 184. 110. 202. 336.  69.  69.  87.  66. 164. 265. 198.\n",
      " 248. 171. 102. 182. 262. 233. 151. 275. 230.  39.  42. 122.  81.  31.\n",
      " 156. 161.  80. 215. 310. 163. 265.  84.  54. 137. 248.  72. 248.  59.\n",
      "  97.  61.  72. 296.  55.  75.  53. 173. 158.  96. 140. 186.  93. 123.\n",
      " 237. 138. 292.  78. 182. 127. 321. 109. 212.  45.  96. 109.  89.  96.\n",
      "  60.  51. 200. 265.  68.  91. 172. 115. 125.  53.  63. 259. 214. 195.\n",
      " 258. 235. 173.  59. 219. 170.  77.  49.  66. 144. 113. 233. 162. 121.\n",
      "  88. 302. 128.  52. 178.  90. 164. 135. 103. 200. 178. 261.  64.  59.\n",
      "  79.  47. 107.  39. 151. 104. 217. 232.  55. 245. 131.  64. 222. 249.\n",
      " 128. 293. 138. 273. 158. 168. 103.]\n",
      "[[197.29585 ]\n",
      " [ 63.622944]\n",
      " [285.30292 ]\n",
      " [208.70836 ]\n",
      " [207.9021  ]\n",
      " [216.51321 ]\n",
      " [274.5649  ]\n",
      " [ 96.31963 ]\n",
      " [165.51414 ]\n",
      " [113.63681 ]\n",
      " [147.09026 ]\n",
      " [222.77292 ]\n",
      " [214.07483 ]\n",
      " [306.08017 ]\n",
      " [243.39526 ]\n",
      " [194.91322 ]\n",
      " [ 79.05324 ]\n",
      " [110.29347 ]\n",
      " [271.69318 ]\n",
      " [305.46472 ]\n",
      " [152.75394 ]\n",
      " [261.2596  ]\n",
      " [ 66.59667 ]\n",
      " [ 68.148636]\n",
      " [ 67.82659 ]\n",
      " [175.76906 ]\n",
      " [ 60.266518]\n",
      " [ 51.80726 ]\n",
      " [193.62837 ]\n",
      " [185.35751 ]\n",
      " [ 83.041145]\n",
      " [241.4009  ]\n",
      " [ 99.46809 ]\n",
      " [251.9631  ]\n",
      " [221.55107 ]\n",
      " [ 66.83716 ]\n",
      " [ 72.643166]\n",
      " [142.25359 ]\n",
      " [250.76062 ]\n",
      " [ 70.23724 ]\n",
      " [209.33682 ]\n",
      " [ 83.73038 ]\n",
      " [234.9379  ]\n",
      " [117.564   ]\n",
      " [ 62.449066]\n",
      " [275.19052 ]\n",
      " [164.76819 ]\n",
      " [ 65.184685]\n",
      " [ 55.862793]\n",
      " [253.95609 ]\n",
      " [189.1859  ]\n",
      " [122.571045]\n",
      " [ 99.18271 ]\n",
      " [210.29956 ]\n",
      " [ 87.45594 ]\n",
      " [199.7329  ]\n",
      " [272.0488  ]\n",
      " [117.12162 ]\n",
      " [200.5275  ]\n",
      " [273.6845  ]\n",
      " [ 90.48883 ]\n",
      " [ 96.33484 ]\n",
      " [282.44543 ]\n",
      " [133.98567 ]\n",
      " [219.29141 ]\n",
      " [ 67.88835 ]\n",
      " [ 84.383354]\n",
      " [ 89.79313 ]\n",
      " [ 96.2538  ]\n",
      " [ 91.79363 ]\n",
      " [ 85.06921 ]\n",
      " [ 72.57152 ]\n",
      " [210.78947 ]\n",
      " [270.66162 ]\n",
      " [ 70.766556]\n",
      " [192.85962 ]\n",
      " [175.06274 ]\n",
      " [101.55471 ]\n",
      " [109.52119 ]\n",
      " [ 78.095116]\n",
      " [ 66.35894 ]\n",
      " [110.773026]\n",
      " [130.50392 ]\n",
      " [263.52536 ]\n",
      " [280.2201  ]\n",
      " [188.7709  ]\n",
      " [115.976105]\n",
      " [ 85.84137 ]\n",
      " [126.73175 ]\n",
      " [185.8951  ]\n",
      " [130.83939 ]\n",
      " [ 65.682205]\n",
      " [243.83278 ]\n",
      " [130.30788 ]\n",
      " [202.42421 ]\n",
      " [244.15955 ]\n",
      " [ 96.1625  ]\n",
      " [165.2861  ]\n",
      " [ 62.912777]\n",
      " [172.46533 ]\n",
      " [ 51.140762]\n",
      " [ 70.011826]\n",
      " [ 95.299805]\n",
      " [195.59645 ]\n",
      " [134.98212 ]\n",
      " [ 67.54314 ]\n",
      " [196.89209 ]\n",
      " [115.14953 ]\n",
      " [244.55438 ]\n",
      " [144.4727  ]\n",
      " [ 52.4396  ]\n",
      " [103.10962 ]\n",
      " [124.4714  ]\n",
      " [ 71.57266 ]\n",
      " [ 77.73877 ]\n",
      " [ 65.290436]\n",
      " [253.75055 ]\n",
      " [ 79.33026 ]\n",
      " [220.86542 ]\n",
      " [255.33481 ]\n",
      " [102.30516 ]\n",
      " [104.91327 ]\n",
      " [141.156   ]\n",
      " [ 55.794632]\n",
      " [238.9461  ]\n",
      " [225.65045 ]\n",
      " [278.12158 ]\n",
      " [190.13477 ]\n",
      " [ 68.148636]\n",
      " [179.48055 ]\n",
      " [129.77023 ]\n",
      " [106.113045]\n",
      " [126.33948 ]]\n",
      "=================\n",
      "R2 :  0.29324386421778914\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.6959\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.0961\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.0433\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.2671\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.6801\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.8519\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.2207\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.1029\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.7420\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.7376\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.1544\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.2439\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.9129\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.5609\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.3891\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 18.5675\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.7082\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.8350\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.3219\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.9171\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.5582\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.4602\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.1866\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.8262\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.1900\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.4585\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.8967\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.7006\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.7863\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.2193\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.9456\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 20.2655\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.9442\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.6124\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.2062\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.6466\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.0081\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.7933\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.2982\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.6937\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.8969\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.2298\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.0049\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.0407\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.9480\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.7660\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.7889\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.6908\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.9039\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.8313\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.7862\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.3727\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.8519\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.8438\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.3206\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.3794\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.7321\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.7238\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.6925\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.8719\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.9183\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.7619\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.8104\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.4867\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.4180\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.7835\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.4233\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.0067\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.5921\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.8952\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.3460\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.5654\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.8351\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.5209\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.4232\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.0677\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.7495\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.2123\n",
      "Epoch 79/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 90us/step - loss: 17.2123\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 52.3588\n",
      "loss :  52.3587532043457\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "=================\n",
      "[185. 150. 246. 184. 110. 202. 336.  69.  69.  87.  66. 164. 265. 198.\n",
      " 248. 171. 102. 182. 262. 233. 151. 275. 230.  39.  42. 122.  81.  31.\n",
      " 156. 161.  80. 215. 310. 163. 265.  84.  54. 137. 248.  72. 248.  59.\n",
      "  97.  61.  72. 296.  55.  75.  53. 173. 158.  96. 140. 186.  93. 123.\n",
      " 237. 138. 292.  78. 182. 127. 321. 109. 212.  45.  96. 109.  89.  96.\n",
      "  60.  51. 200. 265.  68.  91. 172. 115. 125.  53.  63. 259. 214. 195.\n",
      " 258. 235. 173.  59. 219. 170.  77.  49.  66. 144. 113. 233. 162. 121.\n",
      "  88. 302. 128.  52. 178.  90. 164. 135. 103. 200. 178. 261.  64.  59.\n",
      "  79.  47. 107.  39. 151. 104. 217. 232.  55. 245. 131.  64. 222. 249.\n",
      " 128. 293. 138. 273. 158. 168. 103.]\n",
      "[[204.96428 ]\n",
      " [ 71.42916 ]\n",
      " [291.15576 ]\n",
      " [232.70448 ]\n",
      " [230.22127 ]\n",
      " [230.88647 ]\n",
      " [313.80682 ]\n",
      " [ 71.335884]\n",
      " [142.93477 ]\n",
      " [156.05705 ]\n",
      " [211.61801 ]\n",
      " [236.76569 ]\n",
      " [228.88872 ]\n",
      " [331.25677 ]\n",
      " [262.6637  ]\n",
      " [199.18784 ]\n",
      " [ 79.659   ]\n",
      " [238.04695 ]\n",
      " [282.67386 ]\n",
      " [301.93042 ]\n",
      " [175.34422 ]\n",
      " [294.38605 ]\n",
      " [ 84.55801 ]\n",
      " [ 70.7462  ]\n",
      " [ 72.426704]\n",
      " [187.91959 ]\n",
      " [ 59.479855]\n",
      " [ 63.68587 ]\n",
      " [208.96255 ]\n",
      " [200.44252 ]\n",
      " [ 87.65677 ]\n",
      " [268.39966 ]\n",
      " [ 80.70506 ]\n",
      " [285.95587 ]\n",
      " [231.95547 ]\n",
      " [ 70.46893 ]\n",
      " [ 75.2892  ]\n",
      " [144.90135 ]\n",
      " [268.94543 ]\n",
      " [ 80.07317 ]\n",
      " [232.18413 ]\n",
      " [ 99.78095 ]\n",
      " [255.53227 ]\n",
      " [ 71.22144 ]\n",
      " [ 72.19973 ]\n",
      " [302.64276 ]\n",
      " [171.46623 ]\n",
      " [ 73.326614]\n",
      " [ 58.264397]\n",
      " [279.75253 ]\n",
      " [209.73158 ]\n",
      " [123.95319 ]\n",
      " [ 97.17924 ]\n",
      " [250.25256 ]\n",
      " [ 92.191826]\n",
      " [229.86546 ]\n",
      " [305.31683 ]\n",
      " [126.64367 ]\n",
      " [208.06136 ]\n",
      " [309.16727 ]\n",
      " [ 91.60939 ]\n",
      " [ 77.0108  ]\n",
      " [320.725   ]\n",
      " [136.06902 ]\n",
      " [227.14449 ]\n",
      " [ 66.11717 ]\n",
      " [ 86.5     ]\n",
      " [ 97.9611  ]\n",
      " [129.5119  ]\n",
      " [112.96665 ]\n",
      " [ 70.89026 ]\n",
      " [ 75.393074]\n",
      " [220.0249  ]\n",
      " [288.85184 ]\n",
      " [ 68.61437 ]\n",
      " [198.40123 ]\n",
      " [186.85718 ]\n",
      " [ 77.517845]\n",
      " [115.317604]\n",
      " [ 89.60849 ]\n",
      " [ 85.564095]\n",
      " [114.20018 ]\n",
      " [132.28261 ]\n",
      " [278.91357 ]\n",
      " [303.59018 ]\n",
      " [193.18387 ]\n",
      " [127.98043 ]\n",
      " [ 93.12614 ]\n",
      " [153.46678 ]\n",
      " [186.42091 ]\n",
      " [136.66092 ]\n",
      " [ 68.03079 ]\n",
      " [258.14337 ]\n",
      " [139.23705 ]\n",
      " [216.05801 ]\n",
      " [262.82184 ]\n",
      " [108.05915 ]\n",
      " [199.02333 ]\n",
      " [ 69.00231 ]\n",
      " [183.13725 ]\n",
      " [ 49.179893]\n",
      " [ 72.92693 ]\n",
      " [195.28781 ]\n",
      " [214.39565 ]\n",
      " [140.44794 ]\n",
      " [ 70.7462  ]\n",
      " [207.58891 ]\n",
      " [130.6241  ]\n",
      " [271.45178 ]\n",
      " [160.6013  ]\n",
      " [ 48.95055 ]\n",
      " [121.53193 ]\n",
      " [129.31807 ]\n",
      " [ 66.471245]\n",
      " [ 61.950916]\n",
      " [ 71.64251 ]\n",
      " [280.79352 ]\n",
      " [ 85.03762 ]\n",
      " [241.09229 ]\n",
      " [278.44278 ]\n",
      " [125.2173  ]\n",
      " [144.19135 ]\n",
      " [154.234   ]\n",
      " [ 48.95055 ]\n",
      " [214.85205 ]\n",
      " [244.06865 ]\n",
      " [298.60425 ]\n",
      " [219.79782 ]\n",
      " [ 70.7462  ]\n",
      " [196.49701 ]\n",
      " [123.41604 ]\n",
      " [119.70988 ]\n",
      " [164.72325 ]]\n",
      "=================\n",
      "R2 :  0.17702975201860294\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.6639\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.8973\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.8624\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.3018\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.5264\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.9971\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.9110\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.1393\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.3749\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.9387\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.1341\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.7251\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.8331\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.8961\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.1170\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.3972\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.8736\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.2182\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.0921\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.4524\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.2159\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.0392\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.7040\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.9915\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.1590\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.8445\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.3660\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.0923\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.0964\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.2539\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.6139\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 19.5341\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.3560\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.3300\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.3553\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.1850\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.4019\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.9612\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.4312\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.2351\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.3498\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.5885\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.6786\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.4846\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.7014\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.4385\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.3233\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.6843\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.0541\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.2687\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 23.8059\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.3058\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.3350\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.8433\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.6786\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.0130\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.5697\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.7131\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.4371\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.9283\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.3607\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.5737\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 17.6990\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.7815\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.7596\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.8479\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.4356\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.6906\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.5802\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 17.4500\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.0284\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.1692\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.6783\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.0220\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.3144\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.3419\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.6908\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.0344\n",
      "Epoch 79/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 100us/step - loss: 18.0344\n",
      "5/5 [==============================] - 0s 997us/step - loss: 48.1313\n",
      "loss :  48.131343841552734\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "=================\n",
      "[185. 150. 246. 184. 110. 202. 336.  69.  69.  87.  66. 164. 265. 198.\n",
      " 248. 171. 102. 182. 262. 233. 151. 275. 230.  39.  42. 122.  81.  31.\n",
      " 156. 161.  80. 215. 310. 163. 265.  84.  54. 137. 248.  72. 248.  59.\n",
      "  97.  61.  72. 296.  55.  75.  53. 173. 158.  96. 140. 186.  93. 123.\n",
      " 237. 138. 292.  78. 182. 127. 321. 109. 212.  45.  96. 109.  89.  96.\n",
      "  60.  51. 200. 265.  68.  91. 172. 115. 125.  53.  63. 259. 214. 195.\n",
      " 258. 235. 173.  59. 219. 170.  77.  49.  66. 144. 113. 233. 162. 121.\n",
      "  88. 302. 128.  52. 178.  90. 164. 135. 103. 200. 178. 261.  64.  59.\n",
      "  79.  47. 107.  39. 151. 104. 217. 232.  55. 245. 131.  64. 222. 249.\n",
      " 128. 293. 138. 273. 158. 168. 103.]\n",
      "[[184.89056 ]\n",
      " [ 73.79198 ]\n",
      " [272.41476 ]\n",
      " [216.20604 ]\n",
      " [203.93942 ]\n",
      " [209.34749 ]\n",
      " [263.03445 ]\n",
      " [ 53.012455]\n",
      " [129.52211 ]\n",
      " [ 82.10057 ]\n",
      " [110.32713 ]\n",
      " [220.48534 ]\n",
      " [218.34724 ]\n",
      " [300.18207 ]\n",
      " [236.73802 ]\n",
      " [181.90031 ]\n",
      " [ 61.098484]\n",
      " [223.82396 ]\n",
      " [269.55222 ]\n",
      " [281.49414 ]\n",
      " [195.84181 ]\n",
      " [267.63675 ]\n",
      " [ 85.08275 ]\n",
      " [ 72.1102  ]\n",
      " [ 78.38868 ]\n",
      " [190.12659 ]\n",
      " [ 59.49869 ]\n",
      " [ 74.389046]\n",
      " [181.9098  ]\n",
      " [187.83594 ]\n",
      " [122.04605 ]\n",
      " [236.00148 ]\n",
      " [ 88.37459 ]\n",
      " [259.8253  ]\n",
      " [212.1583  ]\n",
      " [ 63.311543]\n",
      " [ 75.515015]\n",
      " [170.33899 ]\n",
      " [247.62132 ]\n",
      " [ 86.29439 ]\n",
      " [196.75276 ]\n",
      " [108.83324 ]\n",
      " [224.19551 ]\n",
      " [105.23872 ]\n",
      " [ 66.149536]\n",
      " [277.88928 ]\n",
      " [172.57953 ]\n",
      " [ 68.32572 ]\n",
      " [ 59.87963 ]\n",
      " [259.96503 ]\n",
      " [178.67102 ]\n",
      " [157.16025 ]\n",
      " [ 96.83313 ]\n",
      " [232.8185  ]\n",
      " [ 98.295006]\n",
      " [210.32152 ]\n",
      " [231.78983 ]\n",
      " [113.53041 ]\n",
      " [192.39394 ]\n",
      " [253.86562 ]\n",
      " [ 93.71615 ]\n",
      " [ 90.00077 ]\n",
      " [270.37256 ]\n",
      " [141.267   ]\n",
      " [229.15305 ]\n",
      " [ 67.954315]\n",
      " [ 95.29593 ]\n",
      " [ 90.21226 ]\n",
      " [126.58199 ]\n",
      " [102.85668 ]\n",
      " [ 81.16016 ]\n",
      " [ 72.1102  ]\n",
      " [228.81754 ]\n",
      " [264.548   ]\n",
      " [ 74.81053 ]\n",
      " [176.78513 ]\n",
      " [152.00954 ]\n",
      " [ 79.52933 ]\n",
      " [120.36745 ]\n",
      " [ 94.89718 ]\n",
      " [ 86.70562 ]\n",
      " [137.47166 ]\n",
      " [152.14423 ]\n",
      " [268.80704 ]\n",
      " [284.96045 ]\n",
      " [167.34096 ]\n",
      " [128.39638 ]\n",
      " [ 96.94315 ]\n",
      " [104.28676 ]\n",
      " [171.64156 ]\n",
      " [ 91.594055]\n",
      " [ 71.83265 ]\n",
      " [248.46284 ]\n",
      " [133.48528 ]\n",
      " [212.42856 ]\n",
      " [252.07994 ]\n",
      " [ 99.96034 ]\n",
      " [186.56682 ]\n",
      " [ 80.587975]\n",
      " [162.32733 ]\n",
      " [ 60.313858]\n",
      " [ 72.1102  ]\n",
      " [154.4805  ]\n",
      " [190.86176 ]\n",
      " [134.54453 ]\n",
      " [ 72.1102  ]\n",
      " [189.83592 ]\n",
      " [119.17471 ]\n",
      " [249.12703 ]\n",
      " [162.11497 ]\n",
      " [ 49.009342]\n",
      " [101.770226]\n",
      " [131.42816 ]\n",
      " [ 61.731888]\n",
      " [ 78.985085]\n",
      " [ 62.584362]\n",
      " [257.80322 ]\n",
      " [ 90.2787  ]\n",
      " [224.28894 ]\n",
      " [266.95447 ]\n",
      " [103.730865]\n",
      " [ 85.02488 ]\n",
      " [119.42138 ]\n",
      " [ 60.47456 ]\n",
      " [250.15993 ]\n",
      " [217.90895 ]\n",
      " [275.81055 ]\n",
      " [184.43417 ]\n",
      " [ 72.1102  ]\n",
      " [178.62679 ]\n",
      " [131.71016 ]\n",
      " [121.60225 ]\n",
      " [111.95312 ]]\n",
      "=================\n",
      "R2 :  0.3090734101833974\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.7093\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.6215\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.8919\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.1371\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.1417\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 22.6697\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.4427\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.1543\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.1894\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.6438\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 18.4093\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.1797\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.3520\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.8428\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.5373\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.9601\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.7394\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.5151\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 17.7854\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.6007\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.0269\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.4440\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.1924\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.1387\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.3037\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 17.3442\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.8190\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.7305\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.1131\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.7009\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.4313\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.2390\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.9399\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.3839\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.6473\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.7959\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.6117\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.9345\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.2941\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.3998\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.4640\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.3383\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.8310\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.1824\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.0228\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.9065\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.5177\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.0139\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.9856\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.5417\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.5078\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.5465\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.9955\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.8216\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.6042\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.9412\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.6653\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.6116\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.8122\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.7372\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.6144\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.6893\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.5673\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.9392\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.0102\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.7157\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.6490\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.8391\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.6082\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.3709\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.6633\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.2370\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.1299\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.6380\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.6315\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.2332\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.9214\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.2221\n",
      "Epoch 79/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 99us/step - loss: 17.2221\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 45.2405\n",
      "loss :  45.240455627441406\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "=================\n",
      "[185. 150. 246. 184. 110. 202. 336.  69.  69.  87.  66. 164. 265. 198.\n",
      " 248. 171. 102. 182. 262. 233. 151. 275. 230.  39.  42. 122.  81.  31.\n",
      " 156. 161.  80. 215. 310. 163. 265.  84.  54. 137. 248.  72. 248.  59.\n",
      "  97.  61.  72. 296.  55.  75.  53. 173. 158.  96. 140. 186.  93. 123.\n",
      " 237. 138. 292.  78. 182. 127. 321. 109. 212.  45.  96. 109.  89.  96.\n",
      "  60.  51. 200. 265.  68.  91. 172. 115. 125.  53.  63. 259. 214. 195.\n",
      " 258. 235. 173.  59. 219. 170.  77.  49.  66. 144. 113. 233. 162. 121.\n",
      "  88. 302. 128.  52. 178.  90. 164. 135. 103. 200. 178. 261.  64.  59.\n",
      "  79.  47. 107.  39. 151. 104. 217. 232.  55. 245. 131.  64. 222. 249.\n",
      " 128. 293. 138. 273. 158. 168. 103.]\n",
      "[[168.61339 ]\n",
      " [ 70.596596]\n",
      " [253.63518 ]\n",
      " [190.96338 ]\n",
      " [192.0704  ]\n",
      " [196.03702 ]\n",
      " [258.8241  ]\n",
      " [ 56.632694]\n",
      " [148.76752 ]\n",
      " [115.81049 ]\n",
      " [116.99868 ]\n",
      " [207.82909 ]\n",
      " [199.41396 ]\n",
      " [282.45007 ]\n",
      " [231.31252 ]\n",
      " [170.74489 ]\n",
      " [ 71.16358 ]\n",
      " [206.5697  ]\n",
      " [248.99228 ]\n",
      " [289.2188  ]\n",
      " [185.33813 ]\n",
      " [248.483   ]\n",
      " [ 72.11312 ]\n",
      " [ 64.909386]\n",
      " [ 59.560028]\n",
      " [183.827   ]\n",
      " [ 62.835545]\n",
      " [ 67.057526]\n",
      " [173.18834 ]\n",
      " [177.15125 ]\n",
      " [ 78.649864]\n",
      " [210.48448 ]\n",
      " [101.03503 ]\n",
      " [243.6354  ]\n",
      " [199.58829 ]\n",
      " [ 59.4079  ]\n",
      " [ 67.98098 ]\n",
      " [169.52109 ]\n",
      " [226.51875 ]\n",
      " [ 76.2254  ]\n",
      " [188.527   ]\n",
      " [ 83.244934]\n",
      " [183.3881  ]\n",
      " [ 95.59766 ]\n",
      " [ 51.255215]\n",
      " [259.3694  ]\n",
      " [152.09528 ]\n",
      " [ 79.76414 ]\n",
      " [ 45.51003 ]\n",
      " [246.63866 ]\n",
      " [154.77234 ]\n",
      " [157.42883 ]\n",
      " [ 89.52274 ]\n",
      " [226.2185  ]\n",
      " [ 98.01252 ]\n",
      " [181.05652 ]\n",
      " [237.06433 ]\n",
      " [102.67177 ]\n",
      " [180.8449  ]\n",
      " [234.2778  ]\n",
      " [ 82.8557  ]\n",
      " [119.94441 ]\n",
      " [263.47125 ]\n",
      " [143.56604 ]\n",
      " [221.2102  ]\n",
      " [ 66.42914 ]\n",
      " [ 99.99864 ]\n",
      " [ 81.63209 ]\n",
      " [103.86022 ]\n",
      " [ 79.4124  ]\n",
      " [ 67.631325]\n",
      " [ 68.89619 ]\n",
      " [221.78429 ]\n",
      " [242.40681 ]\n",
      " [ 73.98692 ]\n",
      " [161.01895 ]\n",
      " [146.02306 ]\n",
      " [ 83.30968 ]\n",
      " [ 88.72489 ]\n",
      " [ 75.257164]\n",
      " [ 64.742386]\n",
      " [121.22372 ]\n",
      " [152.28294 ]\n",
      " [256.14383 ]\n",
      " [259.68585 ]\n",
      " [152.75885 ]\n",
      " [159.76033 ]\n",
      " [ 99.845276]\n",
      " [104.04737 ]\n",
      " [157.03894 ]\n",
      " [105.455956]\n",
      " [ 53.795765]\n",
      " [230.99997 ]\n",
      " [144.61536 ]\n",
      " [196.77466 ]\n",
      " [247.23438 ]\n",
      " [ 98.36014 ]\n",
      " [183.0134  ]\n",
      " [ 61.308247]\n",
      " [155.18103 ]\n",
      " [ 45.40389 ]\n",
      " [ 66.42914 ]\n",
      " [119.557976]\n",
      " [184.59396 ]\n",
      " [149.18369 ]\n",
      " [ 54.21363 ]\n",
      " [173.57208 ]\n",
      " [120.80344 ]\n",
      " [233.27435 ]\n",
      " [193.06343 ]\n",
      " [103.89945 ]\n",
      " [102.56451 ]\n",
      " [117.06978 ]\n",
      " [ 78.680466]\n",
      " [ 78.94631 ]\n",
      " [ 83.63206 ]\n",
      " [240.54385 ]\n",
      " [ 73.61534 ]\n",
      " [204.59708 ]\n",
      " [245.10565 ]\n",
      " [105.74448 ]\n",
      " [189.43341 ]\n",
      " [108.33659 ]\n",
      " [ 55.428577]\n",
      " [212.41827 ]\n",
      " [216.15631 ]\n",
      " [267.39642 ]\n",
      " [165.92717 ]\n",
      " [ 66.42914 ]\n",
      " [143.92673 ]\n",
      " [140.96051 ]\n",
      " [106.34006 ]\n",
      " [ 98.5627  ]]\n",
      "=================\n",
      "R2 :  0.38143801881628303\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.9339\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.0686\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.8428\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.8365\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 17.2751\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.5391\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.3197\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.6051\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.5744\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.4363\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.8436\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.3142\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 28.2557\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 32.3743\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 24.6208\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 21.4619\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.3007\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 18.3987\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.6469\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.8241\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.9383\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.3028\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 16.5133\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.6181\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.3817\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.8200\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.2653\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.3579\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.5885\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.5771\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.5345\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.9121\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 16.3832\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.0439\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.8342\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.5868\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.4864\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.0985\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.7346\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.9200\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.6209\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.8110\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.9053\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.3508\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.8000\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.4403\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.8272\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.2369\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.2952\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.8233\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.8110\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.4859\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.5220\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 17.9355\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.4943\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.8159\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.2073\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.8028\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.6401\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.1890\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 17.4580\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.8665\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.9115\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.0233\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.8332\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.9607\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.9279\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.0617\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.2041\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.4913\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.7699\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.8264\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.7548\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.1907\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.0272\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.3749\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.2675\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.4139\n",
      "Epoch 79/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 100us/step - loss: 17.4139\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 50.1362\n",
      "loss :  50.13618469238281\n",
      "5/5 [==============================] - 0s 899us/step\n",
      "=================\n",
      "[185. 150. 246. 184. 110. 202. 336.  69.  69.  87.  66. 164. 265. 198.\n",
      " 248. 171. 102. 182. 262. 233. 151. 275. 230.  39.  42. 122.  81.  31.\n",
      " 156. 161.  80. 215. 310. 163. 265.  84.  54. 137. 248.  72. 248.  59.\n",
      "  97.  61.  72. 296.  55.  75.  53. 173. 158.  96. 140. 186.  93. 123.\n",
      " 237. 138. 292.  78. 182. 127. 321. 109. 212.  45.  96. 109.  89.  96.\n",
      "  60.  51. 200. 265.  68.  91. 172. 115. 125.  53.  63. 259. 214. 195.\n",
      " 258. 235. 173.  59. 219. 170.  77.  49.  66. 144. 113. 233. 162. 121.\n",
      "  88. 302. 128.  52. 178.  90. 164. 135. 103. 200. 178. 261.  64.  59.\n",
      "  79.  47. 107.  39. 151. 104. 217. 232.  55. 245. 131.  64. 222. 249.\n",
      " 128. 293. 138. 273. 158. 168. 103.]\n",
      "[[194.24265 ]\n",
      " [ 79.62376 ]\n",
      " [292.10474 ]\n",
      " [224.66995 ]\n",
      " [229.5136  ]\n",
      " [219.27802 ]\n",
      " [302.4762  ]\n",
      " [ 75.5644  ]\n",
      " [125.40339 ]\n",
      " [139.83197 ]\n",
      " [170.0214  ]\n",
      " [235.14308 ]\n",
      " [216.3494  ]\n",
      " [311.58524 ]\n",
      " [256.68997 ]\n",
      " [204.00139 ]\n",
      " [ 81.577736]\n",
      " [240.06612 ]\n",
      " [284.81403 ]\n",
      " [302.18988 ]\n",
      " [204.56697 ]\n",
      " [279.88272 ]\n",
      " [ 77.8493  ]\n",
      " [ 72.39653 ]\n",
      " [ 75.96194 ]\n",
      " [173.34627 ]\n",
      " [ 62.643406]\n",
      " [ 75.013   ]\n",
      " [195.78485 ]\n",
      " [202.64241 ]\n",
      " [ 65.56367 ]\n",
      " [259.13147 ]\n",
      " [ 88.95169 ]\n",
      " [278.67554 ]\n",
      " [227.73126 ]\n",
      " [ 67.32494 ]\n",
      " [ 75.5518  ]\n",
      " [151.2055  ]\n",
      " [240.45032 ]\n",
      " [ 88.29765 ]\n",
      " [218.16977 ]\n",
      " [ 97.54955 ]\n",
      " [209.7369  ]\n",
      " [ 92.1642  ]\n",
      " [ 68.275764]\n",
      " [300.6787  ]\n",
      " [177.67134 ]\n",
      " [ 86.861626]\n",
      " [ 57.67592 ]\n",
      " [252.4643  ]\n",
      " [177.43031 ]\n",
      " [187.1988  ]\n",
      " [109.84609 ]\n",
      " [220.44328 ]\n",
      " [102.91212 ]\n",
      " [235.78136 ]\n",
      " [290.21838 ]\n",
      " [119.38677 ]\n",
      " [217.36528 ]\n",
      " [265.3019  ]\n",
      " [ 91.38647 ]\n",
      " [ 86.72938 ]\n",
      " [307.61716 ]\n",
      " [145.91133 ]\n",
      " [247.08406 ]\n",
      " [ 69.1111  ]\n",
      " [105.3592  ]\n",
      " [ 91.33139 ]\n",
      " [125.425674]\n",
      " [ 93.11052 ]\n",
      " [ 85.984795]\n",
      " [ 75.18194 ]\n",
      " [233.79825 ]\n",
      " [281.03217 ]\n",
      " [ 82.94563 ]\n",
      " [171.62787 ]\n",
      " [145.76208 ]\n",
      " [ 92.32888 ]\n",
      " [108.2545  ]\n",
      " [ 80.72002 ]\n",
      " [ 77.258   ]\n",
      " [114.195335]\n",
      " [159.96638 ]\n",
      " [283.89465 ]\n",
      " [296.12466 ]\n",
      " [159.5074  ]\n",
      " [208.9962  ]\n",
      " [107.88184 ]\n",
      " [137.21976 ]\n",
      " [164.89632 ]\n",
      " [168.40567 ]\n",
      " [ 72.39653 ]\n",
      " [259.68292 ]\n",
      " [145.00502 ]\n",
      " [232.14046 ]\n",
      " [287.12076 ]\n",
      " [ 97.64842 ]\n",
      " [183.90244 ]\n",
      " [ 79.4686  ]\n",
      " [161.28844 ]\n",
      " [ 59.72302 ]\n",
      " [ 72.39653 ]\n",
      " [168.24973 ]\n",
      " [222.75197 ]\n",
      " [133.99785 ]\n",
      " [ 65.46651 ]\n",
      " [170.7013  ]\n",
      " [113.49337 ]\n",
      " [263.67844 ]\n",
      " [234.37407 ]\n",
      " [ 53.830383]\n",
      " [ 94.334564]\n",
      " [128.45679 ]\n",
      " [ 70.70675 ]\n",
      " [ 80.4456  ]\n",
      " [ 79.793915]\n",
      " [271.81094 ]\n",
      " [ 87.99937 ]\n",
      " [226.92987 ]\n",
      " [279.62592 ]\n",
      " [111.33831 ]\n",
      " [121.132484]\n",
      " [138.4421  ]\n",
      " [ 58.42049 ]\n",
      " [257.1734  ]\n",
      " [252.0373  ]\n",
      " [296.30957 ]\n",
      " [223.92253 ]\n",
      " [ 72.39654 ]\n",
      " [170.74684 ]\n",
      " [145.4414  ]\n",
      " [125.40598 ]\n",
      " [101.6886  ]]\n",
      "=================\n",
      "R2 :  0.25340385265671095\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.4327\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.9813\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.1552\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.5385\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.1937\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.3541\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.1630\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.1833\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.5837\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.1815\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 18.7378\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.5725\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.9343\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.2859\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.8232\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 19.4379\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.1099\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.9371\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.9401\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.5728\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.1271\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.0768\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 16.9934\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.4029\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.5693\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.4692\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.4714\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 16.6720\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.8939\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.4907\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.7740\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.2412\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.1517\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 16.2919\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.2307\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.4511\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.0853\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.1037\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 15.9880\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.1994\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.1836\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.5400\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.6591\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.2474\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 17.3468\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.6006\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.8422\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.2492\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.9100\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.6146\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.3435\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.3840\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.1020\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.3909\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.5979\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.1381\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.0745\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.8318\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.1565\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.5086\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.4012\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.5380\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.0294\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.9247\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.8472\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.5083\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.3799\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.6132\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.3085\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.7219\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.6667\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.3240\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 16.3657\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.0055\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.6446\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.2672\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.6845\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.1163\n",
      "Epoch 79/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 99us/step - loss: 17.1163\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 49.4146\n",
      "loss :  49.414649963378906\n",
      "5/5 [==============================] - 0s 997us/step\n",
      "=================\n",
      "[185. 150. 246. 184. 110. 202. 336.  69.  69.  87.  66. 164. 265. 198.\n",
      " 248. 171. 102. 182. 262. 233. 151. 275. 230.  39.  42. 122.  81.  31.\n",
      " 156. 161.  80. 215. 310. 163. 265.  84.  54. 137. 248.  72. 248.  59.\n",
      "  97.  61.  72. 296.  55.  75.  53. 173. 158.  96. 140. 186.  93. 123.\n",
      " 237. 138. 292.  78. 182. 127. 321. 109. 212.  45.  96. 109.  89.  96.\n",
      "  60.  51. 200. 265.  68.  91. 172. 115. 125.  53.  63. 259. 214. 195.\n",
      " 258. 235. 173.  59. 219. 170.  77.  49.  66. 144. 113. 233. 162. 121.\n",
      "  88. 302. 128.  52. 178.  90. 164. 135. 103. 200. 178. 261.  64.  59.\n",
      "  79.  47. 107.  39. 151. 104. 217. 232.  55. 245. 131.  64. 222. 249.\n",
      " 128. 293. 138. 273. 158. 168. 103.]\n",
      "[[187.41838 ]\n",
      " [ 78.6281  ]\n",
      " [259.04065 ]\n",
      " [226.8901  ]\n",
      " [204.66667 ]\n",
      " [222.09512 ]\n",
      " [260.66647 ]\n",
      " [ 53.17317 ]\n",
      " [116.02414 ]\n",
      " [141.68138 ]\n",
      " [133.31113 ]\n",
      " [236.84383 ]\n",
      " [239.31554 ]\n",
      " [295.3582  ]\n",
      " [241.81012 ]\n",
      " [175.81078 ]\n",
      " [ 69.78677 ]\n",
      " [224.17247 ]\n",
      " [268.9436  ]\n",
      " [274.3806  ]\n",
      " [207.39598 ]\n",
      " [273.3335  ]\n",
      " [ 73.48903 ]\n",
      " [ 71.964355]\n",
      " [ 66.80713 ]\n",
      " [206.41402 ]\n",
      " [ 56.569584]\n",
      " [ 66.90206 ]\n",
      " [186.68317 ]\n",
      " [186.77002 ]\n",
      " [ 61.783028]\n",
      " [267.8475  ]\n",
      " [108.2697  ]\n",
      " [270.0845  ]\n",
      " [223.34584 ]\n",
      " [ 66.14363 ]\n",
      " [ 75.52689 ]\n",
      " [175.26648 ]\n",
      " [236.47144 ]\n",
      " [ 81.44476 ]\n",
      " [208.78616 ]\n",
      " [106.0816  ]\n",
      " [293.4873  ]\n",
      " [ 97.9817  ]\n",
      " [ 68.09912 ]\n",
      " [277.47827 ]\n",
      " [178.14058 ]\n",
      " [ 75.52267 ]\n",
      " [ 55.984623]\n",
      " [248.00577 ]\n",
      " [166.56036 ]\n",
      " [188.93614 ]\n",
      " [ 85.43799 ]\n",
      " [225.08516 ]\n",
      " [113.546036]\n",
      " [234.23973 ]\n",
      " [235.21248 ]\n",
      " [116.273865]\n",
      " [202.23756 ]\n",
      " [273.01617 ]\n",
      " [ 87.41799 ]\n",
      " [113.85719 ]\n",
      " [266.58316 ]\n",
      " [140.03857 ]\n",
      " [204.13383 ]\n",
      " [ 71.964355]\n",
      " [112.26041 ]\n",
      " [ 91.49747 ]\n",
      " [118.569176]\n",
      " [ 96.47124 ]\n",
      " [ 77.77771 ]\n",
      " [ 76.72953 ]\n",
      " [231.39836 ]\n",
      " [286.77698 ]\n",
      " [ 84.89863 ]\n",
      " [174.86314 ]\n",
      " [162.51927 ]\n",
      " [ 78.9879  ]\n",
      " [106.70919 ]\n",
      " [ 78.74401 ]\n",
      " [ 72.59149 ]\n",
      " [117.50203 ]\n",
      " [187.39658 ]\n",
      " [286.94537 ]\n",
      " [291.68066 ]\n",
      " [154.91748 ]\n",
      " [160.8437  ]\n",
      " [111.95079 ]\n",
      " [114.44653 ]\n",
      " [174.77599 ]\n",
      " [106.63518 ]\n",
      " [ 71.964355]\n",
      " [263.87738 ]\n",
      " [147.47878 ]\n",
      " [223.95644 ]\n",
      " [270.6835  ]\n",
      " [113.5829  ]\n",
      " [198.32016 ]\n",
      " [ 69.22787 ]\n",
      " [177.90637 ]\n",
      " [ 63.333084]\n",
      " [ 71.964355]\n",
      " [ 94.18898 ]\n",
      " [214.36842 ]\n",
      " [154.17477 ]\n",
      " [ 62.32296 ]\n",
      " [170.15935 ]\n",
      " [147.92892 ]\n",
      " [261.78058 ]\n",
      " [191.06705 ]\n",
      " [ 97.44398 ]\n",
      " [ 95.99136 ]\n",
      " [131.75343 ]\n",
      " [ 68.92003 ]\n",
      " [ 76.48749 ]\n",
      " [ 74.43562 ]\n",
      " [265.1276  ]\n",
      " [ 83.63687 ]\n",
      " [200.13106 ]\n",
      " [263.35992 ]\n",
      " [160.97688 ]\n",
      " [209.67403 ]\n",
      " [ 99.96616 ]\n",
      " [ 58.46241 ]\n",
      " [261.9286  ]\n",
      " [242.67366 ]\n",
      " [285.99725 ]\n",
      " [211.92714 ]\n",
      " [ 71.964355]\n",
      " [164.85599 ]\n",
      " [143.2512  ]\n",
      " [120.81216 ]\n",
      " [ 87.043915]]\n",
      "=================\n",
      "R2 :  0.2599481164132903\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.4606\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.0430\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.0855\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.1094\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.1789\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.9294\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.0293\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.0159\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.3054\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.8301\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.9707\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.2021\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.8076\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.4942\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.8073\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.0677\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 18.6143\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.6453\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.7776\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.8321\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.7088\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 17.5655\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.6902\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.8297\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.9106\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.9065\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.6887\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.8556\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.8431\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.3641\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.3846\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.3431\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.9150\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.8151\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.0586\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.3793\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.2943\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.9637\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.0048\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.9249\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.4530\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.0521\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.9062\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.3693\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 15.2125\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.7091\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.5962\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.2227\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.8448\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.1002\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.0281\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.6466\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.0130\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.8493\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.5138\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.4949\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.7735\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.5520\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.6230\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.1750\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.3347\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.6791\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.7183\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.7558\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.1889\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.2418\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.0649\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.2106\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.3754\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.0905\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.3426\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.5300\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.5163\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.3207\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.6535\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.6033\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.8714\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.5540\n",
      "Epoch 79/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 100us/step - loss: 14.5540\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 52.1224\n",
      "loss :  52.12240219116211\n",
      "5/5 [==============================] - 0s 748us/step\n",
      "=================\n",
      "[185. 150. 246. 184. 110. 202. 336.  69.  69.  87.  66. 164. 265. 198.\n",
      " 248. 171. 102. 182. 262. 233. 151. 275. 230.  39.  42. 122.  81.  31.\n",
      " 156. 161.  80. 215. 310. 163. 265.  84.  54. 137. 248.  72. 248.  59.\n",
      "  97.  61.  72. 296.  55.  75.  53. 173. 158.  96. 140. 186.  93. 123.\n",
      " 237. 138. 292.  78. 182. 127. 321. 109. 212.  45.  96. 109.  89.  96.\n",
      "  60.  51. 200. 265.  68.  91. 172. 115. 125.  53.  63. 259. 214. 195.\n",
      " 258. 235. 173.  59. 219. 170.  77.  49.  66. 144. 113. 233. 162. 121.\n",
      "  88. 302. 128.  52. 178.  90. 164. 135. 103. 200. 178. 261.  64.  59.\n",
      "  79.  47. 107.  39. 151. 104. 217. 232.  55. 245. 131.  64. 222. 249.\n",
      " 128. 293. 138. 273. 158. 168. 103.]\n",
      "[[189.99635 ]\n",
      " [ 65.29737 ]\n",
      " [275.36572 ]\n",
      " [217.03928 ]\n",
      " [217.40234 ]\n",
      " [211.03836 ]\n",
      " [282.38687 ]\n",
      " [ 71.85425 ]\n",
      " [172.3663  ]\n",
      " [158.36475 ]\n",
      " [132.24957 ]\n",
      " [202.78801 ]\n",
      " [223.04723 ]\n",
      " [295.96527 ]\n",
      " [237.1297  ]\n",
      " [176.91301 ]\n",
      " [ 60.336544]\n",
      " [238.69104 ]\n",
      " [278.7331  ]\n",
      " [288.49902 ]\n",
      " [213.20747 ]\n",
      " [270.0522  ]\n",
      " [ 76.69978 ]\n",
      " [ 68.563255]\n",
      " [ 64.77918 ]\n",
      " [182.1976  ]\n",
      " [ 50.343815]\n",
      " [ 77.85912 ]\n",
      " [192.16531 ]\n",
      " [194.13712 ]\n",
      " [ 66.36484 ]\n",
      " [239.0029  ]\n",
      " [ 66.67769 ]\n",
      " [267.00858 ]\n",
      " [214.03937 ]\n",
      " [ 61.306484]\n",
      " [ 69.514946]\n",
      " [176.70825 ]\n",
      " [227.37828 ]\n",
      " [ 82.370186]\n",
      " [201.4197  ]\n",
      " [109.56412 ]\n",
      " [295.83783 ]\n",
      " [ 99.32475 ]\n",
      " [ 65.45783 ]\n",
      " [303.0919  ]\n",
      " [195.76236 ]\n",
      " [ 61.338173]\n",
      " [ 60.131092]\n",
      " [256.28702 ]\n",
      " [173.11873 ]\n",
      " [197.80884 ]\n",
      " [ 94.422775]\n",
      " [200.93152 ]\n",
      " [117.9915  ]\n",
      " [221.53578 ]\n",
      " [251.52783 ]\n",
      " [131.9296  ]\n",
      " [206.34854 ]\n",
      " [254.8883  ]\n",
      " [ 88.11401 ]\n",
      " [108.71644 ]\n",
      " [296.6977  ]\n",
      " [130.97711 ]\n",
      " [168.35406 ]\n",
      " [ 63.875656]\n",
      " [110.608765]\n",
      " [ 71.69139 ]\n",
      " [154.28676 ]\n",
      " [101.41707 ]\n",
      " [ 96.84183 ]\n",
      " [ 72.60907 ]\n",
      " [250.85516 ]\n",
      " [289.816   ]\n",
      " [ 96.51871 ]\n",
      " [184.56854 ]\n",
      " [149.18369 ]\n",
      " [ 76.29526 ]\n",
      " [111.99532 ]\n",
      " [ 83.5344  ]\n",
      " [ 78.250946]\n",
      " [119.1495  ]\n",
      " [180.85379 ]\n",
      " [277.09158 ]\n",
      " [283.0447  ]\n",
      " [155.35507 ]\n",
      " [ 74.2468  ]\n",
      " [114.29577 ]\n",
      " [114.56729 ]\n",
      " [162.11128 ]\n",
      " [129.7733  ]\n",
      " [ 68.563255]\n",
      " [260.4966  ]\n",
      " [138.866   ]\n",
      " [227.02975 ]\n",
      " [269.6447  ]\n",
      " [118.06094 ]\n",
      " [174.85704 ]\n",
      " [ 79.60188 ]\n",
      " [160.44916 ]\n",
      " [ 62.13448 ]\n",
      " [ 68.563255]\n",
      " [ 78.04037 ]\n",
      " [224.9769  ]\n",
      " [143.21474 ]\n",
      " [ 67.257774]\n",
      " [159.44637 ]\n",
      " [151.18901 ]\n",
      " [263.25037 ]\n",
      " [159.62367 ]\n",
      " [108.10565 ]\n",
      " [ 79.40418 ]\n",
      " [135.59135 ]\n",
      " [ 57.375355]\n",
      " [ 85.7789  ]\n",
      " [ 70.83617 ]\n",
      " [265.3454  ]\n",
      " [ 91.01147 ]\n",
      " [188.46776 ]\n",
      " [256.35635 ]\n",
      " [117.142   ]\n",
      " [201.01318 ]\n",
      " [100.62056 ]\n",
      " [ 64.26649 ]\n",
      " [187.48576 ]\n",
      " [238.4957  ]\n",
      " [291.74716 ]\n",
      " [197.89844 ]\n",
      " [ 68.563255]\n",
      " [163.4128  ]\n",
      " [134.6266  ]\n",
      " [116.53937 ]\n",
      " [ 78.00618 ]]\n",
      "=================\n",
      "R2 :  0.19547012939592645\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.0938\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.9379\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.0982\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.5668\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.2240\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.7025\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.4353\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.5662\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.3119\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.2856\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.8639\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.8855\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.0426\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.9278\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.9810\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.7209\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.5069\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.0800\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.4176\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.5862\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.3511\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.1536\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.5820\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.3329\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.8356\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.1549\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.6981\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.0482\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.6914\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.7475\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.9764\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.0437\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.4064\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.5338\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.9314\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.7129\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.6853\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.0902\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.3555\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.6219\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 16.5800\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.3424\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.7796\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.7337\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.3828\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.2143\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.4008\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.0269\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.9630\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.5494\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.1440\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.1268\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.1835\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.8722\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.6739\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.3048\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.6054\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.2207\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.4442\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.4744\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.3029\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.1010\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.8673\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.1799\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.4524\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 13.7754\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.4935\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.0068\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.1865\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.2581\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.7903\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.5003\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.1629\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.2497\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.9085\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.6183\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 16.7550\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.6223\n",
      "Epoch 79/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 110us/step - loss: 14.6223\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 50.5682\n",
      "loss :  50.568214416503906\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "=================\n",
      "[185. 150. 246. 184. 110. 202. 336.  69.  69.  87.  66. 164. 265. 198.\n",
      " 248. 171. 102. 182. 262. 233. 151. 275. 230.  39.  42. 122.  81.  31.\n",
      " 156. 161.  80. 215. 310. 163. 265.  84.  54. 137. 248.  72. 248.  59.\n",
      "  97.  61.  72. 296.  55.  75.  53. 173. 158.  96. 140. 186.  93. 123.\n",
      " 237. 138. 292.  78. 182. 127. 321. 109. 212.  45.  96. 109.  89.  96.\n",
      "  60.  51. 200. 265.  68.  91. 172. 115. 125.  53.  63. 259. 214. 195.\n",
      " 258. 235. 173.  59. 219. 170.  77.  49.  66. 144. 113. 233. 162. 121.\n",
      "  88. 302. 128.  52. 178.  90. 164. 135. 103. 200. 178. 261.  64.  59.\n",
      "  79.  47. 107.  39. 151. 104. 217. 232.  55. 245. 131.  64. 222. 249.\n",
      " 128. 293. 138. 273. 158. 168. 103.]\n",
      "[[190.05951 ]\n",
      " [ 68.40293 ]\n",
      " [273.88635 ]\n",
      " [213.44699 ]\n",
      " [215.14548 ]\n",
      " [229.22223 ]\n",
      " [273.4112  ]\n",
      " [ 68.17823 ]\n",
      " [159.94315 ]\n",
      " [148.66893 ]\n",
      " [162.62003 ]\n",
      " [229.11841 ]\n",
      " [244.11371 ]\n",
      " [287.20813 ]\n",
      " [244.50119 ]\n",
      " [177.23721 ]\n",
      " [ 52.977066]\n",
      " [237.38593 ]\n",
      " [284.20425 ]\n",
      " [278.395   ]\n",
      " [207.09036 ]\n",
      " [273.80893 ]\n",
      " [ 73.17995 ]\n",
      " [ 68.22076 ]\n",
      " [ 62.235157]\n",
      " [177.98788 ]\n",
      " [ 44.970596]\n",
      " [ 51.87258 ]\n",
      " [184.70264 ]\n",
      " [189.9401  ]\n",
      " [ 92.840004]\n",
      " [247.96388 ]\n",
      " [ 51.908585]\n",
      " [272.56177 ]\n",
      " [220.00665 ]\n",
      " [ 60.578712]\n",
      " [ 68.22076 ]\n",
      " [143.21385 ]\n",
      " [235.59294 ]\n",
      " [ 52.241035]\n",
      " [204.35599 ]\n",
      " [ 83.648834]\n",
      " [272.92682 ]\n",
      " [113.61269 ]\n",
      " [ 51.525635]\n",
      " [296.5477  ]\n",
      " [166.19885 ]\n",
      " [ 53.85849 ]\n",
      " [ 59.688522]\n",
      " [248.8964  ]\n",
      " [149.00499 ]\n",
      " [182.94868 ]\n",
      " [ 95.71588 ]\n",
      " [199.90515 ]\n",
      " [ 99.25215 ]\n",
      " [232.15459 ]\n",
      " [240.90442 ]\n",
      " [153.96407 ]\n",
      " [198.22414 ]\n",
      " [236.7231  ]\n",
      " [ 83.36178 ]\n",
      " [113.023506]\n",
      " [286.88113 ]\n",
      " [136.20956 ]\n",
      " [218.2786  ]\n",
      " [ 66.698   ]\n",
      " [110.05192 ]\n",
      " [ 65.36336 ]\n",
      " [133.76587 ]\n",
      " [ 77.142   ]\n",
      " [ 75.51447 ]\n",
      " [ 68.921646]\n",
      " [246.12314 ]\n",
      " [278.9574  ]\n",
      " [ 84.95384 ]\n",
      " [180.49335 ]\n",
      " [148.70493 ]\n",
      " [ 87.14819 ]\n",
      " [ 82.10948 ]\n",
      " [ 80.269325]\n",
      " [ 59.316654]\n",
      " [125.075516]\n",
      " [160.20956 ]\n",
      " [282.67126 ]\n",
      " [298.71063 ]\n",
      " [153.14694 ]\n",
      " [ 89.14943 ]\n",
      " [108.65622 ]\n",
      " [120.117294]\n",
      " [186.589   ]\n",
      " [103.65075 ]\n",
      " [ 68.22076 ]\n",
      " [267.00647 ]\n",
      " [159.59505 ]\n",
      " [220.83891 ]\n",
      " [281.16577 ]\n",
      " [102.19497 ]\n",
      " [183.3075  ]\n",
      " [ 56.71833 ]\n",
      " [146.8853  ]\n",
      " [ 68.22076 ]\n",
      " [ 68.22076 ]\n",
      " [105.79205 ]\n",
      " [214.69133 ]\n",
      " [154.62146 ]\n",
      " [ 65.070526]\n",
      " [138.6638  ]\n",
      " [150.45888 ]\n",
      " [269.0414  ]\n",
      " [144.10199 ]\n",
      " [108.420074]\n",
      " [108.68927 ]\n",
      " [122.41251 ]\n",
      " [ 49.607613]\n",
      " [ 81.58339 ]\n",
      " [ 65.96555 ]\n",
      " [267.37448 ]\n",
      " [ 95.59302 ]\n",
      " [200.65613 ]\n",
      " [260.19586 ]\n",
      " [114.43885 ]\n",
      " [144.24017 ]\n",
      " [124.68042 ]\n",
      " [ 56.63214 ]\n",
      " [203.64226 ]\n",
      " [247.83008 ]\n",
      " [297.25662 ]\n",
      " [191.1112  ]\n",
      " [ 68.22076 ]\n",
      " [174.61311 ]\n",
      " [133.21616 ]\n",
      " [134.40907 ]\n",
      " [ 87.01888 ]]\n",
      "=================\n",
      "R2 :  0.21606980401605724\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.9131\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.0069\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.5200\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.7087\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.7606\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.9587\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.5747\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.3387\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.6717\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.8663\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.9035\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.8077\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.0121\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.4854\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.5378\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.1317\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.1064\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.5316\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.7854\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.3910\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.4728\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.4329\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.8607\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.9433\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.0252\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.1156\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.9272\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.3883\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.7557\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.9148\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.4712\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.3314\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.3959\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.5465\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.0255\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.7782\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.1798\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 20.3043\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.3508\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.0702\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.7791\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.4036\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.1818\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.6050\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.4550\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.7108\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.0145\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.8827\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.3398\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.8579\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.9184\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.3557\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.4105\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.9821\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.3603\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.4181\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 13.0712\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.3687\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.9935\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.5634\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.0426\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.2221\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.0181\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.7465\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.8014\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.9464\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.9187\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.4581\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.6674\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.0159\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.5209\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.6636\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.0790\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.7840\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.0297\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.2838\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.5099\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.7089\n",
      "Epoch 79/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 95us/step - loss: 12.7089\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 56.8159\n",
      "loss :  56.81593704223633\n",
      "5/5 [==============================] - 0s 967us/step\n",
      "=================\n",
      "[185. 150. 246. 184. 110. 202. 336.  69.  69.  87.  66. 164. 265. 198.\n",
      " 248. 171. 102. 182. 262. 233. 151. 275. 230.  39.  42. 122.  81.  31.\n",
      " 156. 161.  80. 215. 310. 163. 265.  84.  54. 137. 248.  72. 248.  59.\n",
      "  97.  61.  72. 296.  55.  75.  53. 173. 158.  96. 140. 186.  93. 123.\n",
      " 237. 138. 292.  78. 182. 127. 321. 109. 212.  45.  96. 109.  89.  96.\n",
      "  60.  51. 200. 265.  68.  91. 172. 115. 125.  53.  63. 259. 214. 195.\n",
      " 258. 235. 173.  59. 219. 170.  77.  49.  66. 144. 113. 233. 162. 121.\n",
      "  88. 302. 128.  52. 178.  90. 164. 135. 103. 200. 178. 261.  64.  59.\n",
      "  79.  47. 107.  39. 151. 104. 217. 232.  55. 245. 131.  64. 222. 249.\n",
      " 128. 293. 138. 273. 158. 168. 103.]\n",
      "[[200.23625 ]\n",
      " [ 64.77504 ]\n",
      " [307.57535 ]\n",
      " [208.29025 ]\n",
      " [226.26918 ]\n",
      " [239.435   ]\n",
      " [318.0157  ]\n",
      " [ 52.320457]\n",
      " [188.97261 ]\n",
      " [157.93694 ]\n",
      " [143.64078 ]\n",
      " [242.0178  ]\n",
      " [226.90819 ]\n",
      " [318.55997 ]\n",
      " [255.61565 ]\n",
      " [196.3332  ]\n",
      " [ 41.652554]\n",
      " [257.277   ]\n",
      " [298.78525 ]\n",
      " [311.51514 ]\n",
      " [227.16206 ]\n",
      " [292.63773 ]\n",
      " [ 98.710106]\n",
      " [ 74.00318 ]\n",
      " [ 70.597015]\n",
      " [187.88777 ]\n",
      " [ 47.10671 ]\n",
      " [ 81.39608 ]\n",
      " [192.41705 ]\n",
      " [198.17897 ]\n",
      " [125.55935 ]\n",
      " [254.19008 ]\n",
      " [ 53.55507 ]\n",
      " [285.45187 ]\n",
      " [246.70518 ]\n",
      " [ 61.996143]\n",
      " [ 74.00318 ]\n",
      " [150.10895 ]\n",
      " [244.72346 ]\n",
      " [104.325424]\n",
      " [217.73042 ]\n",
      " [132.39851 ]\n",
      " [269.6024  ]\n",
      " [ 89.431335]\n",
      " [ 65.87786 ]\n",
      " [334.52945 ]\n",
      " [200.88345 ]\n",
      " [ 51.793087]\n",
      " [ 58.004837]\n",
      " [286.79694 ]\n",
      " [185.6379  ]\n",
      " [226.91907 ]\n",
      " [116.90981 ]\n",
      " [218.40782 ]\n",
      " [108.36091 ]\n",
      " [250.13945 ]\n",
      " [323.75638 ]\n",
      " [158.64986 ]\n",
      " [227.76692 ]\n",
      " [322.04187 ]\n",
      " [ 98.6851  ]\n",
      " [117.40119 ]\n",
      " [330.78568 ]\n",
      " [154.9436  ]\n",
      " [260.23    ]\n",
      " [ 66.75508 ]\n",
      " [116.26647 ]\n",
      " [ 79.12403 ]\n",
      " [161.77112 ]\n",
      " [123.49328 ]\n",
      " [ 97.36027 ]\n",
      " [ 74.00318 ]\n",
      " [249.30064 ]\n",
      " [302.6376  ]\n",
      " [ 96.70661 ]\n",
      " [168.45564 ]\n",
      " [165.7011  ]\n",
      " [ 68.65721 ]\n",
      " [129.15167 ]\n",
      " [ 86.345406]\n",
      " [ 78.39497 ]\n",
      " [164.58582 ]\n",
      " [173.38133 ]\n",
      " [298.45044 ]\n",
      " [317.57114 ]\n",
      " [159.14867 ]\n",
      " [129.40607 ]\n",
      " [116.65747 ]\n",
      " [115.10658 ]\n",
      " [189.0957  ]\n",
      " [ 82.7614  ]\n",
      " [ 74.00318 ]\n",
      " [282.0576  ]\n",
      " [141.76233 ]\n",
      " [254.11617 ]\n",
      " [325.02213 ]\n",
      " [132.79147 ]\n",
      " [192.50699 ]\n",
      " [ 57.64567 ]\n",
      " [185.67719 ]\n",
      " [ 74.00318 ]\n",
      " [ 74.00318 ]\n",
      " [ 87.48772 ]\n",
      " [227.25352 ]\n",
      " [138.68633 ]\n",
      " [ 64.076706]\n",
      " [166.19383 ]\n",
      " [126.03583 ]\n",
      " [283.19052 ]\n",
      " [194.85036 ]\n",
      " [ 79.080215]\n",
      " [ 99.419205]\n",
      " [137.25484 ]\n",
      " [ 51.82205 ]\n",
      " [ 91.18094 ]\n",
      " [ 68.95903 ]\n",
      " [281.97098 ]\n",
      " [112.16291 ]\n",
      " [253.98648 ]\n",
      " [266.21124 ]\n",
      " [147.67429 ]\n",
      " [ 97.616066]\n",
      " [130.9255  ]\n",
      " [ 58.03824 ]\n",
      " [232.74998 ]\n",
      " [255.39595 ]\n",
      " [350.97488 ]\n",
      " [223.91966 ]\n",
      " [ 74.00318 ]\n",
      " [180.10013 ]\n",
      " [152.37712 ]\n",
      " [140.30217 ]\n",
      " [ 89.342155]]\n",
      "=================\n",
      "R2 :  0.0382310194976897\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.6318\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.7926\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 13.6134\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.3186\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.3752\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.9654\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.7698\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.1482\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.6914\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.2231\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.2354\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.1629\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.4856\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.3583\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.4902\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.9627\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 13.6248\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.8744\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.6225\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.1476\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.0985\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.3153\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.4121\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.5285\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.2252\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 13.5741\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.8989\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.5998\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.7300\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.2542\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.1926\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.6300\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.9394\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.6297\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.1143\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.4157\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.5967\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.0381\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.8175\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.8160\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.8438\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.2196\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.5373\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.6298\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.2206\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.5573\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.5240\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.9894\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.8295\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.7351\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.5048\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 13.5630\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.3554\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.2382\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.0916\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.5273\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.0058\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.1680\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.3860\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.3027\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.3216\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 11.7823\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.6462\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.4248\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.2383\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.6329\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.5913\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.3098\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.7062\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.6325\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.3501\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.4163\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.8181\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.6988\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.7492\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.3452\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.7501\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.0850\n",
      "Epoch 79/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 108us/step - loss: 13.0850\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 56.2486\n",
      "loss :  56.248573303222656\n",
      "5/5 [==============================] - 0s 996us/step\n",
      "=================\n",
      "[185. 150. 246. 184. 110. 202. 336.  69.  69.  87.  66. 164. 265. 198.\n",
      " 248. 171. 102. 182. 262. 233. 151. 275. 230.  39.  42. 122.  81.  31.\n",
      " 156. 161.  80. 215. 310. 163. 265.  84.  54. 137. 248.  72. 248.  59.\n",
      "  97.  61.  72. 296.  55.  75.  53. 173. 158.  96. 140. 186.  93. 123.\n",
      " 237. 138. 292.  78. 182. 127. 321. 109. 212.  45.  96. 109.  89.  96.\n",
      "  60.  51. 200. 265.  68.  91. 172. 115. 125.  53.  63. 259. 214. 195.\n",
      " 258. 235. 173.  59. 219. 170.  77.  49.  66. 144. 113. 233. 162. 121.\n",
      "  88. 302. 128.  52. 178.  90. 164. 135. 103. 200. 178. 261.  64.  59.\n",
      "  79.  47. 107.  39. 151. 104. 217. 232.  55. 245. 131.  64. 222. 249.\n",
      " 128. 293. 138. 273. 158. 168. 103.]\n",
      "[[195.43008 ]\n",
      " [ 53.012806]\n",
      " [295.66437 ]\n",
      " [218.34819 ]\n",
      " [220.0962  ]\n",
      " [230.27002 ]\n",
      " [321.59634 ]\n",
      " [ 49.79664 ]\n",
      " [162.03268 ]\n",
      " [167.93515 ]\n",
      " [191.1091  ]\n",
      " [222.10904 ]\n",
      " [226.39874 ]\n",
      " [315.935   ]\n",
      " [258.3638  ]\n",
      " [213.25587 ]\n",
      " [ 40.222805]\n",
      " [262.03113 ]\n",
      " [304.92035 ]\n",
      " [310.12067 ]\n",
      " [226.25139 ]\n",
      " [293.502   ]\n",
      " [ 77.37948 ]\n",
      " [ 77.44816 ]\n",
      " [ 48.843483]\n",
      " [183.13191 ]\n",
      " [ 41.416065]\n",
      " [ 49.609035]\n",
      " [202.43362 ]\n",
      " [198.14365 ]\n",
      " [107.56914 ]\n",
      " [234.02533 ]\n",
      " [ 49.34062 ]\n",
      " [284.21152 ]\n",
      " [234.81546 ]\n",
      " [ 57.768696]\n",
      " [ 63.901478]\n",
      " [150.2244  ]\n",
      " [248.7858  ]\n",
      " [ 91.65009 ]\n",
      " [208.11191 ]\n",
      " [121.03803 ]\n",
      " [265.5209  ]\n",
      " [ 90.35308 ]\n",
      " [ 48.838226]\n",
      " [329.55505 ]\n",
      " [200.02296 ]\n",
      " [ 71.08968 ]\n",
      " [ 53.226334]\n",
      " [295.06165 ]\n",
      " [181.99187 ]\n",
      " [192.38483 ]\n",
      " [111.31994 ]\n",
      " [198.61443 ]\n",
      " [112.720695]\n",
      " [223.4877  ]\n",
      " [333.83185 ]\n",
      " [159.0444  ]\n",
      " [212.19164 ]\n",
      " [314.6246  ]\n",
      " [ 88.9463  ]\n",
      " [128.88068 ]\n",
      " [330.58206 ]\n",
      " [159.22253 ]\n",
      " [268.4399  ]\n",
      " [ 63.901478]\n",
      " [106.10334 ]\n",
      " [ 71.25142 ]\n",
      " [173.51302 ]\n",
      " [117.68761 ]\n",
      " [ 83.756996]\n",
      " [ 66.45248 ]\n",
      " [258.97974 ]\n",
      " [295.879   ]\n",
      " [ 86.515526]\n",
      " [176.49832 ]\n",
      " [165.35822 ]\n",
      " [ 86.058685]\n",
      " [122.93069 ]\n",
      " [ 74.03367 ]\n",
      " [ 49.459694]\n",
      " [144.34314 ]\n",
      " [179.62831 ]\n",
      " [302.8358  ]\n",
      " [322.1523  ]\n",
      " [171.25604 ]\n",
      " [213.58075 ]\n",
      " [105.70958 ]\n",
      " [134.52576 ]\n",
      " [177.25755 ]\n",
      " [115.30195 ]\n",
      " [ 63.901478]\n",
      " [284.3971  ]\n",
      " [123.70614 ]\n",
      " [238.84401 ]\n",
      " [318.08527 ]\n",
      " [128.00633 ]\n",
      " [166.27388 ]\n",
      " [ 49.69387 ]\n",
      " [174.48026 ]\n",
      " [ 63.901478]\n",
      " [ 63.901478]\n",
      " [ 75.24381 ]\n",
      " [242.9463  ]\n",
      " [139.41724 ]\n",
      " [ 57.34338 ]\n",
      " [160.79053 ]\n",
      " [118.90953 ]\n",
      " [276.83984 ]\n",
      " [198.71991 ]\n",
      " [125.404526]\n",
      " [ 96.7096  ]\n",
      " [113.07743 ]\n",
      " [ 41.39039 ]\n",
      " [ 72.4224  ]\n",
      " [ 55.486534]\n",
      " [282.813   ]\n",
      " [ 98.20957 ]\n",
      " [259.13516 ]\n",
      " [280.29376 ]\n",
      " [157.14282 ]\n",
      " [147.8024  ]\n",
      " [114.49421 ]\n",
      " [ 59.81255 ]\n",
      " [274.732   ]\n",
      " [261.57205 ]\n",
      " [336.82983 ]\n",
      " [245.83606 ]\n",
      " [ 70.072525]\n",
      " [175.80876 ]\n",
      " [134.90836 ]\n",
      " [145.64796 ]\n",
      " [ 85.34701 ]]\n",
      "=================\n",
      "R2 :  0.05491332245935532\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.7173\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.1096\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 11.6525\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 13.0269\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.2416\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.1917\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.1134\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.2241\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.3262\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.0672\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.8987\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.2454\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.7882\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 15.2176\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.3235\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.3937\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.3177\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.4026\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 11.6390\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 10.8608\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.1095\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.0440\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.0322\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.9078\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.9974\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.5285\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.6309\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.3043\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 11.4741\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.2051\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.2871\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.5322\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.5076\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.9932\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.0757\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.9029\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.3116\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.4544\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.5340\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 11.8418\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.0775\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.6752\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.9196\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.4399\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.2957\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.4913\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.1112\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.3161\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 13.0854\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.7977\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.4673\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.5544\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.8564\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 10.8189\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.7713\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 11.7708\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.9581\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 18.8746\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.0091\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.8590\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.8206\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.6397\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.7749\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.7556\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.1464\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.5111\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.0611\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.3420\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.8059\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.9568\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.4179\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.4037\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 12.2445\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.1874\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.2423\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 11.7579\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 11.1979\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 11.6859\n",
      "Epoch 79/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 90us/step - loss: 11.6859\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 51.1888\n",
      "loss :  51.18880081176758\n",
      "5/5 [==============================] - 0s 997us/step\n",
      "=================\n",
      "[185. 150. 246. 184. 110. 202. 336.  69.  69.  87.  66. 164. 265. 198.\n",
      " 248. 171. 102. 182. 262. 233. 151. 275. 230.  39.  42. 122.  81.  31.\n",
      " 156. 161.  80. 215. 310. 163. 265.  84.  54. 137. 248.  72. 248.  59.\n",
      "  97.  61.  72. 296.  55.  75.  53. 173. 158.  96. 140. 186.  93. 123.\n",
      " 237. 138. 292.  78. 182. 127. 321. 109. 212.  45.  96. 109.  89.  96.\n",
      "  60.  51. 200. 265.  68.  91. 172. 115. 125.  53.  63. 259. 214. 195.\n",
      " 258. 235. 173.  59. 219. 170.  77.  49.  66. 144. 113. 233. 162. 121.\n",
      "  88. 302. 128.  52. 178.  90. 164. 135. 103. 200. 178. 261.  64.  59.\n",
      "  79.  47. 107.  39. 151. 104. 217. 232.  55. 245. 131.  64. 222. 249.\n",
      " 128. 293. 138. 273. 158. 168. 103.]\n",
      "[[187.20157 ]\n",
      " [ 59.047012]\n",
      " [268.7008  ]\n",
      " [205.81241 ]\n",
      " [196.48195 ]\n",
      " [235.35208 ]\n",
      " [283.30313 ]\n",
      " [ 53.56433 ]\n",
      " [155.16101 ]\n",
      " [171.89905 ]\n",
      " [203.29356 ]\n",
      " [208.67896 ]\n",
      " [228.25801 ]\n",
      " [282.49326 ]\n",
      " [235.07626 ]\n",
      " [183.14113 ]\n",
      " [ 47.607224]\n",
      " [246.23076 ]\n",
      " [269.26855 ]\n",
      " [272.8354  ]\n",
      " [219.54945 ]\n",
      " [269.5515  ]\n",
      " [ 89.95406 ]\n",
      " [ 76.139755]\n",
      " [ 47.714195]\n",
      " [175.64236 ]\n",
      " [ 42.829433]\n",
      " [ 75.07702 ]\n",
      " [171.20612 ]\n",
      " [180.2495  ]\n",
      " [ 82.97924 ]\n",
      " [225.67473 ]\n",
      " [ 52.120026]\n",
      " [254.44499 ]\n",
      " [222.2482  ]\n",
      " [ 61.527473]\n",
      " [ 70.16094 ]\n",
      " [128.70052 ]\n",
      " [219.63322 ]\n",
      " [ 89.06328 ]\n",
      " [198.46251 ]\n",
      " [120.873344]\n",
      " [232.88652 ]\n",
      " [ 93.278145]\n",
      " [ 60.45175 ]\n",
      " [303.3187  ]\n",
      " [156.17607 ]\n",
      " [ 86.08739 ]\n",
      " [ 70.16094 ]\n",
      " [259.89218 ]\n",
      " [169.89772 ]\n",
      " [195.57335 ]\n",
      " [117.1213  ]\n",
      " [210.29176 ]\n",
      " [113.33396 ]\n",
      " [227.50569 ]\n",
      " [305.7422  ]\n",
      " [166.23845 ]\n",
      " [200.2109  ]\n",
      " [296.80774 ]\n",
      " [ 94.44169 ]\n",
      " [116.739746]\n",
      " [294.69565 ]\n",
      " [136.8639  ]\n",
      " [234.85423 ]\n",
      " [ 69.401276]\n",
      " [111.16115 ]\n",
      " [ 70.47486 ]\n",
      " [174.16832 ]\n",
      " [115.82676 ]\n",
      " [ 96.75007 ]\n",
      " [ 71.43195 ]\n",
      " [247.65701 ]\n",
      " [273.46912 ]\n",
      " [ 91.4278  ]\n",
      " [170.31595 ]\n",
      " [158.64479 ]\n",
      " [133.57492 ]\n",
      " [145.53113 ]\n",
      " [ 77.97334 ]\n",
      " [ 45.1426  ]\n",
      " [136.52638 ]\n",
      " [170.55688 ]\n",
      " [278.013   ]\n",
      " [289.62003 ]\n",
      " [188.56946 ]\n",
      " [ 83.71297 ]\n",
      " [111.42028 ]\n",
      " [147.61533 ]\n",
      " [162.10527 ]\n",
      " [ 78.93236 ]\n",
      " [ 70.16094 ]\n",
      " [267.0962  ]\n",
      " [157.27727 ]\n",
      " [214.48999 ]\n",
      " [301.71564 ]\n",
      " [130.11218 ]\n",
      " [172.57326 ]\n",
      " [ 54.176636]\n",
      " [171.85927 ]\n",
      " [ 70.16094 ]\n",
      " [ 70.16094 ]\n",
      " [ 75.79153 ]\n",
      " [221.76698 ]\n",
      " [136.42273 ]\n",
      " [ 69.77693 ]\n",
      " [148.33412 ]\n",
      " [121.4754  ]\n",
      " [249.10869 ]\n",
      " [178.15656 ]\n",
      " [138.03413 ]\n",
      " [ 81.521935]\n",
      " [140.44188 ]\n",
      " [ 42.82004 ]\n",
      " [ 76.96984 ]\n",
      " [ 55.03411 ]\n",
      " [255.11005 ]\n",
      " [108.091835]\n",
      " [214.80066 ]\n",
      " [230.4289  ]\n",
      " [157.33827 ]\n",
      " [119.49308 ]\n",
      " [130.23045 ]\n",
      " [ 63.06422 ]\n",
      " [218.89127 ]\n",
      " [237.59041 ]\n",
      " [336.78275 ]\n",
      " [205.058   ]\n",
      " [ 81.652565]\n",
      " [165.06612 ]\n",
      " [134.63246 ]\n",
      " [139.83885 ]\n",
      " [159.52464 ]]\n",
      "=================\n",
      "R2 :  0.1876776137879702\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 11.6133\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.1740\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.2096\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.1639\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.4289\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.2581\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 11.8520\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.6577\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 11.8687\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 11.0504\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.6564\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.2097\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.5897\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.0974\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.5609\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.2608\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.1522\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.1809\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 11.5971\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.1489\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 11.2319\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 11.5738\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 11.7189\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.1433\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.7689\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.3148\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.7387\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.0760\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.5002\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.8228\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 11.8280\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.1718\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.7539\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.5272\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 11.1594\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 11.5378\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 11.9368\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.3898\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.9540\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.2822\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.5736\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.7304\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.0300\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.2162\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 11.9712\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 11.7402\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.8304\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.4048\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.0282\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 11.6158\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.2313\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 11.8979\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.1786\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 11.4387\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.8906\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.6050\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.8664\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 12.6901\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.4028\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.2056\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.2045\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 15.4397\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.0195\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.7627\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.2082\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.4481\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 13.2387\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.7806\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.0655\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.3723\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 11.8382\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.3619\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.4669\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.6797\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.1153\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 11.9777\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.1571\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.6430\n",
      "Epoch 79/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 90us/step - loss: 12.6430\n",
      "5/5 [==============================] - 0s 749us/step - loss: 50.9911\n",
      "loss :  50.99107360839844\n",
      "5/5 [==============================] - 0s 997us/step\n",
      "=================\n",
      "[185. 150. 246. 184. 110. 202. 336.  69.  69.  87.  66. 164. 265. 198.\n",
      " 248. 171. 102. 182. 262. 233. 151. 275. 230.  39.  42. 122.  81.  31.\n",
      " 156. 161.  80. 215. 310. 163. 265.  84.  54. 137. 248.  72. 248.  59.\n",
      "  97.  61.  72. 296.  55.  75.  53. 173. 158.  96. 140. 186.  93. 123.\n",
      " 237. 138. 292.  78. 182. 127. 321. 109. 212.  45.  96. 109.  89.  96.\n",
      "  60.  51. 200. 265.  68.  91. 172. 115. 125.  53.  63. 259. 214. 195.\n",
      " 258. 235. 173.  59. 219. 170.  77.  49.  66. 144. 113. 233. 162. 121.\n",
      "  88. 302. 128.  52. 178.  90. 164. 135. 103. 200. 178. 261.  64.  59.\n",
      "  79.  47. 107.  39. 151. 104. 217. 232.  55. 245. 131.  64. 222. 249.\n",
      " 128. 293. 138. 273. 158. 168. 103.]\n",
      "[[183.44331 ]\n",
      " [ 52.714134]\n",
      " [258.34595 ]\n",
      " [217.36465 ]\n",
      " [194.93265 ]\n",
      " [243.63226 ]\n",
      " [273.2739  ]\n",
      " [104.64459 ]\n",
      " [177.76158 ]\n",
      " [157.21843 ]\n",
      " [160.79065 ]\n",
      " [234.11365 ]\n",
      " [225.59094 ]\n",
      " [283.7483  ]\n",
      " [244.89066 ]\n",
      " [198.59596 ]\n",
      " [ 45.967136]\n",
      " [256.15698 ]\n",
      " [261.05396 ]\n",
      " [260.0221  ]\n",
      " [220.05936 ]\n",
      " [271.77634 ]\n",
      " [101.76653 ]\n",
      " [ 68.647385]\n",
      " [ 46.38735 ]\n",
      " [152.28313 ]\n",
      " [ 48.17857 ]\n",
      " [ 73.39335 ]\n",
      " [163.93619 ]\n",
      " [184.64609 ]\n",
      " [114.724594]\n",
      " [258.86423 ]\n",
      " [ 52.4327  ]\n",
      " [262.30862 ]\n",
      " [236.88571 ]\n",
      " [ 59.86643 ]\n",
      " [ 68.647385]\n",
      " [115.24463 ]\n",
      " [233.43042 ]\n",
      " [119.445305]\n",
      " [200.21492 ]\n",
      " [125.062935]\n",
      " [216.63582 ]\n",
      " [ 80.20612 ]\n",
      " [ 58.84174 ]\n",
      " [291.222   ]\n",
      " [127.24137 ]\n",
      " [ 51.772785]\n",
      " [ 49.47951 ]\n",
      " [261.74905 ]\n",
      " [176.90726 ]\n",
      " [154.49661 ]\n",
      " [106.72389 ]\n",
      " [205.147   ]\n",
      " [108.99934 ]\n",
      " [247.25589 ]\n",
      " [269.36453 ]\n",
      " [154.51794 ]\n",
      " [210.34712 ]\n",
      " [290.5995  ]\n",
      " [ 93.900635]\n",
      " [176.67715 ]\n",
      " [281.69376 ]\n",
      " [131.46329 ]\n",
      " [256.4117  ]\n",
      " [ 58.829063]\n",
      " [105.58027 ]\n",
      " [ 66.78844 ]\n",
      " [100.024635]\n",
      " [112.977356]\n",
      " [ 82.97774 ]\n",
      " [ 68.647385]\n",
      " [245.974   ]\n",
      " [276.30527 ]\n",
      " [ 79.47014 ]\n",
      " [163.05804 ]\n",
      " [140.11761 ]\n",
      " [111.26798 ]\n",
      " [130.92514 ]\n",
      " [ 52.93703 ]\n",
      " [ 46.12783 ]\n",
      " [185.75145 ]\n",
      " [171.26627 ]\n",
      " [294.841   ]\n",
      " [320.96426 ]\n",
      " [136.10576 ]\n",
      " [235.65263 ]\n",
      " [108.05256 ]\n",
      " [118.00172 ]\n",
      " [177.27394 ]\n",
      " [156.99902 ]\n",
      " [ 48.70292 ]\n",
      " [279.0758  ]\n",
      " [158.61449 ]\n",
      " [227.35732 ]\n",
      " [298.54593 ]\n",
      " [123.93285 ]\n",
      " [175.8301  ]\n",
      " [ 47.95766 ]\n",
      " [152.12479 ]\n",
      " [ 68.647385]\n",
      " [ 68.647385]\n",
      " [ 64.725494]\n",
      " [206.27904 ]\n",
      " [154.84586 ]\n",
      " [ 47.703884]\n",
      " [135.3569  ]\n",
      " [123.53153 ]\n",
      " [259.66428 ]\n",
      " [184.40857 ]\n",
      " [140.08162 ]\n",
      " [ 83.289604]\n",
      " [ 78.625786]\n",
      " [ 47.184822]\n",
      " [ 84.11988 ]\n",
      " [ 67.189545]\n",
      " [260.43286 ]\n",
      " [ 99.378685]\n",
      " [238.96494 ]\n",
      " [266.68927 ]\n",
      " [130.28479 ]\n",
      " [106.32535 ]\n",
      " [ 86.211426]\n",
      " [ 50.759693]\n",
      " [229.53479 ]\n",
      " [244.15915 ]\n",
      " [311.95032 ]\n",
      " [210.61978 ]\n",
      " [ 82.20403 ]\n",
      " [175.35654 ]\n",
      " [152.07462 ]\n",
      " [129.30855 ]\n",
      " [ 64.3195  ]]\n",
      "=================\n",
      "R2 :  0.20560407940603065\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.4674\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.5535\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 11.9972\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.9672\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 17.4565\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.7071\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.3947\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 13.2025\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.0108\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.9866\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.5059\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.6891\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 11.1032\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 11.8260\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 10.9433\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 11.0861\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.7192\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.7021\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 12.9328\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.1492\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 11.1768\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.7208\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.7943\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 11.3763\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.6488\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 10.9155\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.8295\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 10.6831\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 11.0628\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.7152\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.6638\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.0490\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.0302\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 11.6600\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.0073\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.0285\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 11.6893\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 11.8219\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 11.5287\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.6624\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 11.6249\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 10.5435\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 16.2128\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.3028\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 11.0079\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 11.7719\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.9220\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.9019\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.5163\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.2697\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 11.2446\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 11.7890\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 10.8523\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.3185\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.2634\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.5104\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.4019\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 11.5194\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.9660\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.3830\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.1616\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.1894\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 11.6040\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.6235\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 10.9152\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.2826\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 10.1559\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.1226\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 15.7552\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 11.5003\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 11.5732\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.7316\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 11.2769\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.7377\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.7230\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 11.9721\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 10.7864\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.4488\n",
      "Epoch 79/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 110us/step - loss: 12.4488\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 50.5432\n",
      "loss :  50.543212890625\n",
      "5/5 [==============================] - 0s 998us/step\n",
      "=================\n",
      "[185. 150. 246. 184. 110. 202. 336.  69.  69.  87.  66. 164. 265. 198.\n",
      " 248. 171. 102. 182. 262. 233. 151. 275. 230.  39.  42. 122.  81.  31.\n",
      " 156. 161.  80. 215. 310. 163. 265.  84.  54. 137. 248.  72. 248.  59.\n",
      "  97.  61.  72. 296.  55.  75.  53. 173. 158.  96. 140. 186.  93. 123.\n",
      " 237. 138. 292.  78. 182. 127. 321. 109. 212.  45.  96. 109.  89.  96.\n",
      "  60.  51. 200. 265.  68.  91. 172. 115. 125.  53.  63. 259. 214. 195.\n",
      " 258. 235. 173.  59. 219. 170.  77.  49.  66. 144. 113. 233. 162. 121.\n",
      "  88. 302. 128.  52. 178.  90. 164. 135. 103. 200. 178. 261.  64.  59.\n",
      "  79.  47. 107.  39. 151. 104. 217. 232.  55. 245. 131.  64. 222. 249.\n",
      " 128. 293. 138. 273. 158. 168. 103.]\n",
      "[[192.27983 ]\n",
      " [ 58.22722 ]\n",
      " [278.49713 ]\n",
      " [193.54597 ]\n",
      " [202.7806  ]\n",
      " [226.18138 ]\n",
      " [277.08194 ]\n",
      " [ 50.85289 ]\n",
      " [146.20299 ]\n",
      " [151.70654 ]\n",
      " [185.62471 ]\n",
      " [204.44125 ]\n",
      " [230.588   ]\n",
      " [280.32193 ]\n",
      " [251.83044 ]\n",
      " [201.27213 ]\n",
      " [ 40.26468 ]\n",
      " [237.92674 ]\n",
      " [260.73975 ]\n",
      " [261.77444 ]\n",
      " [220.93216 ]\n",
      " [276.74524 ]\n",
      " [112.06946 ]\n",
      " [ 69.36992 ]\n",
      " [ 43.57223 ]\n",
      " [158.87811 ]\n",
      " [ 42.44642 ]\n",
      " [ 57.980057]\n",
      " [182.36736 ]\n",
      " [195.41005 ]\n",
      " [116.63263 ]\n",
      " [225.12083 ]\n",
      " [ 50.778   ]\n",
      " [255.75351 ]\n",
      " [220.46455 ]\n",
      " [ 56.389957]\n",
      " [ 69.36992 ]\n",
      " [123.83209 ]\n",
      " [214.27167 ]\n",
      " [100.23506 ]\n",
      " [203.17079 ]\n",
      " [115.02545 ]\n",
      " [254.91093 ]\n",
      " [ 80.28336 ]\n",
      " [ 51.897964]\n",
      " [309.78223 ]\n",
      " [167.7828  ]\n",
      " [ 64.84545 ]\n",
      " [ 69.184135]\n",
      " [246.30655 ]\n",
      " [171.0025  ]\n",
      " [160.60747 ]\n",
      " [111.88166 ]\n",
      " [193.11655 ]\n",
      " [117.82437 ]\n",
      " [221.96692 ]\n",
      " [279.84317 ]\n",
      " [161.70439 ]\n",
      " [217.418   ]\n",
      " [322.28958 ]\n",
      " [ 86.85786 ]\n",
      " [122.014175]\n",
      " [288.09814 ]\n",
      " [115.621346]\n",
      " [234.79932 ]\n",
      " [ 62.32434 ]\n",
      " [114.65241 ]\n",
      " [ 63.25082 ]\n",
      " [167.44038 ]\n",
      " [104.51089 ]\n",
      " [ 87.28296 ]\n",
      " [ 69.70817 ]\n",
      " [243.20473 ]\n",
      " [278.2923  ]\n",
      " [ 86.65601 ]\n",
      " [167.91151 ]\n",
      " [148.15541 ]\n",
      " [139.50961 ]\n",
      " [137.99417 ]\n",
      " [ 51.171284]\n",
      " [ 40.3762  ]\n",
      " [127.24539 ]\n",
      " [173.78815 ]\n",
      " [283.272   ]\n",
      " [289.6402  ]\n",
      " [166.26372 ]\n",
      " [170.51494 ]\n",
      " [115.09629 ]\n",
      " [131.08316 ]\n",
      " [159.69948 ]\n",
      " [ 71.66493 ]\n",
      " [ 69.36992 ]\n",
      " [288.8336  ]\n",
      " [141.731   ]\n",
      " [215.3402  ]\n",
      " [294.53635 ]\n",
      " [138.97562 ]\n",
      " [175.81866 ]\n",
      " [ 47.050884]\n",
      " [151.50623 ]\n",
      " [ 69.36992 ]\n",
      " [ 69.36992 ]\n",
      " [ 54.38609 ]\n",
      " [233.75539 ]\n",
      " [131.3762  ]\n",
      " [ 59.33489 ]\n",
      " [140.58281 ]\n",
      " [121.0423  ]\n",
      " [259.24442 ]\n",
      " [163.72849 ]\n",
      " [146.9453  ]\n",
      " [ 74.6153  ]\n",
      " [ 92.106804]\n",
      " [ 43.13358 ]\n",
      " [ 79.245415]\n",
      " [ 57.92372 ]\n",
      " [272.94638 ]\n",
      " [ 95.20144 ]\n",
      " [213.4464  ]\n",
      " [246.49715 ]\n",
      " [134.62077 ]\n",
      " [ 82.36665 ]\n",
      " [ 98.98182 ]\n",
      " [ 58.70415 ]\n",
      " [249.13405 ]\n",
      " [222.89969 ]\n",
      " [313.41885 ]\n",
      " [212.40042 ]\n",
      " [ 80.63438 ]\n",
      " [161.53212 ]\n",
      " [135.9973  ]\n",
      " [142.08301 ]\n",
      " [107.41947 ]]\n",
      "=================\n",
      "R2 :  0.16666326385613395\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.0783\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.4168\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 11.4968\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.8244\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.2079\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.2557\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 11.5961\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.3430\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 13.0460\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.0235\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.4516\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.4808\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.7652\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.0665\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.2168\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.0102\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 10.9871\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.6039\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.3186\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.2379\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.9674\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.8232\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 11.9882\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 11.6448\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 10.3742\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.0608\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 11.4087\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 11.4658\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.7605\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.8419\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.2289\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 10.8896\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 10.8926\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.6150\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 11.3911\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 11.3630\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.2031\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.8588\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.5373\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.4239\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.2238\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.8005\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.2451\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.2440\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 10.4716\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 10.8550\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 16.5334\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.4737\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 11.8054\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.5698\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 10.8977\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.2279\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.1310\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 10.6618\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 11.2441\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 11.5679\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 10.2365\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 11.4271\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 11.9842\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 10.9978\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 10.9805\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 12.7259\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.1866\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.1708\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 11.3980\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 10.9868\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 11.7188\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 10.9042\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 10.8604\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 11.0518\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.5208\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.3584\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.1556\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.1200\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.7291\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.3471\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 11.8794\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.5847\n",
      "Epoch 79/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 110us/step - loss: 14.5847\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 47.9527\n",
      "loss :  47.95271301269531\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "=================\n",
      "[185. 150. 246. 184. 110. 202. 336.  69.  69.  87.  66. 164. 265. 198.\n",
      " 248. 171. 102. 182. 262. 233. 151. 275. 230.  39.  42. 122.  81.  31.\n",
      " 156. 161.  80. 215. 310. 163. 265.  84.  54. 137. 248.  72. 248.  59.\n",
      "  97.  61.  72. 296.  55.  75.  53. 173. 158.  96. 140. 186.  93. 123.\n",
      " 237. 138. 292.  78. 182. 127. 321. 109. 212.  45.  96. 109.  89.  96.\n",
      "  60.  51. 200. 265.  68.  91. 172. 115. 125.  53.  63. 259. 214. 195.\n",
      " 258. 235. 173.  59. 219. 170.  77.  49.  66. 144. 113. 233. 162. 121.\n",
      "  88. 302. 128.  52. 178.  90. 164. 135. 103. 200. 178. 261.  64.  59.\n",
      "  79.  47. 107.  39. 151. 104. 217. 232.  55. 245. 131.  64. 222. 249.\n",
      " 128. 293. 138. 273. 158. 168. 103.]\n",
      "[[170.11285 ]\n",
      " [ 53.11723 ]\n",
      " [256.75165 ]\n",
      " [177.40279 ]\n",
      " [187.88013 ]\n",
      " [216.06982 ]\n",
      " [279.87665 ]\n",
      " [ 50.589493]\n",
      " [154.41928 ]\n",
      " [155.04272 ]\n",
      " [175.16843 ]\n",
      " [198.46811 ]\n",
      " [210.42123 ]\n",
      " [264.97607 ]\n",
      " [242.08835 ]\n",
      " [188.47069 ]\n",
      " [ 41.8764  ]\n",
      " [258.83157 ]\n",
      " [248.30977 ]\n",
      " [237.59229 ]\n",
      " [211.06026 ]\n",
      " [242.08403 ]\n",
      " [ 99.84156 ]\n",
      " [ 65.80956 ]\n",
      " [ 43.657642]\n",
      " [172.38635 ]\n",
      " [ 44.03554 ]\n",
      " [ 79.35354 ]\n",
      " [161.39778 ]\n",
      " [164.91068 ]\n",
      " [ 75.23879 ]\n",
      " [200.33951 ]\n",
      " [ 59.93066 ]\n",
      " [236.46915 ]\n",
      " [183.73306 ]\n",
      " [ 54.95388 ]\n",
      " [ 65.80956 ]\n",
      " [107.588104]\n",
      " [220.37106 ]\n",
      " [102.19565 ]\n",
      " [181.09042 ]\n",
      " [119.36791 ]\n",
      " [222.75427 ]\n",
      " [ 88.701096]\n",
      " [ 73.89271 ]\n",
      " [272.10315 ]\n",
      " [183.90204 ]\n",
      " [ 56.69344 ]\n",
      " [ 46.427216]\n",
      " [242.56448 ]\n",
      " [179.62997 ]\n",
      " [133.90227 ]\n",
      " [149.92838 ]\n",
      " [179.40187 ]\n",
      " [ 96.75431 ]\n",
      " [185.31015 ]\n",
      " [251.73193 ]\n",
      " [155.03764 ]\n",
      " [203.68527 ]\n",
      " [298.66403 ]\n",
      " [100.0882  ]\n",
      " [130.70284 ]\n",
      " [286.9163  ]\n",
      " [134.3026  ]\n",
      " [223.2962  ]\n",
      " [ 61.87339 ]\n",
      " [106.85305 ]\n",
      " [ 65.315445]\n",
      " [142.52475 ]\n",
      " [126.60611 ]\n",
      " [ 80.407196]\n",
      " [ 65.80956 ]\n",
      " [232.15129 ]\n",
      " [270.7453  ]\n",
      " [ 64.68463 ]\n",
      " [144.99467 ]\n",
      " [153.92949 ]\n",
      " [125.16083 ]\n",
      " [152.62314 ]\n",
      " [ 91.1993  ]\n",
      " [ 44.652386]\n",
      " [ 99.92773 ]\n",
      " [157.2497  ]\n",
      " [277.2461  ]\n",
      " [276.3083  ]\n",
      " [141.35837 ]\n",
      " [160.0621  ]\n",
      " [104.21525 ]\n",
      " [122.273445]\n",
      " [152.4501  ]\n",
      " [113.53213 ]\n",
      " [ 44.441998]\n",
      " [268.69144 ]\n",
      " [152.03073 ]\n",
      " [215.00648 ]\n",
      " [273.074   ]\n",
      " [118.618515]\n",
      " [141.45256 ]\n",
      " [ 73.14935 ]\n",
      " [156.18855 ]\n",
      " [ 65.80956 ]\n",
      " [ 65.80956 ]\n",
      " [120.59026 ]\n",
      " [196.86789 ]\n",
      " [143.30258 ]\n",
      " [ 40.728516]\n",
      " [145.2119  ]\n",
      " [123.443535]\n",
      " [233.44286 ]\n",
      " [184.03162 ]\n",
      " [126.01911 ]\n",
      " [ 95.71976 ]\n",
      " [142.90364 ]\n",
      " [ 45.31595 ]\n",
      " [ 80.56481 ]\n",
      " [ 67.65479 ]\n",
      " [235.15295 ]\n",
      " [121.0218  ]\n",
      " [203.42805 ]\n",
      " [227.70547 ]\n",
      " [163.11595 ]\n",
      " [ 85.364006]\n",
      " [ 97.887245]\n",
      " [ 56.91523 ]\n",
      " [244.76456 ]\n",
      " [237.61017 ]\n",
      " [276.7169  ]\n",
      " [209.93005 ]\n",
      " [ 73.749016]\n",
      " [176.34294 ]\n",
      " [140.01234 ]\n",
      " [134.36052 ]\n",
      " [ 66.649155]]\n",
      "=================\n",
      "R2 :  0.2624200891664955\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 13.0872\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 11.6666\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 11.2939\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 11.1100\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.0195\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 11.8062\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.2997\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.1428\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 9.8455\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 11.8803\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.5165\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 10.7842\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 11.1159\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 11.4260\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.7497\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.8339\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 15.4400\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.3184\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.9416\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 10.2545\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 11.4966\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 10.9813\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 11.4281\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 9.6861\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 18.0400\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.1152\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 9.9043\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.7748\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 11.7006\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.1154\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 11.9587\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 10.8005\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 10.6138\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.0369\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 10.2572\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 11.4546\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 14.1014\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.7246\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 12.9968\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 11.2637\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 10.7654\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.3810\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 10.6908\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 12.6770\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 11.2767\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 15.7537\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 14.4019\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 13.0549\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 17.1643\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 13.1701\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 10.8392\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 11.7280\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 11.2142\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 12.6886\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 11.1372\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 11.4469\n",
      "Epoch 57/100\n",
      " 44/100 [============>.................] - ETA: 0s - loss: 11.4883"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12844\\1772233586.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# 4. 모델 컴파일\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"loss : \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\bitcamp\\anaconda3\\envs\\tf27\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\bitcamp\\anaconda3\\envs\\tf27\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1562\u001b[0m                         ):\n\u001b[0;32m   1563\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1564\u001b[1;33m                             \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1565\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1566\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\bitcamp\\anaconda3\\envs\\tf27\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\bitcamp\\anaconda3\\envs\\tf27\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\bitcamp\\anaconda3\\envs\\tf27\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\bitcamp\\anaconda3\\envs\\tf27\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2494\u001b[0m       (graph_function,\n\u001b[0;32m   2495\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2497\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2498\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\bitcamp\\anaconda3\\envs\\tf27\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1860\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1861\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1862\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1863\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1864\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mc:\\Users\\bitcamp\\anaconda3\\envs\\tf27\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\bitcamp\\anaconda3\\envs\\tf27\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "model.compile(loss=\"mae\",optimizer=\"adam\")\n",
    "f = open(\"C:\\study\\keras\\diabets.txt\",'a')\n",
    "\n",
    "# 4. 모델 컴파일\n",
    "while (True):\n",
    "    model.fit(x_train, y_train, epochs=100, batch_size=1, validation_split=0.25)\n",
    "\n",
    "    loss = model.evaluate(x_test,y_test)\n",
    "    print(\"loss : \",loss)\n",
    "    y_predict =model.predict(x_test)\n",
    "    print(\"=================\")\n",
    "    print(y_test)\n",
    "    print(y_predict)\n",
    "    print(\"=================\")\n",
    "    r2 = r2_score(y_test,y_predict)\n",
    "    print(\"R2 : \",r2)\n",
    "    \n",
    "    f.write(str(datetime.now())+str(r2)+\"\\n\") \n",
    "    \n",
    "    if r2 >= 0.62 :\n",
    "        f.write(str(datetime.now())+str(r2)+\"\\n\") \n",
    "        model.save(\"diabets.h5\")\n",
    "        f.close()\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf27",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b47fb4e6c68d4941015efb0bbf71549277582fe8531338196fc3c7fa71b6aab8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
