{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "dataset = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20640, 8)\n",
      "(20640,)\n"
     ]
    }
   ],
   "source": [
    "x = dataset.data\n",
    "y = dataset.target\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude']\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "# 사이킥 런의 칼럼 조회기능\n",
    "print(dataset.feature_names)\n",
    "print(len(dataset.feature_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _california_housing_dataset:\n",
      "\n",
      "California Housing dataset\n",
      "--------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 20640\n",
      "\n",
      "    :Number of Attributes: 8 numeric, predictive attributes and the target\n",
      "\n",
      "    :Attribute Information:\n",
      "        - MedInc        median income in block group\n",
      "        - HouseAge      median house age in block group\n",
      "        - AveRooms      average number of rooms per household\n",
      "        - AveBedrms     average number of bedrooms per household\n",
      "        - Population    block group population\n",
      "        - AveOccup      average number of household members\n",
      "        - Latitude      block group latitude\n",
      "        - Longitude     block group longitude\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "This dataset was obtained from the StatLib repository.\n",
      "https://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\n",
      "\n",
      "The target variable is the median house value for California districts,\n",
      "expressed in hundreds of thousands of dollars ($100,000).\n",
      "\n",
      "This dataset was derived from the 1990 U.S. census, using one row per census\n",
      "block group. A block group is the smallest geographical unit for which the U.S.\n",
      "Census Bureau publishes sample data (a block group typically has a population\n",
      "of 600 to 3,000 people).\n",
      "\n",
      "An household is a group of people residing within a home. Since the average\n",
      "number of rooms and bedrooms in this dataset are provided per household, these\n",
      "columns may take surpinsingly large values for block groups with few households\n",
      "and many empty houses, such as vacation resorts.\n",
      "\n",
      "It can be downloaded/loaded using the\n",
      ":func:`sklearn.datasets.fetch_california_housing` function.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
      "      Statistics and Probability Letters, 33 (1997) 291-297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 사이킥런의 데이터 요약\n",
    "print(dataset.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14447\n",
      "6193\n"
     ]
    }
   ],
   "source": [
    "# 3. 모델구성\n",
    "# 실습 train 0.7 이상\n",
    "# 평가지표 R2 : 0.8 이상으로 뽑아내보기 / RMSE 사용\n",
    "\n",
    "x_train, x_test,y_train,y_test = train_test_split(x,y,\n",
    "    train_size=0.7,\n",
    "    shuffle = True,\n",
    "    random_state= 123\n",
    ")\n",
    "\n",
    "print(len(x_train))\n",
    "print(len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_90 (Dense)            (None, 10)                90        \n",
      "                                                                 \n",
      " dense_91 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_92 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_93 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_94 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_95 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_96 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_97 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_98 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_99 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_100 (Dense)           (None, 10)                110       \n",
      "                                                                 \n",
      " dense_101 (Dense)           (None, 10)                110       \n",
      "                                                                 \n",
      " dense_102 (Dense)           (None, 10)                110       \n",
      "                                                                 \n",
      " dense_103 (Dense)           (None, 10)                110       \n",
      "                                                                 \n",
      " dense_104 (Dense)           (None, 10)                110       \n",
      "                                                                 \n",
      " dense_105 (Dense)           (None, 10)                110       \n",
      "                                                                 \n",
      " dense_106 (Dense)           (None, 10)                110       \n",
      "                                                                 \n",
      " dense_107 (Dense)           (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,861\n",
      "Trainable params: 1,861\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from random import randrange\n",
    "number1 = randrange(1,10,1)\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(10,input_dim = 8),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(1)\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "100/100 [==============================] - 1s 1ms/step - loss: 1.3425\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.9829\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9808\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.9144\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.9591\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.8949\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.8941\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.9496\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.9306\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.8774\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.9622\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.9165\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.8957\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.8904\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.9677\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.9014\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.8290\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.8037\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.8578\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.9363\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.9169\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.8398\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.8810\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.8546\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.8679\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.8684\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.8570\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.9032\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.8163\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.8941\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.8375\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.8694\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.8570\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.9095\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.8963\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.9113\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.8767\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.9379\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.8341\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.8755\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.8342\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.8508\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.9037\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8750\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8865\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.9014\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.8011\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.8524\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.7990\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.9321\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.7890\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.8339\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.8331\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.8530\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.8564\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.7801\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.8120\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.8232\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.8498\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.7414\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.7607\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.7609\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.7340\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.7679\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.7267\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.7066\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6817\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.7412\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6871\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6947\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.7346\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.7484\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6598\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.7378\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.7173\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.7210\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5787\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.8402\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.7174\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.7360\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6514\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.5958\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6814\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6658\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.5948\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6141\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6274\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6914\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6310\n",
      "Epoch 90/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6389\n",
      "Epoch 91/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6227\n",
      "Epoch 92/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6297\n",
      "Epoch 93/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6767\n",
      "Epoch 94/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6107\n",
      "Epoch 95/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6541\n",
      "Epoch 96/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6987\n",
      "Epoch 97/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6082\n",
      "Epoch 98/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.7261\n",
      "Epoch 99/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6184\n",
      "Epoch 100/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6156\n",
      "194/194 [==============================] - 0s 1ms/step - loss: 0.5929\n",
      "loss :  0.592891275882721\n",
      "194/194 [==============================] - 0s 1ms/step\n",
      "=================\n",
      "[1.516 0.992 1.345 ... 4.869 2.362 1.042]\n",
      "[[2.0637555]\n",
      " [1.717363 ]\n",
      " [1.9538091]\n",
      " ...\n",
      " [2.699182 ]\n",
      " [2.3361955]\n",
      " [1.8868685]]\n",
      "=================\n",
      "R2 :  0.5129328119767547\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.5967\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.7271\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6977\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6069\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6672\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6894\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6638\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6423\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5943\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6804\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6666\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6334\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5990\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6356\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6382\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5841\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5727\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6618\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6339\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6178\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6600\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5889\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6668\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6619\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6053\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6401\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6524\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6395\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6586\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6283\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6036\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.5467\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6893\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5732\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6484\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6409\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6564\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6940\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6214\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5905\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6048\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6330\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6251\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6638\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6494\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6714\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5740\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6430\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5479\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5843\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.5677\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5905\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6605\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6138\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6420\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6194\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6428\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5822\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6333\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6950\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6057\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6021\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6106\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6761\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5415\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6526\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6072\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6202\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.5867\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6170\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5704\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6262\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6070\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6111\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5905\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6219\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6182\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6385\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5497\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6006\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6679\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5698\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6396\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5588\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.5718\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5645\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6049\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6661\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6181\n",
      "Epoch 90/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6054\n",
      "Epoch 91/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6014\n",
      "Epoch 92/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6386\n",
      "Epoch 93/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6541\n",
      "Epoch 94/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6364\n",
      "Epoch 95/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6214\n",
      "Epoch 96/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5758\n",
      "Epoch 97/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6224\n",
      "Epoch 98/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.5639\n",
      "Epoch 99/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6155\n",
      "Epoch 100/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6216\n",
      "194/194 [==============================] - 0s 977us/step - loss: 0.5983\n",
      "loss :  0.5983142256736755\n",
      "194/194 [==============================] - 0s 894us/step\n",
      "=================\n",
      "[1.516 0.992 1.345 ... 4.869 2.362 1.042]\n",
      "[[1.8054408]\n",
      " [1.4279966]\n",
      " [1.5702983]\n",
      " ...\n",
      " [2.6927707]\n",
      " [1.9122648]\n",
      " [1.5305483]]\n",
      "=================\n",
      "R2 :  0.47250470709259007\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6095\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5605\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5875\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6465\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6150\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5685\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6261\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6220\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6231\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6371\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6400\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6508\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6126\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.5550\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6306\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6672\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5819\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5928\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5955\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5574\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6251\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 0.6031\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.5875\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6193\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6026\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5889\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5916\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5809\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6101\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5424\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6091\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.5692\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5869\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5889\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5751\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5881\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5783\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6128\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6504\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5687\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5561\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5988\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6353\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5672\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5648\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6547\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6192\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5726\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5401\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5719\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5294\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6206\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6202\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6067\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5565\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.5985\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5804\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6390\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.5647\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.5605\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.5705\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5640\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6080\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6664\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6098\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.5787\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6405\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5862\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5631\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6036\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5513\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5908\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6147\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5577\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5827\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5904\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5715\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6282\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5699\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5947\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.5892\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.5927\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.5768\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6286\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6073\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.5832\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5446\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5909\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5684\n",
      "Epoch 90/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.5872\n",
      "Epoch 91/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5584\n",
      "Epoch 92/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6036\n",
      "Epoch 93/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.5859\n",
      "Epoch 94/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6151\n",
      "Epoch 95/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6236\n",
      "Epoch 96/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5152\n",
      "Epoch 97/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5892\n",
      "Epoch 98/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.5728\n",
      "Epoch 99/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5577\n",
      "Epoch 100/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5887\n",
      "194/194 [==============================] - 0s 1ms/step - loss: 0.5669\n",
      "loss :  0.566856324672699\n",
      "194/194 [==============================] - 0s 925us/step\n",
      "=================\n",
      "[1.516 0.992 1.345 ... 4.869 2.362 1.042]\n",
      "[[2.1226847]\n",
      " [1.7286956]\n",
      " [1.8603009]\n",
      " ...\n",
      " [2.7606833]\n",
      " [2.4138834]\n",
      " [1.8582793]]\n",
      "=================\n",
      "R2 :  0.5545827753794981\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'_io.TextIOWrapper' object has no attribute 'cloes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10008\\2441110014.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"califonia.h5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcloes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: '_io.TextIOWrapper' object has no attribute 'cloes'"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from sklearn.metrics import r2_score\n",
    "now = datetime.now()\n",
    "\n",
    "model.compile(loss=\"mae\",optimizer=\"adam\")\n",
    "f = open(\"C:\\study\\keras\\califonia.txt\",'a')\n",
    "# 4. 모델 컴파일\n",
    "while (True):\n",
    "    model.fit(x_train,y_train,epochs=100,batch_size=4,steps_per_epoch=100)\n",
    "    loss = model.evaluate(x_test,y_test)\n",
    "    print(\"loss : \",loss)\n",
    "    y_predict =model.predict(x_test)\n",
    "    print(\"=================\")\n",
    "    print(y_test)\n",
    "    print(y_predict)\n",
    "    print(\"=================\")\n",
    "    r2 = r2_score(y_test,y_predict)\n",
    "    print(\"R2 : \",r2)\n",
    "    \n",
    "    f.write(str(now)+str(r2)+\"\\n\") \n",
    "    \n",
    "    if r2 >= 0.55 :\n",
    "        model.save(\"califonia.h5\")\n",
    "        f.write(str(now)+str(r2)+\"\\n\") \n",
    "        f.close()\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf27",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b47fb4e6c68d4941015efb0bbf71549277582fe8531338196fc3c7fa71b6aab8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
