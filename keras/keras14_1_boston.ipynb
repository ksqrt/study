{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.3\n",
      "2.10.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bitcamp\\anaconda3\\envs\\tf27\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn as sk\n",
    "print(sk.__version__)\n",
    "print(tf.__version__)\n",
    "dataset = load_boston()\n",
    "x = dataset.data\n",
    "y = dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13)\n",
      "(506,)\n"
     ]
    }
   ],
   "source": [
    "# 13개의 칼럼 을 가지고있는 데이터를 조회합니다\n",
    "print(x.shape) #(506,13)\n",
    "# print(x)\n",
    "print(y.shape) #(506,)\n",
    "# print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CRIM' 'ZN' 'INDUS' 'CHAS' 'NOX' 'RM' 'AGE' 'DIS' 'RAD' 'TAX' 'PTRATIO'\n",
      " 'B' 'LSTAT']\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "# 사이킥 런의 칼럼 조회기능\n",
    "print(dataset.feature_names)\n",
    "print(len(dataset.feature_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _boston_dataset:\n",
      "\n",
      "Boston house prices dataset\n",
      "---------------------------\n",
      "\n",
      "**Data Set Characteristics:**  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of black people by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      ".. topic:: References\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 사이킥런의 데이터 요약\n",
    "print(dataset.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354\n",
      "152\n"
     ]
    }
   ],
   "source": [
    "# 3. 모델구성\n",
    "# 실습 train 0.7 이상\n",
    "# 평가지표 R2 : 0.8 이상으로 뽑아내보기 / RMSE 사용\n",
    "\n",
    "x_train, x_test,y_train,y_test = train_test_split(x,y,\n",
    "    train_size=0.7,\n",
    "    shuffle = True,\n",
    "    random_state= 123\n",
    ")\n",
    "\n",
    "print(len(x_train))\n",
    "print(len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 10)                140       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,911\n",
      "Trainable params: 1,911\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from random import randrange\n",
    "number1 = randrange(1,10,1)\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(10,input_dim = 13),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(1)\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "100/100 [==============================] - 1s 2ms/step - loss: 22.7375\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 10.3809\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 6.2391\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 6.4281\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 6.2833\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 5.7777\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 5.3951\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 5.4125\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 5.3480\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 5.3404\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 5.2730\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 5.0037\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 5.2520\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.6786\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 5.0887\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 5.2971\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 5.2876\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.8755\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.9922\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.8336\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.6373\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.7625\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.7577\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.5249\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.6755\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.5573\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.4675\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.4691\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.5926\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.5416\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.6704\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.3767\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2593\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.0370\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.5384\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.1211\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.9787\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.9721\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.9550\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.7029\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.5010\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.8556\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.8957\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.7261\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.6445\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.9231\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.5715\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.5442\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.5796\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.7208\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.4173\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.7800\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.3265\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.7440\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.3117\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.4718\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.3351\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.3933\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.3732\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.3605\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.1638\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.2747\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.3487\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.7915\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.1594\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.2973\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.3252\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.3423\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.4435\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.3105\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.0225\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.2120\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.3100\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.2893\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.3065\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.6629\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.3510\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.1464\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.1515\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.4459\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.2321\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.2310\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.0317\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.1888\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.1420\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.3393\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.0348\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.1391\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.6285\n",
      "Epoch 90/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 3.6285\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.3448\n",
      "loss :  3.344844102859497\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "=================\n",
      "[15.  26.6 45.4 20.8 34.9 21.9 28.7  7.2 20.  32.2 24.1 18.5 13.5 27.\n",
      " 23.1 18.9 24.5 43.1 19.8 13.8 15.6 50.  37.2 46.  50.  21.2 14.9 19.6\n",
      " 19.4 18.6 26.5 32.  10.9 20.  21.4 31.  25.  15.4 13.1 37.6 37.  18.9\n",
      " 27.9 50.  14.4 22.  19.9 21.6 15.6 15.  32.4 29.6 20.4 12.3 19.1 14.9\n",
      " 17.8  8.8 35.4 11.5 19.6 20.6 15.6 19.9 23.3 22.3 24.8 16.1 22.8 30.5\n",
      " 20.4 24.4 16.6 26.2 16.4 20.1 13.9 19.4 22.8 13.8 31.6 10.5 23.8 22.4\n",
      " 19.3 22.2 12.6 19.4 22.2 29.8  9.6 34.9 21.4 25.3 32.9 26.6 14.6 31.5\n",
      " 23.3 33.3 17.5 19.1 48.5 17.1 23.1 28.4 18.9 13.  17.2 24.1 18.5 21.8\n",
      " 13.3 23.  14.1 23.9 24.  17.2 21.5 19.1 20.8 36.  20.1  8.7 13.6 22.\n",
      " 22.2 21.1 13.4 17.4 20.1 10.2 23.1 10.2 13.1 14.3 14.5  7.2 19.6 20.6\n",
      " 22.7 26.4  7.5 20.3 50.   8.5 20.3 16.1 22.  19.6 10.2 23.2]\n",
      "[[11.582144 ]\n",
      " [24.72255  ]\n",
      " [39.443733 ]\n",
      " [11.191161 ]\n",
      " [26.303267 ]\n",
      " [29.95935  ]\n",
      " [26.896172 ]\n",
      " [14.979086 ]\n",
      " [18.302626 ]\n",
      " [23.299099 ]\n",
      " [23.364794 ]\n",
      " [21.87721  ]\n",
      " [12.712557 ]\n",
      " [27.04088  ]\n",
      " [17.21538  ]\n",
      " [20.745668 ]\n",
      " [19.460634 ]\n",
      " [33.97739  ]\n",
      " [19.463053 ]\n",
      " [12.385685 ]\n",
      " [12.206186 ]\n",
      " [19.969128 ]\n",
      " [32.84192  ]\n",
      " [42.14321  ]\n",
      " [33.807724 ]\n",
      " [20.73474  ]\n",
      " [10.805481 ]\n",
      " [21.898046 ]\n",
      " [20.797472 ]\n",
      " [14.547523 ]\n",
      " [22.747679 ]\n",
      " [38.53277  ]\n",
      " [11.599097 ]\n",
      " [20.734705 ]\n",
      " [20.944675 ]\n",
      " [26.72503  ]\n",
      " [25.313925 ]\n",
      " [14.309681 ]\n",
      " [17.13202  ]\n",
      " [42.274487 ]\n",
      " [25.111097 ]\n",
      " [18.821703 ]\n",
      " [15.772574 ]\n",
      " [46.370354 ]\n",
      " [15.786842 ]\n",
      " [22.415525 ]\n",
      " [21.611593 ]\n",
      " [23.68638  ]\n",
      " [19.251528 ]\n",
      " [15.794373 ]\n",
      " [40.234272 ]\n",
      " [21.891386 ]\n",
      " [21.78673  ]\n",
      " [11.736992 ]\n",
      " [18.571012 ]\n",
      " [11.9427185]\n",
      " [13.473726 ]\n",
      " [10.042063 ]\n",
      " [28.647232 ]\n",
      " [13.405003 ]\n",
      " [19.192648 ]\n",
      " [22.40154  ]\n",
      " [14.545087 ]\n",
      " [16.565481 ]\n",
      " [21.08578  ]\n",
      " [23.49391  ]\n",
      " [23.68037  ]\n",
      " [14.551516 ]\n",
      " [24.63254  ]\n",
      " [26.540907 ]\n",
      " [19.282831 ]\n",
      " [24.291126 ]\n",
      " [18.980669 ]\n",
      " [23.00799  ]\n",
      " [11.153156 ]\n",
      " [15.790523 ]\n",
      " [10.762766 ]\n",
      " [20.038828 ]\n",
      " [31.784857 ]\n",
      " [10.097261 ]\n",
      " [28.512114 ]\n",
      " [10.772725 ]\n",
      " [23.424067 ]\n",
      " [19.895033 ]\n",
      " [17.873875 ]\n",
      " [23.960726 ]\n",
      " [15.787897 ]\n",
      " [21.44144  ]\n",
      " [20.218512 ]\n",
      " [28.518389 ]\n",
      " [14.547537 ]\n",
      " [29.243515 ]\n",
      " [21.328281 ]\n",
      " [24.354837 ]\n",
      " [25.825941 ]\n",
      " [25.868181 ]\n",
      " [13.93965  ]\n",
      " [32.266026 ]\n",
      " [23.200552 ]\n",
      " [33.06989  ]\n",
      " [19.151232 ]\n",
      " [11.014114 ]\n",
      " [41.313763 ]\n",
      " [13.321706 ]\n",
      " [21.080784 ]\n",
      " [22.656881 ]\n",
      " [15.801588 ]\n",
      " [10.836819 ]\n",
      " [17.70491  ]\n",
      " [21.189522 ]\n",
      " [21.131693 ]\n",
      " [21.247118 ]\n",
      " [15.808365 ]\n",
      " [19.39577  ]\n",
      " [14.548926 ]\n",
      " [23.523558 ]\n",
      " [31.380932 ]\n",
      " [10.461412 ]\n",
      " [18.993395 ]\n",
      " [16.78881  ]\n",
      " [20.402178 ]\n",
      " [32.318604 ]\n",
      " [18.196293 ]\n",
      " [14.644276 ]\n",
      " [16.63088  ]\n",
      " [21.365192 ]\n",
      " [20.077337 ]\n",
      " [22.75168  ]\n",
      " [15.785234 ]\n",
      " [15.771887 ]\n",
      " [20.825129 ]\n",
      " [11.164667 ]\n",
      " [14.549826 ]\n",
      " [10.4689865]\n",
      " [14.545397 ]\n",
      " [14.550618 ]\n",
      " [19.922907 ]\n",
      " [12.282428 ]\n",
      " [19.964962 ]\n",
      " [18.830648 ]\n",
      " [20.476566 ]\n",
      " [22.499174 ]\n",
      " [14.547483 ]\n",
      " [21.249435 ]\n",
      " [38.37944  ]\n",
      " [14.653142 ]\n",
      " [21.181349 ]\n",
      " [18.282084 ]\n",
      " [24.063871 ]\n",
      " [18.036997 ]\n",
      " [14.544821 ]\n",
      " [18.485163 ]]\n",
      "=================\n",
      "R2 :  0.6999383232389755\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.0697\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.2901\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.9160\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.8610\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.3198\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.1989\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.3059\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.0173\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.2602\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.0156\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.0301\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.2925\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.0573\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.0863\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.9950\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.2154\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.9821\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.0998\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.4184\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.1870\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.4157\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.1501\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.1050\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.8401\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.9918\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.8996\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.0268\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.2654\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.0529\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.1084\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.0269\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.0369\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.9730\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.1281\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.9532\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7377\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.2684\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.8384\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.0132\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.1798\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.0682\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.9309\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.8112\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.0942\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.0491\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.8975\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.0861\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.8527\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.0592\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.0424\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.0855\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.8081\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.8793\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.0833\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.0352\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.9326\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.9121\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.9460\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.1702\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.8491\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.1587\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.9729\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.9316\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.9364\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.9434\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.0718\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.0430\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.9928\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.2433\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.8342\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.1065\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.8632\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.0573\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7774\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.0759\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.0830\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.7813\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.2793\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.9368\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.9150\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.0626\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.6958\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.1504\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.2114\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.7001\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.2666\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.0314\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.9404\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.0912\n",
      "Epoch 90/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 130us/step - loss: 3.0912\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.1408\n",
      "loss :  3.140822649002075\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "=================\n",
      "[15.  26.6 45.4 20.8 34.9 21.9 28.7  7.2 20.  32.2 24.1 18.5 13.5 27.\n",
      " 23.1 18.9 24.5 43.1 19.8 13.8 15.6 50.  37.2 46.  50.  21.2 14.9 19.6\n",
      " 19.4 18.6 26.5 32.  10.9 20.  21.4 31.  25.  15.4 13.1 37.6 37.  18.9\n",
      " 27.9 50.  14.4 22.  19.9 21.6 15.6 15.  32.4 29.6 20.4 12.3 19.1 14.9\n",
      " 17.8  8.8 35.4 11.5 19.6 20.6 15.6 19.9 23.3 22.3 24.8 16.1 22.8 30.5\n",
      " 20.4 24.4 16.6 26.2 16.4 20.1 13.9 19.4 22.8 13.8 31.6 10.5 23.8 22.4\n",
      " 19.3 22.2 12.6 19.4 22.2 29.8  9.6 34.9 21.4 25.3 32.9 26.6 14.6 31.5\n",
      " 23.3 33.3 17.5 19.1 48.5 17.1 23.1 28.4 18.9 13.  17.2 24.1 18.5 21.8\n",
      " 13.3 23.  14.1 23.9 24.  17.2 21.5 19.1 20.8 36.  20.1  8.7 13.6 22.\n",
      " 22.2 21.1 13.4 17.4 20.1 10.2 23.1 10.2 13.1 14.3 14.5  7.2 19.6 20.6\n",
      " 22.7 26.4  7.5 20.3 50.   8.5 20.3 16.1 22.  19.6 10.2 23.2]\n",
      "[[12.45678  ]\n",
      " [25.363066 ]\n",
      " [42.384655 ]\n",
      " [15.425092 ]\n",
      " [30.023012 ]\n",
      " [46.01552  ]\n",
      " [26.607635 ]\n",
      " [12.19876  ]\n",
      " [17.562208 ]\n",
      " [22.940332 ]\n",
      " [24.971691 ]\n",
      " [20.48008  ]\n",
      " [13.8599   ]\n",
      " [36.059093 ]\n",
      " [17.564777 ]\n",
      " [19.665434 ]\n",
      " [19.15636  ]\n",
      " [34.810978 ]\n",
      " [18.480742 ]\n",
      " [15.471661 ]\n",
      " [13.493832 ]\n",
      " [22.00664  ]\n",
      " [33.623486 ]\n",
      " [46.283493 ]\n",
      " [46.967876 ]\n",
      " [22.397242 ]\n",
      " [16.114975 ]\n",
      " [20.86035  ]\n",
      " [20.74204  ]\n",
      " [14.699859 ]\n",
      " [23.41511  ]\n",
      " [40.023922 ]\n",
      " [12.527829 ]\n",
      " [19.815346 ]\n",
      " [21.030926 ]\n",
      " [26.822962 ]\n",
      " [27.219322 ]\n",
      " [15.907814 ]\n",
      " [17.459993 ]\n",
      " [45.217197 ]\n",
      " [29.918543 ]\n",
      " [17.8987   ]\n",
      " [17.19748  ]\n",
      " [52.705498 ]\n",
      " [14.89124  ]\n",
      " [21.82969  ]\n",
      " [20.638266 ]\n",
      " [23.434734 ]\n",
      " [17.815222 ]\n",
      " [17.317831 ]\n",
      " [41.60543  ]\n",
      " [20.31725  ]\n",
      " [20.715067 ]\n",
      " [12.061065 ]\n",
      " [18.439993 ]\n",
      " [15.5909195]\n",
      " [13.306926 ]\n",
      " [ 8.721795 ]\n",
      " [29.681612 ]\n",
      " [14.830966 ]\n",
      " [18.656994 ]\n",
      " [21.141306 ]\n",
      " [13.649828 ]\n",
      " [18.840887 ]\n",
      " [20.297276 ]\n",
      " [23.241465 ]\n",
      " [23.27025  ]\n",
      " [13.187111 ]\n",
      " [23.184473 ]\n",
      " [32.656895 ]\n",
      " [18.519983 ]\n",
      " [23.448298 ]\n",
      " [17.829058 ]\n",
      " [22.750769 ]\n",
      " [16.191906 ]\n",
      " [17.436457 ]\n",
      " [10.406222 ]\n",
      " [18.9463   ]\n",
      " [34.368053 ]\n",
      " [ 8.676174 ]\n",
      " [31.349749 ]\n",
      " [10.178248 ]\n",
      " [23.035902 ]\n",
      " [19.129408 ]\n",
      " [17.505436 ]\n",
      " [23.309973 ]\n",
      " [17.278368 ]\n",
      " [20.940195 ]\n",
      " [19.444006 ]\n",
      " [35.448776 ]\n",
      " [12.713292 ]\n",
      " [36.24302  ]\n",
      " [19.822615 ]\n",
      " [23.061666 ]\n",
      " [29.40167  ]\n",
      " [25.610647 ]\n",
      " [15.91089  ]\n",
      " [35.87409  ]\n",
      " [28.483662 ]\n",
      " [38.877377 ]\n",
      " [18.804155 ]\n",
      " [13.565675 ]\n",
      " [43.480392 ]\n",
      " [15.517979 ]\n",
      " [19.652243 ]\n",
      " [22.812984 ]\n",
      " [17.416151 ]\n",
      " [14.134269 ]\n",
      " [17.60713  ]\n",
      " [21.249226 ]\n",
      " [20.648653 ]\n",
      " [22.961271 ]\n",
      " [15.276857 ]\n",
      " [18.934437 ]\n",
      " [12.977096 ]\n",
      " [26.293533 ]\n",
      " [34.41016  ]\n",
      " [ 9.993193 ]\n",
      " [18.634033 ]\n",
      " [18.522104 ]\n",
      " [21.638792 ]\n",
      " [31.717237 ]\n",
      " [18.022959 ]\n",
      " [12.667819 ]\n",
      " [16.765709 ]\n",
      " [20.115082 ]\n",
      " [19.571243 ]\n",
      " [21.551939 ]\n",
      " [14.787971 ]\n",
      " [17.325861 ]\n",
      " [19.851732 ]\n",
      " [11.936824 ]\n",
      " [13.290849 ]\n",
      " [ 9.004188 ]\n",
      " [13.533502 ]\n",
      " [13.211305 ]\n",
      " [18.6766   ]\n",
      " [13.276309 ]\n",
      " [18.775099 ]\n",
      " [20.425592 ]\n",
      " [19.958815 ]\n",
      " [20.28705  ]\n",
      " [12.659427 ]\n",
      " [21.2958   ]\n",
      " [50.496414 ]\n",
      " [15.792434 ]\n",
      " [19.804974 ]\n",
      " [18.136595 ]\n",
      " [23.521788 ]\n",
      " [17.986431 ]\n",
      " [12.70456  ]\n",
      " [19.84936  ]]\n",
      "=================\n",
      "R2 :  0.7124875949788144\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.7858\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.3484\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6726\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7393\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.0112\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.9540\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.9312\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.0952\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.8018\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.0729\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.9995\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.6711\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.9399\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.9249\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.8980\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.9149\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.8536\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.0729\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.9131\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.9005\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.7653\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.7432\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.9156\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.8484\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.9565\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.5814\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.9180\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.7547\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.6941\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.9495\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.8571\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.9052\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.8511\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.7005\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.8276\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.8532\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.7489\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.6183\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.9725\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.8601\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.8220\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.9220\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.8052\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.7706\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.9681\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.9628\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.8335\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.8478\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.9153\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7061\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.8596\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7789\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7657\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.0258\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.8504\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7689\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6494\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.8570\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6431\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7451\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.9906\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6496\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7659\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7939\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7455\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.8936\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6373\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6374\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7940\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7395\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7819\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7538\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7655\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7498\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6858\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.9844\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7685\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.8126\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.0062\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7825\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.8899\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7867\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5772\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.8040\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5884\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6650\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6772\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.8528\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7499\n",
      "Epoch 90/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 110us/step - loss: 2.7499\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.9327\n",
      "loss :  2.9327175617218018\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "=================\n",
      "[15.  26.6 45.4 20.8 34.9 21.9 28.7  7.2 20.  32.2 24.1 18.5 13.5 27.\n",
      " 23.1 18.9 24.5 43.1 19.8 13.8 15.6 50.  37.2 46.  50.  21.2 14.9 19.6\n",
      " 19.4 18.6 26.5 32.  10.9 20.  21.4 31.  25.  15.4 13.1 37.6 37.  18.9\n",
      " 27.9 50.  14.4 22.  19.9 21.6 15.6 15.  32.4 29.6 20.4 12.3 19.1 14.9\n",
      " 17.8  8.8 35.4 11.5 19.6 20.6 15.6 19.9 23.3 22.3 24.8 16.1 22.8 30.5\n",
      " 20.4 24.4 16.6 26.2 16.4 20.1 13.9 19.4 22.8 13.8 31.6 10.5 23.8 22.4\n",
      " 19.3 22.2 12.6 19.4 22.2 29.8  9.6 34.9 21.4 25.3 32.9 26.6 14.6 31.5\n",
      " 23.3 33.3 17.5 19.1 48.5 17.1 23.1 28.4 18.9 13.  17.2 24.1 18.5 21.8\n",
      " 13.3 23.  14.1 23.9 24.  17.2 21.5 19.1 20.8 36.  20.1  8.7 13.6 22.\n",
      " 22.2 21.1 13.4 17.4 20.1 10.2 23.1 10.2 13.1 14.3 14.5  7.2 19.6 20.6\n",
      " 22.7 26.4  7.5 20.3 50.   8.5 20.3 16.1 22.  19.6 10.2 23.2]\n",
      "[[ 9.269344 ]\n",
      " [24.606726 ]\n",
      " [45.351612 ]\n",
      " [12.469306 ]\n",
      " [26.43291  ]\n",
      " [41.201603 ]\n",
      " [26.121832 ]\n",
      " [ 9.230193 ]\n",
      " [17.568163 ]\n",
      " [22.859415 ]\n",
      " [22.924047 ]\n",
      " [21.072924 ]\n",
      " [13.896122 ]\n",
      " [31.925508 ]\n",
      " [18.848951 ]\n",
      " [19.67596  ]\n",
      " [19.708723 ]\n",
      " [39.41862  ]\n",
      " [19.130795 ]\n",
      " [11.808951 ]\n",
      " [13.772492 ]\n",
      " [21.104614 ]\n",
      " [34.663265 ]\n",
      " [48.44569  ]\n",
      " [41.812366 ]\n",
      " [21.639273 ]\n",
      " [12.746348 ]\n",
      " [21.07184  ]\n",
      " [21.17441  ]\n",
      " [16.642326 ]\n",
      " [22.367744 ]\n",
      " [38.72044  ]\n",
      " [ 9.675004 ]\n",
      " [20.267023 ]\n",
      " [21.321062 ]\n",
      " [27.488276 ]\n",
      " [25.463047 ]\n",
      " [12.047242 ]\n",
      " [15.9497795]\n",
      " [47.380302 ]\n",
      " [27.16607  ]\n",
      " [18.022882 ]\n",
      " [14.219365 ]\n",
      " [52.395397 ]\n",
      " [13.911561 ]\n",
      " [21.992527 ]\n",
      " [20.84981  ]\n",
      " [23.041126 ]\n",
      " [17.854567 ]\n",
      " [13.669831 ]\n",
      " [40.605465 ]\n",
      " [20.809498 ]\n",
      " [20.940962 ]\n",
      " [11.20242  ]\n",
      " [19.130108 ]\n",
      " [12.0519495]\n",
      " [13.579927 ]\n",
      " [ 9.704488 ]\n",
      " [28.488377 ]\n",
      " [11.670871 ]\n",
      " [18.477182 ]\n",
      " [21.234114 ]\n",
      " [16.52802  ]\n",
      " [19.148533 ]\n",
      " [21.16862  ]\n",
      " [22.832994 ]\n",
      " [23.152737 ]\n",
      " [15.660149 ]\n",
      " [24.234594 ]\n",
      " [29.167124 ]\n",
      " [18.095673 ]\n",
      " [23.833189 ]\n",
      " [17.896452 ]\n",
      " [23.044441 ]\n",
      " [13.41337  ]\n",
      " [15.49113  ]\n",
      " [11.24822  ]\n",
      " [19.352633 ]\n",
      " [32.094826 ]\n",
      " [ 8.09453  ]\n",
      " [29.86844  ]\n",
      " [11.027127 ]\n",
      " [23.065952 ]\n",
      " [19.894361 ]\n",
      " [17.518263 ]\n",
      " [23.627172 ]\n",
      " [13.587882 ]\n",
      " [20.803762 ]\n",
      " [20.307558 ]\n",
      " [31.193565 ]\n",
      " [11.541108 ]\n",
      " [32.242672 ]\n",
      " [20.328033 ]\n",
      " [24.943113 ]\n",
      " [25.92364  ]\n",
      " [27.965506 ]\n",
      " [11.979718 ]\n",
      " [33.882275 ]\n",
      " [25.407568 ]\n",
      " [35.9923   ]\n",
      " [19.30895  ]\n",
      " [11.657392 ]\n",
      " [43.981327 ]\n",
      " [11.847037 ]\n",
      " [19.312376 ]\n",
      " [22.976168 ]\n",
      " [16.998682 ]\n",
      " [11.59937  ]\n",
      " [18.42565  ]\n",
      " [21.206478 ]\n",
      " [20.759836 ]\n",
      " [21.983719 ]\n",
      " [14.349322 ]\n",
      " [19.205004 ]\n",
      " [12.828824 ]\n",
      " [23.406927 ]\n",
      " [32.421062 ]\n",
      " [10.281167 ]\n",
      " [19.110006 ]\n",
      " [18.188904 ]\n",
      " [20.694796 ]\n",
      " [35.4266   ]\n",
      " [19.111158 ]\n",
      " [ 9.390879 ]\n",
      " [14.558735 ]\n",
      " [20.848011 ]\n",
      " [19.984343 ]\n",
      " [22.253412 ]\n",
      " [14.028394 ]\n",
      " [15.352593 ]\n",
      " [20.08737  ]\n",
      " [10.991975 ]\n",
      " [16.47554  ]\n",
      " [ 9.681201 ]\n",
      " [16.484371 ]\n",
      " [14.038357 ]\n",
      " [18.068094 ]\n",
      " [11.448089 ]\n",
      " [18.595652 ]\n",
      " [19.868956 ]\n",
      " [20.062063 ]\n",
      " [20.122751 ]\n",
      " [11.083835 ]\n",
      " [21.713541 ]\n",
      " [47.62331  ]\n",
      " [12.069148 ]\n",
      " [20.383577 ]\n",
      " [19.34351  ]\n",
      " [23.581118 ]\n",
      " [18.185041 ]\n",
      " [12.23195  ]\n",
      " [19.311071 ]]\n",
      "=================\n",
      "R2 :  0.7378790986827546\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7260\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.8275\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.8467\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.8111\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6630\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7278\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6476\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7728\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.8115\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7494\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5297\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7043\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.8103\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6519\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7242\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7775\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5919\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.8371\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.8163\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6609\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6656\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5769\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.9432\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4907\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7292\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.9196\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.8127\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5344\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.0830\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.8237\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6190\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6934\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7600\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7967\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6776\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6957\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7958\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3677\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.9409\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.8589\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5922\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7845\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4101\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6966\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.8383\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6626\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5736\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.8171\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.8308\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7764\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7639\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4941\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6307\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5498\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7202\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6968\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6637\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5659\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5332\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7432\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6833\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7095\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.8334\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6012\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5910\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6995\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4912\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4511\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7089\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6048\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6424\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7149\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6327\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5729\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.5008\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7386\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6387\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5636\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6448\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6530\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5413\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7841\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6226\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.8996\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6446\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.8902\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6688\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6254\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6914\n",
      "Epoch 90/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 120us/step - loss: 2.6914\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.1616\n",
      "loss :  3.161618709564209\n",
      "5/5 [==============================] - 0s 741us/step\n",
      "=================\n",
      "[15.  26.6 45.4 20.8 34.9 21.9 28.7  7.2 20.  32.2 24.1 18.5 13.5 27.\n",
      " 23.1 18.9 24.5 43.1 19.8 13.8 15.6 50.  37.2 46.  50.  21.2 14.9 19.6\n",
      " 19.4 18.6 26.5 32.  10.9 20.  21.4 31.  25.  15.4 13.1 37.6 37.  18.9\n",
      " 27.9 50.  14.4 22.  19.9 21.6 15.6 15.  32.4 29.6 20.4 12.3 19.1 14.9\n",
      " 17.8  8.8 35.4 11.5 19.6 20.6 15.6 19.9 23.3 22.3 24.8 16.1 22.8 30.5\n",
      " 20.4 24.4 16.6 26.2 16.4 20.1 13.9 19.4 22.8 13.8 31.6 10.5 23.8 22.4\n",
      " 19.3 22.2 12.6 19.4 22.2 29.8  9.6 34.9 21.4 25.3 32.9 26.6 14.6 31.5\n",
      " 23.3 33.3 17.5 19.1 48.5 17.1 23.1 28.4 18.9 13.  17.2 24.1 18.5 21.8\n",
      " 13.3 23.  14.1 23.9 24.  17.2 21.5 19.1 20.8 36.  20.1  8.7 13.6 22.\n",
      " 22.2 21.1 13.4 17.4 20.1 10.2 23.1 10.2 13.1 14.3 14.5  7.2 19.6 20.6\n",
      " 22.7 26.4  7.5 20.3 50.   8.5 20.3 16.1 22.  19.6 10.2 23.2]\n",
      "[[10.857942 ]\n",
      " [26.335197 ]\n",
      " [44.878407 ]\n",
      " [18.930191 ]\n",
      " [29.178778 ]\n",
      " [47.65992  ]\n",
      " [27.40659  ]\n",
      " [10.500739 ]\n",
      " [18.599918 ]\n",
      " [24.803318 ]\n",
      " [25.449154 ]\n",
      " [21.858631 ]\n",
      " [15.650091 ]\n",
      " [36.280804 ]\n",
      " [20.429943 ]\n",
      " [21.08888  ]\n",
      " [21.11216  ]\n",
      " [39.0733   ]\n",
      " [20.147865 ]\n",
      " [17.734333 ]\n",
      " [17.827065 ]\n",
      " [24.32645  ]\n",
      " [34.194164 ]\n",
      " [48.04661  ]\n",
      " [46.242588 ]\n",
      " [24.39019  ]\n",
      " [18.366518 ]\n",
      " [22.531464 ]\n",
      " [22.460842 ]\n",
      " [13.745375 ]\n",
      " [23.659851 ]\n",
      " [39.40695  ]\n",
      " [11.073898 ]\n",
      " [21.441803 ]\n",
      " [22.415344 ]\n",
      " [29.09937  ]\n",
      " [27.109198 ]\n",
      " [15.783294 ]\n",
      " [17.77134  ]\n",
      " [45.42599  ]\n",
      " [32.897327 ]\n",
      " [19.399422 ]\n",
      " [20.14394  ]\n",
      " [53.20706  ]\n",
      " [14.344547 ]\n",
      " [23.604748 ]\n",
      " [22.060661 ]\n",
      " [24.113558 ]\n",
      " [19.002666 ]\n",
      " [18.970192 ]\n",
      " [43.118305 ]\n",
      " [21.657152 ]\n",
      " [22.14925  ]\n",
      " [14.88019  ]\n",
      " [20.436558 ]\n",
      " [19.075243 ]\n",
      " [16.669468 ]\n",
      " [11.981459 ]\n",
      " [30.29336  ]\n",
      " [16.29465  ]\n",
      " [20.138332 ]\n",
      " [22.269373 ]\n",
      " [14.029438 ]\n",
      " [21.609245 ]\n",
      " [22.226456 ]\n",
      " [24.61594  ]\n",
      " [24.69068  ]\n",
      " [14.865282 ]\n",
      " [24.201778 ]\n",
      " [34.128826 ]\n",
      " [20.024418 ]\n",
      " [25.471298 ]\n",
      " [19.131435 ]\n",
      " [23.625828 ]\n",
      " [19.420788 ]\n",
      " [20.27474  ]\n",
      " [11.857185 ]\n",
      " [20.262247 ]\n",
      " [32.07177  ]\n",
      " [ 8.139058 ]\n",
      " [31.155107 ]\n",
      " [11.1681385]\n",
      " [24.24002  ]\n",
      " [21.050716 ]\n",
      " [18.703926 ]\n",
      " [24.642933 ]\n",
      " [18.792475 ]\n",
      " [22.747887 ]\n",
      " [21.45504  ]\n",
      " [37.521107 ]\n",
      " [12.703645 ]\n",
      " [38.3473   ]\n",
      " [21.104372 ]\n",
      " [24.5344   ]\n",
      " [29.531673 ]\n",
      " [27.45858  ]\n",
      " [16.04609  ]\n",
      " [39.583736 ]\n",
      " [27.295774 ]\n",
      " [39.792686 ]\n",
      " [20.608288 ]\n",
      " [16.088863 ]\n",
      " [46.043636 ]\n",
      " [17.04681  ]\n",
      " [20.747986 ]\n",
      " [24.444893 ]\n",
      " [19.699589 ]\n",
      " [15.869371 ]\n",
      " [20.074596 ]\n",
      " [22.825474 ]\n",
      " [22.173595 ]\n",
      " [24.29802  ]\n",
      " [16.361807 ]\n",
      " [20.363556 ]\n",
      " [12.703645 ]\n",
      " [26.25069  ]\n",
      " [32.881165 ]\n",
      " [ 8.59743  ]\n",
      " [20.369987 ]\n",
      " [20.357252 ]\n",
      " [23.320919 ]\n",
      " [34.13374  ]\n",
      " [20.429857 ]\n",
      " [10.921864 ]\n",
      " [15.344221 ]\n",
      " [21.665653 ]\n",
      " [21.608227 ]\n",
      " [23.198858 ]\n",
      " [15.45956  ]\n",
      " [19.101986 ]\n",
      " [21.591904 ]\n",
      " [13.9932   ]\n",
      " [13.06508  ]\n",
      " [ 8.237892 ]\n",
      " [13.842995 ]\n",
      " [13.583246 ]\n",
      " [19.663849 ]\n",
      " [15.753366 ]\n",
      " [19.71344  ]\n",
      " [22.540089 ]\n",
      " [21.473923 ]\n",
      " [21.10284  ]\n",
      " [11.5533285]\n",
      " [22.636112 ]\n",
      " [50.783646 ]\n",
      " [15.896456 ]\n",
      " [21.193394 ]\n",
      " [20.413235 ]\n",
      " [24.721695 ]\n",
      " [20.193096 ]\n",
      " [12.703645 ]\n",
      " [21.954308 ]]\n",
      "=================\n",
      "R2 :  0.7255384210660609\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6650\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5758\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7789\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6359\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.0481\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4758\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6402\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6985\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6639\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6684\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.9323\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4652\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4073\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6720\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6462\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5582\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4798\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6953\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5319\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5669\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5866\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5770\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6578\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6924\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7977\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5177\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.8032\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5288\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5842\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6204\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4441\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7441\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6492\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4229\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6108\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6316\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5025\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5004\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4846\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5178\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7064\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4487\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4975\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5027\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7624\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4830\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5114\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5328\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6894\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7334\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4295\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5931\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4456\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5707\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5206\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2807\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7523\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4050\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6950\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5942\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4044\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6452\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4603\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5561\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6636\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3808\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5814\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5872\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7180\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3880\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6312\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4081\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5746\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7348\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4996\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2684\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5170\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7729\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4504\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4084\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3668\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5113\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4820\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1804\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6475\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.8474\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6154\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6050\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5738\n",
      "Epoch 90/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 120us/step - loss: 2.5738\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.7617\n",
      "loss :  2.7617249488830566\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "=================\n",
      "[15.  26.6 45.4 20.8 34.9 21.9 28.7  7.2 20.  32.2 24.1 18.5 13.5 27.\n",
      " 23.1 18.9 24.5 43.1 19.8 13.8 15.6 50.  37.2 46.  50.  21.2 14.9 19.6\n",
      " 19.4 18.6 26.5 32.  10.9 20.  21.4 31.  25.  15.4 13.1 37.6 37.  18.9\n",
      " 27.9 50.  14.4 22.  19.9 21.6 15.6 15.  32.4 29.6 20.4 12.3 19.1 14.9\n",
      " 17.8  8.8 35.4 11.5 19.6 20.6 15.6 19.9 23.3 22.3 24.8 16.1 22.8 30.5\n",
      " 20.4 24.4 16.6 26.2 16.4 20.1 13.9 19.4 22.8 13.8 31.6 10.5 23.8 22.4\n",
      " 19.3 22.2 12.6 19.4 22.2 29.8  9.6 34.9 21.4 25.3 32.9 26.6 14.6 31.5\n",
      " 23.3 33.3 17.5 19.1 48.5 17.1 23.1 28.4 18.9 13.  17.2 24.1 18.5 21.8\n",
      " 13.3 23.  14.1 23.9 24.  17.2 21.5 19.1 20.8 36.  20.1  8.7 13.6 22.\n",
      " 22.2 21.1 13.4 17.4 20.1 10.2 23.1 10.2 13.1 14.3 14.5  7.2 19.6 20.6\n",
      " 22.7 26.4  7.5 20.3 50.   8.5 20.3 16.1 22.  19.6 10.2 23.2]\n",
      "[[ 8.39643  ]\n",
      " [26.029331 ]\n",
      " [45.262012 ]\n",
      " [14.833202 ]\n",
      " [28.324226 ]\n",
      " [52.86335  ]\n",
      " [28.710068 ]\n",
      " [ 8.583026 ]\n",
      " [15.358151 ]\n",
      " [25.25601  ]\n",
      " [24.850761 ]\n",
      " [21.825071 ]\n",
      " [13.71321  ]\n",
      " [35.26859  ]\n",
      " [20.286587 ]\n",
      " [19.933298 ]\n",
      " [21.292309 ]\n",
      " [37.175022 ]\n",
      " [19.69526  ]\n",
      " [13.864202 ]\n",
      " [15.58607  ]\n",
      " [23.028618 ]\n",
      " [35.922184 ]\n",
      " [50.33929  ]\n",
      " [49.749073 ]\n",
      " [23.38466  ]\n",
      " [15.541821 ]\n",
      " [22.252823 ]\n",
      " [22.35373  ]\n",
      " [14.301171 ]\n",
      " [22.80216  ]\n",
      " [37.44096  ]\n",
      " [ 8.508729 ]\n",
      " [21.318491 ]\n",
      " [22.073902 ]\n",
      " [29.773441 ]\n",
      " [25.150959 ]\n",
      " [13.839173 ]\n",
      " [14.834483 ]\n",
      " [47.681614 ]\n",
      " [29.224787 ]\n",
      " [19.050755 ]\n",
      " [15.431743 ]\n",
      " [49.11792  ]\n",
      " [12.850037 ]\n",
      " [23.517218 ]\n",
      " [22.030197 ]\n",
      " [23.17465  ]\n",
      " [18.930876 ]\n",
      " [14.70835  ]\n",
      " [39.68211  ]\n",
      " [21.398344 ]\n",
      " [21.949202 ]\n",
      " [11.044929 ]\n",
      " [19.809582 ]\n",
      " [14.738828 ]\n",
      " [13.643401 ]\n",
      " [ 8.553527 ]\n",
      " [31.9389   ]\n",
      " [13.306075 ]\n",
      " [19.519846 ]\n",
      " [21.916512 ]\n",
      " [14.3576   ]\n",
      " [20.92296  ]\n",
      " [22.635025 ]\n",
      " [24.160084 ]\n",
      " [24.212482 ]\n",
      " [15.167822 ]\n",
      " [24.741913 ]\n",
      " [30.573534 ]\n",
      " [19.160828 ]\n",
      " [25.71681  ]\n",
      " [19.013908 ]\n",
      " [23.994434 ]\n",
      " [15.729333 ]\n",
      " [19.123161 ]\n",
      " [11.468926 ]\n",
      " [19.887299 ]\n",
      " [31.45276  ]\n",
      " [ 8.425969 ]\n",
      " [31.302643 ]\n",
      " [10.657292 ]\n",
      " [23.665302 ]\n",
      " [20.608166 ]\n",
      " [15.818202 ]\n",
      " [24.358765 ]\n",
      " [14.7100935]\n",
      " [22.491787 ]\n",
      " [21.460041 ]\n",
      " [32.66456  ]\n",
      " [12.004185 ]\n",
      " [33.98476  ]\n",
      " [20.533714 ]\n",
      " [25.330406 ]\n",
      " [28.06997  ]\n",
      " [27.54389  ]\n",
      " [13.97329  ]\n",
      " [34.78908  ]\n",
      " [24.198288 ]\n",
      " [37.132908 ]\n",
      " [20.194744 ]\n",
      " [13.182551 ]\n",
      " [45.803753 ]\n",
      " [13.776364 ]\n",
      " [19.490166 ]\n",
      " [24.005606 ]\n",
      " [17.693016 ]\n",
      " [13.215635 ]\n",
      " [19.633125 ]\n",
      " [22.396952 ]\n",
      " [21.235813 ]\n",
      " [23.700607 ]\n",
      " [14.888867 ]\n",
      " [19.753567 ]\n",
      " [11.884902 ]\n",
      " [24.44318  ]\n",
      " [33.04029  ]\n",
      " [10.659363 ]\n",
      " [19.839157 ]\n",
      " [19.009815 ]\n",
      " [21.625261 ]\n",
      " [34.850895 ]\n",
      " [20.001228 ]\n",
      " [ 8.408223 ]\n",
      " [13.849651 ]\n",
      " [21.611486 ]\n",
      " [21.065697 ]\n",
      " [23.576668 ]\n",
      " [14.36387  ]\n",
      " [20.020777 ]\n",
      " [20.603067 ]\n",
      " [10.6209955]\n",
      " [16.389277 ]\n",
      " [10.01127  ]\n",
      " [14.453067 ]\n",
      " [14.520954 ]\n",
      " [19.035072 ]\n",
      " [12.977405 ]\n",
      " [19.121258 ]\n",
      " [22.22808  ]\n",
      " [20.162159 ]\n",
      " [19.670376 ]\n",
      " [10.138204 ]\n",
      " [22.465199 ]\n",
      " [52.08266  ]\n",
      " [13.71532  ]\n",
      " [20.654518 ]\n",
      " [20.486866 ]\n",
      " [24.91211  ]\n",
      " [19.41331  ]\n",
      " [13.634719 ]\n",
      " [20.65472  ]]\n",
      "=================\n",
      "R2 :  0.7237308056529254\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5594\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2678\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.4427\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6309\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4125\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3869\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.7365\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6754\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3720\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4466\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4287\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4623\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4104\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4092\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7974\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3790\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.8539\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5859\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.7547\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6754\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4050\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3028\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5043\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5295\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4379\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3408\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5120\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3346\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3926\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4950\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4103\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4423\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4179\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3407\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6587\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3662\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5255\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3397\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2944\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3450\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4793\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5161\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3201\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5656\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6602\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6109\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.8841\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5138\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4708\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4080\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6377\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4409\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5613\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3185\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4960\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4988\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4565\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5952\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3274\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6055\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2498\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3625\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5826\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3386\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5131\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3204\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3693\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3014\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7444\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2425\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4266\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5381\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4368\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4633\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4840\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2263\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2716\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5789\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4585\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3612\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4916\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5864\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5131\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5607\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2941\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5759\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5036\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5995\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3096\n",
      "Epoch 90/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 100us/step - loss: 2.3096\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.3124\n",
      "loss :  3.3124115467071533\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "=================\n",
      "[15.  26.6 45.4 20.8 34.9 21.9 28.7  7.2 20.  32.2 24.1 18.5 13.5 27.\n",
      " 23.1 18.9 24.5 43.1 19.8 13.8 15.6 50.  37.2 46.  50.  21.2 14.9 19.6\n",
      " 19.4 18.6 26.5 32.  10.9 20.  21.4 31.  25.  15.4 13.1 37.6 37.  18.9\n",
      " 27.9 50.  14.4 22.  19.9 21.6 15.6 15.  32.4 29.6 20.4 12.3 19.1 14.9\n",
      " 17.8  8.8 35.4 11.5 19.6 20.6 15.6 19.9 23.3 22.3 24.8 16.1 22.8 30.5\n",
      " 20.4 24.4 16.6 26.2 16.4 20.1 13.9 19.4 22.8 13.8 31.6 10.5 23.8 22.4\n",
      " 19.3 22.2 12.6 19.4 22.2 29.8  9.6 34.9 21.4 25.3 32.9 26.6 14.6 31.5\n",
      " 23.3 33.3 17.5 19.1 48.5 17.1 23.1 28.4 18.9 13.  17.2 24.1 18.5 21.8\n",
      " 13.3 23.  14.1 23.9 24.  17.2 21.5 19.1 20.8 36.  20.1  8.7 13.6 22.\n",
      " 22.2 21.1 13.4 17.4 20.1 10.2 23.1 10.2 13.1 14.3 14.5  7.2 19.6 20.6\n",
      " 22.7 26.4  7.5 20.3 50.   8.5 20.3 16.1 22.  19.6 10.2 23.2]\n",
      "[[ 9.549532 ]\n",
      " [28.859451 ]\n",
      " [50.646618 ]\n",
      " [13.479088 ]\n",
      " [29.556925 ]\n",
      " [57.38081  ]\n",
      " [31.978945 ]\n",
      " [ 8.44267  ]\n",
      " [15.502386 ]\n",
      " [26.188473 ]\n",
      " [26.371418 ]\n",
      " [22.014553 ]\n",
      " [12.664057 ]\n",
      " [37.474846 ]\n",
      " [19.58321  ]\n",
      " [19.4153   ]\n",
      " [21.47811  ]\n",
      " [42.40163  ]\n",
      " [19.07914  ]\n",
      " [12.133329 ]\n",
      " [15.311436 ]\n",
      " [23.641975 ]\n",
      " [40.58694  ]\n",
      " [52.409412 ]\n",
      " [54.82935  ]\n",
      " [23.628456 ]\n",
      " [14.6756315]\n",
      " [22.655958 ]\n",
      " [22.573599 ]\n",
      " [14.138645 ]\n",
      " [23.33879  ]\n",
      " [42.67448  ]\n",
      " [10.020771 ]\n",
      " [21.507805 ]\n",
      " [22.117397 ]\n",
      " [30.332176 ]\n",
      " [25.278885 ]\n",
      " [13.28709  ]\n",
      " [14.798185 ]\n",
      " [47.634007 ]\n",
      " [30.292797 ]\n",
      " [19.021431 ]\n",
      " [14.314882 ]\n",
      " [56.116276 ]\n",
      " [12.060596 ]\n",
      " [24.258236 ]\n",
      " [22.163273 ]\n",
      " [23.872238 ]\n",
      " [18.898476 ]\n",
      " [13.863457 ]\n",
      " [46.23338  ]\n",
      " [21.77428  ]\n",
      " [22.068256 ]\n",
      " [11.008281 ]\n",
      " [19.047699 ]\n",
      " [13.938995 ]\n",
      " [12.487285 ]\n",
      " [ 8.402115 ]\n",
      " [33.924236 ]\n",
      " [11.221834 ]\n",
      " [19.074095 ]\n",
      " [22.114225 ]\n",
      " [14.449024 ]\n",
      " [21.045267 ]\n",
      " [23.02824  ]\n",
      " [24.933586 ]\n",
      " [24.688023 ]\n",
      " [18.100168 ]\n",
      " [24.827827 ]\n",
      " [32.013546 ]\n",
      " [19.06653  ]\n",
      " [28.268621 ]\n",
      " [18.938251 ]\n",
      " [24.21632  ]\n",
      " [14.963874 ]\n",
      " [15.392405 ]\n",
      " [11.360659 ]\n",
      " [19.086643 ]\n",
      " [32.991364 ]\n",
      " [ 8.38048  ]\n",
      " [33.08301  ]\n",
      " [10.263925 ]\n",
      " [24.210152 ]\n",
      " [21.382374 ]\n",
      " [15.806524 ]\n",
      " [25.53871  ]\n",
      " [14.019478 ]\n",
      " [23.138992 ]\n",
      " [21.672089 ]\n",
      " [37.16715  ]\n",
      " [12.371559 ]\n",
      " [39.195503 ]\n",
      " [21.382374 ]\n",
      " [25.869213 ]\n",
      " [29.224539 ]\n",
      " [29.33935  ]\n",
      " [13.432697 ]\n",
      " [39.654896 ]\n",
      " [24.238789 ]\n",
      " [43.029408 ]\n",
      " [19.522413 ]\n",
      " [12.93889  ]\n",
      " [50.234936 ]\n",
      " [13.199429 ]\n",
      " [19.276901 ]\n",
      " [25.095173 ]\n",
      " [17.057606 ]\n",
      " [12.904001 ]\n",
      " [19.073174 ]\n",
      " [22.886005 ]\n",
      " [21.382374 ]\n",
      " [23.74368  ]\n",
      " [14.805119 ]\n",
      " [19.057838 ]\n",
      " [13.440891 ]\n",
      " [25.209906 ]\n",
      " [34.801003 ]\n",
      " [ 8.616734 ]\n",
      " [19.082287 ]\n",
      " [18.329103 ]\n",
      " [21.977396 ]\n",
      " [33.59598  ]\n",
      " [19.189423 ]\n",
      " [ 9.50639  ]\n",
      " [14.1093445]\n",
      " [22.077717 ]\n",
      " [21.545609 ]\n",
      " [23.89228  ]\n",
      " [14.225796 ]\n",
      " [19.03833  ]\n",
      " [21.449364 ]\n",
      " [10.473009 ]\n",
      " [15.933253 ]\n",
      " [ 8.835822 ]\n",
      " [13.440891 ]\n",
      " [13.468573 ]\n",
      " [19.039452 ]\n",
      " [10.924686 ]\n",
      " [19.061935 ]\n",
      " [22.069384 ]\n",
      " [19.336714 ]\n",
      " [21.02717  ]\n",
      " [10.389013 ]\n",
      " [22.573404 ]\n",
      " [57.527786 ]\n",
      " [13.098141 ]\n",
      " [21.386612 ]\n",
      " [20.053144 ]\n",
      " [26.353262 ]\n",
      " [19.05203  ]\n",
      " [13.418741 ]\n",
      " [20.10886  ]]\n",
      "=================\n",
      "R2 :  0.6409680133579693\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2761\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4701\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2778\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5593\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5294\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3191\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3893\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3881\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3959\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5399\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3711\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7234\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3611\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5041\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3592\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4393\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4169\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1923\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3799\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4586\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2387\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5612\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5108\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4200\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2609\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3716\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5318\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3471\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1062\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3830\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4145\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6224\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4516\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3149\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4373\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0892\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3184\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3103\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5424\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3678\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2362\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2916\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4413\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2954\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4096\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4236\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3610\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4937\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3934\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3915\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3168\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1880\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5225\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2296\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3187\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3861\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3056\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2234\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3594\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3942\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4706\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3978\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3016\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3508\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3249\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2376\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1694\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5415\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3284\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3021\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2076\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4576\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1937\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4456\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2917\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3953\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3490\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2352\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5971\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5620\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4453\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3502\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5195\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3022\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4478\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5294\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4271\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2837\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3126\n",
      "Epoch 90/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 100us/step - loss: 2.3126\n",
      "5/5 [==============================] - 0s 748us/step - loss: 3.0327\n",
      "loss :  3.0327138900756836\n",
      "5/5 [==============================] - 0s 997us/step\n",
      "=================\n",
      "[15.  26.6 45.4 20.8 34.9 21.9 28.7  7.2 20.  32.2 24.1 18.5 13.5 27.\n",
      " 23.1 18.9 24.5 43.1 19.8 13.8 15.6 50.  37.2 46.  50.  21.2 14.9 19.6\n",
      " 19.4 18.6 26.5 32.  10.9 20.  21.4 31.  25.  15.4 13.1 37.6 37.  18.9\n",
      " 27.9 50.  14.4 22.  19.9 21.6 15.6 15.  32.4 29.6 20.4 12.3 19.1 14.9\n",
      " 17.8  8.8 35.4 11.5 19.6 20.6 15.6 19.9 23.3 22.3 24.8 16.1 22.8 30.5\n",
      " 20.4 24.4 16.6 26.2 16.4 20.1 13.9 19.4 22.8 13.8 31.6 10.5 23.8 22.4\n",
      " 19.3 22.2 12.6 19.4 22.2 29.8  9.6 34.9 21.4 25.3 32.9 26.6 14.6 31.5\n",
      " 23.3 33.3 17.5 19.1 48.5 17.1 23.1 28.4 18.9 13.  17.2 24.1 18.5 21.8\n",
      " 13.3 23.  14.1 23.9 24.  17.2 21.5 19.1 20.8 36.  20.1  8.7 13.6 22.\n",
      " 22.2 21.1 13.4 17.4 20.1 10.2 23.1 10.2 13.1 14.3 14.5  7.2 19.6 20.6\n",
      " 22.7 26.4  7.5 20.3 50.   8.5 20.3 16.1 22.  19.6 10.2 23.2]\n",
      "[[ 9.236472]\n",
      " [26.554586]\n",
      " [48.026443]\n",
      " [14.000574]\n",
      " [24.252577]\n",
      " [58.159714]\n",
      " [29.606054]\n",
      " [ 8.938153]\n",
      " [14.370061]\n",
      " [23.663935]\n",
      " [24.642782]\n",
      " [20.92605 ]\n",
      " [13.826181]\n",
      " [34.72075 ]\n",
      " [19.69555 ]\n",
      " [19.162226]\n",
      " [20.92605 ]\n",
      " [34.879913]\n",
      " [18.591246]\n",
      " [13.456633]\n",
      " [16.788189]\n",
      " [22.782305]\n",
      " [38.079346]\n",
      " [48.249702]\n",
      " [52.658188]\n",
      " [23.03359 ]\n",
      " [14.082849]\n",
      " [20.92605 ]\n",
      " [21.213305]\n",
      " [13.749818]\n",
      " [21.803072]\n",
      " [35.339085]\n",
      " [ 9.983855]\n",
      " [20.753443]\n",
      " [21.488577]\n",
      " [27.459288]\n",
      " [23.4648  ]\n",
      " [13.543103]\n",
      " [14.29568 ]\n",
      " [42.79339 ]\n",
      " [27.386147]\n",
      " [18.361902]\n",
      " [14.708501]\n",
      " [51.828392]\n",
      " [13.744914]\n",
      " [22.529306]\n",
      " [20.92605 ]\n",
      " [22.39666 ]\n",
      " [17.942972]\n",
      " [14.226622]\n",
      " [40.404625]\n",
      " [20.92605 ]\n",
      " [20.92605 ]\n",
      " [10.763007]\n",
      " [18.793493]\n",
      " [13.988931]\n",
      " [13.747165]\n",
      " [ 8.420151]\n",
      " [31.314138]\n",
      " [13.245552]\n",
      " [18.596382]\n",
      " [20.92605 ]\n",
      " [13.76422 ]\n",
      " [20.729445]\n",
      " [21.533373]\n",
      " [23.03528 ]\n",
      " [23.066671]\n",
      " [24.504171]\n",
      " [23.35591 ]\n",
      " [28.877674]\n",
      " [18.507662]\n",
      " [25.304806]\n",
      " [18.082436]\n",
      " [22.862839]\n",
      " [14.551227]\n",
      " [17.225443]\n",
      " [10.272916]\n",
      " [18.594717]\n",
      " [29.605751]\n",
      " [ 8.403799]\n",
      " [30.466053]\n",
      " [ 9.354455]\n",
      " [22.634665]\n",
      " [20.175669]\n",
      " [14.601357]\n",
      " [23.363573]\n",
      " [14.072658]\n",
      " [21.16997 ]\n",
      " [20.92605 ]\n",
      " [32.19688 ]\n",
      " [12.348989]\n",
      " [33.913643]\n",
      " [20.21322 ]\n",
      " [23.873243]\n",
      " [24.289162]\n",
      " [27.381994]\n",
      " [13.609993]\n",
      " [39.864365]\n",
      " [22.609125]\n",
      " [34.75617 ]\n",
      " [19.73807 ]\n",
      " [12.032473]\n",
      " [46.261692]\n",
      " [13.485396]\n",
      " [19.239162]\n",
      " [23.313154]\n",
      " [15.090774]\n",
      " [12.006637]\n",
      " [18.55448 ]\n",
      " [22.01354 ]\n",
      " [20.410374]\n",
      " [23.168777]\n",
      " [14.488204]\n",
      " [18.718283]\n",
      " [13.092   ]\n",
      " [24.476736]\n",
      " [31.316902]\n",
      " [10.216674]\n",
      " [18.999033]\n",
      " [18.609758]\n",
      " [20.954126]\n",
      " [32.13055 ]\n",
      " [19.521542]\n",
      " [ 9.161992]\n",
      " [13.888301]\n",
      " [20.92605 ]\n",
      " [20.161676]\n",
      " [22.321157]\n",
      " [13.931959]\n",
      " [18.09236 ]\n",
      " [20.109951]\n",
      " [ 9.766707]\n",
      " [13.721686]\n",
      " [10.022686]\n",
      " [13.587681]\n",
      " [13.787445]\n",
      " [18.344776]\n",
      " [13.299602]\n",
      " [18.436224]\n",
      " [21.495949]\n",
      " [19.879992]\n",
      " [20.276674]\n",
      " [10.044779]\n",
      " [21.755909]\n",
      " [57.381626]\n",
      " [13.362544]\n",
      " [20.28044 ]\n",
      " [19.97451 ]\n",
      " [24.129583]\n",
      " [18.526949]\n",
      " [12.720053]\n",
      " [20.844368]]\n",
      "=================\n",
      "R2 :  0.6646364412052168\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3819\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2325\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5705\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3022\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3082\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4258\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2573\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3722\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5119\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2673\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3967\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2875\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2824\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3132\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3795\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2203\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2756\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2220\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3842\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3164\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3595\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3216\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2455\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2575\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3851\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3448\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2845\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1884\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4122\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2260\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3099\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3368\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5207\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4893\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4848\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2789\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1665\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3243\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1865\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3628\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2652\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2578\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4033\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2528\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1490\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2682\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3314\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1647\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3844\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2038\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4034\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2280\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3740\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2449\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3806\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3564\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1872\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2068\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2106\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2446\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1072\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3494\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4315\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6005\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3554\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0979\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6394\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3599\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2879\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1961\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2494\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3163\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1047\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2350\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4116\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3538\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2946\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1330\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3176\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2695\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3273\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1838\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2573\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2370\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0777\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2646\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4024\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1793\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4544\n",
      "Epoch 90/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 100us/step - loss: 2.4544\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.9779\n",
      "loss :  2.9778552055358887\n",
      "5/5 [==============================] - 0s 854us/step\n",
      "=================\n",
      "[15.  26.6 45.4 20.8 34.9 21.9 28.7  7.2 20.  32.2 24.1 18.5 13.5 27.\n",
      " 23.1 18.9 24.5 43.1 19.8 13.8 15.6 50.  37.2 46.  50.  21.2 14.9 19.6\n",
      " 19.4 18.6 26.5 32.  10.9 20.  21.4 31.  25.  15.4 13.1 37.6 37.  18.9\n",
      " 27.9 50.  14.4 22.  19.9 21.6 15.6 15.  32.4 29.6 20.4 12.3 19.1 14.9\n",
      " 17.8  8.8 35.4 11.5 19.6 20.6 15.6 19.9 23.3 22.3 24.8 16.1 22.8 30.5\n",
      " 20.4 24.4 16.6 26.2 16.4 20.1 13.9 19.4 22.8 13.8 31.6 10.5 23.8 22.4\n",
      " 19.3 22.2 12.6 19.4 22.2 29.8  9.6 34.9 21.4 25.3 32.9 26.6 14.6 31.5\n",
      " 23.3 33.3 17.5 19.1 48.5 17.1 23.1 28.4 18.9 13.  17.2 24.1 18.5 21.8\n",
      " 13.3 23.  14.1 23.9 24.  17.2 21.5 19.1 20.8 36.  20.1  8.7 13.6 22.\n",
      " 22.2 21.1 13.4 17.4 20.1 10.2 23.1 10.2 13.1 14.3 14.5  7.2 19.6 20.6\n",
      " 22.7 26.4  7.5 20.3 50.   8.5 20.3 16.1 22.  19.6 10.2 23.2]\n",
      "[[ 8.563343]\n",
      " [26.103714]\n",
      " [46.02305 ]\n",
      " [15.714096]\n",
      " [24.779789]\n",
      " [57.57438 ]\n",
      " [29.95921 ]\n",
      " [ 8.688609]\n",
      " [16.330847]\n",
      " [24.112282]\n",
      " [24.849468]\n",
      " [21.96149 ]\n",
      " [16.76995 ]\n",
      " [38.33913 ]\n",
      " [21.653877]\n",
      " [20.188301]\n",
      " [22.465832]\n",
      " [36.533764]\n",
      " [19.556774]\n",
      " [14.221701]\n",
      " [16.184954]\n",
      " [24.362034]\n",
      " [37.431507]\n",
      " [49.722103]\n",
      " [54.288784]\n",
      " [23.70608 ]\n",
      " [16.221064]\n",
      " [22.465832]\n",
      " [22.613518]\n",
      " [14.233959]\n",
      " [23.452404]\n",
      " [35.24402 ]\n",
      " [ 8.549553]\n",
      " [21.63327 ]\n",
      " [22.465832]\n",
      " [27.768654]\n",
      " [24.13303 ]\n",
      " [14.564739]\n",
      " [15.68589 ]\n",
      " [49.417347]\n",
      " [29.287128]\n",
      " [19.436356]\n",
      " [18.782187]\n",
      " [53.32633 ]\n",
      " [15.746885]\n",
      " [23.453852]\n",
      " [22.465832]\n",
      " [23.438911]\n",
      " [19.366646]\n",
      " [18.391916]\n",
      " [36.033337]\n",
      " [21.530449]\n",
      " [22.465832]\n",
      " [11.556814]\n",
      " [19.982761]\n",
      " [15.369091]\n",
      " [15.456621]\n",
      " [ 8.586053]\n",
      " [33.148365]\n",
      " [12.378799]\n",
      " [19.656094]\n",
      " [22.123886]\n",
      " [14.742189]\n",
      " [21.623745]\n",
      " [22.766567]\n",
      " [23.739716]\n",
      " [23.953045]\n",
      " [22.951794]\n",
      " [24.013613]\n",
      " [30.45914 ]\n",
      " [19.51025 ]\n",
      " [24.348316]\n",
      " [19.36633 ]\n",
      " [23.68375 ]\n",
      " [18.400045]\n",
      " [19.504223]\n",
      " [11.540831]\n",
      " [19.607666]\n",
      " [28.082544]\n",
      " [ 8.67761 ]\n",
      " [30.831627]\n",
      " [10.114727]\n",
      " [23.725266]\n",
      " [21.65075 ]\n",
      " [16.732006]\n",
      " [24.32126 ]\n",
      " [15.907645]\n",
      " [21.66227 ]\n",
      " [22.317867]\n",
      " [35.3661  ]\n",
      " [13.315267]\n",
      " [36.097652]\n",
      " [20.985888]\n",
      " [24.838413]\n",
      " [24.792686]\n",
      " [27.35173 ]\n",
      " [14.71364 ]\n",
      " [38.828808]\n",
      " [24.552097]\n",
      " [34.903713]\n",
      " [21.637041]\n",
      " [13.759604]\n",
      " [47.276894]\n",
      " [14.464329]\n",
      " [20.49569 ]\n",
      " [24.28297 ]\n",
      " [18.071178]\n",
      " [13.637294]\n",
      " [19.744152]\n",
      " [23.726843]\n",
      " [22.465832]\n",
      " [23.807854]\n",
      " [15.571682]\n",
      " [19.947662]\n",
      " [12.499737]\n",
      " [24.759014]\n",
      " [32.78601 ]\n",
      " [ 8.587835]\n",
      " [20.575539]\n",
      " [19.944445]\n",
      " [22.898296]\n",
      " [33.292522]\n",
      " [20.187859]\n",
      " [ 8.653719]\n",
      " [15.223868]\n",
      " [21.894844]\n",
      " [21.641445]\n",
      " [23.751965]\n",
      " [15.222027]\n",
      " [21.117615]\n",
      " [21.365124]\n",
      " [10.453253]\n",
      " [16.508379]\n",
      " [ 8.636219]\n",
      " [13.852958]\n",
      " [15.84124 ]\n",
      " [19.416637]\n",
      " [11.876087]\n",
      " [19.46976 ]\n",
      " [22.465832]\n",
      " [21.634594]\n",
      " [20.189075]\n",
      " [ 8.531296]\n",
      " [22.465832]\n",
      " [56.167866]\n",
      " [14.096886]\n",
      " [21.3706  ]\n",
      " [21.64753 ]\n",
      " [24.679405]\n",
      " [19.515274]\n",
      " [13.715534]\n",
      " [21.574806]]\n",
      "=================\n",
      "R2 :  0.6857976878684134\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4972\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3261\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0739\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2175\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4753\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2620\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3131\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4790\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3224\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1091\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2564\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3904\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2173\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0582\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3060\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0643\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4050\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1740\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3868\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0220\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1985\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2736\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1565\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0648\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2290\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5703\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3573\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2212\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1571\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3202\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2941\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2378\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5165\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2788\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2603\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2256\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3257\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1371\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0882\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1747\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2355\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2740\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1850\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2897\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1326\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0125\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2125\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1294\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1665\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2175\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3143\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3145\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1629\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0360\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1506\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4180\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2310\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1851\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3491\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1665\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2371\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3248\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4575\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1244\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3684\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1149\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1470\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9981\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2694\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1088\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2753\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2188\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1196\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2658\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0534\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1771\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1610\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3642\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0376\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2511\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3675\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4050\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0843\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3856\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.1803\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2203\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0229\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3277\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1224\n",
      "Epoch 90/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 100us/step - loss: 2.1224\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.9976\n",
      "loss :  2.9976444244384766\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "=================\n",
      "[15.  26.6 45.4 20.8 34.9 21.9 28.7  7.2 20.  32.2 24.1 18.5 13.5 27.\n",
      " 23.1 18.9 24.5 43.1 19.8 13.8 15.6 50.  37.2 46.  50.  21.2 14.9 19.6\n",
      " 19.4 18.6 26.5 32.  10.9 20.  21.4 31.  25.  15.4 13.1 37.6 37.  18.9\n",
      " 27.9 50.  14.4 22.  19.9 21.6 15.6 15.  32.4 29.6 20.4 12.3 19.1 14.9\n",
      " 17.8  8.8 35.4 11.5 19.6 20.6 15.6 19.9 23.3 22.3 24.8 16.1 22.8 30.5\n",
      " 20.4 24.4 16.6 26.2 16.4 20.1 13.9 19.4 22.8 13.8 31.6 10.5 23.8 22.4\n",
      " 19.3 22.2 12.6 19.4 22.2 29.8  9.6 34.9 21.4 25.3 32.9 26.6 14.6 31.5\n",
      " 23.3 33.3 17.5 19.1 48.5 17.1 23.1 28.4 18.9 13.  17.2 24.1 18.5 21.8\n",
      " 13.3 23.  14.1 23.9 24.  17.2 21.5 19.1 20.8 36.  20.1  8.7 13.6 22.\n",
      " 22.2 21.1 13.4 17.4 20.1 10.2 23.1 10.2 13.1 14.3 14.5  7.2 19.6 20.6\n",
      " 22.7 26.4  7.5 20.3 50.   8.5 20.3 16.1 22.  19.6 10.2 23.2]\n",
      "[[12.045589 ]\n",
      " [28.034357 ]\n",
      " [47.94319  ]\n",
      " [19.504902 ]\n",
      " [27.561277 ]\n",
      " [54.087605 ]\n",
      " [30.383522 ]\n",
      " [ 8.262761 ]\n",
      " [15.460386 ]\n",
      " [25.304865 ]\n",
      " [23.292543 ]\n",
      " [20.770742 ]\n",
      " [15.249144 ]\n",
      " [40.583847 ]\n",
      " [21.142614 ]\n",
      " [19.793644 ]\n",
      " [21.581415 ]\n",
      " [39.924984 ]\n",
      " [18.694105 ]\n",
      " [15.435474 ]\n",
      " [16.119383 ]\n",
      " [24.016283 ]\n",
      " [40.774082 ]\n",
      " [45.92767  ]\n",
      " [51.64395  ]\n",
      " [23.986486 ]\n",
      " [20.304186 ]\n",
      " [22.042181 ]\n",
      " [22.129843 ]\n",
      " [15.165165 ]\n",
      " [23.741926 ]\n",
      " [34.8527   ]\n",
      " [11.5408   ]\n",
      " [20.822489 ]\n",
      " [21.39301  ]\n",
      " [28.325506 ]\n",
      " [23.97101  ]\n",
      " [15.495533 ]\n",
      " [15.143564 ]\n",
      " [41.582863 ]\n",
      " [38.44649  ]\n",
      " [18.19824  ]\n",
      " [19.026834 ]\n",
      " [49.950485 ]\n",
      " [14.219135 ]\n",
      " [22.685583 ]\n",
      " [22.042181 ]\n",
      " [22.662798 ]\n",
      " [17.394724 ]\n",
      " [18.583189 ]\n",
      " [41.98006  ]\n",
      " [20.669012 ]\n",
      " [22.042181 ]\n",
      " [13.646849 ]\n",
      " [20.61024  ]\n",
      " [17.064394 ]\n",
      " [15.809827 ]\n",
      " [ 8.234856 ]\n",
      " [33.197483 ]\n",
      " [14.770142 ]\n",
      " [18.766756 ]\n",
      " [20.879293 ]\n",
      " [14.292589 ]\n",
      " [22.042183 ]\n",
      " [22.154222 ]\n",
      " [23.12145  ]\n",
      " [23.758547 ]\n",
      " [22.992723 ]\n",
      " [25.473135 ]\n",
      " [34.338623 ]\n",
      " [18.527166 ]\n",
      " [26.16051  ]\n",
      " [17.807924 ]\n",
      " [23.406988 ]\n",
      " [20.574629 ]\n",
      " [19.493004 ]\n",
      " [14.003529 ]\n",
      " [18.827322 ]\n",
      " [30.206917 ]\n",
      " [ 8.238543 ]\n",
      " [31.183096 ]\n",
      " [12.613176 ]\n",
      " [23.612522 ]\n",
      " [20.847795 ]\n",
      " [15.849766 ]\n",
      " [24.493544 ]\n",
      " [18.35995  ]\n",
      " [21.03877  ]\n",
      " [21.18751  ]\n",
      " [37.2789   ]\n",
      " [13.295738 ]\n",
      " [35.280594 ]\n",
      " [20.437973 ]\n",
      " [25.696728 ]\n",
      " [27.665901 ]\n",
      " [29.074743 ]\n",
      " [15.557004 ]\n",
      " [42.565544 ]\n",
      " [25.171318 ]\n",
      " [40.129246 ]\n",
      " [20.904213 ]\n",
      " [15.363029 ]\n",
      " [46.04576  ]\n",
      " [15.559084 ]\n",
      " [20.303358 ]\n",
      " [25.120611 ]\n",
      " [17.16925  ]\n",
      " [15.397404 ]\n",
      " [19.137836 ]\n",
      " [22.042181 ]\n",
      " [21.59366  ]\n",
      " [24.103884 ]\n",
      " [15.579969 ]\n",
      " [20.107302 ]\n",
      " [13.509371 ]\n",
      " [23.200623 ]\n",
      " [32.368713 ]\n",
      " [10.7964115]\n",
      " [19.45875  ]\n",
      " [19.894453 ]\n",
      " [22.042181 ]\n",
      " [33.885468 ]\n",
      " [21.02162  ]\n",
      " [ 8.39393  ]\n",
      " [14.405775 ]\n",
      " [21.197226 ]\n",
      " [20.805021 ]\n",
      " [23.391455 ]\n",
      " [15.090086 ]\n",
      " [23.746794 ]\n",
      " [20.406607 ]\n",
      " [13.337211 ]\n",
      " [16.182266 ]\n",
      " [ 8.276406 ]\n",
      " [13.418553 ]\n",
      " [17.15255  ]\n",
      " [18.279118 ]\n",
      " [14.520733 ]\n",
      " [18.391756 ]\n",
      " [22.821009 ]\n",
      " [19.96094  ]\n",
      " [20.923677 ]\n",
      " [10.703447 ]\n",
      " [21.350779 ]\n",
      " [52.461365 ]\n",
      " [15.36124  ]\n",
      " [20.615988 ]\n",
      " [20.745926 ]\n",
      " [24.742437 ]\n",
      " [19.230295 ]\n",
      " [13.367095 ]\n",
      " [21.355974 ]]\n",
      "=================\n",
      "R2 :  0.7064821739200736\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3007\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0476\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1622\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2570\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0313\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2288\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1165\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2868\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3823\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3787\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3462\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0549\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0118\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1621\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1246\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2699\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1318\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1584\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2049\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0148\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2575\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1761\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0378\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0563\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0106\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1965\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7187\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8598\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5115\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.1973\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3481\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2234\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0621\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1695\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2759\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1147\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9335\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3585\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2061\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1872\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2359\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0325\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0345\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0077\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1515\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2050\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2381\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2277\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0428\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9118\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2212\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1928\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9781\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.9948\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3090\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5766\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2303\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1156\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2236\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2450\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0488\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1565\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9802\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0037\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1249\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2086\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0987\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0379\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.1160\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0900\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9593\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4271\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1768\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1651\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3126\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1674\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0702\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2105\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1554\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2030\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1401\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1205\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0092\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2207\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1428\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3118\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2914\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2285\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0114\n",
      "Epoch 90/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 100us/step - loss: 2.0114\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.8754\n",
      "loss :  2.875352621078491\n",
      "5/5 [==============================] - 0s 998us/step\n",
      "=================\n",
      "[15.  26.6 45.4 20.8 34.9 21.9 28.7  7.2 20.  32.2 24.1 18.5 13.5 27.\n",
      " 23.1 18.9 24.5 43.1 19.8 13.8 15.6 50.  37.2 46.  50.  21.2 14.9 19.6\n",
      " 19.4 18.6 26.5 32.  10.9 20.  21.4 31.  25.  15.4 13.1 37.6 37.  18.9\n",
      " 27.9 50.  14.4 22.  19.9 21.6 15.6 15.  32.4 29.6 20.4 12.3 19.1 14.9\n",
      " 17.8  8.8 35.4 11.5 19.6 20.6 15.6 19.9 23.3 22.3 24.8 16.1 22.8 30.5\n",
      " 20.4 24.4 16.6 26.2 16.4 20.1 13.9 19.4 22.8 13.8 31.6 10.5 23.8 22.4\n",
      " 19.3 22.2 12.6 19.4 22.2 29.8  9.6 34.9 21.4 25.3 32.9 26.6 14.6 31.5\n",
      " 23.3 33.3 17.5 19.1 48.5 17.1 23.1 28.4 18.9 13.  17.2 24.1 18.5 21.8\n",
      " 13.3 23.  14.1 23.9 24.  17.2 21.5 19.1 20.8 36.  20.1  8.7 13.6 22.\n",
      " 22.2 21.1 13.4 17.4 20.1 10.2 23.1 10.2 13.1 14.3 14.5  7.2 19.6 20.6\n",
      " 22.7 26.4  7.5 20.3 50.   8.5 20.3 16.1 22.  19.6 10.2 23.2]\n",
      "[[11.027708 ]\n",
      " [24.755182 ]\n",
      " [47.118458 ]\n",
      " [13.767126 ]\n",
      " [23.458967 ]\n",
      " [52.153435 ]\n",
      " [27.080824 ]\n",
      " [ 9.165604 ]\n",
      " [14.630932 ]\n",
      " [22.73255  ]\n",
      " [26.708994 ]\n",
      " [20.07253  ]\n",
      " [14.651098 ]\n",
      " [38.02522  ]\n",
      " [19.645554 ]\n",
      " [19.397425 ]\n",
      " [21.137667 ]\n",
      " [34.321236 ]\n",
      " [18.18092  ]\n",
      " [12.628044 ]\n",
      " [15.720793 ]\n",
      " [24.453426 ]\n",
      " [36.27595  ]\n",
      " [47.00021  ]\n",
      " [48.43443  ]\n",
      " [22.838198 ]\n",
      " [14.300972 ]\n",
      " [20.33773  ]\n",
      " [22.20069  ]\n",
      " [14.14254  ]\n",
      " [22.200686 ]\n",
      " [32.245758 ]\n",
      " [10.831429 ]\n",
      " [19.76349  ]\n",
      " [20.353355 ]\n",
      " [28.837152 ]\n",
      " [23.418072 ]\n",
      " [12.95013  ]\n",
      " [14.574953 ]\n",
      " [45.968494 ]\n",
      " [26.694841 ]\n",
      " [17.90724  ]\n",
      " [14.53095  ]\n",
      " [49.425644 ]\n",
      " [14.466978 ]\n",
      " [22.20069  ]\n",
      " [21.07884  ]\n",
      " [22.20069  ]\n",
      " [16.712585 ]\n",
      " [15.40093  ]\n",
      " [33.15867  ]\n",
      " [20.279535 ]\n",
      " [20.584826 ]\n",
      " [10.982701 ]\n",
      " [18.216793 ]\n",
      " [13.518574 ]\n",
      " [14.608045 ]\n",
      " [ 9.929346 ]\n",
      " [28.62324  ]\n",
      " [11.85194  ]\n",
      " [18.209272 ]\n",
      " [19.894884 ]\n",
      " [13.924836 ]\n",
      " [20.651848 ]\n",
      " [22.20069  ]\n",
      " [22.20069  ]\n",
      " [22.20069  ]\n",
      " [14.236453 ]\n",
      " [23.332106 ]\n",
      " [27.593649 ]\n",
      " [18.369331 ]\n",
      " [23.564318 ]\n",
      " [17.31337  ]\n",
      " [22.601164 ]\n",
      " [15.747332 ]\n",
      " [20.451908 ]\n",
      " [11.259531 ]\n",
      " [18.985643 ]\n",
      " [25.439127 ]\n",
      " [10.516136 ]\n",
      " [27.28736  ]\n",
      " [10.76143  ]\n",
      " [22.20069  ]\n",
      " [20.172949 ]\n",
      " [14.8720875]\n",
      " [23.432848 ]\n",
      " [13.88718  ]\n",
      " [20.646755 ]\n",
      " [20.38799  ]\n",
      " [30.195164 ]\n",
      " [12.443548 ]\n",
      " [31.17031  ]\n",
      " [20.594961 ]\n",
      " [23.686625 ]\n",
      " [23.41139  ]\n",
      " [26.377605 ]\n",
      " [13.063097 ]\n",
      " [38.919575 ]\n",
      " [23.892384 ]\n",
      " [32.80283  ]\n",
      " [19.571337 ]\n",
      " [12.425415 ]\n",
      " [45.063473 ]\n",
      " [12.863557 ]\n",
      " [20.278872 ]\n",
      " [22.482553 ]\n",
      " [15.237405 ]\n",
      " [12.55977  ]\n",
      " [18.211748 ]\n",
      " [24.471048 ]\n",
      " [21.118505 ]\n",
      " [23.006336 ]\n",
      " [14.651643 ]\n",
      " [18.23704  ]\n",
      " [12.425029 ]\n",
      " [27.690125 ]\n",
      " [28.934444 ]\n",
      " [10.208843 ]\n",
      " [18.25266  ]\n",
      " [19.450563 ]\n",
      " [22.519407 ]\n",
      " [29.684134 ]\n",
      " [18.720095 ]\n",
      " [10.378227 ]\n",
      " [14.356293 ]\n",
      " [20.95857  ]\n",
      " [20.154367 ]\n",
      " [22.200686 ]\n",
      " [14.471482 ]\n",
      " [20.074892 ]\n",
      " [20.240274 ]\n",
      " [10.740841 ]\n",
      " [13.481171 ]\n",
      " [10.389862 ]\n",
      " [13.50057  ]\n",
      " [13.504551 ]\n",
      " [18.176168 ]\n",
      " [11.740375 ]\n",
      " [18.157486 ]\n",
      " [21.051098 ]\n",
      " [19.053072 ]\n",
      " [20.294235 ]\n",
      " [10.693602 ]\n",
      " [20.38106  ]\n",
      " [50.790134 ]\n",
      " [12.524181 ]\n",
      " [20.839537 ]\n",
      " [20.069284 ]\n",
      " [23.760962 ]\n",
      " [18.750301 ]\n",
      " [12.505157 ]\n",
      " [20.247557 ]]\n",
      "=================\n",
      "R2 :  0.7083356307294433\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2645\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2235\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2059\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3595\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1531\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2937\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2164\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1733\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1977\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0702\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2588\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2822\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1084\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0474\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3444\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0959\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9554\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1323\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0849\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.1951\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1537\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1717\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1794\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9456\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0615\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1874\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0696\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0661\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0969\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1134\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0317\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0490\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3819\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8262\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0779\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9144\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9856\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1388\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0771\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2049\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0180\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1683\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.1852\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2138\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1461\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2590\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9395\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9638\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3258\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1363\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2448\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9866\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1988\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9214\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1635\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0575\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.1466\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.1112\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0100\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9740\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1749\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0465\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1092\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2827\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5680\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9738\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2771\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9562\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4104\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1446\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1988\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1890\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0074\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1393\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2042\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8918\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1954\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0422\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5282\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3662\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0457\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2495\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1922\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1326\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9885\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1571\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0229\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9963\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2745\n",
      "Epoch 90/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 100us/step - loss: 2.2745\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 2.9560\n",
      "loss :  2.9559857845306396\n",
      "5/5 [==============================] - 0s 998us/step\n",
      "=================\n",
      "[15.  26.6 45.4 20.8 34.9 21.9 28.7  7.2 20.  32.2 24.1 18.5 13.5 27.\n",
      " 23.1 18.9 24.5 43.1 19.8 13.8 15.6 50.  37.2 46.  50.  21.2 14.9 19.6\n",
      " 19.4 18.6 26.5 32.  10.9 20.  21.4 31.  25.  15.4 13.1 37.6 37.  18.9\n",
      " 27.9 50.  14.4 22.  19.9 21.6 15.6 15.  32.4 29.6 20.4 12.3 19.1 14.9\n",
      " 17.8  8.8 35.4 11.5 19.6 20.6 15.6 19.9 23.3 22.3 24.8 16.1 22.8 30.5\n",
      " 20.4 24.4 16.6 26.2 16.4 20.1 13.9 19.4 22.8 13.8 31.6 10.5 23.8 22.4\n",
      " 19.3 22.2 12.6 19.4 22.2 29.8  9.6 34.9 21.4 25.3 32.9 26.6 14.6 31.5\n",
      " 23.3 33.3 17.5 19.1 48.5 17.1 23.1 28.4 18.9 13.  17.2 24.1 18.5 21.8\n",
      " 13.3 23.  14.1 23.9 24.  17.2 21.5 19.1 20.8 36.  20.1  8.7 13.6 22.\n",
      " 22.2 21.1 13.4 17.4 20.1 10.2 23.1 10.2 13.1 14.3 14.5  7.2 19.6 20.6\n",
      " 22.7 26.4  7.5 20.3 50.   8.5 20.3 16.1 22.  19.6 10.2 23.2]\n",
      "[[12.204661 ]\n",
      " [22.544786 ]\n",
      " [45.568066 ]\n",
      " [15.480069 ]\n",
      " [22.016539 ]\n",
      " [49.319084 ]\n",
      " [25.796797 ]\n",
      " [ 8.101848 ]\n",
      " [15.895209 ]\n",
      " [22.016539 ]\n",
      " [26.133097 ]\n",
      " [20.457476 ]\n",
      " [14.819565 ]\n",
      " [29.459446 ]\n",
      " [20.08047  ]\n",
      " [18.72756  ]\n",
      " [20.71832  ]\n",
      " [31.085377 ]\n",
      " [18.58625  ]\n",
      " [14.455527 ]\n",
      " [19.181612 ]\n",
      " [22.016539 ]\n",
      " [34.66524  ]\n",
      " [46.490322 ]\n",
      " [47.546375 ]\n",
      " [22.016539 ]\n",
      " [15.956027 ]\n",
      " [20.67893  ]\n",
      " [22.016539 ]\n",
      " [14.575329 ]\n",
      " [22.016539 ]\n",
      " [31.414682 ]\n",
      " [ 9.995201 ]\n",
      " [20.012054 ]\n",
      " [20.117228 ]\n",
      " [32.02853  ]\n",
      " [23.215567 ]\n",
      " [14.1992655]\n",
      " [15.133298 ]\n",
      " [44.541897 ]\n",
      " [24.831163 ]\n",
      " [18.41134  ]\n",
      " [15.894031 ]\n",
      " [47.575954 ]\n",
      " [14.49653  ]\n",
      " [22.016539 ]\n",
      " [20.675222 ]\n",
      " [22.016539 ]\n",
      " [18.386566 ]\n",
      " [16.911184 ]\n",
      " [32.64394  ]\n",
      " [19.982746 ]\n",
      " [20.679514 ]\n",
      " [12.733101 ]\n",
      " [18.598606 ]\n",
      " [15.044791 ]\n",
      " [14.610647 ]\n",
      " [ 8.133073 ]\n",
      " [26.494156 ]\n",
      " [13.251113 ]\n",
      " [18.540731 ]\n",
      " [20.272844 ]\n",
      " [14.390699 ]\n",
      " [20.493288 ]\n",
      " [22.016539 ]\n",
      " [22.016539 ]\n",
      " [22.016539 ]\n",
      " [22.905588 ]\n",
      " [23.219961 ]\n",
      " [24.44673  ]\n",
      " [18.450014 ]\n",
      " [22.016539 ]\n",
      " [18.31841  ]\n",
      " [22.06878  ]\n",
      " [16.094099 ]\n",
      " [19.982412 ]\n",
      " [12.581206 ]\n",
      " [18.651163 ]\n",
      " [22.37662  ]\n",
      " [ 8.920402 ]\n",
      " [23.586542 ]\n",
      " [11.345841 ]\n",
      " [22.016539 ]\n",
      " [20.026812 ]\n",
      " [16.495302 ]\n",
      " [22.68633  ]\n",
      " [15.32845  ]\n",
      " [20.002924 ]\n",
      " [20.749714 ]\n",
      " [27.359995 ]\n",
      " [13.703696 ]\n",
      " [29.009722 ]\n",
      " [19.92979  ]\n",
      " [23.427813 ]\n",
      " [22.832369 ]\n",
      " [25.980558 ]\n",
      " [14.407989 ]\n",
      " [34.70886  ]\n",
      " [22.617228 ]\n",
      " [30.392488 ]\n",
      " [20.449827 ]\n",
      " [14.323424 ]\n",
      " [43.81496  ]\n",
      " [14.057948 ]\n",
      " [19.96474  ]\n",
      " [22.016539 ]\n",
      " [17.862661 ]\n",
      " [14.608909 ]\n",
      " [18.607832 ]\n",
      " [20.79284  ]\n",
      " [20.040808 ]\n",
      " [22.016539 ]\n",
      " [15.061159 ]\n",
      " [18.580935 ]\n",
      " [12.264926 ]\n",
      " [26.907309 ]\n",
      " [26.32596  ]\n",
      " [ 9.896956 ]\n",
      " [18.590904 ]\n",
      " [19.748884 ]\n",
      " [20.04639  ]\n",
      " [29.717253 ]\n",
      " [18.754705 ]\n",
      " [ 8.193259 ]\n",
      " [14.544248 ]\n",
      " [20.321295 ]\n",
      " [19.797392 ]\n",
      " [22.016539 ]\n",
      " [14.743974 ]\n",
      " [19.42543  ]\n",
      " [19.741232 ]\n",
      " [11.961602 ]\n",
      " [14.045005 ]\n",
      " [10.486211 ]\n",
      " [13.96915  ]\n",
      " [14.410613 ]\n",
      " [18.48471  ]\n",
      " [13.111136 ]\n",
      " [18.464138 ]\n",
      " [21.516397 ]\n",
      " [19.722744 ]\n",
      " [19.970804 ]\n",
      " [ 8.992367 ]\n",
      " [20.092138 ]\n",
      " [48.260094 ]\n",
      " [13.538628 ]\n",
      " [19.995306 ]\n",
      " [19.95513  ]\n",
      " [22.016539 ]\n",
      " [18.534678 ]\n",
      " [13.80561  ]\n",
      " [19.929628 ]]\n",
      "=================\n",
      "R2 :  0.7006138816939944\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3435\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0637\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3424\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2234\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0377\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1891\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1048\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9805\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0669\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0337\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2652\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4068\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2620\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1551\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0238\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1201\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2327\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2178\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0634\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0689\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2683\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0080\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2607\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0603\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0254\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1253\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1409\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8728\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8860\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2670\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9990\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0246\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0394\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3707\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.9307\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.9661\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.7816\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9220\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0438\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9417\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.2834\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2702\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9758\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1164\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1689\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0005\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.8611\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0312\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3416\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4302\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0504\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2129\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0452\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.1205\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1873\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9620\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.2522\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1258\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0010\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0386\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0334\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2493\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0621\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9540\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1062\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1380\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.0349\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0260\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8659\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1235\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9546\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2237\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.1031\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8970\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0414\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1828\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0347\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1771\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8563\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0058\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9252\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0547\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1557\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1483\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2518\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0963\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0015\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.8810\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9629\n",
      "Epoch 90/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 110us/step - loss: 1.9629\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.8935\n",
      "loss :  2.8934810161590576\n",
      "5/5 [==============================] - 0s 997us/step\n",
      "=================\n",
      "[15.  26.6 45.4 20.8 34.9 21.9 28.7  7.2 20.  32.2 24.1 18.5 13.5 27.\n",
      " 23.1 18.9 24.5 43.1 19.8 13.8 15.6 50.  37.2 46.  50.  21.2 14.9 19.6\n",
      " 19.4 18.6 26.5 32.  10.9 20.  21.4 31.  25.  15.4 13.1 37.6 37.  18.9\n",
      " 27.9 50.  14.4 22.  19.9 21.6 15.6 15.  32.4 29.6 20.4 12.3 19.1 14.9\n",
      " 17.8  8.8 35.4 11.5 19.6 20.6 15.6 19.9 23.3 22.3 24.8 16.1 22.8 30.5\n",
      " 20.4 24.4 16.6 26.2 16.4 20.1 13.9 19.4 22.8 13.8 31.6 10.5 23.8 22.4\n",
      " 19.3 22.2 12.6 19.4 22.2 29.8  9.6 34.9 21.4 25.3 32.9 26.6 14.6 31.5\n",
      " 23.3 33.3 17.5 19.1 48.5 17.1 23.1 28.4 18.9 13.  17.2 24.1 18.5 21.8\n",
      " 13.3 23.  14.1 23.9 24.  17.2 21.5 19.1 20.8 36.  20.1  8.7 13.6 22.\n",
      " 22.2 21.1 13.4 17.4 20.1 10.2 23.1 10.2 13.1 14.3 14.5  7.2 19.6 20.6\n",
      " 22.7 26.4  7.5 20.3 50.   8.5 20.3 16.1 22.  19.6 10.2 23.2]\n",
      "[[12.961196 ]\n",
      " [24.992184 ]\n",
      " [46.937565 ]\n",
      " [13.782463 ]\n",
      " [23.797749 ]\n",
      " [49.42308  ]\n",
      " [27.725515 ]\n",
      " [ 8.090564 ]\n",
      " [14.2791195]\n",
      " [23.113075 ]\n",
      " [28.549204 ]\n",
      " [18.977545 ]\n",
      " [15.056004 ]\n",
      " [36.709885 ]\n",
      " [19.308249 ]\n",
      " [18.388418 ]\n",
      " [20.553848 ]\n",
      " [35.006397 ]\n",
      " [18.2701   ]\n",
      " [12.317751 ]\n",
      " [18.461159 ]\n",
      " [23.37402  ]\n",
      " [40.06802  ]\n",
      " [47.378323 ]\n",
      " [47.053364 ]\n",
      " [21.74984  ]\n",
      " [15.043742 ]\n",
      " [20.489803 ]\n",
      " [21.839901 ]\n",
      " [14.7368355]\n",
      " [21.8399   ]\n",
      " [33.096867 ]\n",
      " [11.576464 ]\n",
      " [18.433567 ]\n",
      " [19.473106 ]\n",
      " [31.972706 ]\n",
      " [23.318932 ]\n",
      " [12.733016 ]\n",
      " [14.207762 ]\n",
      " [45.963177 ]\n",
      " [27.198635 ]\n",
      " [17.697647 ]\n",
      " [14.976631 ]\n",
      " [46.675358 ]\n",
      " [14.266121 ]\n",
      " [21.839901 ]\n",
      " [20.494095 ]\n",
      " [21.839901 ]\n",
      " [17.09784  ]\n",
      " [15.773624 ]\n",
      " [33.47329  ]\n",
      " [20.370419 ]\n",
      " [20.475111 ]\n",
      " [11.171388 ]\n",
      " [18.27855  ]\n",
      " [13.29065  ]\n",
      " [14.159294 ]\n",
      " [ 8.081043 ]\n",
      " [31.551888 ]\n",
      " [11.395842 ]\n",
      " [18.31137  ]\n",
      " [19.047356 ]\n",
      " [13.976048 ]\n",
      " [19.743208 ]\n",
      " [21.839901 ]\n",
      " [21.839901 ]\n",
      " [21.839901 ]\n",
      " [18.2178   ]\n",
      " [22.685436 ]\n",
      " [28.1745   ]\n",
      " [18.43304  ]\n",
      " [24.71365  ]\n",
      " [17.341211 ]\n",
      " [21.839901 ]\n",
      " [15.239712 ]\n",
      " [18.052872 ]\n",
      " [11.267636 ]\n",
      " [18.101122 ]\n",
      " [24.476578 ]\n",
      " [ 8.182213 ]\n",
      " [26.844284 ]\n",
      " [10.7111   ]\n",
      " [21.839901 ]\n",
      " [19.13464  ]\n",
      " [14.454306 ]\n",
      " [22.20284  ]\n",
      " [13.578721 ]\n",
      " [20.483273 ]\n",
      " [20.34732  ]\n",
      " [31.035307 ]\n",
      " [13.532003 ]\n",
      " [30.795464 ]\n",
      " [20.473705 ]\n",
      " [23.533464 ]\n",
      " [24.06623  ]\n",
      " [24.467453 ]\n",
      " [12.829159 ]\n",
      " [37.606964 ]\n",
      " [23.330292 ]\n",
      " [33.689587 ]\n",
      " [19.403145 ]\n",
      " [12.417452 ]\n",
      " [44.01116  ]\n",
      " [12.671928 ]\n",
      " [19.81083  ]\n",
      " [21.839901 ]\n",
      " [15.91161  ]\n",
      " [12.597534 ]\n",
      " [18.276474 ]\n",
      " [23.17918  ]\n",
      " [21.062178 ]\n",
      " [21.839901 ]\n",
      " [14.175468 ]\n",
      " [18.295315 ]\n",
      " [13.1959915]\n",
      " [25.877369 ]\n",
      " [30.031681 ]\n",
      " [ 8.954207 ]\n",
      " [18.277323 ]\n",
      " [18.617033 ]\n",
      " [20.839493 ]\n",
      " [32.09952  ]\n",
      " [18.1365   ]\n",
      " [ 8.693585 ]\n",
      " [14.1644335]\n",
      " [20.414356 ]\n",
      " [19.481674 ]\n",
      " [21.8399   ]\n",
      " [14.202093 ]\n",
      " [20.737476 ]\n",
      " [19.652092 ]\n",
      " [10.9134655]\n",
      " [13.648575 ]\n",
      " [ 9.721773 ]\n",
      " [13.507425 ]\n",
      " [14.326132 ]\n",
      " [18.17596  ]\n",
      " [11.364782 ]\n",
      " [18.168406 ]\n",
      " [20.276524 ]\n",
      " [18.766907 ]\n",
      " [21.839901 ]\n",
      " [ 9.981026 ]\n",
      " [19.481218 ]\n",
      " [48.480816 ]\n",
      " [12.30227  ]\n",
      " [20.48883  ]\n",
      " [18.713615 ]\n",
      " [22.80809  ]\n",
      " [18.083782 ]\n",
      " [13.551081 ]\n",
      " [18.84069  ]]\n",
      "=================\n",
      "R2 :  0.7203967737789668\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8961\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1195\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1409\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.1525\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9285\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9958\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2459\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0076\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.0055\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0407\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.8158\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1136\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0647\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0920\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1855\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0668\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.9788\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9577\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0744\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9827\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0416\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.9389\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0025\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1618\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0060\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9885\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.9199\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1809\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8245\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0968\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0234\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9984\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1384\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1087\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5380\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.9928\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5185\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1732\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0479\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0545\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1557\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.0814\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4511\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0155\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1177\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.1477\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1575\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0208\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1090\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0339\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.2232\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2512\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1022\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1079\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.2894\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1873\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0134\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4117\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3112\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.1004\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9944\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4629\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1812\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.3042\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3060\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1650\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1316\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9585\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.2757\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1970\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1970\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1349\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.1200\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0073\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1170\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3357\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0140\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.0176\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.0999\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.1480\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.3451\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.1843\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0913\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.0878\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.4407\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.5594\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0701\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.0931\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.0860\n",
      "Epoch 90/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 140us/step - loss: 2.0860\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.3467\n",
      "loss :  3.346682071685791\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "=================\n",
      "[15.  26.6 45.4 20.8 34.9 21.9 28.7  7.2 20.  32.2 24.1 18.5 13.5 27.\n",
      " 23.1 18.9 24.5 43.1 19.8 13.8 15.6 50.  37.2 46.  50.  21.2 14.9 19.6\n",
      " 19.4 18.6 26.5 32.  10.9 20.  21.4 31.  25.  15.4 13.1 37.6 37.  18.9\n",
      " 27.9 50.  14.4 22.  19.9 21.6 15.6 15.  32.4 29.6 20.4 12.3 19.1 14.9\n",
      " 17.8  8.8 35.4 11.5 19.6 20.6 15.6 19.9 23.3 22.3 24.8 16.1 22.8 30.5\n",
      " 20.4 24.4 16.6 26.2 16.4 20.1 13.9 19.4 22.8 13.8 31.6 10.5 23.8 22.4\n",
      " 19.3 22.2 12.6 19.4 22.2 29.8  9.6 34.9 21.4 25.3 32.9 26.6 14.6 31.5\n",
      " 23.3 33.3 17.5 19.1 48.5 17.1 23.1 28.4 18.9 13.  17.2 24.1 18.5 21.8\n",
      " 13.3 23.  14.1 23.9 24.  17.2 21.5 19.1 20.8 36.  20.1  8.7 13.6 22.\n",
      " 22.2 21.1 13.4 17.4 20.1 10.2 23.1 10.2 13.1 14.3 14.5  7.2 19.6 20.6\n",
      " 22.7 26.4  7.5 20.3 50.   8.5 20.3 16.1 22.  19.6 10.2 23.2]\n",
      "[[11.993593 ]\n",
      " [31.406641 ]\n",
      " [48.379303 ]\n",
      " [19.723442 ]\n",
      " [30.68578  ]\n",
      " [52.656338 ]\n",
      " [33.271442 ]\n",
      " [ 8.459988 ]\n",
      " [17.004345 ]\n",
      " [30.039026 ]\n",
      " [24.73793  ]\n",
      " [21.00409  ]\n",
      " [14.420767 ]\n",
      " [42.741905 ]\n",
      " [21.657276 ]\n",
      " [20.474869 ]\n",
      " [21.084414 ]\n",
      " [43.015423 ]\n",
      " [18.703094 ]\n",
      " [15.019719 ]\n",
      " [14.806838 ]\n",
      " [24.732376 ]\n",
      " [47.061344 ]\n",
      " [46.216507 ]\n",
      " [50.9629   ]\n",
      " [24.313698 ]\n",
      " [23.509388 ]\n",
      " [22.145134 ]\n",
      " [22.145134 ]\n",
      " [16.033604 ]\n",
      " [24.664604 ]\n",
      " [42.017715 ]\n",
      " [12.25809  ]\n",
      " [21.03712  ]\n",
      " [22.193325 ]\n",
      " [30.862864 ]\n",
      " [25.827267 ]\n",
      " [16.364647 ]\n",
      " [16.61332  ]\n",
      " [41.214584 ]\n",
      " [41.47761  ]\n",
      " [18.29567  ]\n",
      " [19.762497 ]\n",
      " [49.764206 ]\n",
      " [14.313636 ]\n",
      " [24.245243 ]\n",
      " [22.145134 ]\n",
      " [22.145134 ]\n",
      " [18.515568 ]\n",
      " [20.140617 ]\n",
      " [43.376923 ]\n",
      " [23.211857 ]\n",
      " [22.145134 ]\n",
      " [12.683368 ]\n",
      " [19.80147  ]\n",
      " [17.337563 ]\n",
      " [15.073718 ]\n",
      " [ 8.228856 ]\n",
      " [41.809723 ]\n",
      " [13.76958  ]\n",
      " [18.564632 ]\n",
      " [20.957794 ]\n",
      " [23.831293 ]\n",
      " [22.145134 ]\n",
      " [23.813265 ]\n",
      " [24.49266  ]\n",
      " [24.49818  ]\n",
      " [22.161932 ]\n",
      " [33.865303 ]\n",
      " [33.262714 ]\n",
      " [18.451965 ]\n",
      " [27.842627 ]\n",
      " [18.37099  ]\n",
      " [23.784708 ]\n",
      " [20.090168 ]\n",
      " [20.139954 ]\n",
      " [13.077062 ]\n",
      " [19.310722 ]\n",
      " [32.42089  ]\n",
      " [ 8.391927 ]\n",
      " [33.67742  ]\n",
      " [12.399924 ]\n",
      " [24.25185  ]\n",
      " [21.339657 ]\n",
      " [17.398338 ]\n",
      " [26.081945 ]\n",
      " [18.237225 ]\n",
      " [22.145134 ]\n",
      " [22.145134 ]\n",
      " [33.992138 ]\n",
      " [13.066119 ]\n",
      " [35.284973 ]\n",
      " [20.148386 ]\n",
      " [28.003798 ]\n",
      " [33.806763 ]\n",
      " [33.85064  ]\n",
      " [17.089275 ]\n",
      " [46.6737   ]\n",
      " [35.725876 ]\n",
      " [45.30266  ]\n",
      " [21.04142  ]\n",
      " [14.289538 ]\n",
      " [47.631332 ]\n",
      " [15.764586 ]\n",
      " [20.343246 ]\n",
      " [27.506588 ]\n",
      " [19.050352 ]\n",
      " [14.79843  ]\n",
      " [19.763914 ]\n",
      " [23.70305  ]\n",
      " [22.145134 ]\n",
      " [24.369379 ]\n",
      " [15.621493 ]\n",
      " [19.779976 ]\n",
      " [14.295035 ]\n",
      " [24.415874 ]\n",
      " [35.066654 ]\n",
      " [11.591399 ]\n",
      " [19.609444 ]\n",
      " [20.139692 ]\n",
      " [23.692165 ]\n",
      " [33.483215 ]\n",
      " [18.843018 ]\n",
      " [ 8.657083 ]\n",
      " [14.546784 ]\n",
      " [22.120132 ]\n",
      " [22.145134 ]\n",
      " [24.937187 ]\n",
      " [14.82686  ]\n",
      " [23.669773 ]\n",
      " [20.833786 ]\n",
      " [12.8730135]\n",
      " [12.4367   ]\n",
      " [ 8.753622 ]\n",
      " [13.37456  ]\n",
      " [15.390552 ]\n",
      " [18.535671 ]\n",
      " [13.897605 ]\n",
      " [18.294365 ]\n",
      " [22.687435 ]\n",
      " [19.776224 ]\n",
      " [24.48941  ]\n",
      " [10.33915  ]\n",
      " [22.21312  ]\n",
      " [52.08534  ]\n",
      " [14.74938  ]\n",
      " [20.25015  ]\n",
      " [21.733871 ]\n",
      " [25.223433 ]\n",
      " [18.478304 ]\n",
      " [13.86745  ]\n",
      " [22.145134 ]]\n",
      "=================\n",
      "R2 :  0.6425369911175681\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3647\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.3178\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.1420\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.8560\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.1697\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.0401\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.0369\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.1775\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.8965\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.2000\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.0838\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.0933\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.9623\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.9794\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.8710\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.2484\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.2056\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.9300\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.1772\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.2087\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.0749\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.9571\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.3232\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.0619\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.1195\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3907\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1261\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9700\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.0041\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0387\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9595\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1739\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5420\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.4219\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.4679\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1941\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.0343\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.0675\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.1987\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.9974\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.9630\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.9635\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0479\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9220\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1159\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.8783\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.9889\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8476\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9950\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9413\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9392\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1213\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0577\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2247\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0892\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9985\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3986\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0569\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4622\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3702\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.0932\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0156\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.0703\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0461\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.9531\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1467\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8699\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9471\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1540\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0519\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0634\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1866\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.1284\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8894\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8263\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0002\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.9288\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0106\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1815\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0296\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0458\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2394\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.4626\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.0504\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.3501\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.8801\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.8578\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8135\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0878\n",
      "Epoch 90/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 120us/step - loss: 2.0878\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.8645\n",
      "loss :  2.864548444747925\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "=================\n",
      "[15.  26.6 45.4 20.8 34.9 21.9 28.7  7.2 20.  32.2 24.1 18.5 13.5 27.\n",
      " 23.1 18.9 24.5 43.1 19.8 13.8 15.6 50.  37.2 46.  50.  21.2 14.9 19.6\n",
      " 19.4 18.6 26.5 32.  10.9 20.  21.4 31.  25.  15.4 13.1 37.6 37.  18.9\n",
      " 27.9 50.  14.4 22.  19.9 21.6 15.6 15.  32.4 29.6 20.4 12.3 19.1 14.9\n",
      " 17.8  8.8 35.4 11.5 19.6 20.6 15.6 19.9 23.3 22.3 24.8 16.1 22.8 30.5\n",
      " 20.4 24.4 16.6 26.2 16.4 20.1 13.9 19.4 22.8 13.8 31.6 10.5 23.8 22.4\n",
      " 19.3 22.2 12.6 19.4 22.2 29.8  9.6 34.9 21.4 25.3 32.9 26.6 14.6 31.5\n",
      " 23.3 33.3 17.5 19.1 48.5 17.1 23.1 28.4 18.9 13.  17.2 24.1 18.5 21.8\n",
      " 13.3 23.  14.1 23.9 24.  17.2 21.5 19.1 20.8 36.  20.1  8.7 13.6 22.\n",
      " 22.2 21.1 13.4 17.4 20.1 10.2 23.1 10.2 13.1 14.3 14.5  7.2 19.6 20.6\n",
      " 22.7 26.4  7.5 20.3 50.   8.5 20.3 16.1 22.  19.6 10.2 23.2]\n",
      "[[11.580369 ]\n",
      " [27.415522 ]\n",
      " [46.206104 ]\n",
      " [18.838367 ]\n",
      " [27.72326  ]\n",
      " [51.12611  ]\n",
      " [28.74162  ]\n",
      " [ 9.1925955]\n",
      " [14.820345 ]\n",
      " [23.086658 ]\n",
      " [23.48317  ]\n",
      " [19.019794 ]\n",
      " [14.228489 ]\n",
      " [41.349476 ]\n",
      " [20.080103 ]\n",
      " [19.260681 ]\n",
      " [20.081448 ]\n",
      " [33.083893 ]\n",
      " [17.546457 ]\n",
      " [13.544493 ]\n",
      " [16.406494 ]\n",
      " [28.70401  ]\n",
      " [39.197937 ]\n",
      " [46.251095 ]\n",
      " [49.48863  ]\n",
      " [22.611252 ]\n",
      " [19.099173 ]\n",
      " [20.080791 ]\n",
      " [21.240597 ]\n",
      " [13.702909 ]\n",
      " [21.240597 ]\n",
      " [33.347195 ]\n",
      " [11.770339 ]\n",
      " [19.81326  ]\n",
      " [20.154877 ]\n",
      " [29.128845 ]\n",
      " [22.671967 ]\n",
      " [14.359134 ]\n",
      " [14.606011 ]\n",
      " [45.608196 ]\n",
      " [34.608547 ]\n",
      " [17.431602 ]\n",
      " [18.916561 ]\n",
      " [48.288357 ]\n",
      " [14.101951 ]\n",
      " [21.240597 ]\n",
      " [20.080471 ]\n",
      " [21.240597 ]\n",
      " [17.272133 ]\n",
      " [20.208286 ]\n",
      " [33.66128  ]\n",
      " [20.952251 ]\n",
      " [19.975773 ]\n",
      " [11.796601 ]\n",
      " [18.500957 ]\n",
      " [15.223765 ]\n",
      " [14.032533 ]\n",
      " [ 7.6153393]\n",
      " [31.469711 ]\n",
      " [12.755798 ]\n",
      " [17.465834 ]\n",
      " [19.54255  ]\n",
      " [14.392139 ]\n",
      " [21.131691 ]\n",
      " [21.240597 ]\n",
      " [21.411642 ]\n",
      " [22.48172  ]\n",
      " [21.666645 ]\n",
      " [24.140665 ]\n",
      " [33.191525 ]\n",
      " [17.679762 ]\n",
      " [25.94051  ]\n",
      " [17.29199  ]\n",
      " [22.478699 ]\n",
      " [18.901806 ]\n",
      " [19.6969   ]\n",
      " [12.738946 ]\n",
      " [18.792698 ]\n",
      " [26.713253 ]\n",
      " [ 7.923092 ]\n",
      " [28.404783 ]\n",
      " [12.312926 ]\n",
      " [21.240597 ]\n",
      " [20.020554 ]\n",
      " [15.293398 ]\n",
      " [22.93729  ]\n",
      " [15.969312 ]\n",
      " [20.538292 ]\n",
      " [20.079689 ]\n",
      " [37.300953 ]\n",
      " [12.422774 ]\n",
      " [40.374027 ]\n",
      " [19.648712 ]\n",
      " [23.075802 ]\n",
      " [27.786232 ]\n",
      " [27.636515 ]\n",
      " [14.684097 ]\n",
      " [42.17969  ]\n",
      " [25.04428  ]\n",
      " [34.223392 ]\n",
      " [20.081547 ]\n",
      " [13.182199 ]\n",
      " [45.844997 ]\n",
      " [13.917304 ]\n",
      " [19.12722  ]\n",
      " [22.75388  ]\n",
      " [17.906757 ]\n",
      " [13.765081 ]\n",
      " [17.864456 ]\n",
      " [21.240597 ]\n",
      " [20.226425 ]\n",
      " [22.649456 ]\n",
      " [14.51176  ]\n",
      " [17.642956 ]\n",
      " [13.039899 ]\n",
      " [22.517637 ]\n",
      " [31.365013 ]\n",
      " [12.378861 ]\n",
      " [17.880882 ]\n",
      " [19.182106 ]\n",
      " [22.70007  ]\n",
      " [29.84255  ]\n",
      " [18.848417 ]\n",
      " [10.242339 ]\n",
      " [14.138959 ]\n",
      " [20.167578 ]\n",
      " [19.540657 ]\n",
      " [21.240597 ]\n",
      " [14.471732 ]\n",
      " [18.711823 ]\n",
      " [18.882187 ]\n",
      " [12.33351  ]\n",
      " [15.191791 ]\n",
      " [10.396882 ]\n",
      " [13.190298 ]\n",
      " [14.792265 ]\n",
      " [18.016045 ]\n",
      " [12.921728 ]\n",
      " [17.439829 ]\n",
      " [21.823257 ]\n",
      " [18.945248 ]\n",
      " [23.544249 ]\n",
      " [11.05222  ]\n",
      " [20.155014 ]\n",
      " [50.735165 ]\n",
      " [13.262136 ]\n",
      " [19.75468  ]\n",
      " [19.962353 ]\n",
      " [22.887539 ]\n",
      " [17.398302 ]\n",
      " [12.689984 ]\n",
      " [20.223995 ]]\n",
      "=================\n",
      "R2 :  0.7404137250021736\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1658\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2251\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1515\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1364\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9957\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.3939\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1229\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.9437\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1991\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0340\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1212\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0749\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8208\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9477\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9778\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9583\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0985\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8828\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9958\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0343\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.9253\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9138\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0299\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.1961\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.0253\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9858\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1327\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8322\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.0736\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2809\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9705\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8709\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2817\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1140\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9332\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2920\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0207\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8894\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1642\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1331\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9177\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.9080\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9307\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8026\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9768\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2048\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9219\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.9471\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9087\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0708\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.7695\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0099\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.7694\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9305\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1594\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0786\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0414\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.9890\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1659\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8268\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2042\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.9502\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8995\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9334\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0129\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8752\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9387\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0317\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.7910\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8092\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9220\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1590\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0821\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2251\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9251\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0504\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9903\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0906\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.1136\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1466\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9472\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8930\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.8839\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0037\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8639\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2974\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.9502\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0379\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.0838\n",
      "Epoch 90/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 120us/step - loss: 2.0838\n",
      "5/5 [==============================] - 0s 997us/step - loss: 3.3605\n",
      "loss :  3.360539674758911\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "=================\n",
      "[15.  26.6 45.4 20.8 34.9 21.9 28.7  7.2 20.  32.2 24.1 18.5 13.5 27.\n",
      " 23.1 18.9 24.5 43.1 19.8 13.8 15.6 50.  37.2 46.  50.  21.2 14.9 19.6\n",
      " 19.4 18.6 26.5 32.  10.9 20.  21.4 31.  25.  15.4 13.1 37.6 37.  18.9\n",
      " 27.9 50.  14.4 22.  19.9 21.6 15.6 15.  32.4 29.6 20.4 12.3 19.1 14.9\n",
      " 17.8  8.8 35.4 11.5 19.6 20.6 15.6 19.9 23.3 22.3 24.8 16.1 22.8 30.5\n",
      " 20.4 24.4 16.6 26.2 16.4 20.1 13.9 19.4 22.8 13.8 31.6 10.5 23.8 22.4\n",
      " 19.3 22.2 12.6 19.4 22.2 29.8  9.6 34.9 21.4 25.3 32.9 26.6 14.6 31.5\n",
      " 23.3 33.3 17.5 19.1 48.5 17.1 23.1 28.4 18.9 13.  17.2 24.1 18.5 21.8\n",
      " 13.3 23.  14.1 23.9 24.  17.2 21.5 19.1 20.8 36.  20.1  8.7 13.6 22.\n",
      " 22.2 21.1 13.4 17.4 20.1 10.2 23.1 10.2 13.1 14.3 14.5  7.2 19.6 20.6\n",
      " 22.7 26.4  7.5 20.3 50.   8.5 20.3 16.1 22.  19.6 10.2 23.2]\n",
      "[[12.004649 ]\n",
      " [23.30736  ]\n",
      " [51.3078   ]\n",
      " [19.148909 ]\n",
      " [26.809603 ]\n",
      " [55.201694 ]\n",
      " [36.182644 ]\n",
      " [ 8.946049 ]\n",
      " [16.084215 ]\n",
      " [23.89904  ]\n",
      " [31.368048 ]\n",
      " [21.23258  ]\n",
      " [15.664239 ]\n",
      " [36.396515 ]\n",
      " [21.553606 ]\n",
      " [19.706194 ]\n",
      " [22.704937 ]\n",
      " [39.357525 ]\n",
      " [19.68759  ]\n",
      " [14.570019 ]\n",
      " [15.471411 ]\n",
      " [24.006723 ]\n",
      " [41.265106 ]\n",
      " [51.315796 ]\n",
      " [53.584305 ]\n",
      " [24.013783 ]\n",
      " [19.30446  ]\n",
      " [22.479666 ]\n",
      " [23.89904  ]\n",
      " [15.440167 ]\n",
      " [22.613678 ]\n",
      " [37.052937 ]\n",
      " [12.496354 ]\n",
      " [21.173323 ]\n",
      " [21.572823 ]\n",
      " [32.277237 ]\n",
      " [25.65266  ]\n",
      " [14.6605425]\n",
      " [15.522788 ]\n",
      " [50.384853 ]\n",
      " [28.127337 ]\n",
      " [19.525114 ]\n",
      " [18.993149 ]\n",
      " [53.757343 ]\n",
      " [15.5761595]\n",
      " [23.89904  ]\n",
      " [22.63862  ]\n",
      " [23.89904  ]\n",
      " [18.818193 ]\n",
      " [20.052872 ]\n",
      " [37.578568 ]\n",
      " [21.283133 ]\n",
      " [22.518534 ]\n",
      " [13.313054 ]\n",
      " [20.840513 ]\n",
      " [15.5488   ]\n",
      " [15.571052 ]\n",
      " [ 8.529303 ]\n",
      " [34.00136  ]\n",
      " [13.905566 ]\n",
      " [19.227652 ]\n",
      " [21.258066 ]\n",
      " [16.401001 ]\n",
      " [21.570847 ]\n",
      " [23.89904  ]\n",
      " [23.89904  ]\n",
      " [23.89904  ]\n",
      " [28.509428 ]\n",
      " [25.526423 ]\n",
      " [31.442034 ]\n",
      " [19.729761 ]\n",
      " [23.89904  ]\n",
      " [19.167143 ]\n",
      " [24.668055 ]\n",
      " [19.582325 ]\n",
      " [21.221037 ]\n",
      " [14.107148 ]\n",
      " [20.995317 ]\n",
      " [25.948301 ]\n",
      " [ 8.665703 ]\n",
      " [30.410997 ]\n",
      " [13.547696 ]\n",
      " [23.89904  ]\n",
      " [21.309732 ]\n",
      " [16.517344 ]\n",
      " [26.021914 ]\n",
      " [15.779971 ]\n",
      " [21.5746   ]\n",
      " [22.574179 ]\n",
      " [36.010902 ]\n",
      " [13.374694 ]\n",
      " [36.41015  ]\n",
      " [22.269756 ]\n",
      " [26.178812 ]\n",
      " [26.720879 ]\n",
      " [31.521955 ]\n",
      " [14.799989 ]\n",
      " [48.133724 ]\n",
      " [22.538332 ]\n",
      " [38.124256 ]\n",
      " [21.792398 ]\n",
      " [14.563691 ]\n",
      " [50.66702  ]\n",
      " [14.586623 ]\n",
      " [20.990538 ]\n",
      " [23.294537 ]\n",
      " [18.887526 ]\n",
      " [15.026163 ]\n",
      " [19.622536 ]\n",
      " [23.89904  ]\n",
      " [21.161734 ]\n",
      " [24.160551 ]\n",
      " [15.478549 ]\n",
      " [20.183634 ]\n",
      " [14.271728 ]\n",
      " [30.108788 ]\n",
      " [34.416073 ]\n",
      " [11.939601 ]\n",
      " [19.582567 ]\n",
      " [21.070517 ]\n",
      " [21.238947 ]\n",
      " [34.6483   ]\n",
      " [19.517508 ]\n",
      " [ 9.569677 ]\n",
      " [15.432044 ]\n",
      " [22.7721   ]\n",
      " [21.124454 ]\n",
      " [23.89904  ]\n",
      " [15.552697 ]\n",
      " [22.940508 ]\n",
      " [19.75891  ]\n",
      " [13.70986  ]\n",
      " [15.602823 ]\n",
      " [ 8.665979 ]\n",
      " [16.268059 ]\n",
      " [15.800849 ]\n",
      " [19.297148 ]\n",
      " [14.066758 ]\n",
      " [19.460028 ]\n",
      " [21.516285 ]\n",
      " [20.19505  ]\n",
      " [21.525282 ]\n",
      " [10.968884 ]\n",
      " [21.573318 ]\n",
      " [54.977196 ]\n",
      " [14.197242 ]\n",
      " [22.439173 ]\n",
      " [21.303892 ]\n",
      " [23.270376 ]\n",
      " [19.30697  ]\n",
      " [13.997455 ]\n",
      " [21.281824 ]]\n",
      "=================\n",
      "R2 :  0.6529364629751442\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8714\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9960\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.7475\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9610\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8189\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0190\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.8694\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8821\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9015\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9190\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4205\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8086\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0417\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9288\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8570\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0279\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1179\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8446\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9738\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0710\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.7485\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0999\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0304\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.9391\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.7910\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8233\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8487\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9708\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8337\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3602\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9576\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8239\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0062\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0318\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0046\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.6653\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0213\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.9509\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8183\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8987\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8809\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.8169\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8805\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9870\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8813\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9871\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9606\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9335\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1033\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1649\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1483\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9957\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8206\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.7956\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.8409\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2481\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0526\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8544\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.7830\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1103\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8589\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0265\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9142\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.7878\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1380\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0153\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8119\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9586\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1312\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9624\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9032\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8729\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.7906\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8421\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8877\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.8125\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.7130\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9524\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8483\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9980\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1363\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.9652\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.7842\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8346\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.7519\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9079\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.7956\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9140\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9869\n",
      "Epoch 90/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 110us/step - loss: 1.9869\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.1662\n",
      "loss :  3.1661574840545654\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "=================\n",
      "[15.  26.6 45.4 20.8 34.9 21.9 28.7  7.2 20.  32.2 24.1 18.5 13.5 27.\n",
      " 23.1 18.9 24.5 43.1 19.8 13.8 15.6 50.  37.2 46.  50.  21.2 14.9 19.6\n",
      " 19.4 18.6 26.5 32.  10.9 20.  21.4 31.  25.  15.4 13.1 37.6 37.  18.9\n",
      " 27.9 50.  14.4 22.  19.9 21.6 15.6 15.  32.4 29.6 20.4 12.3 19.1 14.9\n",
      " 17.8  8.8 35.4 11.5 19.6 20.6 15.6 19.9 23.3 22.3 24.8 16.1 22.8 30.5\n",
      " 20.4 24.4 16.6 26.2 16.4 20.1 13.9 19.4 22.8 13.8 31.6 10.5 23.8 22.4\n",
      " 19.3 22.2 12.6 19.4 22.2 29.8  9.6 34.9 21.4 25.3 32.9 26.6 14.6 31.5\n",
      " 23.3 33.3 17.5 19.1 48.5 17.1 23.1 28.4 18.9 13.  17.2 24.1 18.5 21.8\n",
      " 13.3 23.  14.1 23.9 24.  17.2 21.5 19.1 20.8 36.  20.1  8.7 13.6 22.\n",
      " 22.2 21.1 13.4 17.4 20.1 10.2 23.1 10.2 13.1 14.3 14.5  7.2 19.6 20.6\n",
      " 22.7 26.4  7.5 20.3 50.   8.5 20.3 16.1 22.  19.6 10.2 23.2]\n",
      "[[12.734281 ]\n",
      " [31.138128 ]\n",
      " [50.143276 ]\n",
      " [17.392008 ]\n",
      " [24.700663 ]\n",
      " [52.36494  ]\n",
      " [40.62133  ]\n",
      " [ 9.489924 ]\n",
      " [14.82669  ]\n",
      " [22.99632  ]\n",
      " [20.737986 ]\n",
      " [20.496645 ]\n",
      " [14.376046 ]\n",
      " [39.70381  ]\n",
      " [21.697412 ]\n",
      " [18.716417 ]\n",
      " [21.915773 ]\n",
      " [36.978825 ]\n",
      " [18.733511 ]\n",
      " [13.615163 ]\n",
      " [15.643025 ]\n",
      " [24.556421 ]\n",
      " [47.074974 ]\n",
      " [50.31856  ]\n",
      " [50.912567 ]\n",
      " [23.01122  ]\n",
      " [18.614157 ]\n",
      " [21.693823 ]\n",
      " [22.99632  ]\n",
      " [14.709653 ]\n",
      " [22.99632  ]\n",
      " [34.63345  ]\n",
      " [12.559236 ]\n",
      " [20.42521  ]\n",
      " [20.546824 ]\n",
      " [29.778034 ]\n",
      " [24.508722 ]\n",
      " [13.906476 ]\n",
      " [14.638449 ]\n",
      " [49.82055  ]\n",
      " [28.179075 ]\n",
      " [18.414396 ]\n",
      " [17.39929  ]\n",
      " [50.98951  ]\n",
      " [14.430469 ]\n",
      " [22.99632  ]\n",
      " [22.99632  ]\n",
      " [22.99632  ]\n",
      " [18.505827 ]\n",
      " [17.914326 ]\n",
      " [35.35119  ]\n",
      " [20.446108 ]\n",
      " [21.882036 ]\n",
      " [12.08661  ]\n",
      " [18.651915 ]\n",
      " [15.151315 ]\n",
      " [14.332448 ]\n",
      " [ 7.3439765]\n",
      " [29.09072  ]\n",
      " [13.025741 ]\n",
      " [18.473837 ]\n",
      " [20.573679 ]\n",
      " [14.568336 ]\n",
      " [21.07519  ]\n",
      " [22.99632  ]\n",
      " [22.99632  ]\n",
      " [22.99632  ]\n",
      " [25.089075 ]\n",
      " [24.490782 ]\n",
      " [29.149254 ]\n",
      " [19.148134 ]\n",
      " [27.538023 ]\n",
      " [18.392805 ]\n",
      " [23.519474 ]\n",
      " [18.799044 ]\n",
      " [20.16361  ]\n",
      " [12.593751 ]\n",
      " [20.050993 ]\n",
      " [25.11442  ]\n",
      " [ 8.502303 ]\n",
      " [27.451216 ]\n",
      " [11.936707 ]\n",
      " [22.99632  ]\n",
      " [20.73148  ]\n",
      " [14.964299 ]\n",
      " [26.445883 ]\n",
      " [15.628364 ]\n",
      " [20.451862 ]\n",
      " [21.80432  ]\n",
      " [30.567091 ]\n",
      " [13.028728 ]\n",
      " [32.156277 ]\n",
      " [21.694632 ]\n",
      " [24.877748 ]\n",
      " [24.965689 ]\n",
      " [29.02307  ]\n",
      " [14.252329 ]\n",
      " [39.975105 ]\n",
      " [23.574724 ]\n",
      " [34.440937 ]\n",
      " [21.695177 ]\n",
      " [13.227632 ]\n",
      " [48.510353 ]\n",
      " [13.759745 ]\n",
      " [20.105661 ]\n",
      " [22.99632  ]\n",
      " [19.82208  ]\n",
      " [13.649707 ]\n",
      " [18.57493  ]\n",
      " [22.715464 ]\n",
      " [22.99632  ]\n",
      " [23.16794  ]\n",
      " [14.883456 ]\n",
      " [18.441463 ]\n",
      " [13.493107 ]\n",
      " [21.451366 ]\n",
      " [31.150951 ]\n",
      " [ 9.953284 ]\n",
      " [18.65898  ]\n",
      " [19.819681 ]\n",
      " [21.359793 ]\n",
      " [31.936525 ]\n",
      " [17.444155 ]\n",
      " [ 9.65681  ]\n",
      " [14.217319 ]\n",
      " [22.105906 ]\n",
      " [20.080961 ]\n",
      " [22.99632  ]\n",
      " [14.656168 ]\n",
      " [19.111015 ]\n",
      " [19.41219  ]\n",
      " [12.321483 ]\n",
      " [13.999764 ]\n",
      " [10.044679 ]\n",
      " [16.590574 ]\n",
      " [14.021449 ]\n",
      " [18.418898 ]\n",
      " [13.247843 ]\n",
      " [18.379732 ]\n",
      " [21.924974 ]\n",
      " [21.18137  ]\n",
      " [20.37298  ]\n",
      " [10.731219 ]\n",
      " [20.549936 ]\n",
      " [52.068836 ]\n",
      " [13.454904 ]\n",
      " [21.747229 ]\n",
      " [20.553886 ]\n",
      " [23.850325 ]\n",
      " [18.302103 ]\n",
      " [13.795829 ]\n",
      " [20.374296 ]]\n",
      "=================\n",
      "R2 :  0.6812680218765298\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0189\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3574\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.6860\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8284\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0268\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.9465\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8922\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1082\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0629\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.0494\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9454\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8532\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9019\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.0706\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.7298\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1382\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9492\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8547\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9507\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9004\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1721\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1207\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8020\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9927\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8921\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.6811\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8453\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9368\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0256\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0504\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1720\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0996\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9559\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9511\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9237\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9137\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.7863\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1134\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3879\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9805\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1249\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1229\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0136\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0404\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0084\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.7320\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9448\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.0509\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.8396\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1521\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1520\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.9577\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.7967\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.7962\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8215\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8157\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8397\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.0026\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1116\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2165\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9729\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9388\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.8417\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8822\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8100\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9416\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.0097\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0559\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8972\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9408\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0920\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.8239\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.7678\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9303\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9717\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.0445\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9730\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0314\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0569\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8944\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0672\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.9630\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9031\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8033\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.7475\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9374\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8776\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.8050\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8320\n",
      "Epoch 90/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 130us/step - loss: 1.8320\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.3505\n",
      "loss :  3.3505241870880127\n",
      "5/5 [==============================] - 0s 748us/step\n",
      "=================\n",
      "[15.  26.6 45.4 20.8 34.9 21.9 28.7  7.2 20.  32.2 24.1 18.5 13.5 27.\n",
      " 23.1 18.9 24.5 43.1 19.8 13.8 15.6 50.  37.2 46.  50.  21.2 14.9 19.6\n",
      " 19.4 18.6 26.5 32.  10.9 20.  21.4 31.  25.  15.4 13.1 37.6 37.  18.9\n",
      " 27.9 50.  14.4 22.  19.9 21.6 15.6 15.  32.4 29.6 20.4 12.3 19.1 14.9\n",
      " 17.8  8.8 35.4 11.5 19.6 20.6 15.6 19.9 23.3 22.3 24.8 16.1 22.8 30.5\n",
      " 20.4 24.4 16.6 26.2 16.4 20.1 13.9 19.4 22.8 13.8 31.6 10.5 23.8 22.4\n",
      " 19.3 22.2 12.6 19.4 22.2 29.8  9.6 34.9 21.4 25.3 32.9 26.6 14.6 31.5\n",
      " 23.3 33.3 17.5 19.1 48.5 17.1 23.1 28.4 18.9 13.  17.2 24.1 18.5 21.8\n",
      " 13.3 23.  14.1 23.9 24.  17.2 21.5 19.1 20.8 36.  20.1  8.7 13.6 22.\n",
      " 22.2 21.1 13.4 17.4 20.1 10.2 23.1 10.2 13.1 14.3 14.5  7.2 19.6 20.6\n",
      " 22.7 26.4  7.5 20.3 50.   8.5 20.3 16.1 22.  19.6 10.2 23.2]\n",
      "[[13.168237 ]\n",
      " [34.862026 ]\n",
      " [49.66333  ]\n",
      " [17.945982 ]\n",
      " [31.104643 ]\n",
      " [52.68787  ]\n",
      " [36.08523  ]\n",
      " [ 8.640158 ]\n",
      " [15.217858 ]\n",
      " [25.365185 ]\n",
      " [24.64489  ]\n",
      " [21.494738 ]\n",
      " [14.735742 ]\n",
      " [43.94869  ]\n",
      " [20.935108 ]\n",
      " [20.176517 ]\n",
      " [21.573446 ]\n",
      " [44.805866 ]\n",
      " [20.024755 ]\n",
      " [14.296723 ]\n",
      " [15.614739 ]\n",
      " [28.147295 ]\n",
      " [48.407375 ]\n",
      " [49.701046 ]\n",
      " [51.69439  ]\n",
      " [24.1363   ]\n",
      " [18.81054  ]\n",
      " [21.519789 ]\n",
      " [22.822495 ]\n",
      " [13.851029 ]\n",
      " [22.332159 ]\n",
      " [39.833393 ]\n",
      " [12.578046 ]\n",
      " [20.533298 ]\n",
      " [21.52434  ]\n",
      " [31.428444 ]\n",
      " [24.340164 ]\n",
      " [14.511733 ]\n",
      " [14.696887 ]\n",
      " [44.814434 ]\n",
      " [33.709614 ]\n",
      " [18.201324 ]\n",
      " [19.612873 ]\n",
      " [50.84408  ]\n",
      " [14.628774 ]\n",
      " [23.890026 ]\n",
      " [22.822495 ]\n",
      " [22.293852 ]\n",
      " [15.979505 ]\n",
      " [20.36212  ]\n",
      " [48.06783  ]\n",
      " [24.845104 ]\n",
      " [21.585258 ]\n",
      " [12.521662 ]\n",
      " [19.85886  ]\n",
      " [15.098203 ]\n",
      " [14.724708 ]\n",
      " [ 7.46521  ]\n",
      " [37.342136 ]\n",
      " [13.214722 ]\n",
      " [18.20172  ]\n",
      " [20.775507 ]\n",
      " [14.709806 ]\n",
      " [22.48239  ]\n",
      " [22.822495 ]\n",
      " [24.166435 ]\n",
      " [22.59507  ]\n",
      " [23.035513 ]\n",
      " [25.243559 ]\n",
      " [37.16975  ]\n",
      " [18.384453 ]\n",
      " [34.63432  ]\n",
      " [16.721088 ]\n",
      " [24.193056 ]\n",
      " [19.353153 ]\n",
      " [20.493788 ]\n",
      " [13.399955 ]\n",
      " [20.51488  ]\n",
      " [29.606258 ]\n",
      " [ 8.63727  ]\n",
      " [32.772484 ]\n",
      " [12.810303 ]\n",
      " [22.822495 ]\n",
      " [20.495134 ]\n",
      " [15.6688795]\n",
      " [26.645542 ]\n",
      " [16.499254 ]\n",
      " [22.486382 ]\n",
      " [21.518078 ]\n",
      " [36.116932 ]\n",
      " [13.27068  ]\n",
      " [38.0865   ]\n",
      " [21.276365 ]\n",
      " [25.754295 ]\n",
      " [31.427677 ]\n",
      " [29.757343 ]\n",
      " [14.672128 ]\n",
      " [43.75369  ]\n",
      " [32.33558  ]\n",
      " [47.817253 ]\n",
      " [21.496094 ]\n",
      " [14.098529 ]\n",
      " [46.557663 ]\n",
      " [14.378672 ]\n",
      " [20.462181 ]\n",
      " [25.944805 ]\n",
      " [18.03025  ]\n",
      " [14.464327 ]\n",
      " [18.396843 ]\n",
      " [22.822495 ]\n",
      " [21.526176 ]\n",
      " [24.146118 ]\n",
      " [14.777129 ]\n",
      " [19.532173 ]\n",
      " [13.647777 ]\n",
      " [24.198841 ]\n",
      " [36.07419  ]\n",
      " [12.681722 ]\n",
      " [18.384453 ]\n",
      " [20.392044 ]\n",
      " [24.17475  ]\n",
      " [30.623247 ]\n",
      " [18.502363 ]\n",
      " [ 8.780354 ]\n",
      " [14.691242 ]\n",
      " [22.19196  ]\n",
      " [21.491585 ]\n",
      " [24.889034 ]\n",
      " [14.726645 ]\n",
      " [23.468372 ]\n",
      " [20.550625 ]\n",
      " [12.525204 ]\n",
      " [23.871536 ]\n",
      " [ 8.380136 ]\n",
      " [13.853519 ]\n",
      " [18.45604  ]\n",
      " [18.384453 ]\n",
      " [13.516866 ]\n",
      " [18.855011 ]\n",
      " [23.182201 ]\n",
      " [19.691154 ]\n",
      " [28.733932 ]\n",
      " [ 9.924291 ]\n",
      " [21.519983 ]\n",
      " [52.47766  ]\n",
      " [13.833782 ]\n",
      " [21.505856 ]\n",
      " [20.276684 ]\n",
      " [27.179815 ]\n",
      " [18.324417 ]\n",
      " [14.068532 ]\n",
      " [21.529228 ]]\n",
      "=================\n",
      "R2 :  0.6565534715154449\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0567\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9135\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9033\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.8790\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.6488\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9690\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.8605\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.7756\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9379\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.8584\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1792\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1783\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.7394\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0112\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4081\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3333\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3361\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2409\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0671\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9060\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9884\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.0446\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8275\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0684\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9304\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.0515\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0228\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8833\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.8814\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.7825\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9943\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0485\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9988\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.8721\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8350\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.8768\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1147\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.8539\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8683\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9412\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9847\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.1549\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1199\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8911\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9804\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8683\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.7949\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.7389\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0191\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9604\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0190\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3383\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9038\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1721\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9510\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.7893\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9584\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.8922\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8996\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0201\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8405\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9665\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0370\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.1136\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8620\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8780\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9545\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.7285\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8578\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9482\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9735\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.9696\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.7410\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9518\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8316\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9362\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.9528\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.8166\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.7027\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.9300\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.8070\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.0980\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.3550\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9759\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9026\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9949\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8708\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8398\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0057\n",
      "Epoch 90/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 120us/step - loss: 2.0057\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.0304\n",
      "loss :  3.0303680896759033\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "=================\n",
      "[15.  26.6 45.4 20.8 34.9 21.9 28.7  7.2 20.  32.2 24.1 18.5 13.5 27.\n",
      " 23.1 18.9 24.5 43.1 19.8 13.8 15.6 50.  37.2 46.  50.  21.2 14.9 19.6\n",
      " 19.4 18.6 26.5 32.  10.9 20.  21.4 31.  25.  15.4 13.1 37.6 37.  18.9\n",
      " 27.9 50.  14.4 22.  19.9 21.6 15.6 15.  32.4 29.6 20.4 12.3 19.1 14.9\n",
      " 17.8  8.8 35.4 11.5 19.6 20.6 15.6 19.9 23.3 22.3 24.8 16.1 22.8 30.5\n",
      " 20.4 24.4 16.6 26.2 16.4 20.1 13.9 19.4 22.8 13.8 31.6 10.5 23.8 22.4\n",
      " 19.3 22.2 12.6 19.4 22.2 29.8  9.6 34.9 21.4 25.3 32.9 26.6 14.6 31.5\n",
      " 23.3 33.3 17.5 19.1 48.5 17.1 23.1 28.4 18.9 13.  17.2 24.1 18.5 21.8\n",
      " 13.3 23.  14.1 23.9 24.  17.2 21.5 19.1 20.8 36.  20.1  8.7 13.6 22.\n",
      " 22.2 21.1 13.4 17.4 20.1 10.2 23.1 10.2 13.1 14.3 14.5  7.2 19.6 20.6\n",
      " 22.7 26.4  7.5 20.3 50.   8.5 20.3 16.1 22.  19.6 10.2 23.2]\n",
      "[[13.185239 ]\n",
      " [22.057795 ]\n",
      " [48.126965 ]\n",
      " [14.589709 ]\n",
      " [24.240355 ]\n",
      " [52.143307 ]\n",
      " [31.602058 ]\n",
      " [ 7.4732904]\n",
      " [14.59138  ]\n",
      " [22.556894 ]\n",
      " [23.4684   ]\n",
      " [20.11221  ]\n",
      " [14.287814 ]\n",
      " [35.35973  ]\n",
      " [21.061884 ]\n",
      " [18.200851 ]\n",
      " [21.331709 ]\n",
      " [32.56519  ]\n",
      " [18.353643 ]\n",
      " [12.516013 ]\n",
      " [13.183808 ]\n",
      " [23.64541  ]\n",
      " [39.68963  ]\n",
      " [48.722637 ]\n",
      " [50.902294 ]\n",
      " [22.556894 ]\n",
      " [14.816125 ]\n",
      " [20.294851 ]\n",
      " [22.556894 ]\n",
      " [13.311363 ]\n",
      " [22.556892 ]\n",
      " [31.577353 ]\n",
      " [13.527974 ]\n",
      " [18.408964 ]\n",
      " [20.30374  ]\n",
      " [31.378328 ]\n",
      " [23.76319  ]\n",
      " [12.345199 ]\n",
      " [14.404199 ]\n",
      " [45.665943 ]\n",
      " [27.739138 ]\n",
      " [17.396223 ]\n",
      " [14.474866 ]\n",
      " [50.38148  ]\n",
      " [14.151971 ]\n",
      " [22.556894 ]\n",
      " [21.311136 ]\n",
      " [21.312109 ]\n",
      " [14.622209 ]\n",
      " [14.5645075]\n",
      " [31.90552  ]\n",
      " [20.165117 ]\n",
      " [20.487207 ]\n",
      " [10.329165 ]\n",
      " [18.443754 ]\n",
      " [13.396763 ]\n",
      " [14.399949 ]\n",
      " [ 7.466275 ]\n",
      " [31.944344 ]\n",
      " [11.352106 ]\n",
      " [18.876614 ]\n",
      " [18.568869 ]\n",
      " [13.966275 ]\n",
      " [20.305243 ]\n",
      " [22.556894 ]\n",
      " [22.556894 ]\n",
      " [22.556894 ]\n",
      " [13.559209 ]\n",
      " [23.82392  ]\n",
      " [28.478458 ]\n",
      " [18.921104 ]\n",
      " [21.95503  ]\n",
      " [15.470933 ]\n",
      " [23.38418  ]\n",
      " [15.00128  ]\n",
      " [19.81497  ]\n",
      " [11.810129 ]\n",
      " [20.183725 ]\n",
      " [21.852377 ]\n",
      " [ 7.459424 ]\n",
      " [25.521662 ]\n",
      " [10.776385 ]\n",
      " [22.556894 ]\n",
      " [19.969683 ]\n",
      " [14.821647 ]\n",
      " [24.165277 ]\n",
      " [12.764232 ]\n",
      " [20.256842 ]\n",
      " [21.31481  ]\n",
      " [32.722656 ]\n",
      " [13.713033 ]\n",
      " [30.79419  ]\n",
      " [20.922808 ]\n",
      " [24.02413  ]\n",
      " [24.372915 ]\n",
      " [27.768328 ]\n",
      " [12.55335  ]\n",
      " [42.10333  ]\n",
      " [20.297754 ]\n",
      " [33.258205 ]\n",
      " [20.155256 ]\n",
      " [12.536326 ]\n",
      " [45.000275 ]\n",
      " [12.294552 ]\n",
      " [18.529486 ]\n",
      " [22.07559  ]\n",
      " [14.416499 ]\n",
      " [13.178845 ]\n",
      " [18.587234 ]\n",
      " [21.515894 ]\n",
      " [21.160948 ]\n",
      " [22.556894 ]\n",
      " [14.301982 ]\n",
      " [18.906843 ]\n",
      " [13.48528  ]\n",
      " [21.718859 ]\n",
      " [28.442457 ]\n",
      " [ 8.99502  ]\n",
      " [18.714983 ]\n",
      " [18.074606 ]\n",
      " [18.613344 ]\n",
      " [32.194836 ]\n",
      " [16.989119 ]\n",
      " [ 7.4688277]\n",
      " [14.326028 ]\n",
      " [21.401068 ]\n",
      " [18.582193 ]\n",
      " [22.556892 ]\n",
      " [14.470159 ]\n",
      " [17.057182 ]\n",
      " [18.503382 ]\n",
      " [11.172166 ]\n",
      " [12.698858 ]\n",
      " [ 7.618286 ]\n",
      " [12.766282 ]\n",
      " [13.111207 ]\n",
      " [18.224245 ]\n",
      " [11.699878 ]\n",
      " [18.18247  ]\n",
      " [21.330736 ]\n",
      " [18.551645 ]\n",
      " [19.74895  ]\n",
      " [13.090062 ]\n",
      " [20.325037 ]\n",
      " [51.7288   ]\n",
      " [11.777131 ]\n",
      " [21.318066 ]\n",
      " [19.939701 ]\n",
      " [22.036901 ]\n",
      " [18.18632  ]\n",
      " [14.278088 ]\n",
      " [19.949144 ]]\n",
      "=================\n",
      "R2 :  0.6951364497945371\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.8741\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1894\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0471\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9453\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.6793\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2030\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.9004\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8478\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8697\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.7464\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.8269\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8698\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8456\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.8418\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.0480\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.0402\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.1083\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8733\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9141\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.8975\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9165\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0400\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3524\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.8920\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.0031\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0032\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9583\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8603\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.8922\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1236\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9151\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.6991\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3033\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8761\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.9191\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.7623\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.7040\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8084\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0029\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.7387\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8072\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0634\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8949\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8880\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0583\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.8300\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8733\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.7325\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.0342\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8238\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9676\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.9082\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8481\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1090\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.9106\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.7873\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4346\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1039\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8997\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.8932\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8839\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8666\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.0682\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8961\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0000\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.7565\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8188\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0289\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.7408\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9982\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9598\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9786\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9040\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.2448\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.9318\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1311\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.1053\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1948\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7053\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3461\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1019\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8357\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9354\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1454\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8527\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0269\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.9287\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8341\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8416\n",
      "Epoch 90/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 118us/step - loss: 1.8416\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.7401\n",
      "loss :  2.7401328086853027\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "=================\n",
      "[15.  26.6 45.4 20.8 34.9 21.9 28.7  7.2 20.  32.2 24.1 18.5 13.5 27.\n",
      " 23.1 18.9 24.5 43.1 19.8 13.8 15.6 50.  37.2 46.  50.  21.2 14.9 19.6\n",
      " 19.4 18.6 26.5 32.  10.9 20.  21.4 31.  25.  15.4 13.1 37.6 37.  18.9\n",
      " 27.9 50.  14.4 22.  19.9 21.6 15.6 15.  32.4 29.6 20.4 12.3 19.1 14.9\n",
      " 17.8  8.8 35.4 11.5 19.6 20.6 15.6 19.9 23.3 22.3 24.8 16.1 22.8 30.5\n",
      " 20.4 24.4 16.6 26.2 16.4 20.1 13.9 19.4 22.8 13.8 31.6 10.5 23.8 22.4\n",
      " 19.3 22.2 12.6 19.4 22.2 29.8  9.6 34.9 21.4 25.3 32.9 26.6 14.6 31.5\n",
      " 23.3 33.3 17.5 19.1 48.5 17.1 23.1 28.4 18.9 13.  17.2 24.1 18.5 21.8\n",
      " 13.3 23.  14.1 23.9 24.  17.2 21.5 19.1 20.8 36.  20.1  8.7 13.6 22.\n",
      " 22.2 21.1 13.4 17.4 20.1 10.2 23.1 10.2 13.1 14.3 14.5  7.2 19.6 20.6\n",
      " 22.7 26.4  7.5 20.3 50.   8.5 20.3 16.1 22.  19.6 10.2 23.2]\n",
      "[[11.864028]\n",
      " [28.615894]\n",
      " [47.696674]\n",
      " [16.9815  ]\n",
      " [28.054798]\n",
      " [49.167027]\n",
      " [31.011417]\n",
      " [ 9.776943]\n",
      " [15.037548]\n",
      " [23.543777]\n",
      " [22.116533]\n",
      " [19.831274]\n",
      " [14.333458]\n",
      " [38.96881 ]\n",
      " [20.933056]\n",
      " [19.560509]\n",
      " [20.888157]\n",
      " [35.078953]\n",
      " [17.712694]\n",
      " [12.704202]\n",
      " [14.297564]\n",
      " [23.805038]\n",
      " [36.928673]\n",
      " [47.672848]\n",
      " [48.526817]\n",
      " [22.116533]\n",
      " [17.79119 ]\n",
      " [20.865082]\n",
      " [22.116533]\n",
      " [18.892784]\n",
      " [21.501598]\n",
      " [32.300133]\n",
      " [12.478321]\n",
      " [19.638298]\n",
      " [19.870548]\n",
      " [29.780685]\n",
      " [22.929409]\n",
      " [12.820644]\n",
      " [14.332177]\n",
      " [47.370285]\n",
      " [32.447212]\n",
      " [17.694584]\n",
      " [17.394123]\n",
      " [48.263924]\n",
      " [14.187179]\n",
      " [22.116533]\n",
      " [20.888836]\n",
      " [22.116533]\n",
      " [16.924496]\n",
      " [18.794529]\n",
      " [32.46266 ]\n",
      " [25.082428]\n",
      " [20.88743 ]\n",
      " [10.37121 ]\n",
      " [17.34779 ]\n",
      " [14.34664 ]\n",
      " [14.080841]\n",
      " [ 8.0259  ]\n",
      " [31.022102]\n",
      " [11.393879]\n",
      " [17.835938]\n",
      " [19.692247]\n",
      " [14.920296]\n",
      " [20.98336 ]\n",
      " [22.116533]\n",
      " [22.116533]\n",
      " [22.116533]\n",
      " [14.933399]\n",
      " [23.167545]\n",
      " [33.486847]\n",
      " [17.713886]\n",
      " [28.296682]\n",
      " [17.558388]\n",
      " [22.961563]\n",
      " [17.298248]\n",
      " [19.736515]\n",
      " [11.808331]\n",
      " [19.786486]\n",
      " [23.53001 ]\n",
      " [12.775609]\n",
      " [24.952429]\n",
      " [10.970932]\n",
      " [22.116533]\n",
      " [19.909433]\n",
      " [15.528472]\n",
      " [23.167603]\n",
      " [14.467996]\n",
      " [22.116533]\n",
      " [20.888836]\n",
      " [34.60643 ]\n",
      " [13.089265]\n",
      " [38.12126 ]\n",
      " [20.073029]\n",
      " [23.168758]\n",
      " [28.151045]\n",
      " [26.765928]\n",
      " [13.03132 ]\n",
      " [41.521057]\n",
      " [23.73655 ]\n",
      " [33.7835  ]\n",
      " [20.874386]\n",
      " [12.571642]\n",
      " [44.139122]\n",
      " [12.650017]\n",
      " [19.41974 ]\n",
      " [22.440742]\n",
      " [17.992996]\n",
      " [13.017543]\n",
      " [17.636784]\n",
      " [22.116533]\n",
      " [20.888836]\n",
      " [22.116533]\n",
      " [14.732857]\n",
      " [17.335272]\n",
      " [13.515442]\n",
      " [22.116533]\n",
      " [29.146637]\n",
      " [10.067409]\n",
      " [17.569695]\n",
      " [19.55619 ]\n",
      " [22.116533]\n",
      " [31.187475]\n",
      " [19.744457]\n",
      " [10.682184]\n",
      " [14.347952]\n",
      " [20.888836]\n",
      " [20.846058]\n",
      " [22.116531]\n",
      " [14.459607]\n",
      " [17.358948]\n",
      " [19.540642]\n",
      " [11.238196]\n",
      " [13.578422]\n",
      " [ 8.527851]\n",
      " [14.210648]\n",
      " [13.636614]\n",
      " [17.679794]\n",
      " [11.902556]\n",
      " [17.649815]\n",
      " [20.8795  ]\n",
      " [18.049707]\n",
      " [27.71871 ]\n",
      " [11.912277]\n",
      " [19.872616]\n",
      " [48.97512 ]\n",
      " [11.958228]\n",
      " [20.218838]\n",
      " [19.9056  ]\n",
      " [23.156525]\n",
      " [17.80907 ]\n",
      " [13.490938]\n",
      " [20.249697]]\n",
      "=================\n",
      "R2 :  0.7470138574396744\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8429\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.9013\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.7015\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4334\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9203\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9124\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8766\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0565\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.1243\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9121\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9603\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.1085\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0205\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8366\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.9869\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9885\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.7615\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9739\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1167\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2971\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.9183\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9213\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9956\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.7106\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.9369\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8731\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9603\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8616\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.8725\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.7628\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.8966\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9400\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.7918\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.0273\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8801\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9531\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.7246\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.8732\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8625\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1786\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.8168\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9651\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9068\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0299\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.9619\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8065\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8746\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.0940\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.7556\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.7775\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.9088\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9138\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.6344\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.0480\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2338\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.0854\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.7875\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.7462\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.8053\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0714\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.7779\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8791\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.9681\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8875\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9864\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9646\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.9096\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.8358\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.7759\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8559\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.6409\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.8802\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8314\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.6387\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.9615\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8375\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8164\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8160\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.7999\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9070\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.7355\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9187\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.9743\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.7321\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.7529\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.6349\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.8264\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0496\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8069\n",
      "Epoch 90/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 130us/step - loss: 1.8069\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.2952\n",
      "loss :  3.2951536178588867\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "=================\n",
      "[15.  26.6 45.4 20.8 34.9 21.9 28.7  7.2 20.  32.2 24.1 18.5 13.5 27.\n",
      " 23.1 18.9 24.5 43.1 19.8 13.8 15.6 50.  37.2 46.  50.  21.2 14.9 19.6\n",
      " 19.4 18.6 26.5 32.  10.9 20.  21.4 31.  25.  15.4 13.1 37.6 37.  18.9\n",
      " 27.9 50.  14.4 22.  19.9 21.6 15.6 15.  32.4 29.6 20.4 12.3 19.1 14.9\n",
      " 17.8  8.8 35.4 11.5 19.6 20.6 15.6 19.9 23.3 22.3 24.8 16.1 22.8 30.5\n",
      " 20.4 24.4 16.6 26.2 16.4 20.1 13.9 19.4 22.8 13.8 31.6 10.5 23.8 22.4\n",
      " 19.3 22.2 12.6 19.4 22.2 29.8  9.6 34.9 21.4 25.3 32.9 26.6 14.6 31.5\n",
      " 23.3 33.3 17.5 19.1 48.5 17.1 23.1 28.4 18.9 13.  17.2 24.1 18.5 21.8\n",
      " 13.3 23.  14.1 23.9 24.  17.2 21.5 19.1 20.8 36.  20.1  8.7 13.6 22.\n",
      " 22.2 21.1 13.4 17.4 20.1 10.2 23.1 10.2 13.1 14.3 14.5  7.2 19.6 20.6\n",
      " 22.7 26.4  7.5 20.3 50.   8.5 20.3 16.1 22.  19.6 10.2 23.2]\n",
      "[[12.5813055]\n",
      " [33.651836 ]\n",
      " [50.885258 ]\n",
      " [18.264618 ]\n",
      " [27.517097 ]\n",
      " [51.797104 ]\n",
      " [36.669067 ]\n",
      " [ 9.55745  ]\n",
      " [14.633689 ]\n",
      " [25.802975 ]\n",
      " [24.532925 ]\n",
      " [20.07698  ]\n",
      " [14.137645 ]\n",
      " [42.939552 ]\n",
      " [21.834349 ]\n",
      " [21.103159 ]\n",
      " [22.99689  ]\n",
      " [43.32025  ]\n",
      " [18.817749 ]\n",
      " [13.501096 ]\n",
      " [12.168931 ]\n",
      " [25.146025 ]\n",
      " [42.49596  ]\n",
      " [50.87972  ]\n",
      " [51.10155  ]\n",
      " [23.347677 ]\n",
      " [18.659718 ]\n",
      " [22.99689  ]\n",
      " [23.125431 ]\n",
      " [23.759655 ]\n",
      " [23.648169 ]\n",
      " [35.73601  ]\n",
      " [12.604064 ]\n",
      " [21.67466  ]\n",
      " [20.671112 ]\n",
      " [31.725103 ]\n",
      " [24.657448 ]\n",
      " [13.766642 ]\n",
      " [14.215695 ]\n",
      " [50.312893 ]\n",
      " [36.040768 ]\n",
      " [18.601902 ]\n",
      " [20.289558 ]\n",
      " [51.464283 ]\n",
      " [14.14681  ]\n",
      " [22.99689  ]\n",
      " [22.99689  ]\n",
      " [22.99689  ]\n",
      " [18.274055 ]\n",
      " [20.68044  ]\n",
      " [41.470882 ]\n",
      " [28.914976 ]\n",
      " [22.99689  ]\n",
      " [11.352074 ]\n",
      " [18.096529 ]\n",
      " [14.736047 ]\n",
      " [13.908888 ]\n",
      " [ 7.364711 ]\n",
      " [35.013912 ]\n",
      " [12.660005 ]\n",
      " [18.366852 ]\n",
      " [21.49339  ]\n",
      " [24.466908 ]\n",
      " [21.685856 ]\n",
      " [22.991917 ]\n",
      " [22.99689  ]\n",
      " [25.603724 ]\n",
      " [13.888846 ]\n",
      " [24.936836 ]\n",
      " [38.777775 ]\n",
      " [18.438473 ]\n",
      " [33.25817  ]\n",
      " [18.263313 ]\n",
      " [24.479486 ]\n",
      " [19.268951 ]\n",
      " [19.230839 ]\n",
      " [12.630374 ]\n",
      " [21.155834 ]\n",
      " [29.292742 ]\n",
      " [ 7.269354 ]\n",
      " [31.012356 ]\n",
      " [11.717757 ]\n",
      " [23.177317 ]\n",
      " [21.694214 ]\n",
      " [14.989739 ]\n",
      " [26.647213 ]\n",
      " [17.298021 ]\n",
      " [22.99689  ]\n",
      " [22.99689  ]\n",
      " [38.901134 ]\n",
      " [13.217475 ]\n",
      " [42.41882  ]\n",
      " [21.69582  ]\n",
      " [26.852522 ]\n",
      " [30.149889 ]\n",
      " [29.614433 ]\n",
      " [14.191957 ]\n",
      " [46.13373  ]\n",
      " [26.291866 ]\n",
      " [37.676334 ]\n",
      " [21.738777 ]\n",
      " [13.302848 ]\n",
      " [50.421036 ]\n",
      " [13.745942 ]\n",
      " [20.754505 ]\n",
      " [24.889355 ]\n",
      " [18.112457 ]\n",
      " [13.649123 ]\n",
      " [18.261372 ]\n",
      " [22.99689  ]\n",
      " [22.99689  ]\n",
      " [23.48331  ]\n",
      " [14.998323 ]\n",
      " [17.836834 ]\n",
      " [13.882691 ]\n",
      " [23.869976 ]\n",
      " [34.81533  ]\n",
      " [ 9.556369 ]\n",
      " [19.793125 ]\n",
      " [18.707165 ]\n",
      " [23.481771 ]\n",
      " [34.46131  ]\n",
      " [20.108742 ]\n",
      " [10.014304 ]\n",
      " [14.10769  ]\n",
      " [22.17728  ]\n",
      " [21.841263 ]\n",
      " [22.449345 ]\n",
      " [14.525824 ]\n",
      " [18.02361  ]\n",
      " [21.07133  ]\n",
      " [12.246585 ]\n",
      " [13.608068 ]\n",
      " [ 7.269354 ]\n",
      " [19.336086 ]\n",
      " [14.263803 ]\n",
      " [18.143421 ]\n",
      " [13.010656 ]\n",
      " [18.157112 ]\n",
      " [22.99689  ]\n",
      " [20.748148 ]\n",
      " [30.038668 ]\n",
      " [10.297327 ]\n",
      " [20.6748   ]\n",
      " [51.694897 ]\n",
      " [13.221009 ]\n",
      " [21.682037 ]\n",
      " [21.811008 ]\n",
      " [24.598663 ]\n",
      " [18.19128  ]\n",
      " [13.885766 ]\n",
      " [20.726906 ]]\n",
      "=================\n",
      "R2 :  0.6660735777637566\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.7781\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.0131\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.6502\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.9490\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.0713\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9637\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0779\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0910\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8878\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.9458\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.7789\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.7129\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.7463\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8264\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.6725\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.7675\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.7254\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.7055\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8731\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.7172\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.8753\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.0168\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8296\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.8590\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.2578\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9989\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.9310\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9922\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9044\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.7949\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1343\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.9592\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.7597\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.8216\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9400\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.8764\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.7524\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.6052\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.7466\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.7066\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.6588\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8661\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.7001\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.7984\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.6960\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.7881\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8578\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.8825\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8452\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.7784\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.7853\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9261\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.6824\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.7007\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.1263\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.6937\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8745\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0988\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.7710\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1046\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8508\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9398\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.6443\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9179\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8772\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8397\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.6892\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8578\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.8169\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9818\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8707\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.6867\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.6689\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8266\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.7366\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.7364\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.5708\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.7941\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0531\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8519\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.8887\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.7362\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.8256\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.6703\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8055\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.9022\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.7677\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.8558\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.0187\n",
      "Epoch 90/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 140us/step - loss: 2.0187\n",
      "5/5 [==============================] - 0s 997us/step - loss: 3.0364\n",
      "loss :  3.036395311355591\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "=================\n",
      "[15.  26.6 45.4 20.8 34.9 21.9 28.7  7.2 20.  32.2 24.1 18.5 13.5 27.\n",
      " 23.1 18.9 24.5 43.1 19.8 13.8 15.6 50.  37.2 46.  50.  21.2 14.9 19.6\n",
      " 19.4 18.6 26.5 32.  10.9 20.  21.4 31.  25.  15.4 13.1 37.6 37.  18.9\n",
      " 27.9 50.  14.4 22.  19.9 21.6 15.6 15.  32.4 29.6 20.4 12.3 19.1 14.9\n",
      " 17.8  8.8 35.4 11.5 19.6 20.6 15.6 19.9 23.3 22.3 24.8 16.1 22.8 30.5\n",
      " 20.4 24.4 16.6 26.2 16.4 20.1 13.9 19.4 22.8 13.8 31.6 10.5 23.8 22.4\n",
      " 19.3 22.2 12.6 19.4 22.2 29.8  9.6 34.9 21.4 25.3 32.9 26.6 14.6 31.5\n",
      " 23.3 33.3 17.5 19.1 48.5 17.1 23.1 28.4 18.9 13.  17.2 24.1 18.5 21.8\n",
      " 13.3 23.  14.1 23.9 24.  17.2 21.5 19.1 20.8 36.  20.1  8.7 13.6 22.\n",
      " 22.2 21.1 13.4 17.4 20.1 10.2 23.1 10.2 13.1 14.3 14.5  7.2 19.6 20.6\n",
      " 22.7 26.4  7.5 20.3 50.   8.5 20.3 16.1 22.  19.6 10.2 23.2]\n",
      "[[12.456381 ]\n",
      " [32.37603  ]\n",
      " [48.888382 ]\n",
      " [16.22365  ]\n",
      " [24.175447 ]\n",
      " [49.55495  ]\n",
      " [33.81457  ]\n",
      " [10.373963 ]\n",
      " [14.838802 ]\n",
      " [23.843384 ]\n",
      " [23.924063 ]\n",
      " [20.256655 ]\n",
      " [13.900236 ]\n",
      " [34.263798 ]\n",
      " [20.954737 ]\n",
      " [18.012867 ]\n",
      " [22.221395 ]\n",
      " [33.75249  ]\n",
      " [18.095465 ]\n",
      " [12.641467 ]\n",
      " [13.095774 ]\n",
      " [24.203737 ]\n",
      " [40.867397 ]\n",
      " [48.957256 ]\n",
      " [49.164173 ]\n",
      " [23.886906 ]\n",
      " [17.325384 ]\n",
      " [20.800734 ]\n",
      " [22.452047 ]\n",
      " [15.364655 ]\n",
      " [22.221395 ]\n",
      " [35.051    ]\n",
      " [10.910984 ]\n",
      " [19.817118 ]\n",
      " [19.758553 ]\n",
      " [30.386873 ]\n",
      " [23.998291 ]\n",
      " [12.923977 ]\n",
      " [14.097982 ]\n",
      " [48.639282 ]\n",
      " [28.760183 ]\n",
      " [16.68284  ]\n",
      " [18.51446  ]\n",
      " [49.086914 ]\n",
      " [14.343021 ]\n",
      " [22.221395 ]\n",
      " [22.221395 ]\n",
      " [22.10251  ]\n",
      " [14.935417 ]\n",
      " [17.994606 ]\n",
      " [35.185925 ]\n",
      " [23.802998 ]\n",
      " [22.221395 ]\n",
      " [11.04755  ]\n",
      " [18.152128 ]\n",
      " [13.449422 ]\n",
      " [14.123263 ]\n",
      " [ 7.0827794]\n",
      " [30.819082 ]\n",
      " [11.81056  ]\n",
      " [18.56526  ]\n",
      " [19.821875 ]\n",
      " [18.252085 ]\n",
      " [22.221395 ]\n",
      " [22.516985 ]\n",
      " [22.221395 ]\n",
      " [24.018248 ]\n",
      " [13.637863 ]\n",
      " [24.149849 ]\n",
      " [29.62697  ]\n",
      " [18.618258 ]\n",
      " [31.571505 ]\n",
      " [15.199501 ]\n",
      " [23.928682 ]\n",
      " [17.00045  ]\n",
      " [18.728134 ]\n",
      " [12.0343275]\n",
      " [19.92605  ]\n",
      " [24.23447  ]\n",
      " [ 9.760471 ]\n",
      " [25.036444 ]\n",
      " [11.184185 ]\n",
      " [22.221395 ]\n",
      " [20.79667  ]\n",
      " [15.252701 ]\n",
      " [26.39298  ]\n",
      " [14.669583 ]\n",
      " [20.785152 ]\n",
      " [22.221395 ]\n",
      " [33.434284 ]\n",
      " [13.363306 ]\n",
      " [32.700108 ]\n",
      " [20.39435  ]\n",
      " [24.30601  ]\n",
      " [24.318594 ]\n",
      " [28.984308 ]\n",
      " [13.092361 ]\n",
      " [47.436443 ]\n",
      " [23.877481 ]\n",
      " [36.731937 ]\n",
      " [20.795683 ]\n",
      " [12.468771 ]\n",
      " [48.411095 ]\n",
      " [12.891834 ]\n",
      " [19.909502 ]\n",
      " [23.82163  ]\n",
      " [18.714376 ]\n",
      " [12.790092 ]\n",
      " [18.188488 ]\n",
      " [22.221395 ]\n",
      " [22.221395 ]\n",
      " [23.88703  ]\n",
      " [14.065174 ]\n",
      " [18.429993 ]\n",
      " [13.778078 ]\n",
      " [22.221395 ]\n",
      " [29.944605 ]\n",
      " [10.127226 ]\n",
      " [18.292147 ]\n",
      " [18.50458  ]\n",
      " [22.221395 ]\n",
      " [30.549187 ]\n",
      " [17.80126  ]\n",
      " [11.244198 ]\n",
      " [13.953341 ]\n",
      " [20.990417 ]\n",
      " [19.633532 ]\n",
      " [23.20008  ]\n",
      " [14.336572 ]\n",
      " [17.69813  ]\n",
      " [19.667898 ]\n",
      " [11.340343 ]\n",
      " [12.158571 ]\n",
      " [10.049793 ]\n",
      " [15.089373 ]\n",
      " [13.730957 ]\n",
      " [18.32688  ]\n",
      " [12.145362 ]\n",
      " [18.116796 ]\n",
      " [22.948816 ]\n",
      " [20.76792  ]\n",
      " [24.92792  ]\n",
      " [12.354603 ]\n",
      " [19.769796 ]\n",
      " [49.480076 ]\n",
      " [12.365595 ]\n",
      " [20.826494 ]\n",
      " [20.518106 ]\n",
      " [23.835316 ]\n",
      " [17.961275 ]\n",
      " [13.741587 ]\n",
      " [19.769842 ]]\n",
      "=================\n",
      "R2 :  0.7111592301612097\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8232\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.6293\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.7849\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.8272\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.7668\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.8283\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.6213\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.8436\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.7116\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.8348\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.8735\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.7580\n",
      "Epoch 13/100\n",
      " 41/100 [===========>..................] - ETA: 0s - loss: 1.6908"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12108\\4110350679.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"loss : \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\bitcamp\\anaconda3\\envs\\tf27\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\bitcamp\\anaconda3\\envs\\tf27\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1553\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_load_initial_step_from_ckpt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1554\u001b[0m                     )\n\u001b[1;32m-> 1555\u001b[1;33m                     \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1556\u001b[0m                         with tf.profiler.experimental.Trace(\n\u001b[0;32m   1557\u001b[0m                             \u001b[1;34m\"train\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\bitcamp\\anaconda3\\envs\\tf27\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36msteps\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1372\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1373\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1374\u001b[1;33m             \u001b[0moriginal_spe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_steps_per_execution\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1375\u001b[0m             can_run_full_execution = (\n\u001b[0;32m   1376\u001b[0m                 \u001b[0moriginal_spe\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\bitcamp\\anaconda3\\envs\\tf27\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    635\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 637\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    638\u001b[0m     raise NotImplementedError(\n\u001b[0;32m    639\u001b[0m         \"numpy() is only available when eager execution is enabled.\")\n",
      "\u001b[1;32mc:\\Users\\bitcamp\\anaconda3\\envs\\tf27\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36mread_value\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    723\u001b[0m     \"\"\"\n\u001b[0;32m    724\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Read\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 725\u001b[1;33m       \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_variable_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    726\u001b[0m     \u001b[1;31m# Return an identity so it can get placed on whatever device the context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m     \u001b[1;31m# specifies instead of the device where the variable is.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\bitcamp\\anaconda3\\envs\\tf27\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36m_read_variable_op\u001b[1;34m(self, no_copy)\u001b[0m\n\u001b[0;32m    702\u001b[0m           \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_and_set_handle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mno_copy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    703\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 704\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_and_set_handle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mno_copy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    705\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\bitcamp\\anaconda3\\envs\\tf27\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36mread_and_set_handle\u001b[1;34m(no_copy)\u001b[0m\n\u001b[0;32m    692\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mno_copy\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mforward_compat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_compatible\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2022\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    693\u001b[0m         \u001b[0mgen_resource_variable_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisable_copy_on_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 694\u001b[1;33m       result = gen_resource_variable_ops.read_variable_op(\n\u001b[0m\u001b[0;32m    695\u001b[0m           self.handle, self._dtype)\n\u001b[0;32m    696\u001b[0m       \u001b[0m_maybe_set_handle_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\bitcamp\\anaconda3\\envs\\tf27\\lib\\site-packages\\tensorflow\\python\\ops\\gen_resource_variable_ops.py\u001b[0m in \u001b[0;36mread_variable_op\u001b[1;34m(resource, dtype, name)\u001b[0m\n\u001b[0;32m    522\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 524\u001b[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[0;32m    525\u001b[0m         _ctx, \"ReadVariableOp\", name, resource, \"dtype\", dtype)\n\u001b[0;32m    526\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from sklearn.metrics import r2_score\n",
    "now = datetime.now()\n",
    "\n",
    "model.compile(loss=\"mae\",optimizer=\"adam\")\n",
    "f = open(\"C:\\study\\keras\\\\boston.txt\",'a')\n",
    "while (True):\n",
    "    model.fit(x_train,y_train,epochs=100,batch_size=4,steps_per_epoch=100)\n",
    "    loss = model.evaluate(x_test,y_test)\n",
    "    print(\"loss : \",loss)\n",
    "    y_predict =model.predict(x_test)\n",
    "    print(\"=================\")\n",
    "    print(y_test)\n",
    "    print(y_predict)\n",
    "    print(\"=================\")\n",
    "    r2 = r2_score(y_test,y_predict)\n",
    "    print(\"R2 : \",r2)\n",
    "\n",
    "    f.write(str(r2)+\"\\n\") \n",
    "    \n",
    "    if r2 >= 0.8 :\n",
    "        f.write(now+str(r2)+\"\\n\") \n",
    "        model.save(\"boston.h5\")\n",
    "        f.cloes()\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf27",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b47fb4e6c68d4941015efb0bbf71549277582fe8531338196fc3c7fa71b6aab8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
