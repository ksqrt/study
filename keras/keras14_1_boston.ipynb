{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.3\n",
      "2.10.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bitcamp\\anaconda3\\envs\\tf27\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn as sk\n",
    "print(sk.__version__)\n",
    "print(tf.__version__)\n",
    "dataset = load_boston()\n",
    "x = dataset.data\n",
    "y = dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13)\n",
      "(506,)\n"
     ]
    }
   ],
   "source": [
    "# 13개의 칼럼 을 가지고있는 데이터를 조회합니다\n",
    "print(x.shape) #(506,13)\n",
    "# print(x)\n",
    "print(y.shape) #(506,)\n",
    "# print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CRIM' 'ZN' 'INDUS' 'CHAS' 'NOX' 'RM' 'AGE' 'DIS' 'RAD' 'TAX' 'PTRATIO'\n",
      " 'B' 'LSTAT']\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "# 사이킥 런의 칼럼 조회기능\n",
    "print(dataset.feature_names)\n",
    "print(len(dataset.feature_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _boston_dataset:\n",
      "\n",
      "Boston house prices dataset\n",
      "---------------------------\n",
      "\n",
      "**Data Set Characteristics:**  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of black people by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      ".. topic:: References\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 사이킥런의 데이터 요약\n",
    "print(dataset.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354\n",
      "152\n"
     ]
    }
   ],
   "source": [
    "# 3. 모델구성\n",
    "# 실습 train 0.7 이상\n",
    "# 평가지표 R2 : 0.8 이상으로 뽑아내보기 / RMSE 사용\n",
    "\n",
    "x_train, x_test,y_train,y_test = train_test_split(x,y,\n",
    "    train_size=0.7,\n",
    "    shuffle = True,\n",
    "    random_state= 123\n",
    ")\n",
    "\n",
    "print(len(x_train))\n",
    "print(len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_36 (Dense)            (None, 10)                140       \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_48 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,911\n",
      "Trainable params: 1,911\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from random import randrange\n",
    "number1 = randrange(1,10,1)\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(10,input_dim = 13),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(10,activation=\"relu\"),\n",
    "    Dense(1)\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "100/100 [==============================] - 1s 1ms/step - loss: 21.5445\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 7.6515\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 6.0490\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 6.1167\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.4526\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.9272\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.0822\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.2493\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.4231\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.1050\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.1586\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.1233\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.5929\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.0641\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.0725\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.9730\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.1058\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.8703\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.7779\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.9004\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.8219\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 5.1226\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.6570\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.6544\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.8409\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.3589\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.6985\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.5060\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.3223\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.3453\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.1539\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.2903\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.1561\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.5201\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 4.6088\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.6569\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.0922\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.0445\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.8525\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.9473\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.8862\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.6319\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.0922\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.6861\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.5864\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.5659\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.5577\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.5687\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 4.0613\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.4229\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.6062\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.4917\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.5744\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.2676\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.6959\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.3468\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.3933\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.3395\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.7087\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.2512\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.2999\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.3341\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.4574\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.2106\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.4982\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.3639\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.0461\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.8162\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.1096\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.1601\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.6281\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.1949\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.3258\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.2396\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.2473\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.1395\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.2950\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.0539\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.0741\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.0790\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.0992\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.1793\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.9696\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.4652\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.2848\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.0264\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.0245\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.1977\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.1646\n",
      "Epoch 90/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 140us/step - loss: 3.1646\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.1888\n",
      "loss :  3.188751220703125\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "=================\n",
      "[15.  26.6 45.4 20.8 34.9 21.9 28.7  7.2 20.  32.2 24.1 18.5 13.5 27.\n",
      " 23.1 18.9 24.5 43.1 19.8 13.8 15.6 50.  37.2 46.  50.  21.2 14.9 19.6\n",
      " 19.4 18.6 26.5 32.  10.9 20.  21.4 31.  25.  15.4 13.1 37.6 37.  18.9\n",
      " 27.9 50.  14.4 22.  19.9 21.6 15.6 15.  32.4 29.6 20.4 12.3 19.1 14.9\n",
      " 17.8  8.8 35.4 11.5 19.6 20.6 15.6 19.9 23.3 22.3 24.8 16.1 22.8 30.5\n",
      " 20.4 24.4 16.6 26.2 16.4 20.1 13.9 19.4 22.8 13.8 31.6 10.5 23.8 22.4\n",
      " 19.3 22.2 12.6 19.4 22.2 29.8  9.6 34.9 21.4 25.3 32.9 26.6 14.6 31.5\n",
      " 23.3 33.3 17.5 19.1 48.5 17.1 23.1 28.4 18.9 13.  17.2 24.1 18.5 21.8\n",
      " 13.3 23.  14.1 23.9 24.  17.2 21.5 19.1 20.8 36.  20.1  8.7 13.6 22.\n",
      " 22.2 21.1 13.4 17.4 20.1 10.2 23.1 10.2 13.1 14.3 14.5  7.2 19.6 20.6\n",
      " 22.7 26.4  7.5 20.3 50.   8.5 20.3 16.1 22.  19.6 10.2 23.2]\n",
      "[[12.937689 ]\n",
      " [23.22731  ]\n",
      " [36.95392  ]\n",
      " [18.310175 ]\n",
      " [27.4999   ]\n",
      " [31.673561 ]\n",
      " [24.49676  ]\n",
      " [12.920952 ]\n",
      " [17.770092 ]\n",
      " [22.508692 ]\n",
      " [23.70032  ]\n",
      " [20.380571 ]\n",
      " [11.830445 ]\n",
      " [29.940279 ]\n",
      " [16.164482 ]\n",
      " [19.819279 ]\n",
      " [19.149248 ]\n",
      " [32.00586  ]\n",
      " [19.115396 ]\n",
      " [13.4538145]\n",
      " [12.59561  ]\n",
      " [24.339748 ]\n",
      " [30.950699 ]\n",
      " [40.922344 ]\n",
      " [38.25333  ]\n",
      " [23.08371  ]\n",
      " [18.239933 ]\n",
      " [20.868256 ]\n",
      " [19.862707 ]\n",
      " [10.078436 ]\n",
      " [23.897123 ]\n",
      " [34.954933 ]\n",
      " [13.261571 ]\n",
      " [19.165846 ]\n",
      " [21.85275  ]\n",
      " [24.187672 ]\n",
      " [23.98652  ]\n",
      " [13.755689 ]\n",
      " [16.75459  ]\n",
      " [40.87579  ]\n",
      " [27.44052  ]\n",
      " [18.873423 ]\n",
      " [18.8049   ]\n",
      " [48.706627 ]\n",
      " [15.141042 ]\n",
      " [21.850235 ]\n",
      " [21.017868 ]\n",
      " [22.870207 ]\n",
      " [19.191402 ]\n",
      " [17.667772 ]\n",
      " [37.337784 ]\n",
      " [20.310764 ]\n",
      " [21.268625 ]\n",
      " [11.804444 ]\n",
      " [18.814545 ]\n",
      " [14.813971 ]\n",
      " [13.472841 ]\n",
      " [ 8.055768 ]\n",
      " [27.21898  ]\n",
      " [12.786496 ]\n",
      " [19.923157 ]\n",
      " [21.230185 ]\n",
      " [ 7.970458 ]\n",
      " [20.619173 ]\n",
      " [19.740873 ]\n",
      " [22.845232 ]\n",
      " [23.008146 ]\n",
      " [17.746925 ]\n",
      " [23.661156 ]\n",
      " [28.734808 ]\n",
      " [18.553192 ]\n",
      " [23.467365 ]\n",
      " [18.721899 ]\n",
      " [23.221972 ]\n",
      " [19.087624 ]\n",
      " [17.892765 ]\n",
      " [11.490508 ]\n",
      " [19.297398 ]\n",
      " [29.632862 ]\n",
      " [10.537017 ]\n",
      " [26.956778 ]\n",
      " [11.826021 ]\n",
      " [22.925777 ]\n",
      " [18.969852 ]\n",
      " [17.2082   ]\n",
      " [22.313742 ]\n",
      " [15.052051 ]\n",
      " [20.870289 ]\n",
      " [19.117832 ]\n",
      " [30.448986 ]\n",
      " [12.6352825]\n",
      " [30.390049 ]\n",
      " [19.739271 ]\n",
      " [22.314518 ]\n",
      " [27.00068  ]\n",
      " [23.676409 ]\n",
      " [14.050981 ]\n",
      " [32.62934  ]\n",
      " [25.525034 ]\n",
      " [30.87537  ]\n",
      " [18.527048 ]\n",
      " [12.387297 ]\n",
      " [37.439674 ]\n",
      " [13.436511 ]\n",
      " [19.797129 ]\n",
      " [21.70286  ]\n",
      " [17.996931 ]\n",
      " [14.083341 ]\n",
      " [17.338524 ]\n",
      " [22.583197 ]\n",
      " [22.58317  ]\n",
      " [23.75359  ]\n",
      " [16.110378 ]\n",
      " [20.381784 ]\n",
      " [12.287865 ]\n",
      " [24.400717 ]\n",
      " [28.266382 ]\n",
      " [ 9.066431 ]\n",
      " [18.884182 ]\n",
      " [16.846941 ]\n",
      " [21.207775 ]\n",
      " [30.30665  ]\n",
      " [17.992113 ]\n",
      " [12.908447 ]\n",
      " [16.564209 ]\n",
      " [19.687386 ]\n",
      " [19.023157 ]\n",
      " [21.141544 ]\n",
      " [15.711971 ]\n",
      " [14.748966 ]\n",
      " [19.927181 ]\n",
      " [12.200309 ]\n",
      " [19.050457 ]\n",
      " [ 9.288575 ]\n",
      " [ 9.998432 ]\n",
      " [13.856625 ]\n",
      " [19.140974 ]\n",
      " [12.941036 ]\n",
      " [19.445217 ]\n",
      " [21.286867 ]\n",
      " [21.66432  ]\n",
      " [20.624456 ]\n",
      " [12.909344 ]\n",
      " [22.161417 ]\n",
      " [43.749928 ]\n",
      " [13.253965 ]\n",
      " [19.486313 ]\n",
      " [16.93665  ]\n",
      " [22.391172 ]\n",
      " [17.547735 ]\n",
      " [13.254252 ]\n",
      " [18.449306 ]]\n",
      "=================\n",
      "R2 :  0.7464863794336927\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.1022\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.9734\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.8635\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.0975\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.2218\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.1471\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.9972\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.9824\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.4474\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.9452\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.8056\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.5796\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.8763\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.9683\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.8786\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.8926\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.8276\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.2033\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.9653\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.8537\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.1164\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7344\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.9920\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.0528\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.1727\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.9799\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7066\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.0544\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.9069\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.0679\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5765\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.9566\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.8185\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.8106\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.9962\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7611\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.8592\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.1071\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6647\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6832\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.8815\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7788\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.8107\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.8751\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.8155\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.0482\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.7286\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.1428\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.8464\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7960\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7153\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.8157\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.8727\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7140\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.9123\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.9176\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.0757\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.0054\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7604\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.7069\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 3.0372\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.8378\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.8283\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.9735\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.0321\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.9190\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.9254\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7595\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.7360\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.8105\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7628\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.7205\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.7152\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.8608\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6846\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.9152\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.1950\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4972\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.8461\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.8804\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6646\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.8309\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5945\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6652\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.5193\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.8986\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7093\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5953\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.8059\n",
      "Epoch 90/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 120us/step - loss: 2.8059\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 3.0151\n",
      "loss :  3.0151302814483643\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "=================\n",
      "[15.  26.6 45.4 20.8 34.9 21.9 28.7  7.2 20.  32.2 24.1 18.5 13.5 27.\n",
      " 23.1 18.9 24.5 43.1 19.8 13.8 15.6 50.  37.2 46.  50.  21.2 14.9 19.6\n",
      " 19.4 18.6 26.5 32.  10.9 20.  21.4 31.  25.  15.4 13.1 37.6 37.  18.9\n",
      " 27.9 50.  14.4 22.  19.9 21.6 15.6 15.  32.4 29.6 20.4 12.3 19.1 14.9\n",
      " 17.8  8.8 35.4 11.5 19.6 20.6 15.6 19.9 23.3 22.3 24.8 16.1 22.8 30.5\n",
      " 20.4 24.4 16.6 26.2 16.4 20.1 13.9 19.4 22.8 13.8 31.6 10.5 23.8 22.4\n",
      " 19.3 22.2 12.6 19.4 22.2 29.8  9.6 34.9 21.4 25.3 32.9 26.6 14.6 31.5\n",
      " 23.3 33.3 17.5 19.1 48.5 17.1 23.1 28.4 18.9 13.  17.2 24.1 18.5 21.8\n",
      " 13.3 23.  14.1 23.9 24.  17.2 21.5 19.1 20.8 36.  20.1  8.7 13.6 22.\n",
      " 22.2 21.1 13.4 17.4 20.1 10.2 23.1 10.2 13.1 14.3 14.5  7.2 19.6 20.6\n",
      " 22.7 26.4  7.5 20.3 50.   8.5 20.3 16.1 22.  19.6 10.2 23.2]\n",
      "[[12.702787 ]\n",
      " [24.796404 ]\n",
      " [39.40635  ]\n",
      " [17.8228   ]\n",
      " [25.633738 ]\n",
      " [31.254425 ]\n",
      " [25.776    ]\n",
      " [12.3716755]\n",
      " [19.082783 ]\n",
      " [24.118544 ]\n",
      " [24.168709 ]\n",
      " [21.930286 ]\n",
      " [15.003521 ]\n",
      " [28.262873 ]\n",
      " [19.22134  ]\n",
      " [20.790173 ]\n",
      " [21.45689  ]\n",
      " [33.47316  ]\n",
      " [21.15242  ]\n",
      " [13.633482 ]\n",
      " [16.351324 ]\n",
      " [22.672468 ]\n",
      " [32.480553 ]\n",
      " [43.231518 ]\n",
      " [42.28115  ]\n",
      " [21.537743 ]\n",
      " [17.378277 ]\n",
      " [22.50512  ]\n",
      " [22.037617 ]\n",
      " [12.182138 ]\n",
      " [23.618736 ]\n",
      " [34.371323 ]\n",
      " [12.274765 ]\n",
      " [20.95789  ]\n",
      " [22.751387 ]\n",
      " [25.734325 ]\n",
      " [25.077553 ]\n",
      " [12.895179 ]\n",
      " [17.925047 ]\n",
      " [42.131275 ]\n",
      " [26.267546 ]\n",
      " [20.519821 ]\n",
      " [18.106964 ]\n",
      " [50.44217  ]\n",
      " [17.468489 ]\n",
      " [23.588736 ]\n",
      " [22.493126 ]\n",
      " [23.18762  ]\n",
      " [20.52767  ]\n",
      " [16.543814 ]\n",
      " [36.733475 ]\n",
      " [21.690691 ]\n",
      " [22.542332 ]\n",
      " [12.058151 ]\n",
      " [18.896454 ]\n",
      " [15.123062 ]\n",
      " [14.339563 ]\n",
      " [ 7.9054418]\n",
      " [28.281902 ]\n",
      " [12.038344 ]\n",
      " [19.945053 ]\n",
      " [22.007738 ]\n",
      " [ 9.265071 ]\n",
      " [19.607069 ]\n",
      " [21.981533 ]\n",
      " [23.815212 ]\n",
      " [24.44635  ]\n",
      " [16.59929  ]\n",
      " [25.266893 ]\n",
      " [27.503185 ]\n",
      " [19.971985 ]\n",
      " [24.193014 ]\n",
      " [20.119717 ]\n",
      " [24.689592 ]\n",
      " [17.99968  ]\n",
      " [17.281483 ]\n",
      " [11.6841545]\n",
      " [21.84622  ]\n",
      " [28.187637 ]\n",
      " [ 7.4599814]\n",
      " [26.434418 ]\n",
      " [11.580651 ]\n",
      " [24.050589 ]\n",
      " [21.63198  ]\n",
      " [19.063553 ]\n",
      " [24.268408 ]\n",
      " [14.314469 ]\n",
      " [22.39948  ]\n",
      " [21.871078 ]\n",
      " [29.016607 ]\n",
      " [12.830903 ]\n",
      " [29.198175 ]\n",
      " [21.016489 ]\n",
      " [25.006397 ]\n",
      " [24.989798 ]\n",
      " [26.013931 ]\n",
      " [13.69098  ]\n",
      " [32.464466 ]\n",
      " [23.908215 ]\n",
      " [31.057604 ]\n",
      " [21.243237 ]\n",
      " [12.463648 ]\n",
      " [39.258644 ]\n",
      " [12.998172 ]\n",
      " [20.763634 ]\n",
      " [22.872833 ]\n",
      " [18.050278 ]\n",
      " [14.031807 ]\n",
      " [20.323893 ]\n",
      " [21.431366 ]\n",
      " [22.142244 ]\n",
      " [21.95771  ]\n",
      " [17.081142 ]\n",
      " [19.971863 ]\n",
      " [12.346651 ]\n",
      " [24.369108 ]\n",
      " [28.481503 ]\n",
      " [ 7.8541017]\n",
      " [19.440107 ]\n",
      " [16.420275 ]\n",
      " [18.854502 ]\n",
      " [32.11276  ]\n",
      " [20.145115 ]\n",
      " [12.712294 ]\n",
      " [17.954195 ]\n",
      " [21.545935 ]\n",
      " [20.828264 ]\n",
      " [23.500292 ]\n",
      " [17.393452 ]\n",
      " [18.370844 ]\n",
      " [21.117054 ]\n",
      " [11.843762 ]\n",
      " [17.060236 ]\n",
      " [ 7.498085 ]\n",
      " [12.799853 ]\n",
      " [12.756803 ]\n",
      " [19.867662 ]\n",
      " [12.3078575]\n",
      " [20.606695 ]\n",
      " [20.12599  ]\n",
      " [21.507246 ]\n",
      " [21.349125 ]\n",
      " [12.583632 ]\n",
      " [22.834284 ]\n",
      " [49.748375 ]\n",
      " [12.382707 ]\n",
      " [20.88655  ]\n",
      " [20.16347  ]\n",
      " [23.450888 ]\n",
      " [18.69314  ]\n",
      " [12.37959  ]\n",
      " [17.784498 ]]\n",
      "=================\n",
      "R2 :  0.7650329509500992\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.8022\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.9446\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.8176\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4325\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.8568\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5658\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.7874\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.6104\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.9764\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5616\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.8451\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5972\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.8530\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4844\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6957\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7238\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5943\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7208\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.9886\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.8835\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7344\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6188\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.7212\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.6161\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.7389\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.6857\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.7284\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.8109\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5762\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6653\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.8208\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7545\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.7280\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 3ms/step - loss: 2.5472\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.9582\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6136\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6299\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7735\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3886\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7057\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5924\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4656\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.7813\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.4667\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.7239\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5534\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.8686\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4208\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5941\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.5972\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4665\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.0775\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5738\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6375\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.5166\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7433\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4957\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7132\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6030\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6799\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.8140\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6745\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.5560\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.5633\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.7840\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7634\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.6618\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.7646\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.5880\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.7398\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.5038\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6369\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6931\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.9253\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.6429\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.8549\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.6402\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.5679\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.5130\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7081\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5344\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7383\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.8780\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.5379\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5186\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6531\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6771\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4930\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7689\n",
      "Epoch 90/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 120us/step - loss: 2.7689\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.8786\n",
      "loss :  2.878591775894165\n",
      "5/5 [==============================] - 0s 998us/step\n",
      "=================\n",
      "[15.  26.6 45.4 20.8 34.9 21.9 28.7  7.2 20.  32.2 24.1 18.5 13.5 27.\n",
      " 23.1 18.9 24.5 43.1 19.8 13.8 15.6 50.  37.2 46.  50.  21.2 14.9 19.6\n",
      " 19.4 18.6 26.5 32.  10.9 20.  21.4 31.  25.  15.4 13.1 37.6 37.  18.9\n",
      " 27.9 50.  14.4 22.  19.9 21.6 15.6 15.  32.4 29.6 20.4 12.3 19.1 14.9\n",
      " 17.8  8.8 35.4 11.5 19.6 20.6 15.6 19.9 23.3 22.3 24.8 16.1 22.8 30.5\n",
      " 20.4 24.4 16.6 26.2 16.4 20.1 13.9 19.4 22.8 13.8 31.6 10.5 23.8 22.4\n",
      " 19.3 22.2 12.6 19.4 22.2 29.8  9.6 34.9 21.4 25.3 32.9 26.6 14.6 31.5\n",
      " 23.3 33.3 17.5 19.1 48.5 17.1 23.1 28.4 18.9 13.  17.2 24.1 18.5 21.8\n",
      " 13.3 23.  14.1 23.9 24.  17.2 21.5 19.1 20.8 36.  20.1  8.7 13.6 22.\n",
      " 22.2 21.1 13.4 17.4 20.1 10.2 23.1 10.2 13.1 14.3 14.5  7.2 19.6 20.6\n",
      " 22.7 26.4  7.5 20.3 50.   8.5 20.3 16.1 22.  19.6 10.2 23.2]\n",
      "[[12.675941 ]\n",
      " [27.399727 ]\n",
      " [44.328983 ]\n",
      " [19.621553 ]\n",
      " [26.492496 ]\n",
      " [39.67216  ]\n",
      " [29.364592 ]\n",
      " [12.099758 ]\n",
      " [17.436447 ]\n",
      " [23.573786 ]\n",
      " [23.410864 ]\n",
      " [20.76548  ]\n",
      " [13.932134 ]\n",
      " [33.759907 ]\n",
      " [19.797249 ]\n",
      " [19.791212 ]\n",
      " [20.963127 ]\n",
      " [38.136177 ]\n",
      " [19.346397 ]\n",
      " [14.472152 ]\n",
      " [15.514761 ]\n",
      " [25.95501  ]\n",
      " [36.50275  ]\n",
      " [48.27913  ]\n",
      " [50.728344 ]\n",
      " [23.871103 ]\n",
      " [19.422968 ]\n",
      " [21.870035 ]\n",
      " [21.616034 ]\n",
      " [16.913305 ]\n",
      " [23.307873 ]\n",
      " [37.899612 ]\n",
      " [12.172815 ]\n",
      " [20.368927 ]\n",
      " [22.115751 ]\n",
      " [29.43634  ]\n",
      " [25.01044  ]\n",
      " [14.136031 ]\n",
      " [16.74012  ]\n",
      " [47.04508  ]\n",
      " [28.250227 ]\n",
      " [18.746414 ]\n",
      " [18.352417 ]\n",
      " [57.241333 ]\n",
      " [16.698513 ]\n",
      " [23.073765 ]\n",
      " [21.859074 ]\n",
      " [23.320524 ]\n",
      " [18.70899  ]\n",
      " [17.284002 ]\n",
      " [40.29087  ]\n",
      " [20.712152 ]\n",
      " [21.90844  ]\n",
      " [11.032733 ]\n",
      " [19.43369  ]\n",
      " [16.222435 ]\n",
      " [13.836513 ]\n",
      " [ 7.8892736]\n",
      " [31.134659 ]\n",
      " [12.35767  ]\n",
      " [18.994759 ]\n",
      " [21.206451 ]\n",
      " [11.794205 ]\n",
      " [21.62357  ]\n",
      " [21.4625   ]\n",
      " [23.440603 ]\n",
      " [24.03032  ]\n",
      " [16.484758 ]\n",
      " [24.89833  ]\n",
      " [30.199049 ]\n",
      " [18.895824 ]\n",
      " [26.474075 ]\n",
      " [18.416264 ]\n",
      " [24.446898 ]\n",
      " [20.197165 ]\n",
      " [19.326553 ]\n",
      " [12.938983 ]\n",
      " [19.749506 ]\n",
      " [30.908886 ]\n",
      " [10.414552 ]\n",
      " [30.041548 ]\n",
      " [12.144958 ]\n",
      " [23.71482  ]\n",
      " [20.087963 ]\n",
      " [17.732439 ]\n",
      " [25.606161 ]\n",
      " [15.374747 ]\n",
      " [21.648445 ]\n",
      " [20.660337 ]\n",
      " [32.009174 ]\n",
      " [12.588261 ]\n",
      " [33.964096 ]\n",
      " [19.45264  ]\n",
      " [24.76377  ]\n",
      " [26.04402  ]\n",
      " [27.192135 ]\n",
      " [14.62497  ]\n",
      " [37.212337 ]\n",
      " [25.917877 ]\n",
      " [35.726665 ]\n",
      " [20.397478 ]\n",
      " [14.013517 ]\n",
      " [43.09034  ]\n",
      " [14.076579 ]\n",
      " [19.593023 ]\n",
      " [23.79467  ]\n",
      " [15.462756 ]\n",
      " [15.261377 ]\n",
      " [18.955349 ]\n",
      " [21.419863 ]\n",
      " [21.669249 ]\n",
      " [24.069206 ]\n",
      " [16.006903 ]\n",
      " [19.331425 ]\n",
      " [12.585596 ]\n",
      " [23.797169 ]\n",
      " [31.99647  ]\n",
      " [10.744611 ]\n",
      " [19.005556 ]\n",
      " [18.36611  ]\n",
      " [21.70796  ]\n",
      " [35.590057 ]\n",
      " [18.456936 ]\n",
      " [12.389144 ]\n",
      " [16.596146 ]\n",
      " [19.65002  ]\n",
      " [20.392107 ]\n",
      " [22.921732 ]\n",
      " [16.936789 ]\n",
      " [18.999798 ]\n",
      " [20.357777 ]\n",
      " [11.85514  ]\n",
      " [18.973274 ]\n",
      " [ 7.8892736]\n",
      " [13.042941 ]\n",
      " [13.934138 ]\n",
      " [18.316908 ]\n",
      " [12.978059 ]\n",
      " [18.902485 ]\n",
      " [22.189285 ]\n",
      " [21.013296 ]\n",
      " [20.308067 ]\n",
      " [12.247325 ]\n",
      " [22.557579 ]\n",
      " [55.58717  ]\n",
      " [13.336887 ]\n",
      " [19.289862 ]\n",
      " [19.073347 ]\n",
      " [25.371126 ]\n",
      " [19.238363 ]\n",
      " [12.613604 ]\n",
      " [20.157223 ]]\n",
      "=================\n",
      "R2 :  0.7827711516175685\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.4353\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.7861\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.5380\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5026\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.4918\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.6241\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5725\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6045\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.4258\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5957\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.4100\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.6028\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5042\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6296\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5093\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4828\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.5058\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4228\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 3.3590\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.9642\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.5196\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3177\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7966\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5493\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5936\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6096\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6949\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6073\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2684\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.4462\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6141\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.8707\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6280\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6706\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6189\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4630\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3290\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2886\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5708\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3766\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3789\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.4107\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6171\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5608\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4475\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5550\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4608\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3742\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5154\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4377\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4087\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6454\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7388\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.3061\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3337\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4127\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4176\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5955\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6081\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4873\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3992\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3464\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3657\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4793\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7184\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.7115\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4633\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7658\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3181\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5677\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4276\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3068\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4985\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3993\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3784\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5529\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4815\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.7867\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4983\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3833\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4043\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3245\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5797\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5389\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4721\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1947\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3939\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5276\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.4411\n",
      "Epoch 90/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 110us/step - loss: 2.4411\n",
      "5/5 [==============================] - 0s 748us/step - loss: 3.2997\n",
      "loss :  3.2996959686279297\n",
      "5/5 [==============================] - 0s 991us/step\n",
      "=================\n",
      "[15.  26.6 45.4 20.8 34.9 21.9 28.7  7.2 20.  32.2 24.1 18.5 13.5 27.\n",
      " 23.1 18.9 24.5 43.1 19.8 13.8 15.6 50.  37.2 46.  50.  21.2 14.9 19.6\n",
      " 19.4 18.6 26.5 32.  10.9 20.  21.4 31.  25.  15.4 13.1 37.6 37.  18.9\n",
      " 27.9 50.  14.4 22.  19.9 21.6 15.6 15.  32.4 29.6 20.4 12.3 19.1 14.9\n",
      " 17.8  8.8 35.4 11.5 19.6 20.6 15.6 19.9 23.3 22.3 24.8 16.1 22.8 30.5\n",
      " 20.4 24.4 16.6 26.2 16.4 20.1 13.9 19.4 22.8 13.8 31.6 10.5 23.8 22.4\n",
      " 19.3 22.2 12.6 19.4 22.2 29.8  9.6 34.9 21.4 25.3 32.9 26.6 14.6 31.5\n",
      " 23.3 33.3 17.5 19.1 48.5 17.1 23.1 28.4 18.9 13.  17.2 24.1 18.5 21.8\n",
      " 13.3 23.  14.1 23.9 24.  17.2 21.5 19.1 20.8 36.  20.1  8.7 13.6 22.\n",
      " 22.2 21.1 13.4 17.4 20.1 10.2 23.1 10.2 13.1 14.3 14.5  7.2 19.6 20.6\n",
      " 22.7 26.4  7.5 20.3 50.   8.5 20.3 16.1 22.  19.6 10.2 23.2]\n",
      "[[13.651505 ]\n",
      " [27.138897 ]\n",
      " [44.696266 ]\n",
      " [20.058285 ]\n",
      " [27.105429 ]\n",
      " [53.44827  ]\n",
      " [29.195753 ]\n",
      " [12.913529 ]\n",
      " [15.80054  ]\n",
      " [24.56263  ]\n",
      " [23.604935 ]\n",
      " [20.203915 ]\n",
      " [13.864205 ]\n",
      " [38.966732 ]\n",
      " [19.822508 ]\n",
      " [19.409058 ]\n",
      " [20.627424 ]\n",
      " [37.959343 ]\n",
      " [18.860031 ]\n",
      " [13.45737  ]\n",
      " [15.2511835]\n",
      " [31.192078 ]\n",
      " [36.768314 ]\n",
      " [49.55766  ]\n",
      " [58.402687 ]\n",
      " [24.420362 ]\n",
      " [19.999804 ]\n",
      " [21.536577 ]\n",
      " [21.580072 ]\n",
      " [19.708134 ]\n",
      " [22.99215  ]\n",
      " [37.68337  ]\n",
      " [12.237811 ]\n",
      " [19.983278 ]\n",
      " [21.721771 ]\n",
      " [29.521608 ]\n",
      " [24.608976 ]\n",
      " [13.429906 ]\n",
      " [14.64519  ]\n",
      " [46.913322 ]\n",
      " [29.052439 ]\n",
      " [18.446836 ]\n",
      " [23.120085 ]\n",
      " [62.701073 ]\n",
      " [17.933825 ]\n",
      " [23.106962 ]\n",
      " [21.303381 ]\n",
      " [22.40154  ]\n",
      " [17.234482 ]\n",
      " [19.659946 ]\n",
      " [40.8377   ]\n",
      " [20.093637 ]\n",
      " [21.35394  ]\n",
      " [11.291688 ]\n",
      " [19.893995 ]\n",
      " [14.981921 ]\n",
      " [13.568719 ]\n",
      " [ 7.5614457]\n",
      " [32.312428 ]\n",
      " [12.492419 ]\n",
      " [18.427767 ]\n",
      " [20.525438 ]\n",
      " [11.143321 ]\n",
      " [22.689352 ]\n",
      " [21.160479 ]\n",
      " [23.344198 ]\n",
      " [23.824068 ]\n",
      " [13.86419  ]\n",
      " [24.567812 ]\n",
      " [32.312824 ]\n",
      " [18.621122 ]\n",
      " [26.376455 ]\n",
      " [17.376593 ]\n",
      " [24.296206 ]\n",
      " [20.277727 ]\n",
      " [20.254576 ]\n",
      " [12.480285 ]\n",
      " [19.207693 ]\n",
      " [29.335165 ]\n",
      " [ 7.5614457]\n",
      " [29.46829  ]\n",
      " [11.790792 ]\n",
      " [23.359743 ]\n",
      " [19.73036  ]\n",
      " [15.676896 ]\n",
      " [25.554636 ]\n",
      " [14.815375 ]\n",
      " [21.629026 ]\n",
      " [20.31229  ]\n",
      " [33.962994 ]\n",
      " [13.506337 ]\n",
      " [36.434685 ]\n",
      " [17.86869  ]\n",
      " [24.66622  ]\n",
      " [26.776655 ]\n",
      " [28.04188  ]\n",
      " [13.853129 ]\n",
      " [37.841595 ]\n",
      " [29.240286 ]\n",
      " [38.796753 ]\n",
      " [20.182322 ]\n",
      " [12.428998 ]\n",
      " [45.17332  ]\n",
      " [13.343472 ]\n",
      " [19.144312 ]\n",
      " [23.556545 ]\n",
      " [14.072809 ]\n",
      " [13.840897 ]\n",
      " [18.942968 ]\n",
      " [21.825817 ]\n",
      " [21.447203 ]\n",
      " [24.672049 ]\n",
      " [14.216254 ]\n",
      " [19.414785 ]\n",
      " [12.959163 ]\n",
      " [24.120981 ]\n",
      " [31.342028 ]\n",
      " [10.647637 ]\n",
      " [18.64044  ]\n",
      " [19.43408  ]\n",
      " [32.236294 ]\n",
      " [35.57331  ]\n",
      " [18.151922 ]\n",
      " [13.091223 ]\n",
      " [14.540598 ]\n",
      " [19.101782 ]\n",
      " [20.340984 ]\n",
      " [22.491703 ]\n",
      " [15.689185 ]\n",
      " [20.276922 ]\n",
      " [20.111858 ]\n",
      " [12.246927 ]\n",
      " [12.927351 ]\n",
      " [ 7.563603 ]\n",
      " [14.169686 ]\n",
      " [12.459132 ]\n",
      " [17.536459 ]\n",
      " [12.883063 ]\n",
      " [18.283247 ]\n",
      " [23.125803 ]\n",
      " [20.434647 ]\n",
      " [19.252968 ]\n",
      " [12.873786 ]\n",
      " [22.053516 ]\n",
      " [61.753654 ]\n",
      " [12.941655 ]\n",
      " [17.986778 ]\n",
      " [19.003057 ]\n",
      " [24.687204 ]\n",
      " [20.003992 ]\n",
      " [11.336957 ]\n",
      " [20.687574 ]]\n",
      "=================\n",
      "R2 :  0.6916118875727204\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4928\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5184\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4358\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4502\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3634\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4196\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3958\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3068\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.3986\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3307\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5891\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4795\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1976\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4171\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3654\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4437\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2639\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4075\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.3681\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1963\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4468\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4962\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2449\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3308\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3863\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5092\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3907\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.2577\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.2883\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.4089\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.4101\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.3668\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.5603\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3135\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2903\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3899\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.2540\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.2974\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.3440\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.2660\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.4891\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.2737\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.2265\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.4012\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.3499\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2438\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.5455\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3068\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2781\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5149\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3819\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2397\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.4219\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2975\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.5532\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.3928\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2982\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3846\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2439\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.3696\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.3072\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4215\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.3179\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6132\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3817\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3149\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4823\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1577\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.5118\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2909\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2074\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3699\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3609\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3813\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4697\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 3.2344\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3640\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4821\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.2825\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5116\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2441\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.3025\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2335\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1550\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4244\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2932\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.3152\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2288\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2701\n",
      "Epoch 90/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 110us/step - loss: 2.2701\n",
      "5/5 [==============================] - 0s 997us/step - loss: 2.7658\n",
      "loss :  2.7658345699310303\n",
      "5/5 [==============================] - 0s 997us/step\n",
      "=================\n",
      "[15.  26.6 45.4 20.8 34.9 21.9 28.7  7.2 20.  32.2 24.1 18.5 13.5 27.\n",
      " 23.1 18.9 24.5 43.1 19.8 13.8 15.6 50.  37.2 46.  50.  21.2 14.9 19.6\n",
      " 19.4 18.6 26.5 32.  10.9 20.  21.4 31.  25.  15.4 13.1 37.6 37.  18.9\n",
      " 27.9 50.  14.4 22.  19.9 21.6 15.6 15.  32.4 29.6 20.4 12.3 19.1 14.9\n",
      " 17.8  8.8 35.4 11.5 19.6 20.6 15.6 19.9 23.3 22.3 24.8 16.1 22.8 30.5\n",
      " 20.4 24.4 16.6 26.2 16.4 20.1 13.9 19.4 22.8 13.8 31.6 10.5 23.8 22.4\n",
      " 19.3 22.2 12.6 19.4 22.2 29.8  9.6 34.9 21.4 25.3 32.9 26.6 14.6 31.5\n",
      " 23.3 33.3 17.5 19.1 48.5 17.1 23.1 28.4 18.9 13.  17.2 24.1 18.5 21.8\n",
      " 13.3 23.  14.1 23.9 24.  17.2 21.5 19.1 20.8 36.  20.1  8.7 13.6 22.\n",
      " 22.2 21.1 13.4 17.4 20.1 10.2 23.1 10.2 13.1 14.3 14.5  7.2 19.6 20.6\n",
      " 22.7 26.4  7.5 20.3 50.   8.5 20.3 16.1 22.  19.6 10.2 23.2]\n",
      "[[12.859049 ]\n",
      " [26.203516 ]\n",
      " [42.841274 ]\n",
      " [20.60829  ]\n",
      " [26.805256 ]\n",
      " [46.10316  ]\n",
      " [28.262304 ]\n",
      " [ 9.987109 ]\n",
      " [15.803248 ]\n",
      " [23.929081 ]\n",
      " [23.882975 ]\n",
      " [20.253527 ]\n",
      " [13.580099 ]\n",
      " [30.95231  ]\n",
      " [20.903666 ]\n",
      " [19.766865 ]\n",
      " [21.203133 ]\n",
      " [36.32045  ]\n",
      " [19.262598 ]\n",
      " [13.382756 ]\n",
      " [14.014327 ]\n",
      " [27.108631 ]\n",
      " [35.871483 ]\n",
      " [47.910767 ]\n",
      " [51.30061  ]\n",
      " [24.239452 ]\n",
      " [20.837933 ]\n",
      " [21.677507 ]\n",
      " [21.903923 ]\n",
      " [19.431751 ]\n",
      " [22.88335  ]\n",
      " [35.199993 ]\n",
      " [11.263284 ]\n",
      " [20.258957 ]\n",
      " [21.742249 ]\n",
      " [28.908981 ]\n",
      " [23.986462 ]\n",
      " [12.65786  ]\n",
      " [13.98905  ]\n",
      " [44.472176 ]\n",
      " [28.039076 ]\n",
      " [18.524853 ]\n",
      " [21.108541 ]\n",
      " [53.2099   ]\n",
      " [16.725788 ]\n",
      " [23.360813 ]\n",
      " [21.446678 ]\n",
      " [22.370667 ]\n",
      " [16.739662 ]\n",
      " [20.002922 ]\n",
      " [38.35151  ]\n",
      " [20.225235 ]\n",
      " [21.50056  ]\n",
      " [10.718846 ]\n",
      " [19.467655 ]\n",
      " [16.808937 ]\n",
      " [13.568231 ]\n",
      " [ 7.7202325]\n",
      " [31.21051  ]\n",
      " [11.614105 ]\n",
      " [19.103897 ]\n",
      " [20.549572 ]\n",
      " [17.097122 ]\n",
      " [23.037132 ]\n",
      " [21.39895  ]\n",
      " [23.275608 ]\n",
      " [23.917828 ]\n",
      " [14.027089 ]\n",
      " [24.419832 ]\n",
      " [31.23852  ]\n",
      " [19.193    ]\n",
      " [25.284698 ]\n",
      " [17.14824  ]\n",
      " [24.16968  ]\n",
      " [23.142115 ]\n",
      " [20.253923 ]\n",
      " [12.437933 ]\n",
      " [19.112785 ]\n",
      " [28.005823 ]\n",
      " [10.919953 ]\n",
      " [28.692413 ]\n",
      " [10.226359 ]\n",
      " [23.497097 ]\n",
      " [20.045353 ]\n",
      " [15.815379 ]\n",
      " [24.575481 ]\n",
      " [14.117527 ]\n",
      " [21.819115 ]\n",
      " [20.599785 ]\n",
      " [32.46907  ]\n",
      " [13.053133 ]\n",
      " [34.207283 ]\n",
      " [17.86177  ]\n",
      " [24.617462 ]\n",
      " [26.571419 ]\n",
      " [27.132738 ]\n",
      " [13.432072 ]\n",
      " [34.664356 ]\n",
      " [24.971994 ]\n",
      " [37.906914 ]\n",
      " [20.795885 ]\n",
      " [13.81677  ]\n",
      " [44.161823 ]\n",
      " [12.567166 ]\n",
      " [19.327751 ]\n",
      " [23.22702  ]\n",
      " [16.994522 ]\n",
      " [15.029794 ]\n",
      " [19.782944 ]\n",
      " [21.996424 ]\n",
      " [21.285835 ]\n",
      " [24.497293 ]\n",
      " [15.578662 ]\n",
      " [18.940924 ]\n",
      " [12.925958 ]\n",
      " [24.289    ]\n",
      " [30.469357 ]\n",
      " [10.8483715]\n",
      " [19.028774 ]\n",
      " [19.006037 ]\n",
      " [29.155285 ]\n",
      " [34.348763 ]\n",
      " [17.685696 ]\n",
      " [10.36671  ]\n",
      " [13.633731 ]\n",
      " [18.889961 ]\n",
      " [20.79533  ]\n",
      " [22.474361 ]\n",
      " [16.051403 ]\n",
      " [19.22158  ]\n",
      " [20.423958 ]\n",
      " [10.555128 ]\n",
      " [20.104399 ]\n",
      " [10.797021 ]\n",
      " [14.831449 ]\n",
      " [13.508635 ]\n",
      " [17.902681 ]\n",
      " [11.670981 ]\n",
      " [18.601334 ]\n",
      " [23.304983 ]\n",
      " [20.464245 ]\n",
      " [19.21226  ]\n",
      " [10.495913 ]\n",
      " [22.019043 ]\n",
      " [54.16379  ]\n",
      " [11.926568 ]\n",
      " [17.866838 ]\n",
      " [19.549389 ]\n",
      " [23.741068 ]\n",
      " [19.44064  ]\n",
      " [11.690505 ]\n",
      " [20.509745 ]]\n",
      "=================\n",
      "R2 :  0.7827147317194075\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1133\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3197\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3662\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1634\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3356\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.2098\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2285\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3631\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2484\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2525\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3612\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2485\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.2181\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3076\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2366\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1214\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1892\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1337\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0808\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2863\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0841\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.2125\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3017\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2287\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3065\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.2698\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.3987\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3623\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2059\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.4436\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1261\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2590\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2387\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4407\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2070\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0963\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0152\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4339\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3073\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4500\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2120\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1994\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.4177\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.1819\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.3790\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6380\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2541\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3033\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.7737\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2904\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2886\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1268\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.3697\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4575\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3657\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2153\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1425\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0875\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0440\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4440\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.2156\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4148\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.2252\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.1759\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3714\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3774\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3814\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.0396\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3405\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1626\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3368\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3386\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2110\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4425\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.5220\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2207\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1472\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2414\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2714\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1792\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1669\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.2322\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1470\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9647\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4608\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.9049\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.3200\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.9602\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5536\n",
      "Epoch 90/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 110us/step - loss: 2.5536\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.8536\n",
      "loss :  2.853644847869873\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "=================\n",
      "[15.  26.6 45.4 20.8 34.9 21.9 28.7  7.2 20.  32.2 24.1 18.5 13.5 27.\n",
      " 23.1 18.9 24.5 43.1 19.8 13.8 15.6 50.  37.2 46.  50.  21.2 14.9 19.6\n",
      " 19.4 18.6 26.5 32.  10.9 20.  21.4 31.  25.  15.4 13.1 37.6 37.  18.9\n",
      " 27.9 50.  14.4 22.  19.9 21.6 15.6 15.  32.4 29.6 20.4 12.3 19.1 14.9\n",
      " 17.8  8.8 35.4 11.5 19.6 20.6 15.6 19.9 23.3 22.3 24.8 16.1 22.8 30.5\n",
      " 20.4 24.4 16.6 26.2 16.4 20.1 13.9 19.4 22.8 13.8 31.6 10.5 23.8 22.4\n",
      " 19.3 22.2 12.6 19.4 22.2 29.8  9.6 34.9 21.4 25.3 32.9 26.6 14.6 31.5\n",
      " 23.3 33.3 17.5 19.1 48.5 17.1 23.1 28.4 18.9 13.  17.2 24.1 18.5 21.8\n",
      " 13.3 23.  14.1 23.9 24.  17.2 21.5 19.1 20.8 36.  20.1  8.7 13.6 22.\n",
      " 22.2 21.1 13.4 17.4 20.1 10.2 23.1 10.2 13.1 14.3 14.5  7.2 19.6 20.6\n",
      " 22.7 26.4  7.5 20.3 50.   8.5 20.3 16.1 22.  19.6 10.2 23.2]\n",
      "[[12.587322 ]\n",
      " [24.380442 ]\n",
      " [39.739445 ]\n",
      " [16.820335 ]\n",
      " [24.189138 ]\n",
      " [42.532764 ]\n",
      " [26.54214  ]\n",
      " [10.673648 ]\n",
      " [17.44639  ]\n",
      " [24.038595 ]\n",
      " [23.257788 ]\n",
      " [20.167194 ]\n",
      " [13.770475 ]\n",
      " [24.846342 ]\n",
      " [20.732164 ]\n",
      " [19.24895  ]\n",
      " [20.708973 ]\n",
      " [33.300987 ]\n",
      " [19.697405 ]\n",
      " [13.629261 ]\n",
      " [13.98708  ]\n",
      " [23.262394 ]\n",
      " [34.404736 ]\n",
      " [44.995766 ]\n",
      " [47.408703 ]\n",
      " [23.184923 ]\n",
      " [11.602424 ]\n",
      " [21.295525 ]\n",
      " [21.503153 ]\n",
      " [16.775633 ]\n",
      " [22.417683 ]\n",
      " [32.20546  ]\n",
      " [11.734432 ]\n",
      " [19.832312 ]\n",
      " [21.453419 ]\n",
      " [26.34989  ]\n",
      " [23.71531  ]\n",
      " [14.020281 ]\n",
      " [15.965132 ]\n",
      " [38.507656 ]\n",
      " [24.901052 ]\n",
      " [18.977968 ]\n",
      " [18.899418 ]\n",
      " [45.1604   ]\n",
      " [18.442497 ]\n",
      " [23.182915 ]\n",
      " [20.783049 ]\n",
      " [21.81084  ]\n",
      " [17.941055 ]\n",
      " [19.384226 ]\n",
      " [34.387203 ]\n",
      " [20.076391 ]\n",
      " [20.854185 ]\n",
      " [13.626303 ]\n",
      " [18.797848 ]\n",
      " [13.770004 ]\n",
      " [13.664055 ]\n",
      " [ 7.4700837]\n",
      " [30.328205 ]\n",
      " [13.631887 ]\n",
      " [17.657297 ]\n",
      " [20.043156 ]\n",
      " [14.004618 ]\n",
      " [20.850672 ]\n",
      " [21.099821 ]\n",
      " [23.028906 ]\n",
      " [23.701927 ]\n",
      " [14.03349  ]\n",
      " [24.331726 ]\n",
      " [26.0032   ]\n",
      " [18.90346  ]\n",
      " [23.327444 ]\n",
      " [18.071878 ]\n",
      " [24.311989 ]\n",
      " [18.117945 ]\n",
      " [19.031517 ]\n",
      " [13.606039 ]\n",
      " [19.365065 ]\n",
      " [24.410503 ]\n",
      " [13.612698 ]\n",
      " [25.184666 ]\n",
      " [13.614391 ]\n",
      " [23.17007  ]\n",
      " [20.184399 ]\n",
      " [17.813524 ]\n",
      " [23.661243 ]\n",
      " [16.966303 ]\n",
      " [21.239359 ]\n",
      " [20.413326 ]\n",
      " [27.439264 ]\n",
      " [13.032291 ]\n",
      " [28.210522 ]\n",
      " [18.268122 ]\n",
      " [24.745697 ]\n",
      " [23.93909  ]\n",
      " [26.907288 ]\n",
      " [13.374167 ]\n",
      " [29.232735 ]\n",
      " [23.376545 ]\n",
      " [32.924778 ]\n",
      " [20.392778 ]\n",
      " [13.6216   ]\n",
      " [41.096836 ]\n",
      " [13.599792 ]\n",
      " [18.914549 ]\n",
      " [22.989986 ]\n",
      " [17.119    ]\n",
      " [13.632704 ]\n",
      " [19.728134 ]\n",
      " [20.611895 ]\n",
      " [20.80132  ]\n",
      " [23.076849 ]\n",
      " [13.695624 ]\n",
      " [17.920286 ]\n",
      " [12.357256 ]\n",
      " [23.207312 ]\n",
      " [27.487062 ]\n",
      " [13.503178 ]\n",
      " [18.139795 ]\n",
      " [17.757404 ]\n",
      " [21.026358 ]\n",
      " [31.47216  ]\n",
      " [18.969692 ]\n",
      " [10.6917925]\n",
      " [16.680864 ]\n",
      " [18.790157 ]\n",
      " [20.3946   ]\n",
      " [22.539822 ]\n",
      " [16.135212 ]\n",
      " [18.713255 ]\n",
      " [19.988514 ]\n",
      " [13.629915 ]\n",
      " [19.071407 ]\n",
      " [ 7.6378894]\n",
      " [15.315264 ]\n",
      " [13.361347 ]\n",
      " [18.267523 ]\n",
      " [13.621211 ]\n",
      " [18.953238 ]\n",
      " [21.427292 ]\n",
      " [19.527409 ]\n",
      " [18.987177 ]\n",
      " [10.722661 ]\n",
      " [21.70291  ]\n",
      " [50.667957 ]\n",
      " [13.627737 ]\n",
      " [18.128462 ]\n",
      " [19.706802 ]\n",
      " [22.763649 ]\n",
      " [18.662237 ]\n",
      " [11.654536 ]\n",
      " [19.187483 ]]\n",
      "=================\n",
      "R2 :  0.7627153605334294\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4627\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5308\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4119\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2022\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.2971\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4831\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3132\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.1888\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.3386\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.2163\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5058\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3922\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2833\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0662\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3935\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.1516\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2649\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.4076\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2923\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6915\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1430\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.1895\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3812\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1690\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1166\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2909\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2295\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.1299\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1895\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1735\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1745\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3272\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2545\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5265\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.1900\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5256\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2784\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3159\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.1646\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2577\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0503\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.1010\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1995\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1829\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0886\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2843\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2173\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.2664\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0284\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1234\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.2782\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.3767\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3263\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.3624\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1833\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.1245\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2177\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2785\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.5160\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.6316\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0401\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5413\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0930\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1055\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3645\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.0093\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3044\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1908\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0665\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3383\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.3020\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0463\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.1712\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1569\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.1064\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2373\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1407\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.9952\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2498\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.5023\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3100\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2385\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.1525\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2576\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 1.9732\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.0905\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.1235\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.1111\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 2.0967\n",
      "Epoch 90/100\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 0s 130us/step - loss: 2.0967\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 2.7756\n",
      "loss :  2.775620460510254\n",
      "5/5 [==============================] - 0s 997us/step\n",
      "=================\n",
      "[15.  26.6 45.4 20.8 34.9 21.9 28.7  7.2 20.  32.2 24.1 18.5 13.5 27.\n",
      " 23.1 18.9 24.5 43.1 19.8 13.8 15.6 50.  37.2 46.  50.  21.2 14.9 19.6\n",
      " 19.4 18.6 26.5 32.  10.9 20.  21.4 31.  25.  15.4 13.1 37.6 37.  18.9\n",
      " 27.9 50.  14.4 22.  19.9 21.6 15.6 15.  32.4 29.6 20.4 12.3 19.1 14.9\n",
      " 17.8  8.8 35.4 11.5 19.6 20.6 15.6 19.9 23.3 22.3 24.8 16.1 22.8 30.5\n",
      " 20.4 24.4 16.6 26.2 16.4 20.1 13.9 19.4 22.8 13.8 31.6 10.5 23.8 22.4\n",
      " 19.3 22.2 12.6 19.4 22.2 29.8  9.6 34.9 21.4 25.3 32.9 26.6 14.6 31.5\n",
      " 23.3 33.3 17.5 19.1 48.5 17.1 23.1 28.4 18.9 13.  17.2 24.1 18.5 21.8\n",
      " 13.3 23.  14.1 23.9 24.  17.2 21.5 19.1 20.8 36.  20.1  8.7 13.6 22.\n",
      " 22.2 21.1 13.4 17.4 20.1 10.2 23.1 10.2 13.1 14.3 14.5  7.2 19.6 20.6\n",
      " 22.7 26.4  7.5 20.3 50.   8.5 20.3 16.1 22.  19.6 10.2 23.2]\n",
      "[[13.90755  ]\n",
      " [27.860558 ]\n",
      " [44.572166 ]\n",
      " [21.441126 ]\n",
      " [28.376183 ]\n",
      " [29.093588 ]\n",
      " [29.783838 ]\n",
      " [10.085397 ]\n",
      " [17.839375 ]\n",
      " [26.11634  ]\n",
      " [24.753056 ]\n",
      " [21.255259 ]\n",
      " [13.560304 ]\n",
      " [30.884378 ]\n",
      " [22.043982 ]\n",
      " [20.767742 ]\n",
      " [22.15159  ]\n",
      " [38.03694  ]\n",
      " [20.729324 ]\n",
      " [16.62786  ]\n",
      " [15.062292 ]\n",
      " [24.7343   ]\n",
      " [37.940613 ]\n",
      " [49.975475 ]\n",
      " [48.936737 ]\n",
      " [24.354134 ]\n",
      " [20.76946  ]\n",
      " [22.789013 ]\n",
      " [23.226042 ]\n",
      " [16.1005   ]\n",
      " [23.628754 ]\n",
      " [36.100758 ]\n",
      " [11.701324 ]\n",
      " [21.207277 ]\n",
      " [22.41269  ]\n",
      " [30.632492 ]\n",
      " [25.263474 ]\n",
      " [14.572211 ]\n",
      " [14.705399 ]\n",
      " [46.31725  ]\n",
      " [30.115688 ]\n",
      " [20.129211 ]\n",
      " [20.303741 ]\n",
      " [52.574673 ]\n",
      " [19.001251 ]\n",
      " [24.895948 ]\n",
      " [22.288057 ]\n",
      " [23.407568 ]\n",
      " [17.527733 ]\n",
      " [19.399618 ]\n",
      " [39.19269  ]\n",
      " [21.346495 ]\n",
      " [22.36193  ]\n",
      " [12.376923 ]\n",
      " [19.183144 ]\n",
      " [17.731255 ]\n",
      " [13.890906 ]\n",
      " [ 7.732693 ]\n",
      " [33.797638 ]\n",
      " [13.0597515]\n",
      " [19.560863 ]\n",
      " [21.26727  ]\n",
      " [19.007828 ]\n",
      " [22.816525 ]\n",
      " [22.688766 ]\n",
      " [24.689764 ]\n",
      " [25.31958  ]\n",
      " [14.247009 ]\n",
      " [25.661726 ]\n",
      " [32.56245  ]\n",
      " [19.887253 ]\n",
      " [26.486538 ]\n",
      " [18.023155 ]\n",
      " [25.51799  ]\n",
      " [25.969501 ]\n",
      " [20.689756 ]\n",
      " [14.906992 ]\n",
      " [20.303326 ]\n",
      " [28.39028  ]\n",
      " [ 7.732693 ]\n",
      " [30.178577 ]\n",
      " [11.954364 ]\n",
      " [24.81407  ]\n",
      " [21.42692  ]\n",
      " [17.917868 ]\n",
      " [26.381474 ]\n",
      " [16.879581 ]\n",
      " [22.94835  ]\n",
      " [21.716839 ]\n",
      " [33.57577  ]\n",
      " [13.013654 ]\n",
      " [37.34725  ]\n",
      " [19.260685 ]\n",
      " [26.25     ]\n",
      " [28.398096 ]\n",
      " [30.556332 ]\n",
      " [16.35776  ]\n",
      " [37.506744 ]\n",
      " [24.820967 ]\n",
      " [40.53844  ]\n",
      " [21.731483 ]\n",
      " [16.22821  ]\n",
      " [45.569473 ]\n",
      " [14.859627 ]\n",
      " [20.18028  ]\n",
      " [24.79837  ]\n",
      " [15.727142 ]\n",
      " [15.906518 ]\n",
      " [20.562498 ]\n",
      " [22.976856 ]\n",
      " [21.792728 ]\n",
      " [24.019121 ]\n",
      " [15.882111 ]\n",
      " [19.56142  ]\n",
      " [12.721895 ]\n",
      " [25.1415   ]\n",
      " [31.68607  ]\n",
      " [10.916682 ]\n",
      " [19.75102  ]\n",
      " [20.582033 ]\n",
      " [20.526106 ]\n",
      " [35.909344 ]\n",
      " [19.927387 ]\n",
      " [ 9.548765 ]\n",
      " [15.400225 ]\n",
      " [19.566471 ]\n",
      " [22.114216 ]\n",
      " [23.795164 ]\n",
      " [19.282646 ]\n",
      " [20.217482 ]\n",
      " [21.543524 ]\n",
      " [12.964794 ]\n",
      " [19.29881  ]\n",
      " [ 7.732693 ]\n",
      " [14.339836 ]\n",
      " [13.663994 ]\n",
      " [19.313217 ]\n",
      " [12.974493 ]\n",
      " [19.909145 ]\n",
      " [22.768023 ]\n",
      " [21.12891  ]\n",
      " [20.679937 ]\n",
      " [ 9.6181965]\n",
      " [22.682549 ]\n",
      " [52.146408 ]\n",
      " [13.255099 ]\n",
      " [19.09801  ]\n",
      " [20.664474 ]\n",
      " [24.66682  ]\n",
      " [19.742983 ]\n",
      " [10.452682 ]\n",
      " [21.801842 ]]\n",
      "=================\n",
      "R2 :  0.8123512359763676\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'_io.TextIOWrapper' object has no attribute 'cloes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12108\\824409099.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"boston.h5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcloes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: '_io.TextIOWrapper' object has no attribute 'cloes'"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from sklearn.metrics import r2_score\n",
    "now = datetime.now()\n",
    "\n",
    "model.compile(loss=\"mae\",optimizer=\"adam\")\n",
    "f = open(\"C:\\study\\keras\\\\boston.txt\",'a')\n",
    "while (True):\n",
    "    model.fit(x_train,y_train,epochs=100,batch_size=4,steps_per_epoch=100)\n",
    "    loss = model.evaluate(x_test,y_test)\n",
    "    print(\"loss : \",loss)\n",
    "    y_predict =model.predict(x_test)\n",
    "    print(\"=================\")\n",
    "    print(y_test)\n",
    "    print(y_predict)\n",
    "    print(\"=================\")\n",
    "    r2 = r2_score(y_test,y_predict)\n",
    "    print(\"R2 : \",r2)\n",
    "\n",
    "    f.write(str(now)+str(r2)+\"\\n\") \n",
    "    \n",
    "    if r2 >= 0.8 :\n",
    "        model.save(\"boston.h5\")\n",
    "        f.write(str(now)+str(r2)+\"\\n\") \n",
    "        f.close()\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf27",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b47fb4e6c68d4941015efb0bbf71549277582fe8531338196fc3c7fa71b6aab8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
