{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178, 13) (178, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "# 1. 데이터 \n",
    "datasets = (load_wine())\n",
    "\n",
    "x = pd.DataFrame(datasets[\"data\"])\n",
    "y = pd.DataFrame(datasets[\"target\"])\n",
    "\n",
    "print(x.shape,y.shape)    \n",
    "\n",
    "# 분류모델이기 때문에 y를 원핫 인코딩변환 해주어야합니다.\n",
    "y = to_categorical(y)\n",
    "# print(x.describe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178, 13) (178, 3)\n",
      "[0. 1.]\n",
      "(array([0., 1.], dtype=float32), array([356, 178], dtype=int64))\n",
      "[0. 1.]\n",
      "(array([0., 1.], dtype=float32), array([356, 178], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(x.shape,y.shape) # (178, 13) (178, 1)\n",
    "\n",
    "# y의 클래스 값 분류 + 불균형확인\n",
    "print(np.unique(y)) # [0 1 2]\n",
    "print(np.unique(y,return_counts=True)) # [0 1 2]\n",
    "# \n",
    "print(np.unique(y)) # [0 1 2]\n",
    "print(np.unique(y,return_counts=True)) # [0 1 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n",
      "x_shape :  (142, 13)\n",
      "x_shape :  (36, 13)\n",
      "y_shape :  (142, 3)\n",
      "y_shape :  (36, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# print(x.info())\n",
    "# print(x.describe())\n",
    "# 데이터 분리\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "\n",
    "x_train, x_test, y_train,y_test = train_test_split(x,y,\n",
    "                                                   train_size=0.8,\n",
    "                                                   shuffle = True,\n",
    "                                                #  stratify 는 데이터 불균형을 해결해줌\n",
    "                                                   stratify=y\n",
    "                                                #    random_state=21\n",
    "                                                   )\n",
    "\n",
    "\n",
    "# x_train 을 스케일링\n",
    "# scaler = StandardScaler()\n",
    "# scaler.fit(x_train)\n",
    "# x_train_scaled = scaler.transform(x_train)\n",
    "# # x_test 를 스케일링\n",
    "# x_test = scaler.transform(x_test)\n",
    "\n",
    "\n",
    "print(y_train[:5])\n",
    "print(\"x_shape : \",x_train.shape)\n",
    "print(\"x_shape : \",x_test.shape)\n",
    "print(\"y_shape : \",y_train.shape)\n",
    "print(\"y_shape : \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(16,activation=\"relu\",input_shape=(13,)),\n",
    "    Dense(32,activation=\"relu\") ,\n",
    "    Dense(64,activation=\"relu\") ,\n",
    "    Dense(32,activation=\"relu\") ,\n",
    "    Dense(16,activation=\"relu\") ,\n",
    "    # 다중분류모델의 활성화 함수는 softmax 입니다\n",
    "    Dense(3,activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/15 [==============================] - 0s 13ms/step - loss: 4.6611 - accuracy: 0.3628 - val_loss: 2.6182 - val_accuracy: 0.4138\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.5544 - accuracy: 0.5044 - val_loss: 1.3347 - val_accuracy: 0.4483\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.1086 - accuracy: 0.4779 - val_loss: 0.9226 - val_accuracy: 0.5862\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.8640 - accuracy: 0.6903 - val_loss: 0.7731 - val_accuracy: 0.6897\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.1224 - accuracy: 0.6018 - val_loss: 0.7170 - val_accuracy: 0.7931\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.0109 - accuracy: 0.5929 - val_loss: 0.8977 - val_accuracy: 0.5172\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.8462 - accuracy: 0.5664 - val_loss: 0.7044 - val_accuracy: 0.8276\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.7337 - accuracy: 0.6814 - val_loss: 0.7475 - val_accuracy: 0.6897\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.9460 - accuracy: 0.6106 - val_loss: 0.8361 - val_accuracy: 0.6897\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.9710 - accuracy: 0.6460 - val_loss: 0.8450 - val_accuracy: 0.6897\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.9231 - accuracy: 0.6106 - val_loss: 0.8237 - val_accuracy: 0.6207\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.9830 - accuracy: 0.5575 - val_loss: 1.5443 - val_accuracy: 0.4483\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.7574 - accuracy: 0.6637 - val_loss: 1.1481 - val_accuracy: 0.4138\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.9387 - accuracy: 0.5929 - val_loss: 0.6717 - val_accuracy: 0.6897\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.8584 - accuracy: 0.6372 - val_loss: 1.2584 - val_accuracy: 0.5172\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.8453 - accuracy: 0.6195 - val_loss: 0.9622 - val_accuracy: 0.7586\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.1592 - accuracy: 0.6372 - val_loss: 0.9416 - val_accuracy: 0.5517\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.8354 - accuracy: 0.6283 - val_loss: 0.6054 - val_accuracy: 0.8276\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.5444 - accuracy: 0.7788 - val_loss: 1.2595 - val_accuracy: 0.4483\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.9293 - accuracy: 0.6549 - val_loss: 0.7477 - val_accuracy: 0.6207\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.9037 - accuracy: 0.6106 - val_loss: 1.8547 - val_accuracy: 0.4483\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.4412 - accuracy: 0.5841 - val_loss: 1.0898 - val_accuracy: 0.7241\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.3973 - accuracy: 0.6018 - val_loss: 1.3550 - val_accuracy: 0.6207\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.1855 - accuracy: 0.6549 - val_loss: 0.7620 - val_accuracy: 0.6897\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.9086 - accuracy: 0.6106 - val_loss: 0.8222 - val_accuracy: 0.6552\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.7215 - accuracy: 0.7080 - val_loss: 0.6893 - val_accuracy: 0.6897\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.6138 - accuracy: 0.7080 - val_loss: 0.6062 - val_accuracy: 0.7586\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.9772 - accuracy: 0.6549 - val_loss: 0.6983 - val_accuracy: 0.7241\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.5977 - accuracy: 0.7522 - val_loss: 0.8912 - val_accuracy: 0.5517\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.6986 - accuracy: 0.6549 - val_loss: 0.5108 - val_accuracy: 0.8276\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.5918 - accuracy: 0.7788 - val_loss: 0.7617 - val_accuracy: 0.6207\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.5355 - accuracy: 0.7965 - val_loss: 0.8937 - val_accuracy: 0.5172\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.4949 - accuracy: 0.7965 - val_loss: 0.5964 - val_accuracy: 0.8621\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.7472 - accuracy: 0.6903 - val_loss: 0.8722 - val_accuracy: 0.6207\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.5093 - accuracy: 0.7965 - val_loss: 0.7369 - val_accuracy: 0.6897\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.6000 - accuracy: 0.7522 - val_loss: 0.7817 - val_accuracy: 0.7241\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.6916 - accuracy: 0.6991 - val_loss: 0.5847 - val_accuracy: 0.7931\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.5403 - accuracy: 0.7788 - val_loss: 0.7640 - val_accuracy: 0.6552\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.6225 - accuracy: 0.7788 - val_loss: 0.4837 - val_accuracy: 0.8966\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.4379 - accuracy: 0.8230 - val_loss: 0.7922 - val_accuracy: 0.6207\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.4597 - accuracy: 0.8230 - val_loss: 0.6272 - val_accuracy: 0.7241\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.4465 - accuracy: 0.8230 - val_loss: 0.5522 - val_accuracy: 0.8276\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.9638 - accuracy: 0.6814 - val_loss: 0.5159 - val_accuracy: 0.7586\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.2422 - accuracy: 0.6283 - val_loss: 0.8368 - val_accuracy: 0.5517\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.4725 - accuracy: 0.8407 - val_loss: 0.5005 - val_accuracy: 0.7931\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.4525 - accuracy: 0.8142 - val_loss: 0.4701 - val_accuracy: 0.7586\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.4630 - accuracy: 0.8053 - val_loss: 0.6271 - val_accuracy: 0.6897\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.3796 - accuracy: 0.8673 - val_loss: 0.4786 - val_accuracy: 0.7931\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.4133 - accuracy: 0.8230 - val_loss: 0.3950 - val_accuracy: 0.8276\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.3616 - accuracy: 0.8761 - val_loss: 0.4011 - val_accuracy: 0.8966\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.3395 - accuracy: 0.9115 - val_loss: 0.3770 - val_accuracy: 0.8621\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.4460 - accuracy: 0.8230 - val_loss: 0.5101 - val_accuracy: 0.8621\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.3890 - accuracy: 0.8319 - val_loss: 0.4557 - val_accuracy: 0.8966\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.4410 - accuracy: 0.8230 - val_loss: 0.4397 - val_accuracy: 0.7931\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.3434 - accuracy: 0.8673 - val_loss: 0.4621 - val_accuracy: 0.7931\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.4975 - accuracy: 0.7876 - val_loss: 0.4275 - val_accuracy: 0.8966\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.3229 - accuracy: 0.8850 - val_loss: 0.5417 - val_accuracy: 0.7241\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.4787 - accuracy: 0.7699 - val_loss: 0.6203 - val_accuracy: 0.7931\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.4652 - accuracy: 0.8053 - val_loss: 0.4055 - val_accuracy: 0.8621\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.3485 - accuracy: 0.8496 - val_loss: 0.6701 - val_accuracy: 0.7241\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.3905 - accuracy: 0.8319 - val_loss: 0.4245 - val_accuracy: 0.8276\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.2640 - accuracy: 0.9115 - val_loss: 0.3434 - val_accuracy: 0.8276\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.2976 - accuracy: 0.8850 - val_loss: 0.3624 - val_accuracy: 0.8966\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.4039 - accuracy: 0.8230 - val_loss: 0.5517 - val_accuracy: 0.7586\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.3777 - accuracy: 0.8496 - val_loss: 0.4777 - val_accuracy: 0.7931\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.3018 - accuracy: 0.8761 - val_loss: 0.4113 - val_accuracy: 0.8966\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.2528 - accuracy: 0.9115 - val_loss: 0.4940 - val_accuracy: 0.7586\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.3218 - accuracy: 0.8850 - val_loss: 0.3126 - val_accuracy: 0.8621\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.2885 - accuracy: 0.8850 - val_loss: 0.4986 - val_accuracy: 0.8621\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.5095 - accuracy: 0.8053 - val_loss: 0.9643 - val_accuracy: 0.5172\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.5478 - accuracy: 0.7788 - val_loss: 0.2858 - val_accuracy: 0.8621\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.5947 - accuracy: 0.7965 - val_loss: 0.3218 - val_accuracy: 0.8621\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.3965 - accuracy: 0.8584 - val_loss: 0.4846 - val_accuracy: 0.8621\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.2821 - accuracy: 0.8673 - val_loss: 0.3014 - val_accuracy: 0.8621\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.2123 - accuracy: 0.9292 - val_loss: 0.4768 - val_accuracy: 0.8621\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.2747 - accuracy: 0.8673 - val_loss: 0.2875 - val_accuracy: 0.8621\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.3148 - accuracy: 0.8496 - val_loss: 0.3727 - val_accuracy: 0.8621\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.2485 - accuracy: 0.8938 - val_loss: 0.3262 - val_accuracy: 0.8966\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.2860 - accuracy: 0.9115 - val_loss: 0.2643 - val_accuracy: 0.8621\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.2495 - accuracy: 0.9204 - val_loss: 0.4421 - val_accuracy: 0.8966\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.2602 - accuracy: 0.9292 - val_loss: 0.2898 - val_accuracy: 0.8621\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.2487 - accuracy: 0.8850 - val_loss: 0.2935 - val_accuracy: 0.9310\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.2245 - accuracy: 0.9292 - val_loss: 0.3180 - val_accuracy: 0.8276\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.4176 - accuracy: 0.8407 - val_loss: 0.4964 - val_accuracy: 0.8276\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.3034 - accuracy: 0.8761 - val_loss: 0.2654 - val_accuracy: 0.8966\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.2339 - accuracy: 0.9027 - val_loss: 0.3058 - val_accuracy: 0.8621\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.2129 - accuracy: 0.9292 - val_loss: 0.2672 - val_accuracy: 0.9310\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.2430 - accuracy: 0.9115 - val_loss: 0.3305 - val_accuracy: 0.8621\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.5640 - accuracy: 0.7876 - val_loss: 0.2566 - val_accuracy: 0.8621\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.5194 - accuracy: 0.8142 - val_loss: 0.7807 - val_accuracy: 0.6207\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.4863 - accuracy: 0.8142 - val_loss: 0.2716 - val_accuracy: 0.8966\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.2204 - accuracy: 0.9204 - val_loss: 0.2965 - val_accuracy: 0.8621\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.2508 - accuracy: 0.8938 - val_loss: 0.4141 - val_accuracy: 0.8621\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.2561 - accuracy: 0.8938 - val_loss: 0.4525 - val_accuracy: 0.8621\n",
      "Epoch 00094: early stopping\n"
     ]
    }
   ],
   "source": [
    "# 이진분류는 마지막 활성함수는 sigmoid + loss 는 바이너리 크로스 엔트로피 \n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "monitor='val_loss',\n",
    "min_delta=0.01, patience=15, \n",
    "verbose=1, \n",
    "mode='min')\n",
    "\n",
    "\n",
    "# 훈련값이 int 형이기 때문에 sparse 를 사용합니다.\n",
    "model.compile(loss=\"categorical_crossentropy\"\n",
    "              ,optimizer=\"adam\"\n",
    "              ,metrics=[\"accuracy\"]\n",
    "              )\n",
    "\n",
    "hist = model.fit(x_train, y_train, epochs=100, batch_size=8, \n",
    "                 validation_split=0.2,\n",
    "                 callbacks = [early_stopping])\n",
    "\n",
    "# metrics 에 accuracy 사용가능\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4282 - accuracy: 0.8333\n",
      "loss: 0.42824646830558777 \n",
      "acc : 0.8333333134651184\n"
     ]
    }
   ],
   "source": [
    "loss,accuracy = model.evaluate(x_test,y_test)\n",
    "\n",
    "print(\"loss:\",loss,\"\\nacc :\" ,accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.1223955e-01 8.7648980e-02 1.1150778e-04]\n",
      " [1.5470512e-03 4.6673841e-03 9.9378562e-01]\n",
      " [9.8328453e-01 1.6715214e-02 2.1373363e-07]\n",
      " [8.3323389e-01 1.6669565e-01 7.0423281e-05]\n",
      " [1.7923813e-01 1.5614006e-01 6.6462183e-01]]\n",
      "예측 :  [0 2 0 0 2 1 1 0 2 2 1 1 0 0 1]\n",
      "실제 :  [0 2 0 0 2 1 1 0 2 2 0 1 0 0 1]\n",
      "========================================\n",
      "acc :  0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_predict = model.predict(x_test)\n",
    "\n",
    "# predict 의 값은 총 3개가 나오는데 softmax 특성상 sum 의 값은 1이 됨\n",
    "print(y_predict[:5])\n",
    "\n",
    "# argmax 는 x 를 최대값으로 만들어주는 입력을 구하는함수\n",
    "y_predict = np.argmax(y_predict,axis=1)\n",
    "# y_predict = to_categorical(y_predict,3)\n",
    "print(\"예측 : \", y_predict[:15])\n",
    "# y_test 를 원핫 인코딩 해제 해야함\n",
    "y_test = np.argmax(y_test,axis=1)\n",
    "print(\"실제 : \", y_test[:15])\n",
    "\n",
    "print\n",
    "print(\"========================================\")\n",
    "acc = accuracy_score(y_test,y_predict)\n",
    "print(\"acc : \",acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf274gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "10848e9bd3f5e7d93542d388001135334854454e7336dcf54c4ef52885ee0fb0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
