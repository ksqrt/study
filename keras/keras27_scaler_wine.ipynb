{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "# 1. 데이터 \n",
    "datasets = (load_wine())\n",
    "\n",
    "x = pd.DataFrame(datasets[\"data\"])\n",
    "y = pd.DataFrame(datasets[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178, 13) (178, 1)\n",
      "   0\n",
      "0  0\n",
      "1  0\n",
      "2  0\n",
      "3  0\n",
      "4  0\n",
      "[0 1 2]\n",
      "(array([0, 1, 2]), array([59, 71, 48], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "print(x.shape,y.shape) # (178, 13) (178, 1)\n",
    "print(y[:5])\n",
    "\n",
    "# y의 클래스 값 분류 + 불균형확인\n",
    "print(np.unique(y)) # [0 1 2]\n",
    "print(np.unique(y,return_counts=True)) # [0 1 2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0\n",
      "28   0\n",
      "99   1\n",
      "62   1\n",
      "164  2\n",
      "117  1\n",
      "shape :  (142, 1)\n"
     ]
    }
   ],
   "source": [
    "# print(x.info())\n",
    "# print(x.describe())\n",
    "# 데이터 분리\n",
    "x_train, x_test, y_train,y_test = train_test_split(x,y,\n",
    "                                                   train_size=0.8,\n",
    "                                                   shuffle = True,\n",
    "                                                #  stratify 는 데이터 불균형을 해결해줌\n",
    "                                                   stratify=y\n",
    "                                                #    random_state=21\n",
    "                                                   )\n",
    "# print(x.columns)\n",
    "# y 의 첫번째 칼럼을 원핫 인코딩 변환\n",
    "# y_train[0] = tf.one_hot(y_train[0],3)\n",
    "# y_test[0] = tf.one_hot(y_test[0],3)\n",
    "print(y_train[:5])\n",
    "print(\"shape : \",y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(50,activation=\"relu\",input_shape=(13,)),\n",
    "    Dense(40,activation=\"relu\") ,\n",
    "    Dense(40,activation=\"relu\") ,\n",
    "    Dense(30,activation=\"relu\") ,\n",
    "    Dense(30,activation=\"relu\") ,\n",
    "    Dense(20,activation=\"relu\") ,\n",
    "    # 다중분류모델의 활성화 함수는 softmax 입니다\n",
    "    Dense(3,activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 14.7344 - accuracy: 0.2832 - val_loss: 9.6182 - val_accuracy: 0.3448\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 10.1327 - accuracy: 0.3274 - val_loss: 7.6967 - val_accuracy: 0.3448\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 6.9529 - accuracy: 0.3894 - val_loss: 5.4791 - val_accuracy: 0.3103\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 5.1182 - accuracy: 0.2478 - val_loss: 3.7611 - val_accuracy: 0.3448\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 3.5058 - accuracy: 0.3274 - val_loss: 2.6704 - val_accuracy: 0.4138\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 2.6548 - accuracy: 0.3894 - val_loss: 2.1146 - val_accuracy: 0.3793\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1.6745 - accuracy: 0.3717 - val_loss: 0.8489 - val_accuracy: 0.5862\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.2748 - accuracy: 0.4779 - val_loss: 1.0790 - val_accuracy: 0.5862\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.8770 - accuracy: 0.5752 - val_loss: 0.9313 - val_accuracy: 0.5862\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.9837 - accuracy: 0.4867 - val_loss: 0.8842 - val_accuracy: 0.5172\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.8393 - accuracy: 0.5310 - val_loss: 0.7981 - val_accuracy: 0.5862\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7480 - accuracy: 0.6726 - val_loss: 0.7421 - val_accuracy: 0.6207\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6890 - accuracy: 0.6726 - val_loss: 0.7874 - val_accuracy: 0.5172\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6968 - accuracy: 0.6726 - val_loss: 0.7159 - val_accuracy: 0.7586\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6735 - accuracy: 0.7257 - val_loss: 0.7010 - val_accuracy: 0.6207\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6811 - accuracy: 0.6814 - val_loss: 0.7367 - val_accuracy: 0.5862\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6720 - accuracy: 0.6991 - val_loss: 0.7000 - val_accuracy: 0.7586\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6391 - accuracy: 0.6991 - val_loss: 0.7802 - val_accuracy: 0.5517\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6560 - accuracy: 0.6814 - val_loss: 0.6751 - val_accuracy: 0.6207\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6534 - accuracy: 0.7168 - val_loss: 0.6833 - val_accuracy: 0.6552\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6528 - accuracy: 0.6903 - val_loss: 0.6689 - val_accuracy: 0.6897\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6520 - accuracy: 0.7080 - val_loss: 0.6790 - val_accuracy: 0.6897\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6263 - accuracy: 0.7345 - val_loss: 0.7012 - val_accuracy: 0.6552\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6337 - accuracy: 0.7257 - val_loss: 0.6514 - val_accuracy: 0.6897\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6125 - accuracy: 0.7345 - val_loss: 0.6868 - val_accuracy: 0.6207\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6024 - accuracy: 0.7168 - val_loss: 0.6402 - val_accuracy: 0.6897\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6061 - accuracy: 0.7522 - val_loss: 0.6815 - val_accuracy: 0.6552\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5982 - accuracy: 0.7168 - val_loss: 0.6832 - val_accuracy: 0.6552\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5997 - accuracy: 0.7168 - val_loss: 0.6293 - val_accuracy: 0.6897\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5844 - accuracy: 0.7611 - val_loss: 0.7052 - val_accuracy: 0.6207\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6015 - accuracy: 0.7080 - val_loss: 0.6285 - val_accuracy: 0.6897\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5962 - accuracy: 0.7257 - val_loss: 0.6266 - val_accuracy: 0.7241\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5823 - accuracy: 0.7611 - val_loss: 0.6523 - val_accuracy: 0.7241\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5878 - accuracy: 0.7434 - val_loss: 0.6377 - val_accuracy: 0.6897\n",
      "Epoch 00034: early stopping\n"
     ]
    }
   ],
   "source": [
    "# 이진분류는 마지막 활성함수는 sigmoid + loss 는 바이너리 크로스 엔트로피 \n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "monitor='val_loss',\n",
    "min_delta=0.01, patience=5, \n",
    "verbose=1, \n",
    "mode='min')\n",
    "\n",
    "# 훈련값이 int 형이기 때문에 sparse 를 사용합니다.\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\"\n",
    "              ,optimizer=\"adam\"\n",
    "              ,metrics=[\"accuracy\"]\n",
    "              )\n",
    "\n",
    "hist = model.fit(x_train, y_train, epochs=100, batch_size=32, \n",
    "                 validation_split=0.2,\n",
    "                 callbacks = [early_stopping])\n",
    "\n",
    "# metrics 에 accuracy 사용가능\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5525 - accuracy: 0.6944\n",
      "loss: 0.5525143146514893 \n",
      "acc : 0.6944444179534912\n"
     ]
    }
   ],
   "source": [
    "loss,accuracy = model.evaluate(x_test,y_test)\n",
    "\n",
    "print(\"loss:\",loss,\"\\nacc :\" ,accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.05466958 0.5216007  0.42372966]\n",
      " [0.02895259 0.8273524  0.14369504]\n",
      " [0.02493191 0.7282793  0.2467887 ]\n",
      " [0.41090173 0.28698963 0.3021086 ]\n",
      " [0.22239135 0.40059936 0.37700933]]\n",
      "[1 1 1 0 1]\n",
      "     0\n",
      "165  0\n",
      "105  0\n",
      "85   0\n",
      "82   0\n",
      "129  0\n",
      "========================================\n",
      "0.3888888888888889\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_predict = model.predict(x_test)\n",
    "\n",
    "# predict 의 값은 총 3개가 나오는데 softmax 특성상 sum 의 값은 1이 됨\n",
    "print(y_predict[:5])\n",
    "\n",
    "# argmax 는 x 를 최대값으로 만들어주는 입력을 구하는함수\n",
    "y_predict = np.argmax(y_predict,axis=1)\n",
    "# y_predict = to_categorical(y_predict,3)\n",
    "print(y_predict[:5])\n",
    "# y_test 를 원핫 인코딩 해제 해야함\n",
    "print(y_test[:5])\n",
    "\n",
    "print\n",
    "print(\"========================================\")\n",
    "acc = accuracy_score(y_test,y_predict)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf274gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov 24 2022, 14:39:17) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "10848e9bd3f5e7d93542d388001135334854454e7336dcf54c4ef52885ee0fb0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
