{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,SimpleRNN,LSTM,GRU,Dropout,Bidirectional,Conv1D\n",
    "\n",
    "\n",
    "a = np.array(range(1,101))\n",
    "x_predict = np.array(range(96,106))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96, 5)\n",
      "[[1 2 3 4]\n",
      " [2 3 4 5]\n",
      " [3 4 5 6]\n",
      " [4 5 6 7]\n",
      " [5 6 7 8]] \n",
      " ========================== \n",
      " [5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "def split_x(dataset,timesteps) : \n",
    "    tmp = []\n",
    "    for i in range(len(dataset)-timesteps + 1):\n",
    "        subset = dataset[i : (i+ timesteps)]\n",
    "        tmp.append(subset)\n",
    "    return np.array(tmp)\n",
    "\n",
    "bbb = split_x(a,5)\n",
    "\n",
    "print(bbb.shape)\n",
    "\n",
    "x = bbb[:,:-1]\n",
    "y = bbb[:,-1]\n",
    "\n",
    "print(x[:5:],\"\\n ========================== \\n\",y[:5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96, 4) (96,)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96, 2, 2)\n",
      "[[[ 1  2]\n",
      "  [ 3  4]]\n",
      "\n",
      " [[ 2  3]\n",
      "  [ 4  5]]\n",
      "\n",
      " [[ 3  4]\n",
      "  [ 5  6]]\n",
      "\n",
      " [[ 4  5]\n",
      "  [ 6  7]]\n",
      "\n",
      " [[ 5  6]\n",
      "  [ 7  8]]\n",
      "\n",
      " [[ 6  7]\n",
      "  [ 8  9]]\n",
      "\n",
      " [[ 7  8]\n",
      "  [ 9 10]]\n",
      "\n",
      " [[ 8  9]\n",
      "  [10 11]]\n",
      "\n",
      " [[ 9 10]\n",
      "  [11 12]]\n",
      "\n",
      " [[10 11]\n",
      "  [12 13]]\n",
      "\n",
      " [[11 12]\n",
      "  [13 14]]\n",
      "\n",
      " [[12 13]\n",
      "  [14 15]]\n",
      "\n",
      " [[13 14]\n",
      "  [15 16]]\n",
      "\n",
      " [[14 15]\n",
      "  [16 17]]\n",
      "\n",
      " [[15 16]\n",
      "  [17 18]]\n",
      "\n",
      " [[16 17]\n",
      "  [18 19]]\n",
      "\n",
      " [[17 18]\n",
      "  [19 20]]\n",
      "\n",
      " [[18 19]\n",
      "  [20 21]]\n",
      "\n",
      " [[19 20]\n",
      "  [21 22]]\n",
      "\n",
      " [[20 21]\n",
      "  [22 23]]\n",
      "\n",
      " [[21 22]\n",
      "  [23 24]]\n",
      "\n",
      " [[22 23]\n",
      "  [24 25]]\n",
      "\n",
      " [[23 24]\n",
      "  [25 26]]\n",
      "\n",
      " [[24 25]\n",
      "  [26 27]]\n",
      "\n",
      " [[25 26]\n",
      "  [27 28]]\n",
      "\n",
      " [[26 27]\n",
      "  [28 29]]\n",
      "\n",
      " [[27 28]\n",
      "  [29 30]]\n",
      "\n",
      " [[28 29]\n",
      "  [30 31]]\n",
      "\n",
      " [[29 30]\n",
      "  [31 32]]\n",
      "\n",
      " [[30 31]\n",
      "  [32 33]]\n",
      "\n",
      " [[31 32]\n",
      "  [33 34]]\n",
      "\n",
      " [[32 33]\n",
      "  [34 35]]\n",
      "\n",
      " [[33 34]\n",
      "  [35 36]]\n",
      "\n",
      " [[34 35]\n",
      "  [36 37]]\n",
      "\n",
      " [[35 36]\n",
      "  [37 38]]\n",
      "\n",
      " [[36 37]\n",
      "  [38 39]]\n",
      "\n",
      " [[37 38]\n",
      "  [39 40]]\n",
      "\n",
      " [[38 39]\n",
      "  [40 41]]\n",
      "\n",
      " [[39 40]\n",
      "  [41 42]]\n",
      "\n",
      " [[40 41]\n",
      "  [42 43]]\n",
      "\n",
      " [[41 42]\n",
      "  [43 44]]\n",
      "\n",
      " [[42 43]\n",
      "  [44 45]]\n",
      "\n",
      " [[43 44]\n",
      "  [45 46]]\n",
      "\n",
      " [[44 45]\n",
      "  [46 47]]\n",
      "\n",
      " [[45 46]\n",
      "  [47 48]]\n",
      "\n",
      " [[46 47]\n",
      "  [48 49]]\n",
      "\n",
      " [[47 48]\n",
      "  [49 50]]\n",
      "\n",
      " [[48 49]\n",
      "  [50 51]]\n",
      "\n",
      " [[49 50]\n",
      "  [51 52]]\n",
      "\n",
      " [[50 51]\n",
      "  [52 53]]\n",
      "\n",
      " [[51 52]\n",
      "  [53 54]]\n",
      "\n",
      " [[52 53]\n",
      "  [54 55]]\n",
      "\n",
      " [[53 54]\n",
      "  [55 56]]\n",
      "\n",
      " [[54 55]\n",
      "  [56 57]]\n",
      "\n",
      " [[55 56]\n",
      "  [57 58]]\n",
      "\n",
      " [[56 57]\n",
      "  [58 59]]\n",
      "\n",
      " [[57 58]\n",
      "  [59 60]]\n",
      "\n",
      " [[58 59]\n",
      "  [60 61]]\n",
      "\n",
      " [[59 60]\n",
      "  [61 62]]\n",
      "\n",
      " [[60 61]\n",
      "  [62 63]]\n",
      "\n",
      " [[61 62]\n",
      "  [63 64]]\n",
      "\n",
      " [[62 63]\n",
      "  [64 65]]\n",
      "\n",
      " [[63 64]\n",
      "  [65 66]]\n",
      "\n",
      " [[64 65]\n",
      "  [66 67]]\n",
      "\n",
      " [[65 66]\n",
      "  [67 68]]\n",
      "\n",
      " [[66 67]\n",
      "  [68 69]]\n",
      "\n",
      " [[67 68]\n",
      "  [69 70]]\n",
      "\n",
      " [[68 69]\n",
      "  [70 71]]\n",
      "\n",
      " [[69 70]\n",
      "  [71 72]]\n",
      "\n",
      " [[70 71]\n",
      "  [72 73]]\n",
      "\n",
      " [[71 72]\n",
      "  [73 74]]\n",
      "\n",
      " [[72 73]\n",
      "  [74 75]]\n",
      "\n",
      " [[73 74]\n",
      "  [75 76]]\n",
      "\n",
      " [[74 75]\n",
      "  [76 77]]\n",
      "\n",
      " [[75 76]\n",
      "  [77 78]]\n",
      "\n",
      " [[76 77]\n",
      "  [78 79]]\n",
      "\n",
      " [[77 78]\n",
      "  [79 80]]\n",
      "\n",
      " [[78 79]\n",
      "  [80 81]]\n",
      "\n",
      " [[79 80]\n",
      "  [81 82]]\n",
      "\n",
      " [[80 81]\n",
      "  [82 83]]\n",
      "\n",
      " [[81 82]\n",
      "  [83 84]]\n",
      "\n",
      " [[82 83]\n",
      "  [84 85]]\n",
      "\n",
      " [[83 84]\n",
      "  [85 86]]\n",
      "\n",
      " [[84 85]\n",
      "  [86 87]]\n",
      "\n",
      " [[85 86]\n",
      "  [87 88]]\n",
      "\n",
      " [[86 87]\n",
      "  [88 89]]\n",
      "\n",
      " [[87 88]\n",
      "  [89 90]]\n",
      "\n",
      " [[88 89]\n",
      "  [90 91]]\n",
      "\n",
      " [[89 90]\n",
      "  [91 92]]\n",
      "\n",
      " [[90 91]\n",
      "  [92 93]]\n",
      "\n",
      " [[91 92]\n",
      "  [93 94]]\n",
      "\n",
      " [[92 93]\n",
      "  [94 95]]\n",
      "\n",
      " [[93 94]\n",
      "  [95 96]]\n",
      "\n",
      " [[94 95]\n",
      "  [96 97]]\n",
      "\n",
      " [[95 96]\n",
      "  [97 98]]\n",
      "\n",
      " [[96 97]\n",
      "  [98 99]]]\n"
     ]
    }
   ],
   "source": [
    "# 모델을 리쉐이프해서 7개 데이터 를 (3,1) 로 만들자\n",
    "x = x.reshape(len(x),2,2)\n",
    "print(x.shape)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96, 2, 2) (96,)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96, 2, 2) (96,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train,y_test = train_test_split(\n",
    "    x,y, shuffle = True,\n",
    "    train_size=0.7,\n",
    "\n",
    "    \n",
    ")\n",
    "print(x.shape,y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_18 (Conv1D)          (None, 1, 128)            640       \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 1, 16)             2064      \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 1, 1)              17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,721\n",
      "Trainable params: 2,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# RNN 모델구성 + 리턴시퀀스 적용\n",
    "model = Sequential([\n",
    "    Conv1D(128,kernel_size=2,input_shape=(2,2)),\n",
    "    Dense(16,activation=\"relu\"),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "67/67 [==============================] - 6s 3ms/step - loss: 11.7902\n",
      "Epoch 2/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 7.2288\n",
      "Epoch 3/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 5.0470\n",
      "Epoch 4/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 5.3378\n",
      "Epoch 5/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 5.3347\n",
      "Epoch 6/100\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 5.0421\n",
      "Epoch 7/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 4.9760\n",
      "Epoch 8/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 4.0533\n",
      "Epoch 9/100\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 4.1634\n",
      "Epoch 10/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 5.1170\n",
      "Epoch 11/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 3.9845\n",
      "Epoch 12/100\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 4.5462\n",
      "Epoch 13/100\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 3.6739\n",
      "Epoch 14/100\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 3.9982\n",
      "Epoch 15/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 3.2271\n",
      "Epoch 16/100\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 3.8630\n",
      "Epoch 17/100\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.6592\n",
      "Epoch 18/100\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 3.3262\n",
      "Epoch 19/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 3.4185\n",
      "Epoch 20/100\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 3.2884\n",
      "Epoch 21/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 2.8679\n",
      "Epoch 22/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 4.3880\n",
      "Epoch 23/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 2.6603\n",
      "Epoch 24/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 3.5842\n",
      "Epoch 25/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 3.8232\n",
      "Epoch 26/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 3.0411\n",
      "Epoch 27/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 3.1680\n",
      "Epoch 28/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 3.1322\n",
      "Epoch 29/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 3.0283\n",
      "Epoch 30/100\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.6943\n",
      "Epoch 31/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 2.6292\n",
      "Epoch 32/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 2.7746\n",
      "Epoch 33/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 3.1529\n",
      "Epoch 34/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 3.3698\n",
      "Epoch 35/100\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 3.3280\n",
      "Epoch 36/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 4.0933\n",
      "Epoch 37/100\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.6558\n",
      "Epoch 38/100\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.2980\n",
      "Epoch 39/100\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 3.2300\n",
      "Epoch 40/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 3.3389\n",
      "Epoch 41/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 3.1768\n",
      "Epoch 42/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 2.9348\n",
      "Epoch 43/100\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 3.6674\n",
      "Epoch 44/100\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.9607\n",
      "Epoch 45/100\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.5953\n",
      "Epoch 46/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 3.7553\n",
      "Epoch 47/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 2.2741\n",
      "Epoch 48/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 2.6264\n",
      "Epoch 49/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 2.7354\n",
      "Epoch 50/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 3.2284\n",
      "Epoch 51/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 3.2916\n",
      "Epoch 52/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 2.8772\n",
      "Epoch 53/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 3.0651\n",
      "Epoch 54/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 3.0232\n",
      "Epoch 55/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 3.0142\n",
      "Epoch 56/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 3.1336\n",
      "Epoch 57/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 2.6631\n",
      "Epoch 58/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 2.9260\n",
      "Epoch 59/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 3.6135\n",
      "Epoch 60/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 2.3452\n",
      "Epoch 61/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 3.0321\n",
      "Epoch 62/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 2.7858\n",
      "Epoch 63/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 2.9259\n",
      "Epoch 64/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 2.0745\n",
      "Epoch 65/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 3.2231\n",
      "Epoch 66/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 3.0116\n",
      "Epoch 67/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 3.0002\n",
      "Epoch 68/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 3.1105\n",
      "Epoch 69/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 2.8621\n",
      "Epoch 70/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 2.4523\n",
      "Epoch 71/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 2.7171\n",
      "Epoch 72/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 2.9327\n",
      "Epoch 73/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 3.0781\n",
      "Epoch 74/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 2.3902\n",
      "Epoch 75/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 3.6541\n",
      "Epoch 76/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 2.9305\n",
      "Epoch 77/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 2.0613\n",
      "Epoch 78/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 2.5578\n",
      "Epoch 79/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 3.1437\n",
      "Epoch 80/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 4.2102\n",
      "Epoch 81/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 2.5990\n",
      "Epoch 82/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 2.2459\n",
      "Epoch 83/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 2.3183\n",
      "Epoch 84/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 3.0925\n",
      "Epoch 85/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 2.7261\n",
      "Epoch 86/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 2.2768\n",
      "Epoch 87/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 2.9100\n",
      "Epoch 88/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 2.3085\n",
      "Epoch 89/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 2.9226\n",
      "Epoch 90/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 2.9876\n",
      "Epoch 91/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 3.0348\n",
      "Epoch 92/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 2.4540\n",
      "Epoch 93/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 3.4030\n",
      "Epoch 94/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 2.7743\n",
      "Epoch 95/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 2.7207\n",
      "Epoch 96/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 2.3496\n",
      "Epoch 97/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 2.9155\n",
      "Epoch 98/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 2.7023\n",
      "Epoch 99/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 3.6600\n",
      "Epoch 100/100\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 2.8226\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25a672f9730>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 컴파일 훈련\n",
    "model.compile(loss=\"mae\",optimizer=\"adam\")\n",
    "model.fit(x_train,y_train,epochs=100,batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step - loss: 10.5934\n",
      "10.59337329864502\n"
     ]
    }
   ],
   "source": [
    "loss = model.evaluate(x,y)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 2, 2)\n",
      "결과 \n",
      " [[[ 97.253   ]]\n",
      "\n",
      " [[ 98.22555 ]]\n",
      "\n",
      " [[ 99.198074]]\n",
      "\n",
      " [[100.170616]]\n",
      "\n",
      " [[101.14314 ]]\n",
      "\n",
      " [[102.115685]]\n",
      "\n",
      " [[103.08822 ]]]\n"
     ]
    }
   ],
   "source": [
    "x_predict = np.array(range(96,106))\n",
    "x_predict = split_x(x_predict,4)\n",
    "\n",
    "# x_predict.shape\n",
    "x_predict = x_predict.reshape(7,2,2)\n",
    "print(x_predict.shape)\n",
    "# (7,4) - > (7,4,1)\n",
    "result = model.predict(x_predict)\n",
    "print(\"결과 \\n\",result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "결과 [[[97.253006]]]\n"
     ]
    }
   ],
   "source": [
    "test = np.array([[[96, 97],[98, 99]]])\n",
    "\n",
    "# print(test.shape)\n",
    "\n",
    "result = model.predict(test)\n",
    "print(\"결과\",result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 141ms/step - loss: 28.9607\n",
      "28.960681915283203\n"
     ]
    }
   ],
   "source": [
    "loss = model.evaluate(x_test,y_test)\n",
    "\n",
    "print(loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf274gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "10848e9bd3f5e7d93542d388001135334854454e7336dcf54c4ef52885ee0fb0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
