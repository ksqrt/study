{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 160 images belonging to 2 classes.\n",
      "Found 120 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    # 이미지 반전\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    rotation_range=5,\n",
    "    zoom_range=1.2,\n",
    "    shear_range=0.7,\n",
    "    fill_mode=\"nearest\"\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale =1./255\n",
    ")\n",
    "\n",
    "xy_train = train_datagen.flow_from_directory(\n",
    "    \"./brain/train/\",\n",
    "    target_size = (100,100),\n",
    "    batch_size =1000,\n",
    "    class_mode= \"binary\",\n",
    "    color_mode = \"grayscale\",\n",
    "    shuffle=True,\n",
    "    # Found 160 images belonging to 2 classes.\n",
    ")\n",
    "\n",
    "xy_test = train_datagen.flow_from_directory(\n",
    "    \"./brain/test/\",\n",
    "    target_size = (100,100),\n",
    "    batch_size =10,\n",
    "    class_mode= \"binary\",\n",
    "    color_mode = \"grayscale\",\n",
    "    shuffle=True,\n",
    "    # Found 160 images belonging to 2 classes.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_24 (Conv2D)          (None, 99, 99, 64)        320       \n",
      "                                                                 \n",
      " conv2d_25 (Conv2D)          (None, 97, 97, 64)        36928     \n",
      "                                                                 \n",
      " conv2d_26 (Conv2D)          (None, 95, 95, 32)        18464     \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 288800)            0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 16)                4620816   \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,676,545\n",
      "Trainable params: 4,676,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 정의\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Conv2D,Flatten\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(64,(2,2),input_shape=(100,100,1)),\n",
    "    Conv2D(64,(3,3),activation=\"relu\"),\n",
    "    Conv2D(32,(3,3),activation=\"relu\"),\n",
    "    Flatten(),\n",
    "    Dense(16,activation=\"relu\"),\n",
    "    Dense(1,activation=\"softmax\"),\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bitcamp\\AppData\\Local\\Temp\\ipykernel_7584\\1364006038.py:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  hist = model.fit_generator(xy_train,steps_per_epoch=16,epochs=100,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 39ms/step - loss: 0.7537 - acc: 0.5000 - val_loss: 0.9673 - val_acc: 0.4250\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.7091 - acc: 0.5000 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6929 - val_acc: 0.4500\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6936 - val_acc: 0.6000\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6933 - val_acc: 0.5250\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6940 - val_acc: 0.6250\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6938 - val_acc: 0.6250\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6933 - val_acc: 0.5250\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6933 - val_acc: 0.5250\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6927 - val_acc: 0.4000\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6934 - val_acc: 0.5500\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6931 - val_acc: 0.4750\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6932 - val_acc: 0.5250\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6930 - val_acc: 0.4750\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6928 - val_acc: 0.4000\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6934 - val_acc: 0.6000\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6933 - val_acc: 0.5500\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.6933 - acc: 0.5000 - val_loss: 0.6934 - val_acc: 0.5500\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6928 - val_acc: 0.4000\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6933 - val_acc: 0.6000\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6930 - val_acc: 0.4500\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6931 - val_acc: 0.4750\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.6933 - acc: 0.5000 - val_loss: 0.6930 - val_acc: 0.4000\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6928 - val_acc: 0.3750\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6931 - val_acc: 0.4750\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6933 - val_acc: 0.5250\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6929 - val_acc: 0.4000\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6932 - val_acc: 0.5500\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6932 - val_acc: 0.5500\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6931 - val_acc: 0.4750\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6930 - val_acc: 0.4500\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6933 - val_acc: 0.5500\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6931 - val_acc: 0.4750\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6930 - val_acc: 0.4750\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6931 - val_acc: 0.4750\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6931 - val_acc: 0.4750\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6936 - val_acc: 0.6250\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6929 - val_acc: 0.3750\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6930 - val_acc: 0.4000\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6932 - val_acc: 0.5500\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6931 - val_acc: 0.4750\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6932 - val_acc: 0.5500\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6932 - val_acc: 0.5500\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6933 - val_acc: 0.6000\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6931 - val_acc: 0.4500\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6932 - val_acc: 0.4250\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6932 - val_acc: 0.5500\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6931 - val_acc: 0.4750\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6932 - val_acc: 0.5250\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6930 - val_acc: 0.4500\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6931 - val_acc: 0.4000\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6931 - val_acc: 0.4750\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6931 - val_acc: 0.4750\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6930 - val_acc: 0.4000\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6930 - val_acc: 0.4000\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6932 - val_acc: 0.5500\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6932 - val_acc: 0.5250\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6931 - val_acc: 0.4500\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6932 - val_acc: 0.5500\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6932 - val_acc: 0.4750\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6932 - val_acc: 0.5500\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6932 - val_acc: 0.5250\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6931 - val_acc: 0.4250\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6931 - val_acc: 0.4750\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6932 - val_acc: 0.4500\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6931 - val_acc: 0.4750\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6932 - val_acc: 0.5500\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6931 - val_acc: 0.5250\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6931 - val_acc: 0.4750\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6931 - val_acc: 0.5250\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6931 - val_acc: 0.4500\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6932 - val_acc: 0.4500\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.6933 - acc: 0.5000 - val_loss: 0.6932 - val_acc: 0.4750\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.6931 - acc: 0.5000 - val_loss: 0.6931 - val_acc: 0.5250\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6932 - val_acc: 0.6000\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6932 - val_acc: 0.5500\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6931 - val_acc: 0.4250\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6932 - val_acc: 0.5750\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6932 - val_acc: 0.4500\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6932 - val_acc: 0.4750\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.6931 - acc: 0.5000 - val_loss: 0.6931 - val_acc: 0.4750\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6933 - val_acc: 0.6250\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6932 - val_acc: 0.5750\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6931 - val_acc: 0.4000\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6931 - val_acc: 0.6250\n"
     ]
    }
   ],
   "source": [
    "# 모델 컴파일 훈련\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=[\"acc\"])\n",
    "\n",
    "# hist = model.fit_generator(xy_train,steps_per_epoch=16,epochs=100,\n",
    "#                            validation_data= xy_test,\n",
    "#                            validation_steps=4,\n",
    "#                            )\n",
    "\n",
    "hist = model.fit(xy_train[0][0],xy_train[0][1],epochs=100,steps_per_epoch=16\n",
    "                 validation_data=(xy_test[0][0],xy_test[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc :  0.5\n",
      "val_acc :  0.625\n"
     ]
    }
   ],
   "source": [
    "accuracy = hist.history[\"acc\"]\n",
    "val_acc = hist.history[\"val_acc\"]\n",
    "\n",
    "print(\"acc : \",accuracy[-1])\n",
    "print(\"val_acc : \",val_acc[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss :  0.6931729912757874\n",
      "val_loss :  0.6930820345878601\n"
     ]
    }
   ],
   "source": [
    "loss = hist.history[\"loss\"]\n",
    "val_loss = hist.history[\"val_loss\"]\n",
    "\n",
    "print(\"loss : \",loss[-1])\n",
    "print(\"val_loss : \",val_loss[-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf274gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "10848e9bd3f5e7d93542d388001135334854454e7336dcf54c4ef52885ee0fb0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
