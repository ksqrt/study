{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 160 images belonging to 2 classes.\n",
      "Found 120 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    # 이미지 반전\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    rotation_range=5,\n",
    "    zoom_range=1.2,\n",
    "    shear_range=0.7,\n",
    "    fill_mode=\"nearest\"\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale =1./255\n",
    ")\n",
    "\n",
    "xy_train = train_datagen.flow_from_directory(\n",
    "    \"./brain/train/\",\n",
    "    target_size = (100,100),\n",
    "    batch_size =1000,\n",
    "    class_mode= \"binary\",\n",
    "    color_mode = \"grayscale\",\n",
    "    shuffle=True,\n",
    "    # Found 160 images belonging to 2 classes.\n",
    ")\n",
    "\n",
    "xy_test = train_datagen.flow_from_directory(\n",
    "    \"./brain/test/\",\n",
    "    target_size = (100,100),\n",
    "    batch_size =10,\n",
    "    class_mode= \"binary\",\n",
    "    color_mode = \"grayscale\",\n",
    "    shuffle=True,\n",
    "    # Found 160 images belonging to 2 classes.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 99, 99, 64)        320       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 97, 97, 64)        36928     \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 95, 95, 32)        18464     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 288800)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                4620816   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,676,545\n",
      "Trainable params: 4,676,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 정의\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Conv2D,Flatten\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(64,(2,2),input_shape=(100,100,1)),\n",
    "    Conv2D(64,(3,3),activation=\"relu\"),\n",
    "    Conv2D(32,(3,3),activation=\"relu\"),\n",
    "    Flatten(),\n",
    "    Dense(16,activation=\"relu\"),\n",
    "    Dense(1,activation=\"sigmoid\"),\n",
    "    Dense(2,activation=\"softmax\"),\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 [==============================] - 4s 20ms/step - loss: 0.7063 - acc: 0.5000 - val_loss: 0.7532 - val_acc: 0.3000\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.6969 - acc: 0.5000 - val_loss: 0.6929 - val_acc: 0.3000\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.6949 - acc: 0.5000 - val_loss: 0.6925 - val_acc: 0.3000\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.7147 - acc: 0.5000 - val_loss: 0.6720 - val_acc: 0.3000\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.6935 - acc: 0.5000 - val_loss: 0.6928 - val_acc: 0.3000\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.6930 - acc: 0.5000 - val_loss: 0.6983 - val_acc: 0.3000\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.6868 - acc: 0.5000 - val_loss: 0.6536 - val_acc: 0.3000\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.6831 - acc: 0.5000 - val_loss: 0.6472 - val_acc: 0.3000\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.5788 - acc: 0.5000 - val_loss: 0.6105 - val_acc: 0.3000\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.4305 - acc: 0.5000 - val_loss: 0.7979 - val_acc: 0.3000\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.3094 - acc: 0.5000 - val_loss: 1.1021 - val_acc: 0.3000\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.1370 - acc: 0.5000 - val_loss: 1.2622 - val_acc: 0.3000\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0651 - acc: 0.5000 - val_loss: 1.6533 - val_acc: 0.3000\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0574 - acc: 0.5000 - val_loss: 2.4438 - val_acc: 0.3000\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0140 - acc: 0.5000 - val_loss: 2.2966 - val_acc: 0.3000\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0050 - acc: 0.5000 - val_loss: 2.2251 - val_acc: 0.3000\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0036 - acc: 0.5000 - val_loss: 2.9418 - val_acc: 0.3000\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0014 - acc: 0.5000 - val_loss: 2.5000 - val_acc: 0.3000\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0014 - acc: 0.5000 - val_loss: 2.6181 - val_acc: 0.3000\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 5.2758e-04 - acc: 0.5000 - val_loss: 2.9418 - val_acc: 0.3000\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 2.2655e-04 - acc: 0.5000 - val_loss: 3.1129 - val_acc: 0.3000\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.2923e-04 - acc: 0.5000 - val_loss: 3.2257 - val_acc: 0.3000\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.1034e-04 - acc: 0.5000 - val_loss: 3.3188 - val_acc: 0.3000\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 9.2976e-05 - acc: 0.5000 - val_loss: 3.3709 - val_acc: 0.3000\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 8.3265e-05 - acc: 0.5000 - val_loss: 3.4263 - val_acc: 0.3000\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 7.3260e-05 - acc: 0.5000 - val_loss: 3.4639 - val_acc: 0.3000\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 6.6865e-05 - acc: 0.5000 - val_loss: 3.4980 - val_acc: 0.3000\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 6.0096e-05 - acc: 0.5000 - val_loss: 3.5299 - val_acc: 0.3000\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 5.4314e-05 - acc: 0.5000 - val_loss: 3.5497 - val_acc: 0.3000\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 4.8214e-05 - acc: 0.5000 - val_loss: 3.5719 - val_acc: 0.3000\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 4.2879e-05 - acc: 0.5000 - val_loss: 3.6007 - val_acc: 0.3000\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 3.4721e-05 - acc: 0.5000 - val_loss: 3.5778 - val_acc: 0.3000\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 2.6954e-05 - acc: 0.5000 - val_loss: 3.5752 - val_acc: 0.3000\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.9807e-05 - acc: 0.5000 - val_loss: 3.6226 - val_acc: 0.3000\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4708e-05 - acc: 0.5000 - val_loss: 3.7024 - val_acc: 0.3000\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4366e-05 - acc: 0.5000 - val_loss: 3.7956 - val_acc: 0.3000\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 6.7797e-06 - acc: 0.5000 - val_loss: 3.8175 - val_acc: 0.3000\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 5.2031e-06 - acc: 0.5000 - val_loss: 3.8740 - val_acc: 0.3000\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 3.6194e-06 - acc: 0.5000 - val_loss: 3.8803 - val_acc: 0.3000\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 2.9045e-06 - acc: 0.5000 - val_loss: 3.9473 - val_acc: 0.3000\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 2.3429e-06 - acc: 0.5000 - val_loss: 3.9499 - val_acc: 0.3000\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.9125e-06 - acc: 0.5000 - val_loss: 4.0190 - val_acc: 0.3000\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.6140e-06 - acc: 0.5000 - val_loss: 3.9895 - val_acc: 0.3000\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4239e-06 - acc: 0.5000 - val_loss: 3.9913 - val_acc: 0.3000\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.2434e-06 - acc: 0.5000 - val_loss: 4.0460 - val_acc: 0.3000\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.0981e-06 - acc: 0.5000 - val_loss: 4.0657 - val_acc: 0.3000\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.0055e-06 - acc: 0.5000 - val_loss: 4.0647 - val_acc: 0.3000\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 9.0090e-07 - acc: 0.5000 - val_loss: 4.1052 - val_acc: 0.3000\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 8.1884e-07 - acc: 0.5000 - val_loss: 4.0923 - val_acc: 0.3000\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 7.3811e-07 - acc: 0.5000 - val_loss: 4.1354 - val_acc: 0.3000\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 6.8108e-07 - acc: 0.5000 - val_loss: 4.1243 - val_acc: 0.3000\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 6.2695e-07 - acc: 0.5000 - val_loss: 4.1672 - val_acc: 0.3000\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 5.8521e-07 - acc: 0.5000 - val_loss: 4.1551 - val_acc: 0.3000\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 5.4146e-07 - acc: 0.5000 - val_loss: 4.1876 - val_acc: 0.3000\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 5.0446e-07 - acc: 0.5000 - val_loss: 4.1911 - val_acc: 0.3000\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 4.7077e-07 - acc: 0.5000 - val_loss: 4.2086 - val_acc: 0.3000\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 4.4294e-07 - acc: 0.5000 - val_loss: 4.2046 - val_acc: 0.3000\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 4.1548e-07 - acc: 0.5000 - val_loss: 4.2418 - val_acc: 0.3000\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 3.9049e-07 - acc: 0.5000 - val_loss: 4.2347 - val_acc: 0.3000\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 3.6927e-07 - acc: 0.5000 - val_loss: 4.2357 - val_acc: 0.3000\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 3.4882e-07 - acc: 0.5000 - val_loss: 4.2683 - val_acc: 0.3000\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 3.3021e-07 - acc: 0.5000 - val_loss: 4.2818 - val_acc: 0.3000\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 3.1289e-07 - acc: 0.5000 - val_loss: 4.2627 - val_acc: 0.3000\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 2.9757e-07 - acc: 0.5000 - val_loss: 4.2853 - val_acc: 0.3000\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 2.8364e-07 - acc: 0.5000 - val_loss: 4.2807 - val_acc: 0.3000\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 2.6997e-07 - acc: 0.5000 - val_loss: 4.3146 - val_acc: 0.3000\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 2.5699e-07 - acc: 0.5000 - val_loss: 4.3163 - val_acc: 0.3000\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 2.4478e-07 - acc: 0.5000 - val_loss: 4.3032 - val_acc: 0.3000\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 2.3471e-07 - acc: 0.5000 - val_loss: 4.3213 - val_acc: 0.3000\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 2.2626e-07 - acc: 0.5000 - val_loss: 4.3350 - val_acc: 0.3000\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 2.1595e-07 - acc: 0.5000 - val_loss: 4.3349 - val_acc: 0.3000\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 2.0664e-07 - acc: 0.5000 - val_loss: 4.3576 - val_acc: 0.3000\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.9838e-07 - acc: 0.5000 - val_loss: 4.3625 - val_acc: 0.3000\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.9079e-07 - acc: 0.5000 - val_loss: 4.3583 - val_acc: 0.3000\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.8277e-07 - acc: 0.5000 - val_loss: 4.3848 - val_acc: 0.3000\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.7599e-07 - acc: 0.5000 - val_loss: 4.3945 - val_acc: 0.3000\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.6921e-07 - acc: 0.5000 - val_loss: 4.3915 - val_acc: 0.3000\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 1.6341e-07 - acc: 0.5000 - val_loss: 4.4242 - val_acc: 0.3000\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.5735e-07 - acc: 0.5000 - val_loss: 4.4196 - val_acc: 0.3000\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.5218e-07 - acc: 0.5000 - val_loss: 4.4273 - val_acc: 0.3000\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4701e-07 - acc: 0.5000 - val_loss: 4.4404 - val_acc: 0.3000\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.4230e-07 - acc: 0.5000 - val_loss: 4.4454 - val_acc: 0.3000\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.3825e-07 - acc: 0.5000 - val_loss: 4.4614 - val_acc: 0.3000\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.3356e-07 - acc: 0.5000 - val_loss: 4.4706 - val_acc: 0.3000\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.2996e-07 - acc: 0.5000 - val_loss: 4.4568 - val_acc: 0.3000\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.2587e-07 - acc: 0.5000 - val_loss: 4.4879 - val_acc: 0.3000\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.2214e-07 - acc: 0.5000 - val_loss: 4.4886 - val_acc: 0.3000\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.1826e-07 - acc: 0.5000 - val_loss: 4.4843 - val_acc: 0.3000\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.1508e-07 - acc: 0.5000 - val_loss: 4.4952 - val_acc: 0.3000\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.1223e-07 - acc: 0.5000 - val_loss: 4.5026 - val_acc: 0.3000\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.0848e-07 - acc: 0.5000 - val_loss: 4.5075 - val_acc: 0.3000\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.0596e-07 - acc: 0.5000 - val_loss: 4.5122 - val_acc: 0.3000\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 1.0301e-07 - acc: 0.5000 - val_loss: 4.5173 - val_acc: 0.3000\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 1.0046e-07 - acc: 0.5000 - val_loss: 4.5258 - val_acc: 0.3000\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 9.7650e-08 - acc: 0.5000 - val_loss: 4.5308 - val_acc: 0.3000\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 9.5285e-08 - acc: 0.5000 - val_loss: 4.5473 - val_acc: 0.3000\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 9.3118e-08 - acc: 0.5000 - val_loss: 4.5467 - val_acc: 0.3000\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 9.0640e-08 - acc: 0.5000 - val_loss: 4.5638 - val_acc: 0.3000\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 8.8127e-08 - acc: 0.5000 - val_loss: 4.5619 - val_acc: 0.3000\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 8.5939e-08 - acc: 0.5000 - val_loss: 4.5689 - val_acc: 0.3000\n"
     ]
    }
   ],
   "source": [
    "# 모델 컴파일 훈련\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=[\"acc\"])\n",
    "\n",
    "# hist = model.fit_generator(xy_train,steps_per_epoch=16,epochs=100,\n",
    "#                            validation_data= xy_test,\n",
    "#                            validation_steps=4,\n",
    "#                            )\n",
    "\n",
    "hist = model.fit(xy_train[0][0],xy_train[0][1],epochs=100,steps_per_epoch=16,\n",
    "                 validation_data=(xy_test[0][0],xy_test[0][1])\n",
    "                 \n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc :  0.5\n",
      "val_acc :  0.30000001192092896\n"
     ]
    }
   ],
   "source": [
    "accuracy = hist.history[\"acc\"]\n",
    "val_acc = hist.history[\"val_acc\"]\n",
    "\n",
    "print(\"acc : \",accuracy[-1])\n",
    "print(\"val_acc : \",val_acc[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss :  8.59393765040295e-08\n",
      "val_loss :  4.568866729736328\n"
     ]
    }
   ],
   "source": [
    "loss = hist.history[\"loss\"]\n",
    "val_loss = hist.history[\"val_loss\"]\n",
    "\n",
    "print(\"loss : \",loss[-1])\n",
    "print(\"val_loss : \",val_loss[-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf274gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "10848e9bd3f5e7d93542d388001135334854454e7336dcf54c4ef52885ee0fb0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
